2023-07-02 17:45:17,731:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-02 17:45:17,731:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-02 17:45:17,731:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-02 17:45:17,731:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-02 17:45:19,003:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-07-02 17:45:40,176:INFO:PyCaret ClassificationExperiment
2023-07-02 17:45:40,176:INFO:Logging name: clf-default-name
2023-07-02 17:45:40,176:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-07-02 17:45:40,176:INFO:version 3.0.2
2023-07-02 17:45:40,176:INFO:Initializing setup()
2023-07-02 17:45:40,176:INFO:self.USI: 376d
2023-07-02 17:45:40,176:INFO:self._variable_keys: {'is_multiclass', 'gpu_param', 'n_jobs_param', 'y', 'exp_id', 'idx', 'fold_groups_param', 'y_test', 'pipeline', '_ml_usecase', '_available_plots', 'memory', 'log_plots_param', 'fold_shuffle_param', 'logging_param', 'data', 'X', 'exp_name_log', 'X_train', 'fold_generator', 'fix_imbalance', 'gpu_n_jobs_param', 'target_param', 'seed', 'X_test', 'y_train', 'html_param', 'USI'}
2023-07-02 17:45:40,176:INFO:Checking environment
2023-07-02 17:45:40,177:INFO:python_version: 3.10.9
2023-07-02 17:45:40,177:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2023-07-02 17:45:40,177:INFO:machine: AMD64
2023-07-02 17:45:40,177:INFO:platform: Windows-10-10.0.22621-SP0
2023-07-02 17:45:40,181:INFO:Memory: svmem(total=33664483328, available=23915995136, percent=29.0, used=9748488192, free=23915995136)
2023-07-02 17:45:40,182:INFO:Physical Core: 6
2023-07-02 17:45:40,182:INFO:Logical Core: 12
2023-07-02 17:45:40,182:INFO:Checking libraries
2023-07-02 17:45:40,182:INFO:System:
2023-07-02 17:45:40,182:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2023-07-02 17:45:40,182:INFO:executable: C:\Users\JHossain\anaconda3\python.exe
2023-07-02 17:45:40,182:INFO:   machine: Windows-10-10.0.22621-SP0
2023-07-02 17:45:40,182:INFO:PyCaret required dependencies:
2023-07-02 17:45:40,182:INFO:                 pip: 22.3.1
2023-07-02 17:45:40,182:INFO:          setuptools: 65.6.3
2023-07-02 17:45:40,182:INFO:             pycaret: 3.0.2
2023-07-02 17:45:40,182:INFO:             IPython: 8.10.0
2023-07-02 17:45:40,182:INFO:          ipywidgets: 7.6.5
2023-07-02 17:45:40,182:INFO:                tqdm: 4.64.1
2023-07-02 17:45:40,182:INFO:               numpy: 1.23.5
2023-07-02 17:45:40,182:INFO:              pandas: 1.5.3
2023-07-02 17:45:40,182:INFO:              jinja2: 3.1.2
2023-07-02 17:45:40,182:INFO:               scipy: 1.10.0
2023-07-02 17:45:40,183:INFO:              joblib: 1.2.0
2023-07-02 17:45:40,183:INFO:             sklearn: 1.2.1
2023-07-02 17:45:40,183:INFO:                pyod: 1.0.9
2023-07-02 17:45:40,183:INFO:            imblearn: 0.10.1
2023-07-02 17:45:40,183:INFO:   category_encoders: 2.6.1
2023-07-02 17:45:40,183:INFO:            lightgbm: 3.3.5
2023-07-02 17:45:40,183:INFO:               numba: 0.56.4
2023-07-02 17:45:40,183:INFO:            requests: 2.28.1
2023-07-02 17:45:40,183:INFO:          matplotlib: 3.7.0
2023-07-02 17:45:40,183:INFO:          scikitplot: 0.3.7
2023-07-02 17:45:40,183:INFO:         yellowbrick: 1.5
2023-07-02 17:45:40,183:INFO:              plotly: 5.9.0
2023-07-02 17:45:40,183:INFO:             kaleido: 0.2.1
2023-07-02 17:45:40,183:INFO:         statsmodels: 0.13.5
2023-07-02 17:45:40,183:INFO:              sktime: 0.17.0
2023-07-02 17:45:40,183:INFO:               tbats: 1.1.3
2023-07-02 17:45:40,183:INFO:            pmdarima: 2.0.3
2023-07-02 17:45:40,183:INFO:              psutil: 5.9.0
2023-07-02 17:45:40,183:INFO:PyCaret optional dependencies:
2023-07-02 17:45:40,199:INFO:                shap: Not installed
2023-07-02 17:45:40,199:INFO:           interpret: Not installed
2023-07-02 17:45:40,199:INFO:                umap: Not installed
2023-07-02 17:45:40,199:INFO:    pandas_profiling: Not installed
2023-07-02 17:45:40,199:INFO:  explainerdashboard: Not installed
2023-07-02 17:45:40,199:INFO:             autoviz: Not installed
2023-07-02 17:45:40,199:INFO:           fairlearn: Not installed
2023-07-02 17:45:40,199:INFO:             xgboost: Not installed
2023-07-02 17:45:40,199:INFO:            catboost: Not installed
2023-07-02 17:45:40,199:INFO:              kmodes: Not installed
2023-07-02 17:45:40,199:INFO:             mlxtend: Not installed
2023-07-02 17:45:40,199:INFO:       statsforecast: Not installed
2023-07-02 17:45:40,199:INFO:        tune_sklearn: Not installed
2023-07-02 17:45:40,199:INFO:                 ray: Not installed
2023-07-02 17:45:40,199:INFO:            hyperopt: Not installed
2023-07-02 17:45:40,199:INFO:              optuna: Not installed
2023-07-02 17:45:40,199:INFO:               skopt: Not installed
2023-07-02 17:45:40,199:INFO:              mlflow: Not installed
2023-07-02 17:45:40,199:INFO:              gradio: Not installed
2023-07-02 17:45:40,199:INFO:             fastapi: Not installed
2023-07-02 17:45:40,199:INFO:             uvicorn: Not installed
2023-07-02 17:45:40,199:INFO:              m2cgen: Not installed
2023-07-02 17:45:40,199:INFO:           evidently: Not installed
2023-07-02 17:45:40,199:INFO:               fugue: Not installed
2023-07-02 17:45:40,199:INFO:           streamlit: Not installed
2023-07-02 17:45:40,200:INFO:             prophet: Not installed
2023-07-02 17:45:40,200:INFO:None
2023-07-02 17:45:40,200:INFO:Set up data.
2023-07-02 17:45:40,210:INFO:Set up train/test split.
2023-07-02 17:45:40,219:INFO:Set up index.
2023-07-02 17:45:40,219:INFO:Set up folding strategy.
2023-07-02 17:45:40,219:INFO:Assigning column types.
2023-07-02 17:45:40,222:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-07-02 17:45:40,260:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-02 17:45:40,263:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-02 17:45:40,294:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-02 17:45:40,529:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-02 17:45:40,565:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-02 17:45:40,566:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-02 17:45:40,588:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-02 17:45:40,588:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-02 17:45:40,588:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-07-02 17:45:40,624:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-02 17:45:40,647:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-02 17:45:40,647:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-02 17:45:40,683:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-02 17:45:40,705:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-02 17:45:40,705:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-02 17:45:40,706:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-07-02 17:45:40,764:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-02 17:45:40,764:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-02 17:45:40,823:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-02 17:45:40,823:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-02 17:45:40,836:INFO:Preparing preprocessing pipeline...
2023-07-02 17:45:40,838:INFO:Set up label encoding.
2023-07-02 17:45:40,838:INFO:Set up simple imputation.
2023-07-02 17:45:40,842:INFO:Set up encoding of ordinal features.
2023-07-02 17:45:40,850:INFO:Set up encoding of categorical features.
2023-07-02 17:45:41,025:INFO:Finished creating preprocessing pipeline.
2023-07-02 17:45:41,089:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\JHossain\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['id', 'age', 'bp', 'sg', 'al',
                                             'su', 'bgr', 'bu', 'sc', 'sod',
                                             'pot', 'hemo'],
                                    transformer=SimpleImputer(add_...
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['pcv', 'wc', 'rc'],
                                    transformer=TargetEncoder(cols=['pcv', 'wc',
                                                                    'rc'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2023-07-02 17:45:41,090:INFO:Creating final display dataframe.
2023-07-02 17:45:41,527:INFO:Setup _display_container:                     Description                        Value
0                    Session id                          123
1                        Target               classification
2                   Target type                   Multiclass
3                Target mapping  ckd: 0, ckd\t: 1, notckd: 2
4           Original data shape                    (400, 26)
5        Transformed data shape                    (400, 32)
6   Transformed train set shape                    (280, 32)
7    Transformed test set shape                    (120, 32)
8              Ordinal features                            8
9              Numeric features                           12
10         Categorical features                           13
11     Rows with missing values                        60.5%
12                   Preprocess                         True
13              Imputation type                       simple
14           Numeric imputation                         mean
15       Categorical imputation                         mode
16     Maximum one-hot encoding                           25
17              Encoding method                         None
18               Fold Generator              StratifiedKFold
19                  Fold Number                           10
20                     CPU Jobs                           -1
21                      Use GPU                        False
22               Log Experiment                        False
23              Experiment Name             clf-default-name
24                          USI                         376d
2023-07-02 17:45:41,606:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-02 17:45:41,607:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-02 17:45:41,667:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-02 17:45:41,668:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-02 17:45:41,668:INFO:setup() successfully completed in 1.56s...............
2023-07-02 17:46:13,828:INFO:Initializing compare_models()
2023-07-02 17:46:13,828:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000208E69CDB70>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000208E69CDB70>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-07-02 17:46:13,829:INFO:Checking exceptions
2023-07-02 17:46:13,832:INFO:Preparing display monitor
2023-07-02 17:46:13,852:INFO:Initializing Logistic Regression
2023-07-02 17:46:13,852:INFO:Total runtime is 0.0 minutes
2023-07-02 17:46:13,855:INFO:SubProcess create_model() called ==================================
2023-07-02 17:46:13,855:INFO:Initializing create_model()
2023-07-02 17:46:13,855:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000208E69CDB70>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000208E762F9A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-02 17:46:13,856:INFO:Checking exceptions
2023-07-02 17:46:13,856:INFO:Importing libraries
2023-07-02 17:46:13,856:INFO:Copying training dataset
2023-07-02 17:46:13,859:INFO:Defining folds
2023-07-02 17:46:13,859:INFO:Declaring metric variables
2023-07-02 17:46:13,862:INFO:Importing untrained model
2023-07-02 17:46:13,866:INFO:Logistic Regression Imported successfully
2023-07-02 17:46:13,871:INFO:Starting cross validation
2023-07-02 17:46:13,873:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-02 17:46:13,886:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2023-07-02 17:46:13,886:WARNING:  warnings.warn(
2023-07-02 17:46:19,629:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-07-02 17:46:19,646:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-07-02 17:46:19,652:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-07-02 17:46:19,655:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-07-02 17:46:19,661:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-07-02 17:46:19,668:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-07-02 17:46:19,670:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-07-02 17:46:19,684:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-07-02 17:46:19,872:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:19,876:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:19,877:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:19,878:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:19,879:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:20,096:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:20,099:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:20,100:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:20,101:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:20,102:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:20,102:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:20,103:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:20,104:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:20,104:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:20,105:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:20,106:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:20,106:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:20,107:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:20,107:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:20,107:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:20,107:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:20,108:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:20,108:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:20,108:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:20,109:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:20,109:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:20,109:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:20,109:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:20,109:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:20,109:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:20,110:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:20,110:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:20,110:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:20,110:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:20,110:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:20,111:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:20,111:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:20,111:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:20,111:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:20,112:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:20,112:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:20,113:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:20,113:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:20,113:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:20,113:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:20,115:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:20,116:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:20,117:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:20,118:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:20,120:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:20,143:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:20,145:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:20,147:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:20,148:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:20,150:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:20,172:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:20,174:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:20,175:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:20,176:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:20,177:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:20,177:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:20,178:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:20,349:INFO:Calculating mean and std
2023-07-02 17:46:20,350:INFO:Creating metrics dataframe
2023-07-02 17:46:20,395:INFO:Uploading results into container
2023-07-02 17:46:20,396:INFO:Uploading model into container now
2023-07-02 17:46:20,396:INFO:_master_model_container: 1
2023-07-02 17:46:20,396:INFO:_display_container: 2
2023-07-02 17:46:20,397:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-02 17:46:20,397:INFO:create_model() successfully completed......................................
2023-07-02 17:46:20,692:INFO:SubProcess create_model() end ==================================
2023-07-02 17:46:20,693:INFO:Creating metrics dataframe
2023-07-02 17:46:20,700:INFO:Initializing K Neighbors Classifier
2023-07-02 17:46:20,700:INFO:Total runtime is 0.11413037776947021 minutes
2023-07-02 17:46:20,703:INFO:SubProcess create_model() called ==================================
2023-07-02 17:46:20,704:INFO:Initializing create_model()
2023-07-02 17:46:20,704:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000208E69CDB70>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000208E762F9A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-02 17:46:20,704:INFO:Checking exceptions
2023-07-02 17:46:20,704:INFO:Importing libraries
2023-07-02 17:46:20,704:INFO:Copying training dataset
2023-07-02 17:46:20,708:INFO:Defining folds
2023-07-02 17:46:20,708:INFO:Declaring metric variables
2023-07-02 17:46:20,711:INFO:Importing untrained model
2023-07-02 17:46:20,713:INFO:K Neighbors Classifier Imported successfully
2023-07-02 17:46:20,718:INFO:Starting cross validation
2023-07-02 17:46:20,719:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-02 17:46:20,721:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2023-07-02 17:46:20,721:WARNING:  warnings.warn(
2023-07-02 17:46:21,684:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:21,685:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:21,686:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:21,686:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:21,687:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:21,688:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:21,689:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:21,692:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:21,693:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:21,694:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:21,695:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:21,695:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:21,696:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:21,696:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:21,696:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:21,697:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:21,697:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:21,697:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:21,698:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:21,698:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

ric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:21,699:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:21,699:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:21,700:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:21,700:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:21,700:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:21,700:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:21,701:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:21,701:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:21,701:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

, msg_start, len(result))

2023-07-02 17:46:21,701:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:21,701:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:21,702:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:21,702:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:21,702:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:21,702:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:21,702:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:21,702:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:21,703:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:21,703:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:21,703:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:21,704:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:21,704:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:21,704:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:21,704:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:21,705:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:21,705:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:21,706:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:21,706:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:21,706:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:21,707:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:21,707:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:23,582:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:23,584:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:23,584:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:23,585:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:23,586:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:23,586:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:23,586:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:23,586:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:23,587:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:23,587:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:23,588:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:23,588:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:23,588:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:23,589:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:23,618:INFO:Calculating mean and std
2023-07-02 17:46:23,619:INFO:Creating metrics dataframe
2023-07-02 17:46:23,666:INFO:Uploading results into container
2023-07-02 17:46:23,667:INFO:Uploading model into container now
2023-07-02 17:46:23,667:INFO:_master_model_container: 2
2023-07-02 17:46:23,668:INFO:_display_container: 2
2023-07-02 17:46:23,668:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-07-02 17:46:23,668:INFO:create_model() successfully completed......................................
2023-07-02 17:46:23,971:INFO:SubProcess create_model() end ==================================
2023-07-02 17:46:23,971:INFO:Creating metrics dataframe
2023-07-02 17:46:23,979:INFO:Initializing Naive Bayes
2023-07-02 17:46:23,979:INFO:Total runtime is 0.1687842885653178 minutes
2023-07-02 17:46:23,981:INFO:SubProcess create_model() called ==================================
2023-07-02 17:46:23,982:INFO:Initializing create_model()
2023-07-02 17:46:23,982:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000208E69CDB70>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000208E762F9A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-02 17:46:23,982:INFO:Checking exceptions
2023-07-02 17:46:23,982:INFO:Importing libraries
2023-07-02 17:46:23,982:INFO:Copying training dataset
2023-07-02 17:46:23,986:INFO:Defining folds
2023-07-02 17:46:23,986:INFO:Declaring metric variables
2023-07-02 17:46:23,989:INFO:Importing untrained model
2023-07-02 17:46:23,992:INFO:Naive Bayes Imported successfully
2023-07-02 17:46:23,997:INFO:Starting cross validation
2023-07-02 17:46:23,999:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-02 17:46:24,001:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2023-07-02 17:46:24,001:WARNING:  warnings.warn(
2023-07-02 17:46:24,642:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:24,643:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:24,644:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:24,645:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:24,646:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:24,647:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:24,648:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:24,698:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:24,699:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:24,700:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:24,701:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:24,702:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:24,703:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:24,704:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:24,708:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:24,709:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:24,710:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:24,711:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:24,712:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:24,713:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:24,713:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:24,714:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:24,714:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:24,715:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:24,716:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:24,716:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:24,729:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:24,730:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:24,731:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:24,732:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:24,733:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:24,734:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:24,736:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:24,748:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:24,749:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:24,750:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:24,751:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:24,752:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:24,753:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:24,754:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:24,754:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:24,755:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:24,756:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:24,757:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:24,758:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:24,759:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:24,760:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:24,761:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:24,762:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:24,763:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:24,763:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:24,764:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:24,765:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:24,765:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:24,769:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:24,769:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:24,770:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:24,771:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:24,771:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:24,772:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:24,773:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:24,789:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:24,789:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:24,789:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:24,790:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:24,790:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:24,792:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:24,792:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:24,942:INFO:Calculating mean and std
2023-07-02 17:46:24,944:INFO:Creating metrics dataframe
2023-07-02 17:46:24,993:INFO:Uploading results into container
2023-07-02 17:46:24,993:INFO:Uploading model into container now
2023-07-02 17:46:24,994:INFO:_master_model_container: 3
2023-07-02 17:46:24,994:INFO:_display_container: 2
2023-07-02 17:46:24,994:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-07-02 17:46:24,994:INFO:create_model() successfully completed......................................
2023-07-02 17:46:25,287:INFO:SubProcess create_model() end ==================================
2023-07-02 17:46:25,287:INFO:Creating metrics dataframe
2023-07-02 17:46:25,295:INFO:Initializing Decision Tree Classifier
2023-07-02 17:46:25,295:INFO:Total runtime is 0.19072089989980062 minutes
2023-07-02 17:46:25,298:INFO:SubProcess create_model() called ==================================
2023-07-02 17:46:25,298:INFO:Initializing create_model()
2023-07-02 17:46:25,298:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000208E69CDB70>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000208E762F9A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-02 17:46:25,298:INFO:Checking exceptions
2023-07-02 17:46:25,298:INFO:Importing libraries
2023-07-02 17:46:25,300:INFO:Copying training dataset
2023-07-02 17:46:25,303:INFO:Defining folds
2023-07-02 17:46:25,303:INFO:Declaring metric variables
2023-07-02 17:46:25,306:INFO:Importing untrained model
2023-07-02 17:46:25,309:INFO:Decision Tree Classifier Imported successfully
2023-07-02 17:46:25,317:INFO:Starting cross validation
2023-07-02 17:46:25,321:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-02 17:46:25,325:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2023-07-02 17:46:25,325:WARNING:  warnings.warn(
2023-07-02 17:46:26,046:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:26,047:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:26,047:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:26,048:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:26,048:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:26,049:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:26,049:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:26,050:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:26,050:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:26,051:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:26,052:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:26,074:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:26,074:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:26,075:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:26,075:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:26,076:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:26,076:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:26,077:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:26,077:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:26,078:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:26,079:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:26,079:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:26,080:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:26,095:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:26,096:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:26,096:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:26,097:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:26,098:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:26,098:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:26,099:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:26,099:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:26,100:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:26,101:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:26,102:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:26,103:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:26,104:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:26,105:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:26,109:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:26,110:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:26,110:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:26,111:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:26,111:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:26,112:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:26,113:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:26,113:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:26,114:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:26,114:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:26,115:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:26,115:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:26,130:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:26,130:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:26,131:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:26,132:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:26,133:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:26,166:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:26,166:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:26,167:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:26,168:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:26,169:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:26,169:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:26,170:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:26,332:INFO:Calculating mean and std
2023-07-02 17:46:26,333:INFO:Creating metrics dataframe
2023-07-02 17:46:26,382:INFO:Uploading results into container
2023-07-02 17:46:26,383:INFO:Uploading model into container now
2023-07-02 17:46:26,383:INFO:_master_model_container: 4
2023-07-02 17:46:26,384:INFO:_display_container: 2
2023-07-02 17:46:26,384:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-07-02 17:46:26,384:INFO:create_model() successfully completed......................................
2023-07-02 17:46:26,686:INFO:SubProcess create_model() end ==================================
2023-07-02 17:46:26,686:INFO:Creating metrics dataframe
2023-07-02 17:46:26,694:INFO:Initializing SVM - Linear Kernel
2023-07-02 17:46:26,694:INFO:Total runtime is 0.21402887105941773 minutes
2023-07-02 17:46:26,697:INFO:SubProcess create_model() called ==================================
2023-07-02 17:46:26,697:INFO:Initializing create_model()
2023-07-02 17:46:26,697:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000208E69CDB70>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000208E762F9A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-02 17:46:26,697:INFO:Checking exceptions
2023-07-02 17:46:26,697:INFO:Importing libraries
2023-07-02 17:46:26,697:INFO:Copying training dataset
2023-07-02 17:46:26,701:INFO:Defining folds
2023-07-02 17:46:26,702:INFO:Declaring metric variables
2023-07-02 17:46:26,705:INFO:Importing untrained model
2023-07-02 17:46:26,707:INFO:SVM - Linear Kernel Imported successfully
2023-07-02 17:46:26,712:INFO:Starting cross validation
2023-07-02 17:46:26,714:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-02 17:46:26,716:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2023-07-02 17:46:26,716:WARNING:  warnings.warn(
2023-07-02 17:46:27,384:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-02 17:46:27,384:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-02 17:46:27,385:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:27,386:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:27,386:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:27,387:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:27,388:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:27,388:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:27,388:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-02 17:46:27,389:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:27,389:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:27,389:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:27,390:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:27,390:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-02 17:46:27,390:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:27,390:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:27,391:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:27,391:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:27,391:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:27,391:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:27,391:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:27,392:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:27,392:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:27,393:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:27,393:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:27,394:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-02 17:46:27,394:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:27,395:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:27,395:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:27,395:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:27,396:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:27,397:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:27,399:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:27,400:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:27,401:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:27,406:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-02 17:46:27,407:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:27,409:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:27,410:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:27,411:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:27,412:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:27,413:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:27,443:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-02 17:46:27,444:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:27,446:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:27,447:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:27,448:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:27,448:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:27,449:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:27,451:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-02 17:46:27,452:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:27,453:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:27,454:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:27,455:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-02 17:46:27,455:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-02 17:46:27,455:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:27,456:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:27,456:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:27,456:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:27,456:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:27,457:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:27,457:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:27,457:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:27,458:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:27,458:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:27,458:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:27,458:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:27,459:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:27,687:INFO:Calculating mean and std
2023-07-02 17:46:27,688:INFO:Creating metrics dataframe
2023-07-02 17:46:27,742:INFO:Uploading results into container
2023-07-02 17:46:27,742:INFO:Uploading model into container now
2023-07-02 17:46:27,743:INFO:_master_model_container: 5
2023-07-02 17:46:27,743:INFO:_display_container: 2
2023-07-02 17:46:27,743:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-07-02 17:46:27,743:INFO:create_model() successfully completed......................................
2023-07-02 17:46:28,037:INFO:SubProcess create_model() end ==================================
2023-07-02 17:46:28,038:INFO:Creating metrics dataframe
2023-07-02 17:46:28,046:INFO:Initializing Ridge Classifier
2023-07-02 17:46:28,046:INFO:Total runtime is 0.2365609049797058 minutes
2023-07-02 17:46:28,049:INFO:SubProcess create_model() called ==================================
2023-07-02 17:46:28,049:INFO:Initializing create_model()
2023-07-02 17:46:28,049:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000208E69CDB70>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000208E762F9A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-02 17:46:28,049:INFO:Checking exceptions
2023-07-02 17:46:28,050:INFO:Importing libraries
2023-07-02 17:46:28,050:INFO:Copying training dataset
2023-07-02 17:46:28,053:INFO:Defining folds
2023-07-02 17:46:28,054:INFO:Declaring metric variables
2023-07-02 17:46:28,057:INFO:Importing untrained model
2023-07-02 17:46:28,059:INFO:Ridge Classifier Imported successfully
2023-07-02 17:46:28,064:INFO:Starting cross validation
2023-07-02 17:46:28,066:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-02 17:46:28,068:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2023-07-02 17:46:28,068:WARNING:  warnings.warn(
2023-07-02 17:46:28,716:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-02 17:46:28,717:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:28,718:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:28,719:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:28,720:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:28,721:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:28,721:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-02 17:46:28,722:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:28,723:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:28,723:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:28,724:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:28,725:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:28,726:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:28,731:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-02 17:46:28,732:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:28,733:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:28,734:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:28,735:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:28,736:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:28,737:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:28,738:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-02 17:46:28,739:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:28,740:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:28,742:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:28,743:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:28,744:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:28,745:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:28,755:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-02 17:46:28,756:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:28,757:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:28,757:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-02 17:46:28,758:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:28,758:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:28,759:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:28,760:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:28,760:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:28,761:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:28,761:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:28,762:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:28,762:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:28,763:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:28,769:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-02 17:46:28,770:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:28,771:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:28,772:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:28,772:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-02 17:46:28,773:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:28,773:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:28,774:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:28,774:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:28,775:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:28,775:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:28,777:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:28,777:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:28,779:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:28,780:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-02 17:46:28,781:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:28,783:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:28,784:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:28,786:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:28,787:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:28,788:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:28,822:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-02 17:46:28,822:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:28,824:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:28,824:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:28,825:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:29,037:INFO:Calculating mean and std
2023-07-02 17:46:29,038:INFO:Creating metrics dataframe
2023-07-02 17:46:29,094:INFO:Uploading results into container
2023-07-02 17:46:29,095:INFO:Uploading model into container now
2023-07-02 17:46:29,095:INFO:_master_model_container: 6
2023-07-02 17:46:29,095:INFO:_display_container: 2
2023-07-02 17:46:29,096:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-07-02 17:46:29,096:INFO:create_model() successfully completed......................................
2023-07-02 17:46:29,392:INFO:SubProcess create_model() end ==================================
2023-07-02 17:46:29,392:INFO:Creating metrics dataframe
2023-07-02 17:46:29,401:INFO:Initializing Random Forest Classifier
2023-07-02 17:46:29,401:INFO:Total runtime is 0.2591450850168864 minutes
2023-07-02 17:46:29,403:INFO:SubProcess create_model() called ==================================
2023-07-02 17:46:29,404:INFO:Initializing create_model()
2023-07-02 17:46:29,404:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000208E69CDB70>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000208E762F9A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-02 17:46:29,404:INFO:Checking exceptions
2023-07-02 17:46:29,404:INFO:Importing libraries
2023-07-02 17:46:29,404:INFO:Copying training dataset
2023-07-02 17:46:29,408:INFO:Defining folds
2023-07-02 17:46:29,408:INFO:Declaring metric variables
2023-07-02 17:46:29,411:INFO:Importing untrained model
2023-07-02 17:46:29,414:INFO:Random Forest Classifier Imported successfully
2023-07-02 17:46:29,420:INFO:Starting cross validation
2023-07-02 17:46:29,422:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-02 17:46:29,424:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2023-07-02 17:46:29,424:WARNING:  warnings.warn(
2023-07-02 17:46:30,752:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:30,753:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:30,754:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:30,755:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:30,756:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:30,756:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:30,757:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:30,757:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:30,758:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:30,758:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:30,759:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:30,760:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:30,761:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:30,761:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:30,762:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:30,763:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:30,763:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:30,763:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:30,763:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:30,764:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:30,764:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:30,765:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:30,765:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:30,766:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:30,766:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:30,766:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:30,767:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:30,767:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:30,767:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:30,768:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:30,768:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:30,768:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:30,769:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:30,823:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:30,824:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:30,825:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:30,827:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:30,828:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:30,829:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:30,830:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:30,835:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:30,836:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:30,836:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:30,837:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:30,838:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:30,838:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:30,839:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:30,857:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:30,858:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:30,858:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:30,859:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:30,859:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:30,860:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:30,860:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:30,861:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:30,861:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:30,861:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:30,862:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:30,862:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:30,870:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:30,871:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:30,872:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:30,873:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:30,874:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:30,875:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:30,877:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:31,147:INFO:Calculating mean and std
2023-07-02 17:46:31,149:INFO:Creating metrics dataframe
2023-07-02 17:46:31,209:INFO:Uploading results into container
2023-07-02 17:46:31,209:INFO:Uploading model into container now
2023-07-02 17:46:31,210:INFO:_master_model_container: 7
2023-07-02 17:46:31,210:INFO:_display_container: 2
2023-07-02 17:46:31,210:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-07-02 17:46:31,210:INFO:create_model() successfully completed......................................
2023-07-02 17:46:31,495:INFO:SubProcess create_model() end ==================================
2023-07-02 17:46:31,495:INFO:Creating metrics dataframe
2023-07-02 17:46:31,504:INFO:Initializing Quadratic Discriminant Analysis
2023-07-02 17:46:31,504:INFO:Total runtime is 0.29419282674789426 minutes
2023-07-02 17:46:31,507:INFO:SubProcess create_model() called ==================================
2023-07-02 17:46:31,507:INFO:Initializing create_model()
2023-07-02 17:46:31,507:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000208E69CDB70>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000208E762F9A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-02 17:46:31,508:INFO:Checking exceptions
2023-07-02 17:46:31,508:INFO:Importing libraries
2023-07-02 17:46:31,508:INFO:Copying training dataset
2023-07-02 17:46:31,512:INFO:Defining folds
2023-07-02 17:46:31,512:INFO:Declaring metric variables
2023-07-02 17:46:31,515:INFO:Importing untrained model
2023-07-02 17:46:31,518:INFO:Quadratic Discriminant Analysis Imported successfully
2023-07-02 17:46:31,523:INFO:Starting cross validation
2023-07-02 17:46:31,525:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-02 17:46:31,526:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2023-07-02 17:46:31,526:WARNING:  warnings.warn(
2023-07-02 17:46:31,814:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-02 17:46:31,826:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-02 17:46:31,842:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-02 17:46:31,855:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-02 17:46:31,875:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-02 17:46:31,879:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-02 17:46:31,891:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-02 17:46:31,893:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-02 17:46:31,900:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-02 17:46:31,904:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-02 17:46:32,093:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:32,093:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:32,094:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:32,095:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:32,096:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:32,191:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:378: FitFailedWarning: 
2023-07-02 17:46:32,191:WARNING:9 fits failed out of a total of 10.
2023-07-02 17:46:32,191:WARNING:The score on these train-test partitions for these parameters will be set to 0.
2023-07-02 17:46:32,191:WARNING:If these failures are not expected, you can try to debug them by setting error_score='raise'.
2023-07-02 17:46:32,191:WARNING:
2023-07-02 17:46:32,191:WARNING:Below are more details about the failures:
2023-07-02 17:46:32,191:WARNING:--------------------------------------------------------------------------------
2023-07-02 17:46:32,191:WARNING:9 fits failed with the following error:
2023-07-02 17:46:32,191:WARNING:Traceback (most recent call last):
2023-07-02 17:46:32,191:WARNING:  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
2023-07-02 17:46:32,191:WARNING:    estimator.fit(X_train, y_train, **fit_params)
2023-07-02 17:46:32,191:WARNING:  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
2023-07-02 17:46:32,191:WARNING:    fitted_estimator = self._memory_fit(
2023-07-02 17:46:32,192:WARNING:  File "C:\Users\JHossain\anaconda3\lib\site-packages\joblib\memory.py", line 594, in __call__
2023-07-02 17:46:32,192:WARNING:    return self._cached_call(args, kwargs)[0]
2023-07-02 17:46:32,192:WARNING:  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
2023-07-02 17:46:32,192:WARNING:    out, metadata = self.call(*args, **kwargs)
2023-07-02 17:46:32,192:WARNING:  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 309, in call
2023-07-02 17:46:32,192:WARNING:    output = self.func(*args, **kwargs)
2023-07-02 17:46:32,192:WARNING:  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
2023-07-02 17:46:32,192:WARNING:    transformer.fit(*args, **fit_params)
2023-07-02 17:46:32,192:WARNING:  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py", line 917, in fit
2023-07-02 17:46:32,192:WARNING:    raise ValueError(
2023-07-02 17:46:32,192:WARNING:ValueError: y has only 1 sample in class 1, covariance is ill defined.
2023-07-02 17:46:32,192:WARNING:
2023-07-02 17:46:32,192:WARNING:  warnings.warn(some_fits_failed_message, FitFailedWarning)
2023-07-02 17:46:32,193:INFO:Calculating mean and std
2023-07-02 17:46:32,194:INFO:Creating metrics dataframe
2023-07-02 17:46:32,255:INFO:Uploading results into container
2023-07-02 17:46:32,255:INFO:Uploading model into container now
2023-07-02 17:46:32,256:INFO:_master_model_container: 8
2023-07-02 17:46:32,256:INFO:_display_container: 2
2023-07-02 17:46:32,256:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-07-02 17:46:32,256:INFO:create_model() successfully completed......................................
2023-07-02 17:46:32,550:WARNING:create_model() for QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001) raised an exception or returned all 0.0, trying without fit_kwargs:
2023-07-02 17:46:32,552:WARNING:Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

2023-07-02 17:46:32,552:INFO:Initializing create_model()
2023-07-02 17:46:32,552:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000208E69CDB70>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000208E762F9A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-02 17:46:32,552:INFO:Checking exceptions
2023-07-02 17:46:32,552:INFO:Importing libraries
2023-07-02 17:46:32,552:INFO:Copying training dataset
2023-07-02 17:46:32,557:INFO:Defining folds
2023-07-02 17:46:32,557:INFO:Declaring metric variables
2023-07-02 17:46:32,560:INFO:Importing untrained model
2023-07-02 17:46:32,563:INFO:Quadratic Discriminant Analysis Imported successfully
2023-07-02 17:46:32,567:INFO:Starting cross validation
2023-07-02 17:46:32,569:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-02 17:46:32,571:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2023-07-02 17:46:32,571:WARNING:  warnings.warn(
2023-07-02 17:46:32,844:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-02 17:46:32,869:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-02 17:46:32,876:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-02 17:46:32,902:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-02 17:46:32,926:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-02 17:46:32,927:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-02 17:46:32,933:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-02 17:46:32,933:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-02 17:46:32,942:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-02 17:46:32,963:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-02 17:46:33,131:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:33,132:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:33,133:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:33,133:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:33,134:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:33,218:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:378: FitFailedWarning: 
2023-07-02 17:46:33,218:WARNING:9 fits failed out of a total of 10.
2023-07-02 17:46:33,218:WARNING:The score on these train-test partitions for these parameters will be set to 0.
2023-07-02 17:46:33,218:WARNING:If these failures are not expected, you can try to debug them by setting error_score='raise'.
2023-07-02 17:46:33,218:WARNING:
2023-07-02 17:46:33,218:WARNING:Below are more details about the failures:
2023-07-02 17:46:33,218:WARNING:--------------------------------------------------------------------------------
2023-07-02 17:46:33,218:WARNING:9 fits failed with the following error:
2023-07-02 17:46:33,218:WARNING:Traceback (most recent call last):
2023-07-02 17:46:33,219:WARNING:  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
2023-07-02 17:46:33,219:WARNING:    estimator.fit(X_train, y_train, **fit_params)
2023-07-02 17:46:33,219:WARNING:  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
2023-07-02 17:46:33,219:WARNING:    fitted_estimator = self._memory_fit(
2023-07-02 17:46:33,219:WARNING:  File "C:\Users\JHossain\anaconda3\lib\site-packages\joblib\memory.py", line 594, in __call__
2023-07-02 17:46:33,219:WARNING:    return self._cached_call(args, kwargs)[0]
2023-07-02 17:46:33,219:WARNING:  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
2023-07-02 17:46:33,219:WARNING:    out, metadata = self.call(*args, **kwargs)
2023-07-02 17:46:33,219:WARNING:  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 309, in call
2023-07-02 17:46:33,219:WARNING:    output = self.func(*args, **kwargs)
2023-07-02 17:46:33,219:WARNING:  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
2023-07-02 17:46:33,219:WARNING:    transformer.fit(*args, **fit_params)
2023-07-02 17:46:33,219:WARNING:  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py", line 917, in fit
2023-07-02 17:46:33,219:WARNING:    raise ValueError(
2023-07-02 17:46:33,220:WARNING:ValueError: y has only 1 sample in class 1, covariance is ill defined.
2023-07-02 17:46:33,220:WARNING:
2023-07-02 17:46:33,220:WARNING:  warnings.warn(some_fits_failed_message, FitFailedWarning)
2023-07-02 17:46:33,220:INFO:Calculating mean and std
2023-07-02 17:46:33,221:INFO:Creating metrics dataframe
2023-07-02 17:46:33,282:INFO:Uploading results into container
2023-07-02 17:46:33,283:INFO:Uploading model into container now
2023-07-02 17:46:33,283:INFO:_master_model_container: 9
2023-07-02 17:46:33,283:INFO:_display_container: 2
2023-07-02 17:46:33,284:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-07-02 17:46:33,284:INFO:create_model() successfully completed......................................
2023-07-02 17:46:33,579:ERROR:create_model() for QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001) raised an exception or returned all 0.0:
2023-07-02 17:46:33,579:ERROR:Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 811, in compare_models
    np.sum(
AssertionError

2023-07-02 17:46:33,579:INFO:Initializing Ada Boost Classifier
2023-07-02 17:46:33,579:INFO:Total runtime is 0.3287783900896708 minutes
2023-07-02 17:46:33,582:INFO:SubProcess create_model() called ==================================
2023-07-02 17:46:33,582:INFO:Initializing create_model()
2023-07-02 17:46:33,583:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000208E69CDB70>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000208E762F9A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-02 17:46:33,583:INFO:Checking exceptions
2023-07-02 17:46:33,583:INFO:Importing libraries
2023-07-02 17:46:33,583:INFO:Copying training dataset
2023-07-02 17:46:33,587:INFO:Defining folds
2023-07-02 17:46:33,587:INFO:Declaring metric variables
2023-07-02 17:46:33,590:INFO:Importing untrained model
2023-07-02 17:46:33,592:INFO:Ada Boost Classifier Imported successfully
2023-07-02 17:46:33,597:INFO:Starting cross validation
2023-07-02 17:46:33,599:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-02 17:46:33,600:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2023-07-02 17:46:33,600:WARNING:  warnings.warn(
2023-07-02 17:46:34,410:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:34,410:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:34,412:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:34,413:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:34,414:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:34,493:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:34,493:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:34,493:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:34,494:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:34,494:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:34,495:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:34,495:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:34,496:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:34,496:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:34,496:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:34,497:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:34,497:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:34,498:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:34,498:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:34,504:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:34,505:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:34,507:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:34,508:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:34,509:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:34,510:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:34,511:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:34,520:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:34,521:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:34,523:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:34,524:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:34,525:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:34,526:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:34,527:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:34,539:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:34,540:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:34,541:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:34,542:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:34,543:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:34,544:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:34,545:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:34,547:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:34,549:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:34,550:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:34,551:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:34,552:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:34,553:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:34,555:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:34,556:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:34,557:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:34,558:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:34,560:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:34,561:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:34,562:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:34,563:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:34,635:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:34,636:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:34,637:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:34,637:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:34,638:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:34,641:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:34,642:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:34,643:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:34,643:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:34,644:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:34,644:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:34,645:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:34,832:INFO:Calculating mean and std
2023-07-02 17:46:34,833:INFO:Creating metrics dataframe
2023-07-02 17:46:34,899:INFO:Uploading results into container
2023-07-02 17:46:34,899:INFO:Uploading model into container now
2023-07-02 17:46:34,900:INFO:_master_model_container: 10
2023-07-02 17:46:34,900:INFO:_display_container: 2
2023-07-02 17:46:34,900:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-07-02 17:46:34,900:INFO:create_model() successfully completed......................................
2023-07-02 17:46:35,196:INFO:SubProcess create_model() end ==================================
2023-07-02 17:46:35,196:INFO:Creating metrics dataframe
2023-07-02 17:46:35,205:INFO:Initializing Gradient Boosting Classifier
2023-07-02 17:46:35,205:INFO:Total runtime is 0.3558873136838277 minutes
2023-07-02 17:46:35,209:INFO:SubProcess create_model() called ==================================
2023-07-02 17:46:35,209:INFO:Initializing create_model()
2023-07-02 17:46:35,209:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000208E69CDB70>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000208E762F9A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-02 17:46:35,209:INFO:Checking exceptions
2023-07-02 17:46:35,209:INFO:Importing libraries
2023-07-02 17:46:35,209:INFO:Copying training dataset
2023-07-02 17:46:35,213:INFO:Defining folds
2023-07-02 17:46:35,213:INFO:Declaring metric variables
2023-07-02 17:46:35,216:INFO:Importing untrained model
2023-07-02 17:46:35,219:INFO:Gradient Boosting Classifier Imported successfully
2023-07-02 17:46:35,224:INFO:Starting cross validation
2023-07-02 17:46:35,225:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-02 17:46:35,227:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2023-07-02 17:46:35,227:WARNING:  warnings.warn(
2023-07-02 17:46:36,214:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:36,215:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:36,216:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:36,217:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:36,217:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:36,798:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:36,799:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:36,800:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:36,801:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:36,802:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:36,803:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:36,804:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:36,845:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:36,846:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:36,848:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:36,848:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:36,850:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:36,850:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:36,852:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:36,853:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:36,854:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:36,855:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:36,856:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:36,857:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:36,858:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:36,859:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:36,876:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:36,877:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:36,878:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:36,879:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:36,881:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:36,911:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:36,912:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:36,913:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:36,914:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:36,915:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:36,917:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:36,918:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:36,933:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:36,934:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:36,935:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:36,935:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:36,936:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:36,937:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:36,937:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:36,961:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:36,962:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:36,962:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:36,963:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:36,964:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:36,964:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:36,965:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:36,987:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:36,988:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:36,989:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:36,989:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:36,990:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:37,039:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:37,039:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:37,040:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:37,041:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:37,041:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:37,042:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:37,042:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:37,196:INFO:Calculating mean and std
2023-07-02 17:46:37,197:INFO:Creating metrics dataframe
2023-07-02 17:46:37,269:INFO:Uploading results into container
2023-07-02 17:46:37,270:INFO:Uploading model into container now
2023-07-02 17:46:37,270:INFO:_master_model_container: 11
2023-07-02 17:46:37,270:INFO:_display_container: 2
2023-07-02 17:46:37,271:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-02 17:46:37,271:INFO:create_model() successfully completed......................................
2023-07-02 17:46:37,575:INFO:SubProcess create_model() end ==================================
2023-07-02 17:46:37,576:INFO:Creating metrics dataframe
2023-07-02 17:46:37,585:INFO:Initializing Linear Discriminant Analysis
2023-07-02 17:46:37,585:INFO:Total runtime is 0.395541250705719 minutes
2023-07-02 17:46:37,588:INFO:SubProcess create_model() called ==================================
2023-07-02 17:46:37,588:INFO:Initializing create_model()
2023-07-02 17:46:37,588:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000208E69CDB70>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000208E762F9A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-02 17:46:37,588:INFO:Checking exceptions
2023-07-02 17:46:37,588:INFO:Importing libraries
2023-07-02 17:46:37,589:INFO:Copying training dataset
2023-07-02 17:46:37,593:INFO:Defining folds
2023-07-02 17:46:37,593:INFO:Declaring metric variables
2023-07-02 17:46:37,595:INFO:Importing untrained model
2023-07-02 17:46:37,598:INFO:Linear Discriminant Analysis Imported successfully
2023-07-02 17:46:37,603:INFO:Starting cross validation
2023-07-02 17:46:37,604:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-02 17:46:37,606:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2023-07-02 17:46:37,606:WARNING:  warnings.warn(
2023-07-02 17:46:38,280:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:38,280:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

ric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:38,281:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:38,281:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:38,282:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:38,282:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:38,282:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:38,283:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:38,283:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:38,283:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:38,284:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:38,284:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:38,284:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:38,311:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:38,312:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:38,313:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:38,314:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:38,315:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:38,316:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:38,317:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:38,328:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:38,329:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:38,330:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:38,331:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:38,334:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:38,338:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:38,339:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:38,340:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:38,340:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:38,341:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:38,342:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:38,343:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:38,343:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:38,344:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:38,344:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:38,345:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:38,346:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:38,352:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:38,353:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:38,353:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:38,354:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:38,354:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:38,355:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:38,355:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:38,356:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:38,356:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:38,357:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:38,357:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:38,358:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:38,358:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:38,359:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:38,374:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:38,375:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:38,376:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:38,377:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:38,379:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:38,399:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:38,400:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:38,401:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:38,401:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:38,402:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:38,720:INFO:Calculating mean and std
2023-07-02 17:46:38,721:INFO:Creating metrics dataframe
2023-07-02 17:46:38,794:INFO:Uploading results into container
2023-07-02 17:46:38,795:INFO:Uploading model into container now
2023-07-02 17:46:38,795:INFO:_master_model_container: 12
2023-07-02 17:46:38,795:INFO:_display_container: 2
2023-07-02 17:46:38,795:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-07-02 17:46:38,796:INFO:create_model() successfully completed......................................
2023-07-02 17:46:39,092:INFO:SubProcess create_model() end ==================================
2023-07-02 17:46:39,092:INFO:Creating metrics dataframe
2023-07-02 17:46:39,102:INFO:Initializing Extra Trees Classifier
2023-07-02 17:46:39,102:INFO:Total runtime is 0.4208290934562683 minutes
2023-07-02 17:46:39,105:INFO:SubProcess create_model() called ==================================
2023-07-02 17:46:39,105:INFO:Initializing create_model()
2023-07-02 17:46:39,105:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000208E69CDB70>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000208E762F9A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-02 17:46:39,106:INFO:Checking exceptions
2023-07-02 17:46:39,106:INFO:Importing libraries
2023-07-02 17:46:39,106:INFO:Copying training dataset
2023-07-02 17:46:39,110:INFO:Defining folds
2023-07-02 17:46:39,110:INFO:Declaring metric variables
2023-07-02 17:46:39,113:INFO:Importing untrained model
2023-07-02 17:46:39,116:INFO:Extra Trees Classifier Imported successfully
2023-07-02 17:46:39,121:INFO:Starting cross validation
2023-07-02 17:46:39,123:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-02 17:46:39,125:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2023-07-02 17:46:39,125:WARNING:  warnings.warn(
2023-07-02 17:46:40,494:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:40,495:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:40,496:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:40,497:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:40,498:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:40,499:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:40,499:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:40,500:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:40,500:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:40,501:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:40,502:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:40,503:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:40,504:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:40,505:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:40,517:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:40,517:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:40,518:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:40,518:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:40,519:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:40,520:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:40,521:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:40,521:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:40,522:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:40,522:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:40,523:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:40,523:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:40,523:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:40,524:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:40,524:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:40,524:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:40,526:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:40,526:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:40,528:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:40,529:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:40,530:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:40,545:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:40,546:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:40,548:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:40,549:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:40,550:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:40,551:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:40,552:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:40,562:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:40,563:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:40,564:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:40,565:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:40,567:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:40,568:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:40,569:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:40,570:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:40,571:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:40,572:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:40,573:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:40,574:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:40,576:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:40,577:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:40,617:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:40,619:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:40,620:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:40,621:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:40,622:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:40,623:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:40,624:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:40,624:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:40,625:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:40,625:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:40,626:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:40,627:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:40,975:INFO:Calculating mean and std
2023-07-02 17:46:40,976:INFO:Creating metrics dataframe
2023-07-02 17:46:41,058:INFO:Uploading results into container
2023-07-02 17:46:41,059:INFO:Uploading model into container now
2023-07-02 17:46:41,060:INFO:_master_model_container: 13
2023-07-02 17:46:41,060:INFO:_display_container: 2
2023-07-02 17:46:41,060:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-07-02 17:46:41,060:INFO:create_model() successfully completed......................................
2023-07-02 17:46:41,358:INFO:SubProcess create_model() end ==================================
2023-07-02 17:46:41,358:INFO:Creating metrics dataframe
2023-07-02 17:46:41,368:INFO:Initializing Light Gradient Boosting Machine
2023-07-02 17:46:41,368:INFO:Total runtime is 0.4585942228635152 minutes
2023-07-02 17:46:41,371:INFO:SubProcess create_model() called ==================================
2023-07-02 17:46:41,371:INFO:Initializing create_model()
2023-07-02 17:46:41,371:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000208E69CDB70>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000208E762F9A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-02 17:46:41,371:INFO:Checking exceptions
2023-07-02 17:46:41,371:INFO:Importing libraries
2023-07-02 17:46:41,371:INFO:Copying training dataset
2023-07-02 17:46:41,375:INFO:Defining folds
2023-07-02 17:46:41,375:INFO:Declaring metric variables
2023-07-02 17:46:41,378:INFO:Importing untrained model
2023-07-02 17:46:41,381:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-02 17:46:41,386:INFO:Starting cross validation
2023-07-02 17:46:41,388:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-02 17:46:41,389:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2023-07-02 17:46:41,389:WARNING:  warnings.warn(
2023-07-02 17:46:43,443:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:43,444:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:43,445:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:43,446:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:43,447:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:43,448:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:43,448:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:43,449:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:43,449:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:43,450:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:43,450:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:43,451:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:43,451:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:43,452:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:43,452:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:43,453:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:43,453:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:43,454:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:43,454:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:43,455:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:43,455:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:43,456:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:43,457:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:43,457:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:43,457:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:43,457:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:43,458:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:43,460:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:43,462:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:43,464:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:43,465:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:43,467:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:43,472:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:43,473:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:43,474:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:43,475:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:43,476:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:43,478:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:43,480:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:43,488:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:43,489:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:43,491:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:43,492:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:43,493:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:43,494:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:43,496:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:43,508:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:43,509:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:43,511:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:43,512:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:43,514:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:43,515:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:43,516:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:43,523:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:43,524:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:43,524:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:43,525:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:43,526:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:43,526:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:43,527:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:43,528:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:43,528:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:43,529:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:43,529:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:43,530:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:43,530:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:43,531:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:43,937:INFO:Calculating mean and std
2023-07-02 17:46:43,938:INFO:Creating metrics dataframe
2023-07-02 17:46:44,022:INFO:Uploading results into container
2023-07-02 17:46:44,023:INFO:Uploading model into container now
2023-07-02 17:46:44,023:INFO:_master_model_container: 14
2023-07-02 17:46:44,023:INFO:_display_container: 2
2023-07-02 17:46:44,024:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-07-02 17:46:44,024:INFO:create_model() successfully completed......................................
2023-07-02 17:46:44,318:INFO:SubProcess create_model() end ==================================
2023-07-02 17:46:44,318:INFO:Creating metrics dataframe
2023-07-02 17:46:44,328:INFO:Initializing Dummy Classifier
2023-07-02 17:46:44,328:INFO:Total runtime is 0.5079328656196594 minutes
2023-07-02 17:46:44,330:INFO:SubProcess create_model() called ==================================
2023-07-02 17:46:44,331:INFO:Initializing create_model()
2023-07-02 17:46:44,331:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000208E69CDB70>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000208E762F9A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-02 17:46:44,331:INFO:Checking exceptions
2023-07-02 17:46:44,331:INFO:Importing libraries
2023-07-02 17:46:44,331:INFO:Copying training dataset
2023-07-02 17:46:44,335:INFO:Defining folds
2023-07-02 17:46:44,335:INFO:Declaring metric variables
2023-07-02 17:46:44,338:INFO:Importing untrained model
2023-07-02 17:46:44,341:INFO:Dummy Classifier Imported successfully
2023-07-02 17:46:44,345:INFO:Starting cross validation
2023-07-02 17:46:44,347:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-02 17:46:44,349:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2023-07-02 17:46:44,349:WARNING:  warnings.warn(
2023-07-02 17:46:45,046:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:45,047:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:45,047:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:45,048:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:45,048:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:45,049:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:45,049:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:45,050:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:45,051:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:45,051:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:45,052:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:45,052:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:45,054:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:45,063:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:45,064:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:45,065:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:45,066:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:45,067:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:45,069:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:45,070:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:45,080:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:45,081:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:45,082:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:45,083:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:45,085:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:45,086:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:45,087:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:45,087:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:45,088:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:45,090:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:45,091:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:45,092:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:45,093:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:45,094:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

ic code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:45,095:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:45,097:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:45,097:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:45,098:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:45,099:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:45,099:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:45,100:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:45,100:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:45,101:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:45,101:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:45,103:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:45,104:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:45,106:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:45,117:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:45,118:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:45,118:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:45,119:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:45,120:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:45,120:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:45,121:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:45,121:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:45,122:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:45,122:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:45,123:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:45,124:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:45,124:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:45,125:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:46:45,138:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:46:45,139:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:45,141:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:45,143:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:46:45,144:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:46:45,569:INFO:Calculating mean and std
2023-07-02 17:46:45,573:INFO:Creating metrics dataframe
2023-07-02 17:46:45,659:INFO:Uploading results into container
2023-07-02 17:46:45,660:INFO:Uploading model into container now
2023-07-02 17:46:45,660:INFO:_master_model_container: 15
2023-07-02 17:46:45,660:INFO:_display_container: 2
2023-07-02 17:46:45,660:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-07-02 17:46:45,660:INFO:create_model() successfully completed......................................
2023-07-02 17:46:45,957:INFO:SubProcess create_model() end ==================================
2023-07-02 17:46:45,958:INFO:Creating metrics dataframe
2023-07-02 17:46:45,975:INFO:Initializing create_model()
2023-07-02 17:46:45,975:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000208E69CDB70>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-02 17:46:45,975:INFO:Checking exceptions
2023-07-02 17:46:45,977:INFO:Importing libraries
2023-07-02 17:46:45,977:INFO:Copying training dataset
2023-07-02 17:46:45,980:INFO:Defining folds
2023-07-02 17:46:45,980:INFO:Declaring metric variables
2023-07-02 17:46:45,980:INFO:Importing untrained model
2023-07-02 17:46:45,981:INFO:Declaring custom model
2023-07-02 17:46:45,981:INFO:Random Forest Classifier Imported successfully
2023-07-02 17:46:45,983:INFO:Cross validation set to False
2023-07-02 17:46:45,983:INFO:Fitting Model
2023-07-02 17:46:46,420:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-07-02 17:46:46,420:INFO:create_model() successfully completed......................................
2023-07-02 17:46:46,743:INFO:_master_model_container: 15
2023-07-02 17:46:46,743:INFO:_display_container: 2
2023-07-02 17:46:46,744:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-07-02 17:46:46,744:INFO:compare_models() successfully completed......................................
2023-07-02 17:47:54,525:INFO:Initializing plot_model()
2023-07-02 17:47:54,525:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000208E69CDB70>, system=True)
2023-07-02 17:47:54,525:INFO:Checking exceptions
2023-07-02 17:47:54,540:INFO:Preloading libraries
2023-07-02 17:47:54,547:INFO:Copying training dataset
2023-07-02 17:47:54,548:INFO:Plot type: confusion_matrix
2023-07-02 17:47:54,943:INFO:Fitting Model
2023-07-02 17:47:54,946:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\base.py:420: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
2023-07-02 17:47:54,946:WARNING:  warnings.warn(
2023-07-02 17:47:54,946:INFO:Scoring test/hold-out set
2023-07-02 17:47:55,079:INFO:Visual Rendered Successfully
2023-07-02 17:47:55,376:INFO:plot_model() successfully completed......................................
2023-07-02 17:48:41,552:INFO:Initializing plot_model()
2023-07-02 17:48:41,552:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000208E69CDB70>, system=True)
2023-07-02 17:48:41,552:INFO:Checking exceptions
2023-07-02 17:48:41,566:INFO:Preloading libraries
2023-07-02 17:48:41,574:INFO:Copying training dataset
2023-07-02 17:48:41,574:INFO:Plot type: auc
2023-07-02 17:48:41,967:INFO:Fitting Model
2023-07-02 17:48:41,967:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\base.py:420: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
2023-07-02 17:48:41,967:WARNING:  warnings.warn(
2023-07-02 17:48:41,968:INFO:Scoring test/hold-out set
2023-07-02 17:48:42,155:INFO:Visual Rendered Successfully
2023-07-02 17:48:42,452:INFO:plot_model() successfully completed......................................
2023-07-02 17:48:47,624:INFO:Initializing plot_model()
2023-07-02 17:48:47,624:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000208E69CDB70>, system=True)
2023-07-02 17:48:47,624:INFO:Checking exceptions
2023-07-02 17:48:47,639:INFO:Preloading libraries
2023-07-02 17:48:47,646:INFO:Copying training dataset
2023-07-02 17:48:47,646:INFO:Plot type: feature
2023-07-02 17:48:47,646:WARNING:No coef_ found. Trying feature_importances_
2023-07-02 17:48:47,864:INFO:Visual Rendered Successfully
2023-07-02 17:48:48,160:INFO:plot_model() successfully completed......................................
2023-07-02 17:49:10,880:INFO:Initializing evaluate_model()
2023-07-02 17:49:10,880:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000208E69CDB70>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-07-02 17:49:10,906:INFO:Initializing plot_model()
2023-07-02 17:49:10,906:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000208E69CDB70>, system=True)
2023-07-02 17:49:10,906:INFO:Checking exceptions
2023-07-02 17:49:10,925:INFO:Preloading libraries
2023-07-02 17:49:10,935:INFO:Copying training dataset
2023-07-02 17:49:10,935:INFO:Plot type: pipeline
2023-07-02 17:49:11,120:INFO:Visual Rendered Successfully
2023-07-02 17:49:11,417:INFO:plot_model() successfully completed......................................
2023-07-02 17:49:13,502:INFO:Initializing plot_model()
2023-07-02 17:49:13,502:INFO:plot_model(plot=confusion_matrix, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000208E69CDB70>, system=True)
2023-07-02 17:49:13,502:INFO:Checking exceptions
2023-07-02 17:49:13,515:INFO:Preloading libraries
2023-07-02 17:49:13,520:INFO:Copying training dataset
2023-07-02 17:49:13,520:INFO:Plot type: confusion_matrix
2023-07-02 17:49:13,908:INFO:Fitting Model
2023-07-02 17:49:13,908:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\base.py:420: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
2023-07-02 17:49:13,908:WARNING:  warnings.warn(
2023-07-02 17:49:13,908:INFO:Scoring test/hold-out set
2023-07-02 17:49:14,034:INFO:Visual Rendered Successfully
2023-07-02 17:49:14,335:INFO:plot_model() successfully completed......................................
2023-07-02 17:49:16,791:INFO:Initializing plot_model()
2023-07-02 17:49:16,792:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000208E69CDB70>, system=True)
2023-07-02 17:49:16,792:INFO:Checking exceptions
2023-07-02 17:49:16,804:INFO:Preloading libraries
2023-07-02 17:49:16,809:INFO:Copying training dataset
2023-07-02 17:49:16,809:INFO:Plot type: pipeline
2023-07-02 17:49:16,932:INFO:Visual Rendered Successfully
2023-07-02 17:49:17,229:INFO:plot_model() successfully completed......................................
2023-07-02 17:49:35,620:INFO:Initializing predict_model()
2023-07-02 17:49:35,620:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000208E69CDB70>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000208E7642B90>)
2023-07-02 17:49:35,620:INFO:Checking exceptions
2023-07-02 17:49:35,620:INFO:Preloading libraries
2023-07-02 17:49:35,858:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\utils\generic.py:586: UserWarning: Traceback (most recent call last):
2023-07-02 17:49:35,858:WARNING:  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 580, in _calculate_metric
2023-07-02 17:49:35,858:WARNING:    calculated_metric = score_func(y_test, target, sample_weight=weights, **kwargs)
2023-07-02 17:49:35,858:WARNING:  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
2023-07-02 17:49:35,858:WARNING:    return self.score_func(y_true, y_pred, **kwargs)
2023-07-02 17:49:35,858:WARNING:  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
2023-07-02 17:49:35,858:WARNING:    return _multiclass_roc_auc_score(
2023-07-02 17:49:35,858:WARNING:  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 638, in _multiclass_roc_auc_score
2023-07-02 17:49:35,858:WARNING:    if not np.allclose(1, y_score.sum(axis=1)):
2023-07-02 17:49:35,858:WARNING:  File "C:\Users\JHossain\anaconda3\lib\site-packages\numpy\core\_methods.py", line 48, in _sum
2023-07-02 17:49:35,858:WARNING:    return umr_sum(a, axis, dtype, out, keepdims, initial, where)
2023-07-02 17:49:35,858:WARNING:numpy.AxisError: axis 1 is out of bounds for array of dimension 1
2023-07-02 17:49:35,858:WARNING:
2023-07-02 17:49:35,858:WARNING:During handling of the above exception, another exception occurred:
2023-07-02 17:49:35,858:WARNING:
2023-07-02 17:49:35,858:WARNING:Traceback (most recent call last):
2023-07-02 17:49:35,858:WARNING:  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 584, in _calculate_metric
2023-07-02 17:49:35,858:WARNING:    calculated_metric = score_func(y_test, target, **kwargs)
2023-07-02 17:49:35,858:WARNING:  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
2023-07-02 17:49:35,858:WARNING:    return self.score_func(y_true, y_pred, **kwargs)
2023-07-02 17:49:35,858:WARNING:  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
2023-07-02 17:49:35,858:WARNING:    return _multiclass_roc_auc_score(
2023-07-02 17:49:35,859:WARNING:  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 638, in _multiclass_roc_auc_score
2023-07-02 17:49:35,859:WARNING:    if not np.allclose(1, y_score.sum(axis=1)):
2023-07-02 17:49:35,859:WARNING:  File "C:\Users\JHossain\anaconda3\lib\site-packages\numpy\core\_methods.py", line 48, in _sum
2023-07-02 17:49:35,859:WARNING:    return umr_sum(a, axis, dtype, out, keepdims, initial, where)
2023-07-02 17:49:35,859:WARNING:numpy.AxisError: axis 1 is out of bounds for array of dimension 1
2023-07-02 17:49:35,859:WARNING:
2023-07-02 17:49:35,859:WARNING:  warnings.warn(traceback.format_exc())
2023-07-02 17:49:35,860:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
2023-07-02 17:49:35,860:WARNING:  warnings.warn(
2023-07-02 17:49:35,861:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
2023-07-02 17:49:35,861:WARNING:  warnings.warn(
2023-07-02 17:49:35,862:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
2023-07-02 17:49:35,862:WARNING:  _warn_prf(average, modifier, msg_start, len(result))
2023-07-02 17:49:35,863:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
2023-07-02 17:49:35,863:WARNING:  warnings.warn(
2023-07-02 17:50:21,414:INFO:Initializing predict_model()
2023-07-02 17:50:21,415:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000208E69CDB70>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000208E7A06560>)
2023-07-02 17:50:21,415:INFO:Checking exceptions
2023-07-02 17:50:21,415:INFO:Preloading libraries
2023-07-02 17:50:21,416:INFO:Set up data.
2023-07-02 17:50:21,424:INFO:Set up index.
2023-07-02 17:51:51,148:INFO:Initializing create_model()
2023-07-02 17:51:51,148:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000208E69CDB70>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-02 17:51:51,149:INFO:Checking exceptions
2023-07-02 17:51:51,161:INFO:Importing libraries
2023-07-02 17:51:51,161:INFO:Copying training dataset
2023-07-02 17:51:51,165:INFO:Defining folds
2023-07-02 17:51:51,165:INFO:Declaring metric variables
2023-07-02 17:51:51,168:INFO:Importing untrained model
2023-07-02 17:51:51,171:INFO:Random Forest Classifier Imported successfully
2023-07-02 17:51:51,177:INFO:Starting cross validation
2023-07-02 17:51:51,179:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-02 17:51:51,180:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2023-07-02 17:51:51,180:WARNING:  warnings.warn(
2023-07-02 17:51:56,840:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:51:56,842:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:51:56,843:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:51:56,844:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:51:56,845:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:51:56,846:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:51:56,848:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:51:56,884:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:51:56,887:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:51:56,887:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:51:56,888:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:51:56,889:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:51:56,889:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:51:56,891:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:51:56,891:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:51:56,892:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:51:56,892:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:51:56,893:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:51:56,893:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:51:56,894:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:51:56,896:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:51:56,896:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:51:56,896:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:51:56,898:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:51:56,899:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:51:56,900:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:51:56,901:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:51:56,901:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:51:56,902:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:51:56,903:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:51:56,903:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:51:56,904:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:51:56,904:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:51:56,908:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:51:56,908:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:51:56,910:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:51:56,910:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:51:56,912:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:51:56,912:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:51:56,913:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:51:56,913:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:51:56,914:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:51:56,914:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:51:56,914:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:51:56,915:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:51:56,915:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:51:56,916:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:51:56,916:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:51:56,917:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:51:56,918:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:51:56,920:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:51:56,921:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:51:56,922:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:51:56,923:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:51:56,935:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:51:56,936:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:51:56,937:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:51:56,938:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:51:56,939:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:51:56,939:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:51:56,940:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:51:56,940:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:51:56,941:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:51:56,942:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:51:56,942:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:51:56,943:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:51:56,943:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:51:56,944:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:51:57,416:INFO:Calculating mean and std
2023-07-02 17:51:57,417:INFO:Creating metrics dataframe
2023-07-02 17:51:57,423:INFO:Finalizing model
2023-07-02 17:51:57,726:INFO:Uploading results into container
2023-07-02 17:51:57,727:INFO:Uploading model into container now
2023-07-02 17:51:57,738:INFO:_master_model_container: 16
2023-07-02 17:51:57,738:INFO:_display_container: 4
2023-07-02 17:51:57,738:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-07-02 17:51:57,739:INFO:create_model() successfully completed......................................
2023-07-02 17:52:52,830:INFO:Initializing tune_model()
2023-07-02 17:52:52,831:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000208E69CDB70>)
2023-07-02 17:52:52,831:INFO:Checking exceptions
2023-07-02 17:52:52,845:INFO:Copying training dataset
2023-07-02 17:52:52,848:INFO:Checking base model
2023-07-02 17:52:52,849:INFO:Base model : Random Forest Classifier
2023-07-02 17:52:52,851:INFO:Declaring metric variables
2023-07-02 17:52:52,854:INFO:Defining Hyperparameters
2023-07-02 17:52:53,139:INFO:Tuning with n_jobs=-1
2023-07-02 17:52:53,139:INFO:Initializing RandomizedSearchCV
2023-07-02 17:53:05,860:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-02 17:53:06,016:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-02 17:53:08,159:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-02 17:53:11,018:INFO:best_params: {'actual_estimator__n_estimators': 190, 'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0.001, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 6, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': 'balanced_subsample', 'actual_estimator__bootstrap': False}
2023-07-02 17:53:11,019:INFO:Hyperparameter search completed
2023-07-02 17:53:11,019:INFO:SubProcess create_model() called ==================================
2023-07-02 17:53:11,020:INFO:Initializing create_model()
2023-07-02 17:53:11,020:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000208E69CDB70>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000208EB1F5CF0>, model_only=True, return_train_score=False, kwargs={'n_estimators': 190, 'min_samples_split': 9, 'min_samples_leaf': 6, 'min_impurity_decrease': 0.001, 'max_features': 'log2', 'max_depth': 6, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'bootstrap': False})
2023-07-02 17:53:11,020:INFO:Checking exceptions
2023-07-02 17:53:11,020:INFO:Importing libraries
2023-07-02 17:53:11,020:INFO:Copying training dataset
2023-07-02 17:53:11,025:INFO:Defining folds
2023-07-02 17:53:11,025:INFO:Declaring metric variables
2023-07-02 17:53:11,028:INFO:Importing untrained model
2023-07-02 17:53:11,028:INFO:Declaring custom model
2023-07-02 17:53:11,032:INFO:Random Forest Classifier Imported successfully
2023-07-02 17:53:11,038:INFO:Starting cross validation
2023-07-02 17:53:11,040:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-02 17:53:11,042:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2023-07-02 17:53:11,042:WARNING:  warnings.warn(
2023-07-02 17:53:12,237:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:53:12,238:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:12,239:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:53:12,240:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:12,241:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:53:12,242:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:12,243:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:53:12,312:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:53:12,313:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:12,314:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:53:12,315:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:53:12,315:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:53:12,315:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:12,316:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:12,316:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:12,316:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:53:12,317:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

art, len(result))

2023-07-02 17:53:12,317:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:53:12,318:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:12,318:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:53:12,318:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:12,319:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:12,319:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:53:12,320:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:53:12,320:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:53:12,320:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:12,321:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:53:12,321:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:12,321:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:53:12,322:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:53:12,323:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:12,324:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:53:12,325:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:12,326:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:53:12,352:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:53:12,353:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:12,355:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:53:12,356:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:12,357:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:53:12,359:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:12,360:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:53:12,369:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:53:12,370:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:12,372:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:53:12,373:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:12,374:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:53:12,375:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:12,377:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:53:12,399:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:53:12,402:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:12,403:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:53:12,404:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:12,405:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:53:12,406:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:12,407:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:53:12,412:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:53:12,413:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:12,416:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:12,417:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:53:12,418:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:12,423:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:53:12,425:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:12,426:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:53:12,427:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:12,428:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:53:12,429:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:12,430:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:53:13,193:INFO:Calculating mean and std
2023-07-02 17:53:13,195:INFO:Creating metrics dataframe
2023-07-02 17:53:13,200:INFO:Finalizing model
2023-07-02 17:53:13,891:INFO:Uploading results into container
2023-07-02 17:53:13,892:INFO:Uploading model into container now
2023-07-02 17:53:13,892:INFO:_master_model_container: 17
2023-07-02 17:53:13,892:INFO:_display_container: 5
2023-07-02 17:53:13,893:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='gini',
                       max_depth=6, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.001,
                       min_samples_leaf=6, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, n_estimators=190,
                       n_jobs=-1, oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2023-07-02 17:53:13,893:INFO:create_model() successfully completed......................................
2023-07-02 17:53:14,194:INFO:SubProcess create_model() end ==================================
2023-07-02 17:53:14,194:INFO:choose_better activated
2023-07-02 17:53:14,197:INFO:SubProcess create_model() called ==================================
2023-07-02 17:53:14,198:INFO:Initializing create_model()
2023-07-02 17:53:14,198:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000208E69CDB70>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-02 17:53:14,198:INFO:Checking exceptions
2023-07-02 17:53:14,200:INFO:Importing libraries
2023-07-02 17:53:14,200:INFO:Copying training dataset
2023-07-02 17:53:14,203:INFO:Defining folds
2023-07-02 17:53:14,203:INFO:Declaring metric variables
2023-07-02 17:53:14,204:INFO:Importing untrained model
2023-07-02 17:53:14,204:INFO:Declaring custom model
2023-07-02 17:53:14,204:INFO:Random Forest Classifier Imported successfully
2023-07-02 17:53:14,204:INFO:Starting cross validation
2023-07-02 17:53:14,206:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-02 17:53:14,207:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2023-07-02 17:53:14,207:WARNING:  warnings.warn(
2023-07-02 17:53:14,786:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:53:14,787:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:14,788:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:53:14,789:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:14,789:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:53:14,790:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:14,791:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:53:14,799:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:53:14,801:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:14,802:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:53:14,803:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:14,804:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:53:14,805:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:14,807:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:53:14,827:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:53:14,828:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:14,829:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:53:14,830:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:14,830:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:53:14,831:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:53:14,832:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:14,833:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:53:14,833:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:53:14,833:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:53:14,834:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:14,834:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:14,834:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:53:14,835:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:53:14,835:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:53:14,835:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:53:14,835:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:14,836:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:14,836:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:14,836:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:14,836:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:53:14,837:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:53:14,837:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:53:14,837:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:53:14,837:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:14,838:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:14,838:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:14,838:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:53:14,839:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:53:14,839:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:53:14,839:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:14,840:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:14,841:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:53:14,841:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:53:14,892:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:53:14,893:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:14,894:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:53:14,896:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:14,897:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:53:14,898:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:14,899:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:53:14,914:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:53:14,915:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:14,916:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:53:14,918:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:14,919:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:53:14,920:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:14,921:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:53:15,017:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:53:15,018:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:15,019:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:15,020:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:53:15,020:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:15,690:INFO:Calculating mean and std
2023-07-02 17:53:15,690:INFO:Creating metrics dataframe
2023-07-02 17:53:15,692:INFO:Finalizing model
2023-07-02 17:53:16,033:INFO:Uploading results into container
2023-07-02 17:53:16,034:INFO:Uploading model into container now
2023-07-02 17:53:16,035:INFO:_master_model_container: 18
2023-07-02 17:53:16,035:INFO:_display_container: 6
2023-07-02 17:53:16,035:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-07-02 17:53:16,035:INFO:create_model() successfully completed......................................
2023-07-02 17:53:16,334:INFO:SubProcess create_model() end ==================================
2023-07-02 17:53:16,335:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False) result for Accuracy is 0.9964
2023-07-02 17:53:16,335:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='gini',
                       max_depth=6, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.001,
                       min_samples_leaf=6, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, n_estimators=190,
                       n_jobs=-1, oob_score=False, random_state=123, verbose=0,
                       warm_start=False) result for Accuracy is 0.9964
2023-07-02 17:53:16,335:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False) is best model
2023-07-02 17:53:16,335:INFO:choose_better completed
2023-07-02 17:53:16,336:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-07-02 17:53:16,345:INFO:_master_model_container: 18
2023-07-02 17:53:16,345:INFO:_display_container: 5
2023-07-02 17:53:16,345:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-07-02 17:53:16,346:INFO:tune_model() successfully completed......................................
2023-07-02 17:53:44,932:INFO:Initializing tune_model()
2023-07-02 17:53:44,932:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=True, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000208E69CDB70>)
2023-07-02 17:53:44,932:INFO:Checking exceptions
2023-07-02 17:53:44,948:INFO:Copying training dataset
2023-07-02 17:53:44,951:INFO:Checking base model
2023-07-02 17:53:44,951:INFO:Base model : Random Forest Classifier
2023-07-02 17:53:44,954:INFO:Declaring metric variables
2023-07-02 17:53:44,957:INFO:Defining Hyperparameters
2023-07-02 17:53:45,241:INFO:Tuning with n_jobs=-1
2023-07-02 17:53:45,242:INFO:Initializing RandomizedSearchCV
2023-07-02 17:53:57,218:INFO:best_params: {'actual_estimator__n_estimators': 190, 'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0.001, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 6, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': 'balanced_subsample', 'actual_estimator__bootstrap': False}
2023-07-02 17:53:57,220:INFO:Hyperparameter search completed
2023-07-02 17:53:57,220:INFO:SubProcess create_model() called ==================================
2023-07-02 17:53:57,220:INFO:Initializing create_model()
2023-07-02 17:53:57,220:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000208E69CDB70>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000208E40AD9C0>, model_only=True, return_train_score=False, kwargs={'n_estimators': 190, 'min_samples_split': 9, 'min_samples_leaf': 6, 'min_impurity_decrease': 0.001, 'max_features': 'log2', 'max_depth': 6, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'bootstrap': False})
2023-07-02 17:53:57,221:INFO:Checking exceptions
2023-07-02 17:53:57,221:INFO:Importing libraries
2023-07-02 17:53:57,221:INFO:Copying training dataset
2023-07-02 17:53:57,224:INFO:Defining folds
2023-07-02 17:53:57,225:INFO:Declaring metric variables
2023-07-02 17:53:57,228:INFO:Importing untrained model
2023-07-02 17:53:57,228:INFO:Declaring custom model
2023-07-02 17:53:57,231:INFO:Random Forest Classifier Imported successfully
2023-07-02 17:53:57,237:INFO:Starting cross validation
2023-07-02 17:53:57,239:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-02 17:53:57,241:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2023-07-02 17:53:57,241:WARNING:  warnings.warn(
2023-07-02 17:53:58,041:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:53:58,042:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:58,043:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:53:58,044:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:58,045:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:53:58,046:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:58,047:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:53:58,047:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:53:58,048:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:58,049:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:53:58,050:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:58,051:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:53:58,052:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:58,054:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:53:58,065:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:53:58,066:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:58,067:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:53:58,068:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:58,070:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:53:58,071:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:58,072:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:53:58,084:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:53:58,085:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:58,086:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:53:58,087:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:58,088:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:53:58,089:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:58,091:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:53:58,094:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:53:58,095:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:58,096:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:53:58,097:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:58,098:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:53:58,099:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:58,100:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:53:58,125:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:53:58,127:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:58,128:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:53:58,129:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:58,130:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:53:58,131:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:58,133:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:53:58,133:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:53:58,134:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:58,136:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:53:58,137:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:58,138:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:53:58,139:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:58,140:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:53:58,149:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:53:58,150:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:58,151:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:53:58,152:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:58,154:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:53:58,155:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:58,156:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:53:58,218:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:53:58,220:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:58,221:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:53:58,222:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:58,223:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:53:58,224:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:58,225:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:53:58,264:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:53:58,265:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:58,266:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:58,267:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:53:58,267:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:53:58,984:INFO:Calculating mean and std
2023-07-02 17:53:58,985:INFO:Creating metrics dataframe
2023-07-02 17:53:58,990:INFO:Finalizing model
2023-07-02 17:53:59,372:INFO:Uploading results into container
2023-07-02 17:53:59,372:INFO:Uploading model into container now
2023-07-02 17:53:59,373:INFO:_master_model_container: 19
2023-07-02 17:53:59,373:INFO:_display_container: 6
2023-07-02 17:53:59,373:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='gini',
                       max_depth=6, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.001,
                       min_samples_leaf=6, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, n_estimators=190,
                       n_jobs=-1, oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2023-07-02 17:53:59,373:INFO:create_model() successfully completed......................................
2023-07-02 17:53:59,673:INFO:SubProcess create_model() end ==================================
2023-07-02 17:53:59,674:INFO:choose_better activated
2023-07-02 17:53:59,677:INFO:SubProcess create_model() called ==================================
2023-07-02 17:53:59,677:INFO:Initializing create_model()
2023-07-02 17:53:59,677:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000208E69CDB70>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-02 17:53:59,677:INFO:Checking exceptions
2023-07-02 17:53:59,679:INFO:Importing libraries
2023-07-02 17:53:59,679:INFO:Copying training dataset
2023-07-02 17:53:59,682:INFO:Defining folds
2023-07-02 17:53:59,682:INFO:Declaring metric variables
2023-07-02 17:53:59,683:INFO:Importing untrained model
2023-07-02 17:53:59,683:INFO:Declaring custom model
2023-07-02 17:53:59,683:INFO:Random Forest Classifier Imported successfully
2023-07-02 17:53:59,684:INFO:Starting cross validation
2023-07-02 17:53:59,685:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-02 17:53:59,687:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2023-07-02 17:53:59,687:WARNING:  warnings.warn(
2023-07-02 17:54:00,286:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:54:00,287:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:54:00,288:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:54:00,289:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:54:00,290:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:54:00,291:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:54:00,292:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:54:00,308:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:54:00,309:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:54:00,310:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:54:00,311:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:54:00,313:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:54:00,314:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:54:00,315:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:54:00,321:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:54:00,323:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:54:00,324:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:54:00,325:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:54:00,325:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:54:00,326:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:54:00,327:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:54:00,328:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:54:00,328:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:54:00,329:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:54:00,329:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:54:00,330:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:54:00,331:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:54:00,332:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:54:00,363:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:54:00,364:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:54:00,366:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:54:00,367:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:54:00,368:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:54:00,369:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:54:00,369:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:54:00,370:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:54:00,370:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:54:00,372:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:54:00,373:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:54:00,374:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:54:00,403:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:54:00,404:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:54:00,406:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:54:00,407:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:54:00,408:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:54:00,409:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:54:00,411:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:54:00,440:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:54:00,441:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:54:00,442:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:54:00,443:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:54:00,445:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:54:00,446:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:54:00,447:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:54:00,462:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:54:00,463:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:54:00,464:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:54:00,465:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:54:00,466:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:54:00,468:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:54:00,469:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:54:00,493:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-02 17:54:00,493:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:54:00,494:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:54:00,495:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:54:00,496:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-02 17:54:00,496:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-02 17:54:00,497:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-02 17:54:01,219:INFO:Calculating mean and std
2023-07-02 17:54:01,220:INFO:Creating metrics dataframe
2023-07-02 17:54:01,221:INFO:Finalizing model
2023-07-02 17:54:01,565:INFO:Uploading results into container
2023-07-02 17:54:01,566:INFO:Uploading model into container now
2023-07-02 17:54:01,567:INFO:_master_model_container: 20
2023-07-02 17:54:01,567:INFO:_display_container: 7
2023-07-02 17:54:01,567:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-07-02 17:54:01,567:INFO:create_model() successfully completed......................................
2023-07-02 17:54:01,889:INFO:SubProcess create_model() end ==================================
2023-07-02 17:54:01,890:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False) result for Accuracy is 0.9964
2023-07-02 17:54:01,890:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='gini',
                       max_depth=6, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.001,
                       min_samples_leaf=6, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, n_estimators=190,
                       n_jobs=-1, oob_score=False, random_state=123, verbose=0,
                       warm_start=False) result for Accuracy is 0.9964
2023-07-02 17:54:01,890:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False) is best model
2023-07-02 17:54:01,890:INFO:choose_better completed
2023-07-02 17:54:01,891:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-07-02 17:54:01,903:INFO:_master_model_container: 20
2023-07-02 17:54:01,903:INFO:_display_container: 6
2023-07-02 17:54:01,903:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-07-02 17:54:01,903:INFO:tune_model() successfully completed......................................
2023-07-02 17:54:43,856:INFO:Initializing plot_model()
2023-07-02 17:54:43,856:INFO:plot_model(plot=class_report, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000208E69CDB70>, system=True)
2023-07-02 17:54:43,856:INFO:Checking exceptions
2023-07-02 17:54:43,871:INFO:Preloading libraries
2023-07-02 17:54:43,877:INFO:Copying training dataset
2023-07-02 17:54:43,877:INFO:Plot type: class_report
2023-07-02 17:54:44,279:INFO:Fitting Model
2023-07-02 17:54:44,279:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\base.py:420: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
2023-07-02 17:54:44,279:WARNING:  warnings.warn(
2023-07-02 17:54:44,279:INFO:Scoring test/hold-out set
2023-07-02 17:54:44,310:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
2023-07-02 17:54:44,310:WARNING:  _warn_prf(average, modifier, msg_start, len(result))
2023-07-02 17:54:44,473:INFO:Visual Rendered Successfully
2023-07-02 17:54:44,780:INFO:plot_model() successfully completed......................................
2023-07-02 17:54:52,072:INFO:Initializing plot_model()
2023-07-02 17:54:52,072:INFO:plot_model(plot=class_report, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=2, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000208E69CDB70>, system=True)
2023-07-02 17:54:52,072:INFO:Checking exceptions
2023-07-02 17:54:52,086:INFO:Preloading libraries
2023-07-02 17:54:52,092:INFO:Copying training dataset
2023-07-02 17:54:52,092:INFO:Plot type: class_report
2023-07-02 17:54:52,488:INFO:Fitting Model
2023-07-02 17:54:52,488:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\base.py:420: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
2023-07-02 17:54:52,488:WARNING:  warnings.warn(
2023-07-02 17:54:52,488:INFO:Scoring test/hold-out set
2023-07-02 17:54:52,518:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
2023-07-02 17:54:52,518:WARNING:  _warn_prf(average, modifier, msg_start, len(result))
2023-07-02 17:54:52,723:INFO:Visual Rendered Successfully
2023-07-02 17:54:53,025:INFO:plot_model() successfully completed......................................
2023-07-02 17:55:18,761:INFO:Initializing interpret_model()
2023-07-02 17:55:18,761:INFO:interpret_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000208E69CDB70>)
2023-07-02 17:55:18,761:INFO:Checking exceptions
2023-07-02 17:55:18,761:ERROR:
'shap' is a soft dependency and not included in the pycaret installation. Please run: `pip install shap` to install.
Alternately, you can install this by running `pip install pycaret[analysis]`
NoneType: None
2023-07-02 17:55:45,910:ERROR:
'autoviz' is a soft dependency and not included in the pycaret installation. Please run: `pip install autoviz` to install.
Alternately, you can install this by running `pip install pycaret[mlops]`
NoneType: None
2023-07-02 17:55:54,606:ERROR:
'gradio' is a soft dependency and not included in the pycaret installation. Please run: `pip install gradio` to install.
Alternately, you can install this by running `pip install pycaret[mlops]`
NoneType: None
2023-07-03 09:00:02,476:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-03 09:00:02,485:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-03 09:00:02,485:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-03 09:00:02,485:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-03 09:00:03,333:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-07-03 09:00:03,902:INFO:PyCaret ClassificationExperiment
2023-07-03 09:00:03,902:INFO:Logging name: clf-default-name
2023-07-03 09:00:03,902:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-07-03 09:00:03,902:INFO:version 3.0.2
2023-07-03 09:00:03,902:INFO:Initializing setup()
2023-07-03 09:00:03,902:INFO:self.USI: 2b33
2023-07-03 09:00:03,902:INFO:self._variable_keys: {'n_jobs_param', 'idx', '_ml_usecase', 'exp_id', 'log_plots_param', 'exp_name_log', 'fold_shuffle_param', 'target_param', 'y_test', 'y', 'data', 'y_train', 'pipeline', 'seed', 'X_train', 'fold_groups_param', 'gpu_n_jobs_param', 'memory', '_available_plots', 'X_test', 'fix_imbalance', 'X', 'logging_param', 'gpu_param', 'fold_generator', 'html_param', 'is_multiclass', 'USI'}
2023-07-03 09:00:03,902:INFO:Checking environment
2023-07-03 09:00:03,902:INFO:python_version: 3.10.9
2023-07-03 09:00:03,902:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2023-07-03 09:00:03,902:INFO:machine: AMD64
2023-07-03 09:00:03,902:INFO:platform: Windows-10-10.0.22621-SP0
2023-07-03 09:00:03,906:INFO:Memory: svmem(total=33664483328, available=23639711744, percent=29.8, used=10024771584, free=23639711744)
2023-07-03 09:00:03,906:INFO:Physical Core: 6
2023-07-03 09:00:03,906:INFO:Logical Core: 12
2023-07-03 09:00:03,906:INFO:Checking libraries
2023-07-03 09:00:03,906:INFO:System:
2023-07-03 09:00:03,906:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2023-07-03 09:00:03,906:INFO:executable: C:\Users\JHossain\anaconda3\python.exe
2023-07-03 09:00:03,906:INFO:   machine: Windows-10-10.0.22621-SP0
2023-07-03 09:00:03,906:INFO:PyCaret required dependencies:
2023-07-03 09:00:03,906:INFO:                 pip: 22.3.1
2023-07-03 09:00:03,906:INFO:          setuptools: 65.6.3
2023-07-03 09:00:03,906:INFO:             pycaret: 3.0.2
2023-07-03 09:00:03,906:INFO:             IPython: 8.10.0
2023-07-03 09:00:03,906:INFO:          ipywidgets: 7.6.5
2023-07-03 09:00:03,906:INFO:                tqdm: 4.64.1
2023-07-03 09:00:03,906:INFO:               numpy: 1.23.5
2023-07-03 09:00:03,906:INFO:              pandas: 1.5.3
2023-07-03 09:00:03,906:INFO:              jinja2: 3.1.2
2023-07-03 09:00:03,906:INFO:               scipy: 1.10.0
2023-07-03 09:00:03,906:INFO:              joblib: 1.2.0
2023-07-03 09:00:03,906:INFO:             sklearn: 1.2.1
2023-07-03 09:00:03,906:INFO:                pyod: 1.0.9
2023-07-03 09:00:03,906:INFO:            imblearn: 0.10.1
2023-07-03 09:00:03,906:INFO:   category_encoders: 2.6.1
2023-07-03 09:00:03,907:INFO:            lightgbm: 3.3.5
2023-07-03 09:00:03,907:INFO:               numba: 0.56.4
2023-07-03 09:00:03,907:INFO:            requests: 2.28.1
2023-07-03 09:00:03,907:INFO:          matplotlib: 3.7.0
2023-07-03 09:00:03,907:INFO:          scikitplot: 0.3.7
2023-07-03 09:00:03,907:INFO:         yellowbrick: 1.5
2023-07-03 09:00:03,907:INFO:              plotly: 5.9.0
2023-07-03 09:00:03,907:INFO:             kaleido: 0.2.1
2023-07-03 09:00:03,907:INFO:         statsmodels: 0.13.5
2023-07-03 09:00:03,907:INFO:              sktime: 0.17.0
2023-07-03 09:00:03,907:INFO:               tbats: 1.1.3
2023-07-03 09:00:03,907:INFO:            pmdarima: 2.0.3
2023-07-03 09:00:03,907:INFO:              psutil: 5.9.0
2023-07-03 09:00:03,907:INFO:PyCaret optional dependencies:
2023-07-03 09:00:05,069:INFO:                shap: Not installed
2023-07-03 09:00:05,069:INFO:           interpret: Not installed
2023-07-03 09:00:05,069:INFO:                umap: Not installed
2023-07-03 09:00:05,069:INFO:    pandas_profiling: Not installed
2023-07-03 09:00:05,069:INFO:  explainerdashboard: Not installed
2023-07-03 09:00:05,069:INFO:             autoviz: Not installed
2023-07-03 09:00:05,069:INFO:           fairlearn: Not installed
2023-07-03 09:00:05,069:INFO:             xgboost: Not installed
2023-07-03 09:00:05,069:INFO:            catboost: Not installed
2023-07-03 09:00:05,069:INFO:              kmodes: Not installed
2023-07-03 09:00:05,069:INFO:             mlxtend: Not installed
2023-07-03 09:00:05,069:INFO:       statsforecast: Not installed
2023-07-03 09:00:05,070:INFO:        tune_sklearn: Not installed
2023-07-03 09:00:05,070:INFO:                 ray: Not installed
2023-07-03 09:00:05,070:INFO:            hyperopt: Not installed
2023-07-03 09:00:05,070:INFO:              optuna: Not installed
2023-07-03 09:00:05,070:INFO:               skopt: Not installed
2023-07-03 09:00:05,070:INFO:              mlflow: Not installed
2023-07-03 09:00:05,070:INFO:              gradio: 3.35.2
2023-07-03 09:00:05,070:INFO:             fastapi: 0.99.0
2023-07-03 09:00:05,070:INFO:             uvicorn: 0.22.0
2023-07-03 09:00:05,070:INFO:              m2cgen: Not installed
2023-07-03 09:00:05,070:INFO:           evidently: Not installed
2023-07-03 09:00:05,070:INFO:               fugue: Not installed
2023-07-03 09:00:05,070:INFO:           streamlit: Not installed
2023-07-03 09:00:05,070:INFO:             prophet: Not installed
2023-07-03 09:00:05,070:INFO:None
2023-07-03 09:00:05,070:INFO:Set up data.
2023-07-03 09:00:05,080:INFO:Set up train/test split.
2023-07-03 09:00:05,088:INFO:Set up index.
2023-07-03 09:00:05,088:INFO:Set up folding strategy.
2023-07-03 09:00:05,088:INFO:Assigning column types.
2023-07-03 09:00:05,091:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-07-03 09:00:05,127:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-03 09:00:05,131:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-03 09:00:05,160:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:00:05,368:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:00:05,405:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-03 09:00:05,406:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-03 09:00:05,431:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:00:05,431:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:00:05,431:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-07-03 09:00:05,468:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-03 09:00:05,492:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:00:05,492:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:00:05,530:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-03 09:00:05,553:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:00:05,553:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:00:05,554:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-07-03 09:00:05,613:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:00:05,614:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:00:05,673:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:00:05,674:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:00:05,686:INFO:Preparing preprocessing pipeline...
2023-07-03 09:00:05,689:INFO:Set up label encoding.
2023-07-03 09:00:05,689:INFO:Set up simple imputation.
2023-07-03 09:00:05,693:INFO:Set up encoding of ordinal features.
2023-07-03 09:00:05,700:INFO:Set up encoding of categorical features.
2023-07-03 09:00:05,880:INFO:Finished creating preprocessing pipeline.
2023-07-03 09:00:05,943:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\JHossain\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['id', 'age', 'bp', 'sg', 'al',
                                             'su', 'bgr', 'bu', 'sc', 'sod',
                                             'pot', 'hemo'],
                                    transformer=SimpleImputer(add_...
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['pcv', 'wc', 'rc'],
                                    transformer=TargetEncoder(cols=['pcv', 'wc',
                                                                    'rc'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2023-07-03 09:00:05,943:INFO:Creating final display dataframe.
2023-07-03 09:00:06,521:INFO:Setup _display_container:                     Description                        Value
0                    Session id                          123
1                        Target               classification
2                   Target type                   Multiclass
3                Target mapping  ckd: 0, ckd\t: 1, notckd: 2
4           Original data shape                    (400, 26)
5        Transformed data shape                    (400, 32)
6   Transformed train set shape                    (280, 32)
7    Transformed test set shape                    (120, 32)
8              Ordinal features                            8
9              Numeric features                           12
10         Categorical features                           13
11     Rows with missing values                        60.5%
12                   Preprocess                         True
13              Imputation type                       simple
14           Numeric imputation                         mean
15       Categorical imputation                         mode
16     Maximum one-hot encoding                           25
17              Encoding method                         None
18               Fold Generator              StratifiedKFold
19                  Fold Number                           10
20                     CPU Jobs                           -1
21                      Use GPU                        False
22               Log Experiment                        False
23              Experiment Name             clf-default-name
24                          USI                         2b33
2023-07-03 09:00:06,590:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:00:06,590:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:00:06,650:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:00:06,650:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:00:06,651:INFO:setup() successfully completed in 3.01s...............
2023-07-03 09:00:10,104:INFO:Initializing compare_models()
2023-07-03 09:00:10,104:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027231F26FE0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000027231F26FE0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-07-03 09:00:10,104:INFO:Checking exceptions
2023-07-03 09:00:10,107:INFO:Preparing display monitor
2023-07-03 09:00:10,130:INFO:Initializing Logistic Regression
2023-07-03 09:00:10,130:INFO:Total runtime is 0.0 minutes
2023-07-03 09:00:10,133:INFO:SubProcess create_model() called ==================================
2023-07-03 09:00:10,133:INFO:Initializing create_model()
2023-07-03 09:00:10,133:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027231F26FE0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027231D95B10>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:00:10,133:INFO:Checking exceptions
2023-07-03 09:00:10,134:INFO:Importing libraries
2023-07-03 09:00:10,134:INFO:Copying training dataset
2023-07-03 09:00:10,137:INFO:Defining folds
2023-07-03 09:00:10,137:INFO:Declaring metric variables
2023-07-03 09:00:10,141:INFO:Importing untrained model
2023-07-03 09:00:10,143:INFO:Logistic Regression Imported successfully
2023-07-03 09:00:10,149:INFO:Starting cross validation
2023-07-03 09:00:10,151:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:00:10,161:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2023-07-03 09:00:15,497:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:15,500:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:15,503:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:15,504:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:15,505:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:15,775:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:15,776:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:15,776:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:15,777:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:15,778:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:15,778:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:15,779:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:15,779:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:15,779:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:15,780:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:15,780:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:15,781:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:15,781:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:15,781:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:15,781:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:15,781:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:15,782:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

, msg_start, len(result))

2023-07-03 09:00:15,783:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:15,783:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:15,783:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:15,783:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:15,784:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:15,784:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:15,785:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:15,785:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:15,785:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:15,786:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:15,787:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:15,787:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:15,788:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:15,788:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:15,788:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:15,789:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:15,789:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:15,790:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:15,790:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:15,791:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:15,791:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:15,792:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:15,792:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:15,793:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:15,794:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:15,794:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:15,796:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:15,798:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:15,798:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:15,800:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:15,801:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:15,802:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:15,812:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:15,813:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:15,815:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:15,816:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:15,817:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:15,818:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:15,820:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:16,608:INFO:Calculating mean and std
2023-07-03 09:00:16,609:INFO:Creating metrics dataframe
2023-07-03 09:00:16,758:INFO:Uploading results into container
2023-07-03 09:00:16,759:INFO:Uploading model into container now
2023-07-03 09:00:16,760:INFO:_master_model_container: 1
2023-07-03 09:00:16,760:INFO:_display_container: 2
2023-07-03 09:00:16,760:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-03 09:00:16,761:INFO:create_model() successfully completed......................................
2023-07-03 09:00:16,904:INFO:SubProcess create_model() end ==================================
2023-07-03 09:00:16,904:INFO:Creating metrics dataframe
2023-07-03 09:00:16,912:INFO:Initializing K Neighbors Classifier
2023-07-03 09:00:16,912:INFO:Total runtime is 0.11304774284362792 minutes
2023-07-03 09:00:16,915:INFO:SubProcess create_model() called ==================================
2023-07-03 09:00:16,915:INFO:Initializing create_model()
2023-07-03 09:00:16,915:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027231F26FE0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027231D95B10>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:00:16,916:INFO:Checking exceptions
2023-07-03 09:00:16,916:INFO:Importing libraries
2023-07-03 09:00:16,916:INFO:Copying training dataset
2023-07-03 09:00:16,920:INFO:Defining folds
2023-07-03 09:00:16,920:INFO:Declaring metric variables
2023-07-03 09:00:16,923:INFO:Importing untrained model
2023-07-03 09:00:16,926:INFO:K Neighbors Classifier Imported successfully
2023-07-03 09:00:16,932:INFO:Starting cross validation
2023-07-03 09:00:16,933:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:00:16,935:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2023-07-03 09:00:17,495:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:17,496:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:17,496:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:17,497:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:17,497:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:17,498:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:17,498:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:17,499:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:17,499:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:17,500:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:17,501:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:17,502:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:17,503:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:17,504:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:17,517:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:17,518:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:17,518:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:17,519:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:17,519:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:17,520:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:17,520:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:17,521:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:17,521:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:17,522:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:17,522:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:17,523:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:17,523:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:17,523:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:17,530:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:17,531:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:17,532:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:17,533:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:17,534:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:17,535:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:17,536:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:17,547:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:17,548:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:17,548:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:17,549:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:17,549:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:17,550:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:17,551:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:17,551:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:17,552:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:17,552:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:17,553:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:17,554:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:19,499:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:19,499:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:19,500:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:19,501:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:19,501:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:19,501:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:19,502:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:19,502:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:19,502:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:19,502:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:19,503:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:19,503:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:19,503:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:19,504:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:19,604:INFO:Calculating mean and std
2023-07-03 09:00:19,605:INFO:Creating metrics dataframe
2023-07-03 09:00:19,761:INFO:Uploading results into container
2023-07-03 09:00:19,762:INFO:Uploading model into container now
2023-07-03 09:00:19,763:INFO:_master_model_container: 2
2023-07-03 09:00:19,763:INFO:_display_container: 2
2023-07-03 09:00:19,763:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-07-03 09:00:19,763:INFO:create_model() successfully completed......................................
2023-07-03 09:00:19,907:INFO:SubProcess create_model() end ==================================
2023-07-03 09:00:19,907:INFO:Creating metrics dataframe
2023-07-03 09:00:19,915:INFO:Initializing Naive Bayes
2023-07-03 09:00:19,915:INFO:Total runtime is 0.16308573881785074 minutes
2023-07-03 09:00:19,918:INFO:SubProcess create_model() called ==================================
2023-07-03 09:00:19,918:INFO:Initializing create_model()
2023-07-03 09:00:19,919:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027231F26FE0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027231D95B10>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:00:19,919:INFO:Checking exceptions
2023-07-03 09:00:19,919:INFO:Importing libraries
2023-07-03 09:00:19,919:INFO:Copying training dataset
2023-07-03 09:00:19,923:INFO:Defining folds
2023-07-03 09:00:19,923:INFO:Declaring metric variables
2023-07-03 09:00:19,926:INFO:Importing untrained model
2023-07-03 09:00:19,929:INFO:Naive Bayes Imported successfully
2023-07-03 09:00:19,934:INFO:Starting cross validation
2023-07-03 09:00:19,936:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:00:19,938:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2023-07-03 09:00:20,310:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:20,310:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:20,312:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:20,312:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:20,313:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:20,314:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:20,315:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:20,320:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:20,321:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:20,322:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:20,323:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:20,324:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:20,324:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:20,325:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:20,341:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:20,342:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:20,343:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:20,343:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:20,344:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:20,344:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:20,345:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:20,345:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:20,346:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:20,346:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:20,347:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:20,347:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:20,348:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:20,349:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:20,355:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:20,356:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:20,357:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:20,358:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:20,359:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:20,360:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:20,362:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:20,379:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:20,380:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:20,381:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:20,381:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:20,382:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:20,382:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:20,383:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:20,383:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:20,384:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:20,384:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:20,386:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:20,386:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:20,387:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:20,387:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:20,388:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:20,388:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:20,391:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:20,392:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:20,393:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:20,399:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:20,400:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:20,401:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:20,402:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:20,402:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:20,403:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:20,403:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:20,404:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:20,404:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:20,404:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:20,405:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:20,406:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:20,407:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:20,409:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:21,191:INFO:Calculating mean and std
2023-07-03 09:00:21,192:INFO:Creating metrics dataframe
2023-07-03 09:00:21,338:INFO:Uploading results into container
2023-07-03 09:00:21,339:INFO:Uploading model into container now
2023-07-03 09:00:21,339:INFO:_master_model_container: 3
2023-07-03 09:00:21,339:INFO:_display_container: 2
2023-07-03 09:00:21,340:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-07-03 09:00:21,340:INFO:create_model() successfully completed......................................
2023-07-03 09:00:21,485:INFO:SubProcess create_model() end ==================================
2023-07-03 09:00:21,485:INFO:Creating metrics dataframe
2023-07-03 09:00:21,494:INFO:Initializing Decision Tree Classifier
2023-07-03 09:00:21,494:INFO:Total runtime is 0.18941126267115274 minutes
2023-07-03 09:00:21,497:INFO:SubProcess create_model() called ==================================
2023-07-03 09:00:21,498:INFO:Initializing create_model()
2023-07-03 09:00:21,498:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027231F26FE0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027231D95B10>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:00:21,498:INFO:Checking exceptions
2023-07-03 09:00:21,498:INFO:Importing libraries
2023-07-03 09:00:21,498:INFO:Copying training dataset
2023-07-03 09:00:21,502:INFO:Defining folds
2023-07-03 09:00:21,502:INFO:Declaring metric variables
2023-07-03 09:00:21,505:INFO:Importing untrained model
2023-07-03 09:00:21,508:INFO:Decision Tree Classifier Imported successfully
2023-07-03 09:00:21,513:INFO:Starting cross validation
2023-07-03 09:00:21,515:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:00:21,517:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2023-07-03 09:00:21,941:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:21,943:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:21,944:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:21,944:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:21,944:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:21,945:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:21,945:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:21,946:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:21,946:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:21,946:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:21,947:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:21,948:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:21,949:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:21,950:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:21,964:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:21,965:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:21,966:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:21,967:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:21,968:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:21,975:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:21,976:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:21,977:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:21,978:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:21,979:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:21,980:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:21,981:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:21,981:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:21,982:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:21,983:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:21,984:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:21,985:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:21,985:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:21,986:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:21,987:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:21,987:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:21,988:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:21,988:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:21,990:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:21,994:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:21,995:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:21,996:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:21,997:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:21,999:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:22,000:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:22,001:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:22,011:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:22,012:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:22,012:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:22,013:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:22,014:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:22,015:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:22,015:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:22,016:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:22,016:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:22,017:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:22,018:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:22,018:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:22,034:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:22,035:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:22,038:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:22,039:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:22,040:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:22,845:INFO:Calculating mean and std
2023-07-03 09:00:22,847:INFO:Creating metrics dataframe
2023-07-03 09:00:22,994:INFO:Uploading results into container
2023-07-03 09:00:22,994:INFO:Uploading model into container now
2023-07-03 09:00:22,995:INFO:_master_model_container: 4
2023-07-03 09:00:22,995:INFO:_display_container: 2
2023-07-03 09:00:22,995:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-07-03 09:00:22,996:INFO:create_model() successfully completed......................................
2023-07-03 09:00:23,130:INFO:SubProcess create_model() end ==================================
2023-07-03 09:00:23,130:INFO:Creating metrics dataframe
2023-07-03 09:00:23,140:INFO:Initializing SVM - Linear Kernel
2023-07-03 09:00:23,140:INFO:Total runtime is 0.21683723926544188 minutes
2023-07-03 09:00:23,143:INFO:SubProcess create_model() called ==================================
2023-07-03 09:00:23,144:INFO:Initializing create_model()
2023-07-03 09:00:23,144:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027231F26FE0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027231D95B10>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:00:23,144:INFO:Checking exceptions
2023-07-03 09:00:23,144:INFO:Importing libraries
2023-07-03 09:00:23,144:INFO:Copying training dataset
2023-07-03 09:00:23,149:INFO:Defining folds
2023-07-03 09:00:23,149:INFO:Declaring metric variables
2023-07-03 09:00:23,152:INFO:Importing untrained model
2023-07-03 09:00:23,155:INFO:SVM - Linear Kernel Imported successfully
2023-07-03 09:00:23,161:INFO:Starting cross validation
2023-07-03 09:00:23,163:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:00:23,164:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2023-07-03 09:00:23,563:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 09:00:23,563:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 09:00:23,564:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:23,564:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:23,564:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:23,564:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:23,565:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:23,565:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:23,565:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:23,566:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:23,566:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:23,566:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:23,567:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:23,567:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:23,567:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:23,568:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:23,568:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:23,568:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 09:00:23,568:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:23,569:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:23,569:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:23,569:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:23,570:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:23,571:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:23,572:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:23,573:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:23,573:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 09:00:23,574:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:23,574:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:23,576:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:23,577:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:23,578:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:23,579:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:23,580:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:23,581:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 09:00:23,582:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:23,583:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:23,584:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:23,585:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:23,585:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:23,586:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:23,588:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 09:00:23,589:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 09:00:23,589:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:23,589:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:23,590:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:23,591:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:23,591:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:23,591:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:23,593:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:23,593:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:23,593:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:23,594:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:23,594:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:23,595:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:23,606:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 09:00:23,607:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:23,608:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:23,610:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:23,611:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:23,612:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:23,613:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:23,619:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 09:00:23,620:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:23,623:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:23,624:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:23,625:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:24,490:INFO:Calculating mean and std
2023-07-03 09:00:24,492:INFO:Creating metrics dataframe
2023-07-03 09:00:24,639:INFO:Uploading results into container
2023-07-03 09:00:24,639:INFO:Uploading model into container now
2023-07-03 09:00:24,640:INFO:_master_model_container: 5
2023-07-03 09:00:24,640:INFO:_display_container: 2
2023-07-03 09:00:24,640:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-07-03 09:00:24,640:INFO:create_model() successfully completed......................................
2023-07-03 09:00:24,786:INFO:SubProcess create_model() end ==================================
2023-07-03 09:00:24,786:INFO:Creating metrics dataframe
2023-07-03 09:00:24,796:INFO:Initializing Ridge Classifier
2023-07-03 09:00:24,796:INFO:Total runtime is 0.244438099861145 minutes
2023-07-03 09:00:24,799:INFO:SubProcess create_model() called ==================================
2023-07-03 09:00:24,799:INFO:Initializing create_model()
2023-07-03 09:00:24,799:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027231F26FE0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027231D95B10>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:00:24,799:INFO:Checking exceptions
2023-07-03 09:00:24,799:INFO:Importing libraries
2023-07-03 09:00:24,799:INFO:Copying training dataset
2023-07-03 09:00:24,804:INFO:Defining folds
2023-07-03 09:00:24,804:INFO:Declaring metric variables
2023-07-03 09:00:24,806:INFO:Importing untrained model
2023-07-03 09:00:24,809:INFO:Ridge Classifier Imported successfully
2023-07-03 09:00:24,815:INFO:Starting cross validation
2023-07-03 09:00:24,817:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:00:24,818:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2023-07-03 09:00:25,190:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 09:00:25,190:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 09:00:25,190:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 09:00:25,191:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:25,191:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:25,191:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:25,192:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:25,192:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:25,192:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:25,193:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:25,193:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:25,193:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:25,194:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:25,194:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:25,195:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:25,195:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:25,195:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:25,196:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:25,196:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:25,196:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:25,197:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:25,199:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 09:00:25,200:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:25,201:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:25,202:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:25,203:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:25,205:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:25,206:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:25,206:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 09:00:25,207:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:25,209:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:25,209:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:25,211:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:25,212:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:25,213:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:25,226:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 09:00:25,227:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:25,229:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:25,230:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:25,231:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:25,232:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:25,232:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 09:00:25,233:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:25,234:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:25,235:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:25,237:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:25,238:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:25,239:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:25,240:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:25,247:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 09:00:25,248:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:25,249:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:25,250:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:25,251:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:25,252:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:25,254:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:25,267:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 09:00:25,268:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:25,270:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:25,271:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:25,272:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:25,273:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:25,274:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:25,276:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 09:00:25,277:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:25,279:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:25,281:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:25,282:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:26,082:INFO:Calculating mean and std
2023-07-03 09:00:26,084:INFO:Creating metrics dataframe
2023-07-03 09:00:26,234:INFO:Uploading results into container
2023-07-03 09:00:26,235:INFO:Uploading model into container now
2023-07-03 09:00:26,235:INFO:_master_model_container: 6
2023-07-03 09:00:26,235:INFO:_display_container: 2
2023-07-03 09:00:26,236:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-07-03 09:00:26,236:INFO:create_model() successfully completed......................................
2023-07-03 09:00:26,371:INFO:SubProcess create_model() end ==================================
2023-07-03 09:00:26,371:INFO:Creating metrics dataframe
2023-07-03 09:00:26,380:INFO:Initializing Random Forest Classifier
2023-07-03 09:00:26,380:INFO:Total runtime is 0.2708468755086263 minutes
2023-07-03 09:00:26,383:INFO:SubProcess create_model() called ==================================
2023-07-03 09:00:26,383:INFO:Initializing create_model()
2023-07-03 09:00:26,383:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027231F26FE0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027231D95B10>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:00:26,383:INFO:Checking exceptions
2023-07-03 09:00:26,383:INFO:Importing libraries
2023-07-03 09:00:26,383:INFO:Copying training dataset
2023-07-03 09:00:26,388:INFO:Defining folds
2023-07-03 09:00:26,388:INFO:Declaring metric variables
2023-07-03 09:00:26,391:INFO:Importing untrained model
2023-07-03 09:00:26,394:INFO:Random Forest Classifier Imported successfully
2023-07-03 09:00:26,399:INFO:Starting cross validation
2023-07-03 09:00:26,401:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:00:26,403:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2023-07-03 09:00:26,982:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:26,983:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:26,984:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:26,985:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:26,986:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:26,986:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:26,987:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:26,992:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:26,993:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:26,993:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:26,994:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:26,994:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:26,995:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:26,996:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:26,997:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:26,997:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:26,998:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:26,998:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:26,999:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:27,045:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:27,046:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:27,047:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:27,048:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:27,049:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:27,050:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:27,051:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:27,060:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:27,061:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:27,063:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:27,063:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:27,064:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:27,065:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:27,065:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:27,065:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:27,066:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:27,067:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:27,067:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:27,069:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:27,070:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:27,071:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:27,079:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:27,080:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:27,080:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:27,081:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:27,081:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:27,082:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:27,082:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:27,083:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:27,084:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:27,084:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:27,085:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:27,085:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:27,086:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:27,087:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:27,095:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:27,096:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:27,097:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:27,098:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:27,099:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:27,099:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:27,100:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:27,101:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:27,101:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:27,102:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:27,103:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:27,104:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:27,105:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:27,106:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:27,880:INFO:Calculating mean and std
2023-07-03 09:00:27,881:INFO:Creating metrics dataframe
2023-07-03 09:00:28,025:INFO:Uploading results into container
2023-07-03 09:00:28,025:INFO:Uploading model into container now
2023-07-03 09:00:28,026:INFO:_master_model_container: 7
2023-07-03 09:00:28,026:INFO:_display_container: 2
2023-07-03 09:00:28,026:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-07-03 09:00:28,026:INFO:create_model() successfully completed......................................
2023-07-03 09:00:28,169:INFO:SubProcess create_model() end ==================================
2023-07-03 09:00:28,169:INFO:Creating metrics dataframe
2023-07-03 09:00:28,179:INFO:Initializing Quadratic Discriminant Analysis
2023-07-03 09:00:28,180:INFO:Total runtime is 0.3008405844370524 minutes
2023-07-03 09:00:28,183:INFO:SubProcess create_model() called ==================================
2023-07-03 09:00:28,183:INFO:Initializing create_model()
2023-07-03 09:00:28,183:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027231F26FE0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027231D95B10>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:00:28,183:INFO:Checking exceptions
2023-07-03 09:00:28,183:INFO:Importing libraries
2023-07-03 09:00:28,183:INFO:Copying training dataset
2023-07-03 09:00:28,188:INFO:Defining folds
2023-07-03 09:00:28,188:INFO:Declaring metric variables
2023-07-03 09:00:28,191:INFO:Importing untrained model
2023-07-03 09:00:28,194:INFO:Quadratic Discriminant Analysis Imported successfully
2023-07-03 09:00:28,199:INFO:Starting cross validation
2023-07-03 09:00:28,201:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:00:28,203:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2023-07-03 09:00:28,499:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-03 09:00:28,506:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-03 09:00:28,523:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-03 09:00:28,541:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-03 09:00:28,544:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-03 09:00:28,572:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-03 09:00:28,575:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-03 09:00:28,578:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-03 09:00:28,587:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-03 09:00:28,809:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:28,809:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:28,810:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:28,811:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:28,811:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:29,394:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:378: FitFailedWarning: 
9 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
9 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py", line 917, in fit
    raise ValueError(
ValueError: y has only 1 sample in class 1, covariance is ill defined.

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2023-07-03 09:00:29,395:INFO:Calculating mean and std
2023-07-03 09:00:29,396:INFO:Creating metrics dataframe
2023-07-03 09:00:29,541:INFO:Uploading results into container
2023-07-03 09:00:29,542:INFO:Uploading model into container now
2023-07-03 09:00:29,543:INFO:_master_model_container: 8
2023-07-03 09:00:29,543:INFO:_display_container: 2
2023-07-03 09:00:29,543:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-07-03 09:00:29,543:INFO:create_model() successfully completed......................................
2023-07-03 09:00:29,684:WARNING:create_model() for QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001) raised an exception or returned all 0.0, trying without fit_kwargs:
2023-07-03 09:00:29,697:WARNING:Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

2023-07-03 09:00:29,697:INFO:Initializing create_model()
2023-07-03 09:00:29,697:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027231F26FE0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027231D95B10>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:00:29,697:INFO:Checking exceptions
2023-07-03 09:00:29,697:INFO:Importing libraries
2023-07-03 09:00:29,697:INFO:Copying training dataset
2023-07-03 09:00:29,701:INFO:Defining folds
2023-07-03 09:00:29,701:INFO:Declaring metric variables
2023-07-03 09:00:29,704:INFO:Importing untrained model
2023-07-03 09:00:29,707:INFO:Quadratic Discriminant Analysis Imported successfully
2023-07-03 09:00:29,712:INFO:Starting cross validation
2023-07-03 09:00:29,714:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:00:29,716:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2023-07-03 09:00:29,990:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-03 09:00:30,003:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-03 09:00:30,040:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-03 09:00:30,043:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-03 09:00:30,044:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-03 09:00:30,048:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-03 09:00:30,053:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-03 09:00:30,087:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-03 09:00:30,091:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-03 09:00:30,092:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-03 09:00:30,304:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:30,305:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:30,307:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:30,307:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:30,308:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:30,888:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:378: FitFailedWarning: 
9 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
9 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py", line 917, in fit
    raise ValueError(
ValueError: y has only 1 sample in class 1, covariance is ill defined.

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2023-07-03 09:00:30,888:INFO:Calculating mean and std
2023-07-03 09:00:30,889:INFO:Creating metrics dataframe
2023-07-03 09:00:31,033:INFO:Uploading results into container
2023-07-03 09:00:31,034:INFO:Uploading model into container now
2023-07-03 09:00:31,034:INFO:_master_model_container: 9
2023-07-03 09:00:31,034:INFO:_display_container: 2
2023-07-03 09:00:31,035:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-07-03 09:00:31,035:INFO:create_model() successfully completed......................................
2023-07-03 09:00:31,177:ERROR:create_model() for QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001) raised an exception or returned all 0.0:
2023-07-03 09:00:31,177:ERROR:Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 811, in compare_models
    np.sum(
AssertionError

2023-07-03 09:00:31,178:INFO:Initializing Ada Boost Classifier
2023-07-03 09:00:31,178:INFO:Total runtime is 0.35079972743988036 minutes
2023-07-03 09:00:31,181:INFO:SubProcess create_model() called ==================================
2023-07-03 09:00:31,181:INFO:Initializing create_model()
2023-07-03 09:00:31,181:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027231F26FE0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027231D95B10>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:00:31,181:INFO:Checking exceptions
2023-07-03 09:00:31,181:INFO:Importing libraries
2023-07-03 09:00:31,181:INFO:Copying training dataset
2023-07-03 09:00:31,185:INFO:Defining folds
2023-07-03 09:00:31,185:INFO:Declaring metric variables
2023-07-03 09:00:31,189:INFO:Importing untrained model
2023-07-03 09:00:31,191:INFO:Ada Boost Classifier Imported successfully
2023-07-03 09:00:31,196:INFO:Starting cross validation
2023-07-03 09:00:31,198:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:00:31,199:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2023-07-03 09:00:31,638:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:31,638:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:31,640:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:31,641:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:31,642:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:31,698:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:31,699:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:31,701:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:31,701:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:31,702:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:31,703:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:31,704:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:31,731:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:31,732:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:31,733:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:31,733:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:31,734:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:31,778:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:31,778:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:31,778:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:31,779:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:31,779:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:31,780:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:31,780:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:31,780:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:31,781:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:31,782:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:31,782:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:31,783:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:31,784:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:31,809:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:31,810:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:31,810:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:31,811:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:31,812:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:31,812:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:31,813:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:31,813:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:31,814:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:31,815:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:31,815:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:31,816:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:31,833:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:31,834:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:31,835:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:31,836:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:31,837:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:31,838:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:31,839:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:31,916:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:31,916:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:31,917:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:31,918:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:31,919:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:31,919:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:31,920:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:31,929:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:31,929:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:31,930:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:31,931:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:31,931:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:31,932:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:31,933:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:32,554:INFO:Calculating mean and std
2023-07-03 09:00:32,556:INFO:Creating metrics dataframe
2023-07-03 09:00:32,700:INFO:Uploading results into container
2023-07-03 09:00:32,701:INFO:Uploading model into container now
2023-07-03 09:00:32,701:INFO:_master_model_container: 10
2023-07-03 09:00:32,701:INFO:_display_container: 2
2023-07-03 09:00:32,701:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-07-03 09:00:32,701:INFO:create_model() successfully completed......................................
2023-07-03 09:00:32,836:INFO:SubProcess create_model() end ==================================
2023-07-03 09:00:32,836:INFO:Creating metrics dataframe
2023-07-03 09:00:32,846:INFO:Initializing Gradient Boosting Classifier
2023-07-03 09:00:32,846:INFO:Total runtime is 0.378604777654012 minutes
2023-07-03 09:00:32,849:INFO:SubProcess create_model() called ==================================
2023-07-03 09:00:32,849:INFO:Initializing create_model()
2023-07-03 09:00:32,849:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027231F26FE0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027231D95B10>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:00:32,849:INFO:Checking exceptions
2023-07-03 09:00:32,849:INFO:Importing libraries
2023-07-03 09:00:32,849:INFO:Copying training dataset
2023-07-03 09:00:32,854:INFO:Defining folds
2023-07-03 09:00:32,854:INFO:Declaring metric variables
2023-07-03 09:00:32,857:INFO:Importing untrained model
2023-07-03 09:00:32,860:INFO:Gradient Boosting Classifier Imported successfully
2023-07-03 09:00:32,865:INFO:Starting cross validation
2023-07-03 09:00:32,867:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:00:32,869:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2023-07-03 09:00:33,531:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:33,532:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:33,534:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:33,535:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:33,536:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:33,986:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:33,987:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:33,988:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:33,989:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:33,990:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:33,991:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:33,992:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:34,003:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:34,003:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:34,004:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:34,005:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:34,006:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:34,011:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:34,011:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:34,012:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:34,012:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:34,013:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:34,013:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:34,014:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:34,014:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:34,015:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:34,016:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:34,016:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:34,017:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:34,017:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:34,018:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:34,021:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:34,022:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:34,023:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:34,024:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:34,024:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:34,025:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:34,026:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:34,027:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:34,028:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:34,029:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:34,030:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:34,031:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:34,040:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:34,041:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:34,042:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:34,043:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:34,044:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:34,045:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:34,046:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:34,055:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:34,056:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:34,057:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:34,058:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:34,059:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:34,060:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:34,061:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:34,101:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:34,102:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:34,103:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:34,104:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:34,105:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:34,106:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:34,107:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:34,783:INFO:Calculating mean and std
2023-07-03 09:00:34,784:INFO:Creating metrics dataframe
2023-07-03 09:00:34,932:INFO:Uploading results into container
2023-07-03 09:00:34,933:INFO:Uploading model into container now
2023-07-03 09:00:34,933:INFO:_master_model_container: 11
2023-07-03 09:00:34,934:INFO:_display_container: 2
2023-07-03 09:00:34,934:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-03 09:00:34,934:INFO:create_model() successfully completed......................................
2023-07-03 09:00:35,071:INFO:SubProcess create_model() end ==================================
2023-07-03 09:00:35,071:INFO:Creating metrics dataframe
2023-07-03 09:00:35,083:INFO:Initializing Linear Discriminant Analysis
2023-07-03 09:00:35,083:INFO:Total runtime is 0.41588982741038 minutes
2023-07-03 09:00:35,085:INFO:SubProcess create_model() called ==================================
2023-07-03 09:00:35,086:INFO:Initializing create_model()
2023-07-03 09:00:35,086:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027231F26FE0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027231D95B10>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:00:35,086:INFO:Checking exceptions
2023-07-03 09:00:35,086:INFO:Importing libraries
2023-07-03 09:00:35,086:INFO:Copying training dataset
2023-07-03 09:00:35,090:INFO:Defining folds
2023-07-03 09:00:35,090:INFO:Declaring metric variables
2023-07-03 09:00:35,093:INFO:Importing untrained model
2023-07-03 09:00:35,096:INFO:Linear Discriminant Analysis Imported successfully
2023-07-03 09:00:35,101:INFO:Starting cross validation
2023-07-03 09:00:35,103:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:00:35,104:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2023-07-03 09:00:35,492:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:35,493:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:35,494:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:35,495:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:35,496:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:35,497:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:35,497:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:35,498:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:35,498:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:35,498:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:35,499:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:35,499:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:35,500:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:35,500:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:35,501:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:35,501:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:35,503:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:35,503:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:35,504:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:35,504:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:35,505:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:35,506:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:35,507:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:35,508:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:35,509:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:35,510:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:35,513:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:35,514:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:35,515:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:35,516:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:35,517:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:35,518:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:35,519:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:35,531:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:35,532:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:35,533:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:35,533:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:35,534:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:35,534:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:35,535:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:35,535:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:35,536:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:35,536:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:35,537:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

 is", len(true_sum))

2023-07-03 09:00:35,538:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:35,540:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:35,540:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:35,541:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:35,542:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:35,543:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:35,545:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:35,561:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:35,562:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:35,564:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:35,565:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:35,566:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:35,581:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:35,582:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:35,584:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:35,585:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:35,587:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:36,389:INFO:Calculating mean and std
2023-07-03 09:00:36,390:INFO:Creating metrics dataframe
2023-07-03 09:00:36,541:INFO:Uploading results into container
2023-07-03 09:00:36,542:INFO:Uploading model into container now
2023-07-03 09:00:36,542:INFO:_master_model_container: 12
2023-07-03 09:00:36,543:INFO:_display_container: 2
2023-07-03 09:00:36,543:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-07-03 09:00:36,543:INFO:create_model() successfully completed......................................
2023-07-03 09:00:36,685:INFO:SubProcess create_model() end ==================================
2023-07-03 09:00:36,685:INFO:Creating metrics dataframe
2023-07-03 09:00:36,694:INFO:Initializing Extra Trees Classifier
2023-07-03 09:00:36,695:INFO:Total runtime is 0.44275052944819127 minutes
2023-07-03 09:00:36,697:INFO:SubProcess create_model() called ==================================
2023-07-03 09:00:36,697:INFO:Initializing create_model()
2023-07-03 09:00:36,698:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027231F26FE0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027231D95B10>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:00:36,698:INFO:Checking exceptions
2023-07-03 09:00:36,698:INFO:Importing libraries
2023-07-03 09:00:36,698:INFO:Copying training dataset
2023-07-03 09:00:36,702:INFO:Defining folds
2023-07-03 09:00:36,702:INFO:Declaring metric variables
2023-07-03 09:00:36,705:INFO:Importing untrained model
2023-07-03 09:00:36,708:INFO:Extra Trees Classifier Imported successfully
2023-07-03 09:00:36,714:INFO:Starting cross validation
2023-07-03 09:00:36,715:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:00:36,717:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2023-07-03 09:00:37,301:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:37,302:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:37,303:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:37,304:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:37,305:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:37,306:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:37,307:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:37,326:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:37,326:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:37,327:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:37,327:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:37,328:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:37,328:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:37,329:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:37,329:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:37,330:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:37,331:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:37,331:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:37,332:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:37,332:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:37,332:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:37,333:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:37,333:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:37,335:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:37,336:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:37,337:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:37,338:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:37,339:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:37,348:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:37,349:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:37,351:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:37,352:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:37,353:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:37,354:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:37,356:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:37,367:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:37,368:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:37,369:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:37,370:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:37,371:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:37,372:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:37,373:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:37,377:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:37,378:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:37,379:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:37,380:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:37,381:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:37,382:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:37,383:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:37,416:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:37,417:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:37,418:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:37,419:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:37,420:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:37,421:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:37,421:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:37,422:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:37,422:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:37,423:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:37,423:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:37,424:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:37,425:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:37,426:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:37,426:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:37,427:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:37,428:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:37,429:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:38,215:INFO:Calculating mean and std
2023-07-03 09:00:38,216:INFO:Creating metrics dataframe
2023-07-03 09:00:38,369:INFO:Uploading results into container
2023-07-03 09:00:38,369:INFO:Uploading model into container now
2023-07-03 09:00:38,370:INFO:_master_model_container: 13
2023-07-03 09:00:38,370:INFO:_display_container: 2
2023-07-03 09:00:38,370:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-07-03 09:00:38,371:INFO:create_model() successfully completed......................................
2023-07-03 09:00:38,508:INFO:SubProcess create_model() end ==================================
2023-07-03 09:00:38,508:INFO:Creating metrics dataframe
2023-07-03 09:00:38,518:INFO:Initializing Light Gradient Boosting Machine
2023-07-03 09:00:38,518:INFO:Total runtime is 0.4731433431307474 minutes
2023-07-03 09:00:38,522:INFO:SubProcess create_model() called ==================================
2023-07-03 09:00:38,522:INFO:Initializing create_model()
2023-07-03 09:00:38,522:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027231F26FE0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027231D95B10>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:00:38,522:INFO:Checking exceptions
2023-07-03 09:00:38,522:INFO:Importing libraries
2023-07-03 09:00:38,522:INFO:Copying training dataset
2023-07-03 09:00:38,526:INFO:Defining folds
2023-07-03 09:00:38,526:INFO:Declaring metric variables
2023-07-03 09:00:38,529:INFO:Importing untrained model
2023-07-03 09:00:38,532:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-03 09:00:38,538:INFO:Starting cross validation
2023-07-03 09:00:38,540:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:00:38,541:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2023-07-03 09:00:39,968:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:39,969:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:39,969:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:39,970:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:39,970:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:39,971:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:39,971:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:39,972:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:39,972:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:39,973:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:39,973:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:39,974:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:39,974:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:39,975:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:39,980:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:39,980:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:39,981:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:39,982:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:39,983:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:39,984:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:39,984:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:40,007:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:40,007:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:40,009:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:40,010:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:40,011:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:40,011:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:40,012:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:40,068:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:40,069:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:40,070:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:40,071:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:40,072:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:40,073:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:40,074:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:40,087:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:40,088:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:40,089:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:40,090:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:40,092:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:40,093:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:40,094:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:40,094:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:40,095:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:40,097:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:40,098:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:40,099:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:40,111:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:40,112:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:40,114:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:40,115:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:40,116:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:40,117:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:40,118:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:40,149:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:40,150:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:40,151:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:40,152:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:40,153:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:40,154:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:40,154:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:40,173:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:40,173:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:40,175:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:40,176:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:40,177:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:40,178:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:40,179:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:40,881:INFO:Calculating mean and std
2023-07-03 09:00:40,882:INFO:Creating metrics dataframe
2023-07-03 09:00:41,038:INFO:Uploading results into container
2023-07-03 09:00:41,039:INFO:Uploading model into container now
2023-07-03 09:00:41,039:INFO:_master_model_container: 14
2023-07-03 09:00:41,039:INFO:_display_container: 2
2023-07-03 09:00:41,040:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-07-03 09:00:41,040:INFO:create_model() successfully completed......................................
2023-07-03 09:00:41,178:INFO:SubProcess create_model() end ==================================
2023-07-03 09:00:41,178:INFO:Creating metrics dataframe
2023-07-03 09:00:41,189:INFO:Initializing Dummy Classifier
2023-07-03 09:00:41,189:INFO:Total runtime is 0.5176609834035237 minutes
2023-07-03 09:00:41,191:INFO:SubProcess create_model() called ==================================
2023-07-03 09:00:41,192:INFO:Initializing create_model()
2023-07-03 09:00:41,192:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027231F26FE0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027231D95B10>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:00:41,192:INFO:Checking exceptions
2023-07-03 09:00:41,192:INFO:Importing libraries
2023-07-03 09:00:41,192:INFO:Copying training dataset
2023-07-03 09:00:41,197:INFO:Defining folds
2023-07-03 09:00:41,198:INFO:Declaring metric variables
2023-07-03 09:00:41,201:INFO:Importing untrained model
2023-07-03 09:00:41,203:INFO:Dummy Classifier Imported successfully
2023-07-03 09:00:41,208:INFO:Starting cross validation
2023-07-03 09:00:41,210:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:00:41,211:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2023-07-03 09:00:41,562:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:41,562:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:41,563:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:41,563:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:41,563:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:41,564:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:41,564:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:41,565:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:41,565:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:41,565:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:41,566:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:41,566:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:41,567:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:41,568:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:41,592:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:41,593:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:41,594:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:41,595:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:41,596:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:41,597:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:41,598:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:41,600:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:41,601:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:41,603:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:41,604:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:41,604:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:41,605:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:41,606:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:41,607:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:41,608:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:41,609:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:41,610:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:41,611:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:41,617:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:41,617:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:41,618:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:41,619:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:41,619:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:41,620:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:41,621:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:41,646:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:41,647:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:41,648:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:41,649:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:41,651:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:41,652:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:41,653:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:41,658:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:41,659:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:41,660:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:41,661:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:41,663:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:41,664:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:41,665:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:41,668:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:41,669:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:41,670:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:41,671:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:00:41,672:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:41,672:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:41,673:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:41,674:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:41,674:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:41,675:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:41,675:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:41,676:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:00:41,677:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:00:41,678:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:00:42,458:INFO:Calculating mean and std
2023-07-03 09:00:42,463:INFO:Creating metrics dataframe
2023-07-03 09:00:42,616:INFO:Uploading results into container
2023-07-03 09:00:42,617:INFO:Uploading model into container now
2023-07-03 09:00:42,617:INFO:_master_model_container: 15
2023-07-03 09:00:42,617:INFO:_display_container: 2
2023-07-03 09:00:42,618:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-07-03 09:00:42,618:INFO:create_model() successfully completed......................................
2023-07-03 09:00:42,755:INFO:SubProcess create_model() end ==================================
2023-07-03 09:00:42,755:INFO:Creating metrics dataframe
2023-07-03 09:00:42,773:INFO:Initializing create_model()
2023-07-03 09:00:42,773:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027231F26FE0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:00:42,773:INFO:Checking exceptions
2023-07-03 09:00:42,775:INFO:Importing libraries
2023-07-03 09:00:42,775:INFO:Copying training dataset
2023-07-03 09:00:42,779:INFO:Defining folds
2023-07-03 09:00:42,779:INFO:Declaring metric variables
2023-07-03 09:00:42,779:INFO:Importing untrained model
2023-07-03 09:00:42,779:INFO:Declaring custom model
2023-07-03 09:00:42,779:INFO:Random Forest Classifier Imported successfully
2023-07-03 09:00:42,781:INFO:Cross validation set to False
2023-07-03 09:00:42,781:INFO:Fitting Model
2023-07-03 09:00:43,074:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-07-03 09:00:43,074:INFO:create_model() successfully completed......................................
2023-07-03 09:00:43,234:INFO:_master_model_container: 15
2023-07-03 09:00:43,235:INFO:_display_container: 2
2023-07-03 09:00:43,235:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-07-03 09:00:43,235:INFO:compare_models() successfully completed......................................
2023-07-03 09:01:00,428:INFO:Initializing create_model()
2023-07-03 09:01:00,428:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027231F26FE0>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:01:00,428:INFO:Checking exceptions
2023-07-03 09:01:00,449:INFO:Importing libraries
2023-07-03 09:01:00,450:INFO:Copying training dataset
2023-07-03 09:01:00,454:INFO:Defining folds
2023-07-03 09:01:00,454:INFO:Declaring metric variables
2023-07-03 09:01:00,456:INFO:Importing untrained model
2023-07-03 09:01:00,460:INFO:Random Forest Classifier Imported successfully
2023-07-03 09:01:00,465:INFO:Starting cross validation
2023-07-03 09:01:00,467:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:01:00,469:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2023-07-03 09:01:01,012:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:01:01,013:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:01:01,014:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:01:01,015:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:01:01,016:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:01:01,017:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:01:01,018:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:01:01,067:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:01:01,068:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:01:01,070:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:01:01,071:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:01:01,072:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:01:01,073:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:01:01,074:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:01:01,076:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:01:01,077:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:01:01,078:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:01:01,079:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:01:01,080:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:01:01,081:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:01:01,083:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:01:01,115:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:01:01,116:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:01:01,118:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:01:01,119:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:01:01,120:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:01:01,121:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:01:01,123:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:01:01,123:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:01:01,124:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:01:01,124:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:01:01,125:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:01:01,126:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:01:01,126:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:01:01,127:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:01:01,127:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:01:01,128:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:01:01,128:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:01:01,129:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:01:01,129:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:01:01,130:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:01:01,131:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:01:01,156:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:01:01,157:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:01:01,158:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:01:01,159:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:01:01,160:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:01:01,164:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:01:01,165:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:01:01,166:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:01:01,168:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:01:01,169:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:01:01,170:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:01:01,171:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:01:01,222:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:01:01,223:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:01:01,224:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:01:01,225:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:01:01,227:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:01:01,228:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:01:01,229:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:01:01,241:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:01:01,242:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:01:01,243:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:01:01,244:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:01:01,246:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:01:01,247:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:01:01,248:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:01:01,981:INFO:Calculating mean and std
2023-07-03 09:01:01,982:INFO:Creating metrics dataframe
2023-07-03 09:01:01,988:INFO:Finalizing model
2023-07-03 09:01:02,353:INFO:Uploading results into container
2023-07-03 09:01:02,354:INFO:Uploading model into container now
2023-07-03 09:01:02,362:INFO:_master_model_container: 16
2023-07-03 09:01:02,362:INFO:_display_container: 3
2023-07-03 09:01:02,362:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-07-03 09:01:02,363:INFO:create_model() successfully completed......................................
2023-07-03 09:01:54,291:INFO:Initializing tune_model()
2023-07-03 09:01:54,291:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027231F26FE0>)
2023-07-03 09:01:54,291:INFO:Checking exceptions
2023-07-03 09:01:54,305:INFO:Copying training dataset
2023-07-03 09:01:54,309:INFO:Checking base model
2023-07-03 09:01:54,309:INFO:Base model : Random Forest Classifier
2023-07-03 09:01:54,312:INFO:Declaring metric variables
2023-07-03 09:01:54,315:INFO:Defining Hyperparameters
2023-07-03 09:01:54,479:INFO:Tuning with n_jobs=-1
2023-07-03 09:01:54,479:INFO:Initializing RandomizedSearchCV
2023-07-03 09:01:54,483:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2023-07-03 09:02:06,599:INFO:best_params: {'actual_estimator__n_estimators': 190, 'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0.001, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 6, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': 'balanced_subsample', 'actual_estimator__bootstrap': False}
2023-07-03 09:02:06,600:INFO:Hyperparameter search completed
2023-07-03 09:02:06,600:INFO:SubProcess create_model() called ==================================
2023-07-03 09:02:06,600:INFO:Initializing create_model()
2023-07-03 09:02:06,601:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027231F26FE0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027239577DC0>, model_only=True, return_train_score=False, kwargs={'n_estimators': 190, 'min_samples_split': 9, 'min_samples_leaf': 6, 'min_impurity_decrease': 0.001, 'max_features': 'log2', 'max_depth': 6, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'bootstrap': False})
2023-07-03 09:02:06,601:INFO:Checking exceptions
2023-07-03 09:02:06,601:INFO:Importing libraries
2023-07-03 09:02:06,601:INFO:Copying training dataset
2023-07-03 09:02:06,606:INFO:Defining folds
2023-07-03 09:02:06,606:INFO:Declaring metric variables
2023-07-03 09:02:06,609:INFO:Importing untrained model
2023-07-03 09:02:06,609:INFO:Declaring custom model
2023-07-03 09:02:06,612:INFO:Random Forest Classifier Imported successfully
2023-07-03 09:02:06,617:INFO:Starting cross validation
2023-07-03 09:02:06,619:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:02:06,621:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2023-07-03 09:02:07,430:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:02:07,431:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:07,432:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:07,433:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:07,435:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:07,436:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:07,437:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:02:07,445:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:02:07,446:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:07,447:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:07,448:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:07,449:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:07,451:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:07,452:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:02:07,469:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:02:07,470:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:07,472:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:07,473:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:07,474:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:07,475:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:07,476:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:02:07,492:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:02:07,492:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:02:07,493:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:07,493:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:02:07,494:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:07,494:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:07,495:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:07,495:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:07,496:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:07,496:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:07,496:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:07,496:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:07,497:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:07,498:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:07,498:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:07,499:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:02:07,499:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:07,499:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:07,501:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:02:07,501:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:02:07,504:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:02:07,505:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:07,506:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:07,507:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:07,508:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:02:07,509:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:07,509:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:07,510:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:07,511:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:07,511:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:02:07,512:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:07,513:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:07,514:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:07,515:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:02:07,529:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:02:07,531:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:07,532:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:07,533:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:07,534:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:07,535:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:07,537:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:02:07,575:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:02:07,577:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:07,579:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:07,581:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:07,582:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:08,384:INFO:Calculating mean and std
2023-07-03 09:02:08,386:INFO:Creating metrics dataframe
2023-07-03 09:02:08,391:INFO:Finalizing model
2023-07-03 09:02:08,787:INFO:Uploading results into container
2023-07-03 09:02:08,788:INFO:Uploading model into container now
2023-07-03 09:02:08,789:INFO:_master_model_container: 17
2023-07-03 09:02:08,789:INFO:_display_container: 4
2023-07-03 09:02:08,789:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='gini',
                       max_depth=6, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.001,
                       min_samples_leaf=6, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, n_estimators=190,
                       n_jobs=-1, oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2023-07-03 09:02:08,789:INFO:create_model() successfully completed......................................
2023-07-03 09:02:08,953:INFO:SubProcess create_model() end ==================================
2023-07-03 09:02:08,953:INFO:choose_better activated
2023-07-03 09:02:08,957:INFO:SubProcess create_model() called ==================================
2023-07-03 09:02:08,957:INFO:Initializing create_model()
2023-07-03 09:02:08,957:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027231F26FE0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:02:08,957:INFO:Checking exceptions
2023-07-03 09:02:08,959:INFO:Importing libraries
2023-07-03 09:02:08,959:INFO:Copying training dataset
2023-07-03 09:02:08,963:INFO:Defining folds
2023-07-03 09:02:08,963:INFO:Declaring metric variables
2023-07-03 09:02:08,963:INFO:Importing untrained model
2023-07-03 09:02:08,963:INFO:Declaring custom model
2023-07-03 09:02:08,964:INFO:Random Forest Classifier Imported successfully
2023-07-03 09:02:08,964:INFO:Starting cross validation
2023-07-03 09:02:08,966:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:02:08,967:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2023-07-03 09:02:09,521:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:02:09,522:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:09,523:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:09,524:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:09,525:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:09,525:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:09,526:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:02:09,547:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:02:09,548:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:09,550:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:09,551:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:09,552:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:09,553:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:09,554:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:02:09,568:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:02:09,568:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:09,570:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:09,571:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:09,572:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:09,572:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:09,574:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:02:09,583:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:02:09,584:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:09,585:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:09,587:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:09,588:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:09,589:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:09,589:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:02:09,590:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:02:09,591:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:09,592:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:09,593:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:09,594:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:09,595:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:09,596:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:02:09,613:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:02:09,614:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:09,616:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:09,617:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:09,618:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:09,636:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:02:09,637:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:09,638:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:09,639:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:09,640:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:09,641:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:09,642:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:02:09,663:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:02:09,664:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:09,665:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:09,666:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:09,667:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:09,668:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:09,669:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:02:09,679:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:02:09,680:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:09,681:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:09,682:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:09,684:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:09,685:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:09,686:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:02:09,718:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:02:09,719:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:09,721:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:09,722:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:09,723:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:09,724:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:09,725:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:02:10,483:INFO:Calculating mean and std
2023-07-03 09:02:10,484:INFO:Creating metrics dataframe
2023-07-03 09:02:10,486:INFO:Finalizing model
2023-07-03 09:02:10,843:INFO:Uploading results into container
2023-07-03 09:02:10,843:INFO:Uploading model into container now
2023-07-03 09:02:10,844:INFO:_master_model_container: 18
2023-07-03 09:02:10,844:INFO:_display_container: 5
2023-07-03 09:02:10,844:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-07-03 09:02:10,844:INFO:create_model() successfully completed......................................
2023-07-03 09:02:11,000:INFO:SubProcess create_model() end ==================================
2023-07-03 09:02:11,001:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False) result for Accuracy is 0.9964
2023-07-03 09:02:11,001:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='gini',
                       max_depth=6, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.001,
                       min_samples_leaf=6, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, n_estimators=190,
                       n_jobs=-1, oob_score=False, random_state=123, verbose=0,
                       warm_start=False) result for Accuracy is 0.9964
2023-07-03 09:02:11,001:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False) is best model
2023-07-03 09:02:11,001:INFO:choose_better completed
2023-07-03 09:02:11,002:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-07-03 09:02:11,011:INFO:_master_model_container: 18
2023-07-03 09:02:11,011:INFO:_display_container: 4
2023-07-03 09:02:11,011:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-07-03 09:02:11,011:INFO:tune_model() successfully completed......................................
2023-07-03 09:02:40,121:INFO:Initializing tune_model()
2023-07-03 09:02:40,121:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=True, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027231F26FE0>)
2023-07-03 09:02:40,121:INFO:Checking exceptions
2023-07-03 09:02:40,136:INFO:Copying training dataset
2023-07-03 09:02:40,140:INFO:Checking base model
2023-07-03 09:02:40,140:INFO:Base model : Random Forest Classifier
2023-07-03 09:02:40,144:INFO:Declaring metric variables
2023-07-03 09:02:40,147:INFO:Defining Hyperparameters
2023-07-03 09:02:40,311:INFO:Tuning with n_jobs=-1
2023-07-03 09:02:40,311:INFO:Initializing RandomizedSearchCV
2023-07-03 09:02:40,315:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2023-07-03 09:02:52,447:INFO:best_params: {'actual_estimator__n_estimators': 190, 'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0.001, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 6, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': 'balanced_subsample', 'actual_estimator__bootstrap': False}
2023-07-03 09:02:52,448:INFO:Hyperparameter search completed
2023-07-03 09:02:52,448:INFO:SubProcess create_model() called ==================================
2023-07-03 09:02:52,449:INFO:Initializing create_model()
2023-07-03 09:02:52,449:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027231F26FE0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027231E53AF0>, model_only=True, return_train_score=False, kwargs={'n_estimators': 190, 'min_samples_split': 9, 'min_samples_leaf': 6, 'min_impurity_decrease': 0.001, 'max_features': 'log2', 'max_depth': 6, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'bootstrap': False})
2023-07-03 09:02:52,449:INFO:Checking exceptions
2023-07-03 09:02:52,449:INFO:Importing libraries
2023-07-03 09:02:52,449:INFO:Copying training dataset
2023-07-03 09:02:52,453:INFO:Defining folds
2023-07-03 09:02:52,453:INFO:Declaring metric variables
2023-07-03 09:02:52,456:INFO:Importing untrained model
2023-07-03 09:02:52,456:INFO:Declaring custom model
2023-07-03 09:02:52,459:INFO:Random Forest Classifier Imported successfully
2023-07-03 09:02:52,464:INFO:Starting cross validation
2023-07-03 09:02:52,466:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:02:52,468:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2023-07-03 09:02:53,254:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:02:53,255:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:53,257:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:53,257:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:53,258:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:53,259:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:53,260:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:02:53,272:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:02:53,273:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:53,275:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:53,276:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:53,277:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:53,278:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:53,279:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:02:53,303:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:02:53,304:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:53,305:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:53,306:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:53,308:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:53,309:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:53,310:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:02:53,310:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:02:53,311:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:53,313:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:53,314:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:53,315:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:53,316:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:53,317:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:02:53,327:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:02:53,328:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:53,329:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:53,330:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:53,331:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:53,332:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:53,333:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:02:53,335:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:02:53,336:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:53,337:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:53,339:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:53,340:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:53,341:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:53,342:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:02:53,374:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:02:53,375:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:53,377:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:53,378:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:53,379:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:53,379:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:02:53,380:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:53,380:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:53,382:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:02:53,383:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:53,384:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:53,385:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:53,401:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:02:53,402:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:53,404:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:53,404:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:53,405:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:53,407:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:53,408:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:02:53,459:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:02:53,460:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:53,462:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:53,463:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:53,464:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:53,465:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:53,466:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:02:54,201:INFO:Calculating mean and std
2023-07-03 09:02:54,202:INFO:Creating metrics dataframe
2023-07-03 09:02:54,207:INFO:Finalizing model
2023-07-03 09:02:54,584:INFO:Uploading results into container
2023-07-03 09:02:54,585:INFO:Uploading model into container now
2023-07-03 09:02:54,585:INFO:_master_model_container: 19
2023-07-03 09:02:54,585:INFO:_display_container: 5
2023-07-03 09:02:54,586:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='gini',
                       max_depth=6, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.001,
                       min_samples_leaf=6, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, n_estimators=190,
                       n_jobs=-1, oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2023-07-03 09:02:54,586:INFO:create_model() successfully completed......................................
2023-07-03 09:02:54,755:INFO:SubProcess create_model() end ==================================
2023-07-03 09:02:54,755:INFO:choose_better activated
2023-07-03 09:02:54,758:INFO:SubProcess create_model() called ==================================
2023-07-03 09:02:54,758:INFO:Initializing create_model()
2023-07-03 09:02:54,759:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027231F26FE0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:02:54,759:INFO:Checking exceptions
2023-07-03 09:02:54,760:INFO:Importing libraries
2023-07-03 09:02:54,760:INFO:Copying training dataset
2023-07-03 09:02:54,764:INFO:Defining folds
2023-07-03 09:02:54,764:INFO:Declaring metric variables
2023-07-03 09:02:54,764:INFO:Importing untrained model
2023-07-03 09:02:54,764:INFO:Declaring custom model
2023-07-03 09:02:54,764:INFO:Random Forest Classifier Imported successfully
2023-07-03 09:02:54,765:INFO:Starting cross validation
2023-07-03 09:02:54,766:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:02:54,768:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2023-07-03 09:02:55,346:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:02:55,348:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:55,349:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:55,350:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:55,351:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:55,352:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:55,353:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:02:55,385:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:02:55,386:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:55,388:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:55,389:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:55,390:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:55,391:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:55,392:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:02:55,397:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:02:55,398:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:55,399:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:55,400:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:55,402:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:55,404:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:55,405:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:02:55,405:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:02:55,406:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:55,407:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:55,409:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:55,409:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:02:55,410:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:55,410:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:55,411:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:55,411:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:55,412:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:55,413:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:02:55,413:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:55,415:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:55,416:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:02:55,429:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:02:55,430:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:55,431:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:55,432:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:55,434:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:55,435:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:55,436:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:02:55,445:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:02:55,446:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:55,448:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:55,449:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:55,451:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:55,452:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:55,453:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:02:55,467:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:02:55,468:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:55,470:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:55,470:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:02:55,471:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:55,472:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:55,473:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:55,473:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:55,474:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:55,474:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:55,475:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:02:55,475:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:55,476:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:55,478:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:02:55,483:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:02:55,484:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:55,486:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:55,488:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:02:55,489:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:02:56,313:INFO:Calculating mean and std
2023-07-03 09:02:56,313:INFO:Creating metrics dataframe
2023-07-03 09:02:56,315:INFO:Finalizing model
2023-07-03 09:02:56,668:INFO:Uploading results into container
2023-07-03 09:02:56,669:INFO:Uploading model into container now
2023-07-03 09:02:56,669:INFO:_master_model_container: 20
2023-07-03 09:02:56,670:INFO:_display_container: 6
2023-07-03 09:02:56,670:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-07-03 09:02:56,670:INFO:create_model() successfully completed......................................
2023-07-03 09:02:56,844:INFO:SubProcess create_model() end ==================================
2023-07-03 09:02:56,845:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False) result for Accuracy is 0.9964
2023-07-03 09:02:56,845:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='gini',
                       max_depth=6, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.001,
                       min_samples_leaf=6, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, n_estimators=190,
                       n_jobs=-1, oob_score=False, random_state=123, verbose=0,
                       warm_start=False) result for Accuracy is 0.9964
2023-07-03 09:02:56,845:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False) is best model
2023-07-03 09:02:56,845:INFO:choose_better completed
2023-07-03 09:02:56,846:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-07-03 09:02:56,855:INFO:_master_model_container: 20
2023-07-03 09:02:56,856:INFO:_display_container: 5
2023-07-03 09:02:56,856:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-07-03 09:02:56,856:INFO:tune_model() successfully completed......................................
2023-07-03 09:04:21,823:INFO:Initializing plot_model()
2023-07-03 09:04:21,823:INFO:plot_model(plot=class_report, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027231F26FE0>, system=True)
2023-07-03 09:04:21,824:INFO:Checking exceptions
2023-07-03 09:04:21,839:INFO:Preloading libraries
2023-07-03 09:04:21,846:INFO:Copying training dataset
2023-07-03 09:04:21,847:INFO:Plot type: class_report
2023-07-03 09:04:22,237:INFO:Fitting Model
2023-07-03 09:04:22,251:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\base.py:420: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2023-07-03 09:04:22,251:INFO:Scoring test/hold-out set
2023-07-03 09:04:22,282:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:04:22,452:INFO:Visual Rendered Successfully
2023-07-03 09:04:22,619:INFO:plot_model() successfully completed......................................
2023-07-03 09:05:34,773:INFO:Initializing finalize_model()
2023-07-03 09:05:34,773:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027231F26FE0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-07-03 09:05:34,773:INFO:Finalizing RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-07-03 09:05:34,776:INFO:Initializing create_model()
2023-07-03 09:05:34,776:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027231F26FE0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-07-03 09:05:34,776:INFO:Checking exceptions
2023-07-03 09:05:34,778:INFO:Importing libraries
2023-07-03 09:05:34,778:INFO:Copying training dataset
2023-07-03 09:05:34,778:INFO:Defining folds
2023-07-03 09:05:34,778:INFO:Declaring metric variables
2023-07-03 09:05:34,778:INFO:Importing untrained model
2023-07-03 09:05:34,778:INFO:Declaring custom model
2023-07-03 09:05:34,779:INFO:Random Forest Classifier Imported successfully
2023-07-03 09:05:34,780:INFO:Cross validation set to False
2023-07-03 09:05:34,780:INFO:Fitting Model
2023-07-03 09:05:35,211:INFO:Pipeline(memory=FastMemory(location=C:\Users\JHossain\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['id', 'age', 'bp', 'sg', 'al',
                                             'su', 'bgr', 'bu', 'sc', 'sod',
                                             'pot', 'hemo'],
                                    transformer=SimpleImputer(add_...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='sqrt',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        n_estimators=100, n_jobs=-1,
                                        oob_score=False, random_state=123,
                                        verbose=0, warm_start=False))],
         verbose=False)
2023-07-03 09:05:35,211:INFO:create_model() successfully completed......................................
2023-07-03 09:05:35,372:INFO:_master_model_container: 20
2023-07-03 09:05:35,372:INFO:_display_container: 5
2023-07-03 09:05:35,433:INFO:Pipeline(memory=FastMemory(location=C:\Users\JHossain\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['id', 'age', 'bp', 'sg', 'al',
                                             'su', 'bgr', 'bu', 'sc', 'sod',
                                             'pot', 'hemo'],
                                    transformer=SimpleImputer(add_...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='sqrt',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        n_estimators=100, n_jobs=-1,
                                        oob_score=False, random_state=123,
                                        verbose=0, warm_start=False))],
         verbose=False)
2023-07-03 09:05:35,434:INFO:finalize_model() successfully completed......................................
2023-07-03 09:05:50,969:INFO:Initializing predict_model()
2023-07-03 09:05:50,969:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027231F26FE0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000027239DDFEB0>)
2023-07-03 09:05:50,970:INFO:Checking exceptions
2023-07-03 09:05:50,970:INFO:Preloading libraries
2023-07-03 09:05:51,227:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\utils\generic.py:586: UserWarning: Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 580, in _calculate_metric
    calculated_metric = score_func(y_test, target, sample_weight=weights, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 638, in _multiclass_roc_auc_score
    if not np.allclose(1, y_score.sum(axis=1)):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\numpy\core\_methods.py", line 48, in _sum
    return umr_sum(a, axis, dtype, out, keepdims, initial, where)
numpy.AxisError: axis 1 is out of bounds for array of dimension 1

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 584, in _calculate_metric
    calculated_metric = score_func(y_test, target, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 638, in _multiclass_roc_auc_score
    if not np.allclose(1, y_score.sum(axis=1)):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\numpy\core\_methods.py", line 48, in _sum
    return umr_sum(a, axis, dtype, out, keepdims, initial, where)
numpy.AxisError: axis 1 is out of bounds for array of dimension 1

  warnings.warn(traceback.format_exc())

2023-07-03 09:05:51,228:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:05:51,229:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:05:51,230:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:05:51,230:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:06:02,015:INFO:Initializing predict_model()
2023-07-03 09:06:02,015:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027231F26FE0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000027239DDF6D0>)
2023-07-03 09:06:02,015:INFO:Checking exceptions
2023-07-03 09:06:02,015:INFO:Preloading libraries
2023-07-03 09:06:02,018:INFO:Set up data.
2023-07-03 09:06:02,026:INFO:Set up index.
2023-07-03 09:06:58,035:INFO:Initializing save_model()
2023-07-03 09:06:58,036:INFO:save_model(model=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), model_name=chronic_kidney, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JHossain\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['id', 'age', 'bp', 'sg', 'al',
                                             'su', 'bgr', 'bu', 'sc', 'sod',
                                             'pot', 'hemo'],
                                    transformer=SimpleImputer(add_...
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['pcv', 'wc', 'rc'],
                                    transformer=TargetEncoder(cols=['pcv', 'wc',
                                                                    'rc'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-07-03 09:06:58,036:INFO:Adding model into prep_pipe
2023-07-03 09:06:58,081:INFO:chronic_kidney.pkl saved in current working directory
2023-07-03 09:06:58,142:INFO:Pipeline(memory=FastMemory(location=C:\Users\JHossain\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['id', 'age', 'bp', 'sg', 'al',
                                             'su', 'bgr', 'bu', 'sc', 'sod',
                                             'pot', 'hemo'],
                                    transformer=SimpleImputer(add_...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='sqrt',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        n_estimators=100, n_jobs=-1,
                                        oob_score=False, random_state=123,
                                        verbose=0, warm_start=False))],
         verbose=False)
2023-07-03 09:06:58,142:INFO:save_model() successfully completed......................................
2023-07-03 09:07:11,313:INFO:Initializing load_model()
2023-07-03 09:07:11,313:INFO:load_model(model_name=chronic_kidney, platform=None, authentication=None, verbose=True)
2023-07-03 09:08:01,983:INFO:Initializing predict_model()
2023-07-03 09:08:01,983:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027231F26FE0>, estimator=loaded_best_pipeline, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000027239DDFE20>)
2023-07-03 09:08:01,983:INFO:Checking exceptions
2023-07-03 09:08:01,983:INFO:Preloading libraries
2023-07-03 09:08:41,881:INFO:Initializing save_model()
2023-07-03 09:08:41,881:INFO:save_model(model=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), model_name=models/chronic_kidney, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JHossain\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['id', 'age', 'bp', 'sg', 'al',
                                             'su', 'bgr', 'bu', 'sc', 'sod',
                                             'pot', 'hemo'],
                                    transformer=SimpleImputer(add_...
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['pcv', 'wc', 'rc'],
                                    transformer=TargetEncoder(cols=['pcv', 'wc',
                                                                    'rc'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-07-03 09:08:41,881:INFO:Adding model into prep_pipe
2023-07-03 09:08:50,303:INFO:Initializing save_model()
2023-07-03 09:08:50,303:INFO:save_model(model=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), model_name=models/chronic_kidney.pkl, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JHossain\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['id', 'age', 'bp', 'sg', 'al',
                                             'su', 'bgr', 'bu', 'sc', 'sod',
                                             'pot', 'hemo'],
                                    transformer=SimpleImputer(add_...
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['pcv', 'wc', 'rc'],
                                    transformer=TargetEncoder(cols=['pcv', 'wc',
                                                                    'rc'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-07-03 09:08:50,303:INFO:Adding model into prep_pipe
2023-07-03 09:09:23,079:INFO:Initializing save_model()
2023-07-03 09:09:23,079:INFO:save_model(model=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), model_name=../models/chronic_kidney, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JHossain\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['id', 'age', 'bp', 'sg', 'al',
                                             'su', 'bgr', 'bu', 'sc', 'sod',
                                             'pot', 'hemo'],
                                    transformer=SimpleImputer(add_...
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['pcv', 'wc', 'rc'],
                                    transformer=TargetEncoder(cols=['pcv', 'wc',
                                                                    'rc'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-07-03 09:09:23,079:INFO:Adding model into prep_pipe
2023-07-03 09:09:48,727:INFO:Initializing save_model()
2023-07-03 09:09:48,727:INFO:save_model(model=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), model_name=../models/my_first_pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JHossain\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['id', 'age', 'bp', 'sg', 'al',
                                             'su', 'bgr', 'bu', 'sc', 'sod',
                                             'pot', 'hemo'],
                                    transformer=SimpleImputer(add_...
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['pcv', 'wc', 'rc'],
                                    transformer=TargetEncoder(cols=['pcv', 'wc',
                                                                    'rc'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-07-03 09:09:48,727:INFO:Adding model into prep_pipe
2023-07-03 09:10:13,914:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7308_c6904063489c469b8ff0bad1b70b90ee_0418cfc75a7d474d9426b57ca4d34556
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 09:10:13,914:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7308_16969df351064abfae1f27f51d116264_7c70b12ec6ff405b826253bb65a970f4
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 09:10:13,914:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7308_c6904063489c469b8ff0bad1b70b90ee_b04abc2e95d74301816595fce52bcace
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 09:10:13,914:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7308_ff25c67d7e734bb0b233c2201cc99e83_c5e5d1a9af464353b5ceef417c3a2db8
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 09:10:13,914:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7308_c6904063489c469b8ff0bad1b70b90ee_f8e5a9137bc74ad4a4f65ab0b863e3bb
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 09:10:13,914:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7308_d040743b06a4481ea5033a357b9a5b47_39094abfac584290802f2cfe4ac2c58f
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 09:10:13,914:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7308_c6904063489c469b8ff0bad1b70b90ee_4fdb49878b704606bc82edf6b8266180
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 09:10:13,915:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7308_2cfa7de2539a4076a1003091da199271_27f9f801367545fa97d607168b005641
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 09:10:13,915:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7308_c6904063489c469b8ff0bad1b70b90ee_170bba3f2a5840f08440c4d65adf950f
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 09:10:13,915:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7308_634be4ccdf93415197136596be7aec2b_f157de6546cd42ba9124ee0ef5c87029
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 09:10:13,915:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7308_c6904063489c469b8ff0bad1b70b90ee_69b7cd626d3e4077ae00bccdc96c8743
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 09:10:13,915:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7308_fac2a6e91f2c43259f04e6c083e40182_58e2f8a6418d424da08c5e3386948603
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 09:10:13,915:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7308_c6904063489c469b8ff0bad1b70b90ee_098ca41798bc4517a7921ca69893b4b0
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 09:10:13,915:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7308_cebb51f8be59439898230082cd117e67_0cc64abcfc1b46bcb3dc2b01a65e7a23
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 09:10:13,915:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7308_c6904063489c469b8ff0bad1b70b90ee_1c49b5db06fe4d53bb25ea5e06b92486
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 09:10:13,915:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7308_db785ccfb5cb499ba19028d2a0d331ef_a3aa2847b402418e92fb9008cbe2a4b7
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 09:10:13,915:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7308_c6904063489c469b8ff0bad1b70b90ee_b1fc1db83c8d4b44acc8bd387eaeaf45
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 09:10:13,915:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7308_e0fc9f0c1cd1439ca884d871583c90a9_2f62ca7fdef346b1a0b3778c919b71c5
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 09:10:13,915:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7308_c6904063489c469b8ff0bad1b70b90ee_244df7469ba340f8ab6a79c504a1cb37
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 09:10:13,916:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7308_22e5f20d8f1b463d9b7521c896e56ad4_04a5916a585741a0a3463ad63027910d
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 09:10:13,916:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7308_c6904063489c469b8ff0bad1b70b90ee_8020978c4a5947c8820e2d4eb4d0b1b0
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 09:10:13,916:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7308_0b7d90ecc9d8467cad94970a4a86dbc8_4cf5e796eed64b0aa9278bdedb94bc9b
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 09:10:13,916:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7308_c6904063489c469b8ff0bad1b70b90ee_5717d828985c43ee9fe22b7c337ae784
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 09:10:13,916:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7308_13588d6609014393a849ae685dd01db3_f76ed7be0116489b9a43b7b6ebbb5741
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 09:10:13,916:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7308_c6904063489c469b8ff0bad1b70b90ee_5a672803acb54bd6ba52ecd28a30f460
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 09:10:13,916:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7308_0a8f98613bc14d838a7eb4a6c1925aa9_bb505368e65642a3b4934c7b59afc303
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 09:10:13,916:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7308_c6904063489c469b8ff0bad1b70b90ee_f7dd5ca4a024478e959660e409a9c184
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 09:10:13,916:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7308_576569a6d9c24e6fad4ff52002712f34_45c0192baf5d40e4975fe0688d971cfd
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 09:10:13,916:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7308_c6904063489c469b8ff0bad1b70b90ee_16e76d5d4fa541e08054df4113cc2783
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 09:10:13,916:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7308_8ab0203e09e04d7e99dc32a441aec58d_53ee8988202a43d4ae95e56c1924e68a
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 09:10:13,916:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7308_c6904063489c469b8ff0bad1b70b90ee_a8f1bdc91612444fa239f01398beb955
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 09:10:13,917:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7308_7eb2f4521cfc4203abacf0b6351898f1_0a36da28e94e453fb2448fe2a19102bc
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 09:10:13,917:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7308_c6904063489c469b8ff0bad1b70b90ee_a0d56e9f97f8462ebb56ab2de628287d
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 09:10:13,917:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7308_910b8dfe381348d7845cf238aa24b4c1_db4da2805e1a4fc1b8aaf6b80fbf5977
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 09:10:13,917:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7308_c6904063489c469b8ff0bad1b70b90ee_b682a4f7ec2f488fa9d01a2112fb9e13
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 09:10:13,917:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7308_fdb56585a5e54eb88f18df15b8555f3c_d7fa79f0f32c43f5b37baf8b428e7abc
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 09:10:13,917:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7308_c6904063489c469b8ff0bad1b70b90ee_36abd7e5ea28447999f2e36aea9709ea
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 09:10:13,917:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7308_1b0c45e1365944ecaecd89a0a4ebec39_c2b3a47ab49d4dc58921d9557dc2834b
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 09:10:13,917:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7308_c6904063489c469b8ff0bad1b70b90ee_fab49fb3b185487baa314e93441bddf3
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 09:10:13,917:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7308_f57511cd03aa4b48b16450912e22d26b_15ebb4a307e242e583804a01d16691d0
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 09:10:13,917:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7308_c6904063489c469b8ff0bad1b70b90ee_3188516fd7eb47d685680f1d11905453
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 09:10:13,917:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7308_c1fd2f0e1560465487e4cda2ee32f2ab_2d1bb865a6b9436c89518613293811f4
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 09:10:13,917:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7308_c6904063489c469b8ff0bad1b70b90ee_9017339821394f8aa3ea3c093128a632
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 09:10:13,918:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7308_c6904063489c469b8ff0bad1b70b90ee_c6da1d3438f54d2c83436f5476423f8d
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 09:10:40,670:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-03 09:10:40,670:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-03 09:10:40,670:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-03 09:10:40,670:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-03 09:10:41,186:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-07-03 09:10:41,503:INFO:PyCaret ClassificationExperiment
2023-07-03 09:10:41,504:INFO:Logging name: clf-default-name
2023-07-03 09:10:41,504:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-07-03 09:10:41,504:INFO:version 3.0.2
2023-07-03 09:10:41,504:INFO:Initializing setup()
2023-07-03 09:10:41,504:INFO:self.USI: 240f
2023-07-03 09:10:41,504:INFO:self._variable_keys: {'fold_generator', 'fold_groups_param', 'y_train', 'logging_param', 'idx', 'memory', 'exp_name_log', 'gpu_param', 'X', 'is_multiclass', '_available_plots', 'fold_shuffle_param', 'target_param', 'y_test', '_ml_usecase', 'gpu_n_jobs_param', 'X_train', 'USI', 'log_plots_param', 'fix_imbalance', 'exp_id', 'data', 'n_jobs_param', 'y', 'seed', 'html_param', 'X_test', 'pipeline'}
2023-07-03 09:10:41,504:INFO:Checking environment
2023-07-03 09:10:41,504:INFO:python_version: 3.10.9
2023-07-03 09:10:41,504:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2023-07-03 09:10:41,504:INFO:machine: AMD64
2023-07-03 09:10:41,504:INFO:platform: Windows-10-10.0.22621-SP0
2023-07-03 09:10:41,507:INFO:Memory: svmem(total=33664483328, available=23944630272, percent=28.9, used=9719853056, free=23944630272)
2023-07-03 09:10:41,507:INFO:Physical Core: 6
2023-07-03 09:10:41,507:INFO:Logical Core: 12
2023-07-03 09:10:41,507:INFO:Checking libraries
2023-07-03 09:10:41,507:INFO:System:
2023-07-03 09:10:41,507:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2023-07-03 09:10:41,507:INFO:executable: C:\Users\JHossain\anaconda3\python.exe
2023-07-03 09:10:41,507:INFO:   machine: Windows-10-10.0.22621-SP0
2023-07-03 09:10:41,507:INFO:PyCaret required dependencies:
2023-07-03 09:10:41,507:INFO:                 pip: 22.3.1
2023-07-03 09:10:41,507:INFO:          setuptools: 65.6.3
2023-07-03 09:10:41,508:INFO:             pycaret: 3.0.2
2023-07-03 09:10:41,508:INFO:             IPython: 8.10.0
2023-07-03 09:10:41,508:INFO:          ipywidgets: 7.6.5
2023-07-03 09:10:41,508:INFO:                tqdm: 4.64.1
2023-07-03 09:10:41,508:INFO:               numpy: 1.23.5
2023-07-03 09:10:41,508:INFO:              pandas: 1.5.3
2023-07-03 09:10:41,508:INFO:              jinja2: 3.1.2
2023-07-03 09:10:41,508:INFO:               scipy: 1.10.0
2023-07-03 09:10:41,508:INFO:              joblib: 1.2.0
2023-07-03 09:10:41,508:INFO:             sklearn: 1.2.1
2023-07-03 09:10:41,508:INFO:                pyod: 1.0.9
2023-07-03 09:10:41,508:INFO:            imblearn: 0.10.1
2023-07-03 09:10:41,508:INFO:   category_encoders: 2.6.1
2023-07-03 09:10:41,508:INFO:            lightgbm: 3.3.5
2023-07-03 09:10:41,508:INFO:               numba: 0.56.4
2023-07-03 09:10:41,508:INFO:            requests: 2.28.1
2023-07-03 09:10:41,508:INFO:          matplotlib: 3.7.0
2023-07-03 09:10:41,508:INFO:          scikitplot: 0.3.7
2023-07-03 09:10:41,508:INFO:         yellowbrick: 1.5
2023-07-03 09:10:41,508:INFO:              plotly: 5.9.0
2023-07-03 09:10:41,508:INFO:             kaleido: 0.2.1
2023-07-03 09:10:41,508:INFO:         statsmodels: 0.13.5
2023-07-03 09:10:41,508:INFO:              sktime: 0.17.0
2023-07-03 09:10:41,508:INFO:               tbats: 1.1.3
2023-07-03 09:10:41,508:INFO:            pmdarima: 2.0.3
2023-07-03 09:10:41,508:INFO:              psutil: 5.9.0
2023-07-03 09:10:41,508:INFO:PyCaret optional dependencies:
2023-07-03 09:10:42,420:INFO:                shap: Not installed
2023-07-03 09:10:42,420:INFO:           interpret: Not installed
2023-07-03 09:10:42,420:INFO:                umap: Not installed
2023-07-03 09:10:42,420:INFO:    pandas_profiling: Not installed
2023-07-03 09:10:42,420:INFO:  explainerdashboard: Not installed
2023-07-03 09:10:42,420:INFO:             autoviz: Not installed
2023-07-03 09:10:42,420:INFO:           fairlearn: Not installed
2023-07-03 09:10:42,420:INFO:             xgboost: Not installed
2023-07-03 09:10:42,420:INFO:            catboost: Not installed
2023-07-03 09:10:42,420:INFO:              kmodes: Not installed
2023-07-03 09:10:42,420:INFO:             mlxtend: Not installed
2023-07-03 09:10:42,420:INFO:       statsforecast: Not installed
2023-07-03 09:10:42,420:INFO:        tune_sklearn: Not installed
2023-07-03 09:10:42,420:INFO:                 ray: Not installed
2023-07-03 09:10:42,420:INFO:            hyperopt: Not installed
2023-07-03 09:10:42,420:INFO:              optuna: Not installed
2023-07-03 09:10:42,420:INFO:               skopt: Not installed
2023-07-03 09:10:42,420:INFO:              mlflow: Not installed
2023-07-03 09:10:42,420:INFO:              gradio: 3.35.2
2023-07-03 09:10:42,420:INFO:             fastapi: 0.99.0
2023-07-03 09:10:42,420:INFO:             uvicorn: 0.22.0
2023-07-03 09:10:42,420:INFO:              m2cgen: Not installed
2023-07-03 09:10:42,421:INFO:           evidently: Not installed
2023-07-03 09:10:42,421:INFO:               fugue: Not installed
2023-07-03 09:10:42,421:INFO:           streamlit: Not installed
2023-07-03 09:10:42,421:INFO:             prophet: Not installed
2023-07-03 09:10:42,421:INFO:None
2023-07-03 09:10:42,421:INFO:Set up data.
2023-07-03 09:10:42,430:INFO:Set up train/test split.
2023-07-03 09:10:42,436:INFO:Set up index.
2023-07-03 09:10:42,436:INFO:Set up folding strategy.
2023-07-03 09:10:42,436:INFO:Assigning column types.
2023-07-03 09:10:42,439:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-07-03 09:10:42,474:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-03 09:10:42,476:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-03 09:10:42,504:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:10:42,646:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:10:42,682:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-03 09:10:42,684:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-03 09:10:42,706:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:10:42,706:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:10:42,706:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-07-03 09:10:42,742:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-03 09:10:42,764:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:10:42,764:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:10:42,800:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-03 09:10:42,823:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:10:42,823:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:10:42,823:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-07-03 09:10:42,881:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:10:42,881:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:10:42,938:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:10:42,939:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:10:42,940:INFO:Preparing preprocessing pipeline...
2023-07-03 09:10:42,941:INFO:Set up label encoding.
2023-07-03 09:10:42,942:INFO:Set up simple imputation.
2023-07-03 09:10:42,946:INFO:Set up encoding of ordinal features.
2023-07-03 09:10:42,953:INFO:Set up encoding of categorical features.
2023-07-03 09:10:43,109:INFO:Finished creating preprocessing pipeline.
2023-07-03 09:10:43,170:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\JHossain\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['id', 'age', 'bp', 'sg', 'al',
                                             'su', 'bgr', 'bu', 'sc', 'sod',
                                             'pot', 'hemo'],
                                    transformer=SimpleImputer(add_...
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['pcv', 'wc', 'rc'],
                                    transformer=TargetEncoder(cols=['pcv', 'wc',
                                                                    'rc'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2023-07-03 09:10:43,170:INFO:Creating final display dataframe.
2023-07-03 09:10:43,561:INFO:Setup _display_container:                     Description                        Value
0                    Session id                          123
1                        Target               classification
2                   Target type                   Multiclass
3                Target mapping  ckd: 0, ckd\t: 1, notckd: 2
4           Original data shape                    (400, 26)
5        Transformed data shape                    (400, 32)
6   Transformed train set shape                    (280, 32)
7    Transformed test set shape                    (120, 32)
8              Ordinal features                            8
9              Numeric features                           12
10         Categorical features                           13
11     Rows with missing values                        60.5%
12                   Preprocess                         True
13              Imputation type                       simple
14           Numeric imputation                         mean
15       Categorical imputation                         mode
16     Maximum one-hot encoding                           25
17              Encoding method                         None
18               Fold Generator              StratifiedKFold
19                  Fold Number                           10
20                     CPU Jobs                           -1
21                      Use GPU                        False
22               Log Experiment                        False
23              Experiment Name             clf-default-name
24                          USI                         240f
2023-07-03 09:10:43,625:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:10:43,625:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:10:43,683:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:10:43,683:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:10:43,684:INFO:setup() successfully completed in 2.28s...............
2023-07-03 09:10:43,699:INFO:Initializing compare_models()
2023-07-03 09:10:43,699:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000132A2C66CB0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000132A2C66CB0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-07-03 09:10:43,699:INFO:Checking exceptions
2023-07-03 09:10:43,702:INFO:Preparing display monitor
2023-07-03 09:10:43,722:INFO:Initializing Logistic Regression
2023-07-03 09:10:43,722:INFO:Total runtime is 0.0 minutes
2023-07-03 09:10:43,725:INFO:SubProcess create_model() called ==================================
2023-07-03 09:10:43,725:INFO:Initializing create_model()
2023-07-03 09:10:43,725:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000132A2C66CB0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000132A2B07A90>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:10:43,726:INFO:Checking exceptions
2023-07-03 09:10:43,726:INFO:Importing libraries
2023-07-03 09:10:43,726:INFO:Copying training dataset
2023-07-03 09:10:43,730:INFO:Defining folds
2023-07-03 09:10:43,730:INFO:Declaring metric variables
2023-07-03 09:10:43,732:INFO:Importing untrained model
2023-07-03 09:10:43,735:INFO:Logistic Regression Imported successfully
2023-07-03 09:10:43,742:INFO:Starting cross validation
2023-07-03 09:10:43,744:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:10:43,753:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2023-07-03 09:10:48,700:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:10:48,702:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:48,704:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:48,705:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:48,706:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:48,707:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:48,708:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:10:48,713:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:10:48,714:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:10:48,715:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:48,716:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:48,716:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:48,717:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:48,718:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:48,718:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:48,719:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:48,719:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:48,720:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:10:48,721:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:48,731:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:10:48,734:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:48,735:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:48,736:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:48,737:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:48,738:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:48,739:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:10:48,901:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:10:48,903:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:48,903:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:10:48,905:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:48,906:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:48,906:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:48,907:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:48,908:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:10:48,908:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:48,910:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:48,911:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:48,911:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:48,912:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:10:48,912:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:48,913:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:48,915:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:48,926:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:10:48,928:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:48,929:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:48,930:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:48,931:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:48,932:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:48,933:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:10:48,949:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:10:48,951:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:48,953:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:48,954:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:48,956:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:48,957:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:48,958:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:10:48,975:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:10:48,977:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:48,979:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:48,981:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:48,982:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:49,660:INFO:Calculating mean and std
2023-07-03 09:10:49,661:INFO:Creating metrics dataframe
2023-07-03 09:10:49,816:INFO:Uploading results into container
2023-07-03 09:10:49,817:INFO:Uploading model into container now
2023-07-03 09:10:49,817:INFO:_master_model_container: 1
2023-07-03 09:10:49,817:INFO:_display_container: 2
2023-07-03 09:10:49,818:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-03 09:10:49,818:INFO:create_model() successfully completed......................................
2023-07-03 09:10:49,959:INFO:SubProcess create_model() end ==================================
2023-07-03 09:10:49,959:INFO:Creating metrics dataframe
2023-07-03 09:10:49,966:INFO:Initializing K Neighbors Classifier
2023-07-03 09:10:49,967:INFO:Total runtime is 0.10408566395441692 minutes
2023-07-03 09:10:49,969:INFO:SubProcess create_model() called ==================================
2023-07-03 09:10:49,970:INFO:Initializing create_model()
2023-07-03 09:10:49,970:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000132A2C66CB0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000132A2B07A90>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:10:49,970:INFO:Checking exceptions
2023-07-03 09:10:49,970:INFO:Importing libraries
2023-07-03 09:10:49,970:INFO:Copying training dataset
2023-07-03 09:10:49,974:INFO:Defining folds
2023-07-03 09:10:49,974:INFO:Declaring metric variables
2023-07-03 09:10:49,977:INFO:Importing untrained model
2023-07-03 09:10:49,980:INFO:K Neighbors Classifier Imported successfully
2023-07-03 09:10:49,986:INFO:Starting cross validation
2023-07-03 09:10:49,989:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:10:49,990:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2023-07-03 09:10:50,523:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:10:50,524:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:50,525:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:50,526:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:50,527:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:50,528:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:50,529:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:10:50,534:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:10:50,535:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:50,535:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:10:50,536:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:50,536:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:50,537:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:50,537:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:50,538:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:50,538:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:50,539:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:50,539:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:10:50,540:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:50,541:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:50,542:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:10:50,549:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:10:50,550:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:50,551:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:50,552:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:50,552:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:50,553:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:50,554:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:10:50,556:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:10:50,557:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:50,558:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:50,559:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:50,560:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:50,562:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:50,563:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:10:50,567:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:10:50,568:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:50,568:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:10:50,569:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:50,569:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:50,570:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:50,571:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:50,571:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:50,572:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:50,573:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:10:50,573:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:10:50,573:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:50,574:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:50,574:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:50,575:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:10:50,576:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:50,577:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:50,578:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:52,505:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:10:52,506:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:10:52,506:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:52,507:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:52,507:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:52,508:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:52,508:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:52,508:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:52,508:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:52,509:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:52,509:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:52,509:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:10:52,510:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:52,510:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:10:52,611:INFO:Calculating mean and std
2023-07-03 09:10:52,612:INFO:Creating metrics dataframe
2023-07-03 09:10:52,771:INFO:Uploading results into container
2023-07-03 09:10:52,772:INFO:Uploading model into container now
2023-07-03 09:10:52,772:INFO:_master_model_container: 2
2023-07-03 09:10:52,773:INFO:_display_container: 2
2023-07-03 09:10:52,773:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-07-03 09:10:52,773:INFO:create_model() successfully completed......................................
2023-07-03 09:10:52,915:INFO:SubProcess create_model() end ==================================
2023-07-03 09:10:52,915:INFO:Creating metrics dataframe
2023-07-03 09:10:52,923:INFO:Initializing Naive Bayes
2023-07-03 09:10:52,923:INFO:Total runtime is 0.1533585031827291 minutes
2023-07-03 09:10:52,926:INFO:SubProcess create_model() called ==================================
2023-07-03 09:10:52,926:INFO:Initializing create_model()
2023-07-03 09:10:52,926:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000132A2C66CB0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000132A2B07A90>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:10:52,927:INFO:Checking exceptions
2023-07-03 09:10:52,927:INFO:Importing libraries
2023-07-03 09:10:52,927:INFO:Copying training dataset
2023-07-03 09:10:52,931:INFO:Defining folds
2023-07-03 09:10:52,931:INFO:Declaring metric variables
2023-07-03 09:10:52,934:INFO:Importing untrained model
2023-07-03 09:10:52,937:INFO:Naive Bayes Imported successfully
2023-07-03 09:10:52,944:INFO:Starting cross validation
2023-07-03 09:10:52,946:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:10:52,947:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2023-07-03 09:10:53,315:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:10:53,315:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:53,316:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:53,317:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:53,317:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:53,317:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:10:53,318:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:53,318:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:53,319:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:10:53,319:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:53,320:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:53,320:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:53,328:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:10:53,329:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:53,330:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:53,331:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:53,332:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:53,333:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:53,333:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:10:53,333:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:10:53,334:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:53,334:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:53,334:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:10:53,335:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:10:53,335:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:53,335:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:53,336:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:53,336:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:53,336:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:53,337:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

lt))

2023-07-03 09:10:53,337:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:53,338:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:53,338:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:53,339:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

 is", len(true_sum))

2023-07-03 09:10:53,339:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:10:53,340:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:53,341:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:10:53,364:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:10:53,365:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:53,366:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:53,367:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:53,368:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:53,369:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:53,370:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:10:53,371:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:10:53,372:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:53,373:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:53,374:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:53,375:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:53,377:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:53,378:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:10:53,381:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:10:53,382:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:53,384:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:53,385:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:53,386:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:53,387:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:53,388:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:10:53,392:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:10:53,393:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:53,395:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:53,396:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:53,397:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:53,398:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:53,399:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:10:54,217:INFO:Calculating mean and std
2023-07-03 09:10:54,218:INFO:Creating metrics dataframe
2023-07-03 09:10:54,373:INFO:Uploading results into container
2023-07-03 09:10:54,374:INFO:Uploading model into container now
2023-07-03 09:10:54,374:INFO:_master_model_container: 3
2023-07-03 09:10:54,374:INFO:_display_container: 2
2023-07-03 09:10:54,374:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-07-03 09:10:54,374:INFO:create_model() successfully completed......................................
2023-07-03 09:10:54,517:INFO:SubProcess create_model() end ==================================
2023-07-03 09:10:54,517:INFO:Creating metrics dataframe
2023-07-03 09:10:54,525:INFO:Initializing Decision Tree Classifier
2023-07-03 09:10:54,526:INFO:Total runtime is 0.18007293144861858 minutes
2023-07-03 09:10:54,528:INFO:SubProcess create_model() called ==================================
2023-07-03 09:10:54,529:INFO:Initializing create_model()
2023-07-03 09:10:54,529:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000132A2C66CB0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000132A2B07A90>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:10:54,529:INFO:Checking exceptions
2023-07-03 09:10:54,529:INFO:Importing libraries
2023-07-03 09:10:54,529:INFO:Copying training dataset
2023-07-03 09:10:54,534:INFO:Defining folds
2023-07-03 09:10:54,534:INFO:Declaring metric variables
2023-07-03 09:10:54,537:INFO:Importing untrained model
2023-07-03 09:10:54,540:INFO:Decision Tree Classifier Imported successfully
2023-07-03 09:10:54,545:INFO:Starting cross validation
2023-07-03 09:10:54,547:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:10:54,549:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2023-07-03 09:10:54,878:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:10:54,879:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:54,880:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:54,881:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:54,881:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:10:54,882:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:54,882:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:54,882:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:54,884:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

"F-score is", len(true_sum))

2023-07-03 09:10:54,884:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:54,885:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:54,886:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:54,887:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:10:54,897:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:10:54,897:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:54,898:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:54,899:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:54,900:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:54,901:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:54,902:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:10:54,945:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:10:54,946:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:54,947:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:54,948:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:54,949:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:10:54,950:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:54,950:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:54,951:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:54,952:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:54,953:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:54,954:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:54,955:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:10:54,961:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:10:54,962:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:54,963:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:54,964:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:54,966:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:54,997:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:10:54,998:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:55,000:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:55,001:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:55,002:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:55,011:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:10:55,012:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:55,012:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:10:55,013:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:55,014:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:55,015:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:55,015:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:55,016:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:55,016:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:55,017:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:55,017:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:55,017:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:10:55,018:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:55,018:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:55,018:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:10:55,019:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:10:55,019:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:55,020:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:55,023:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:55,775:INFO:Calculating mean and std
2023-07-03 09:10:55,776:INFO:Creating metrics dataframe
2023-07-03 09:10:55,931:INFO:Uploading results into container
2023-07-03 09:10:55,932:INFO:Uploading model into container now
2023-07-03 09:10:55,932:INFO:_master_model_container: 4
2023-07-03 09:10:55,932:INFO:_display_container: 2
2023-07-03 09:10:55,933:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-07-03 09:10:55,933:INFO:create_model() successfully completed......................................
2023-07-03 09:10:56,074:INFO:SubProcess create_model() end ==================================
2023-07-03 09:10:56,074:INFO:Creating metrics dataframe
2023-07-03 09:10:56,082:INFO:Initializing SVM - Linear Kernel
2023-07-03 09:10:56,082:INFO:Total runtime is 0.2060041626294454 minutes
2023-07-03 09:10:56,085:INFO:SubProcess create_model() called ==================================
2023-07-03 09:10:56,085:INFO:Initializing create_model()
2023-07-03 09:10:56,085:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000132A2C66CB0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000132A2B07A90>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:10:56,085:INFO:Checking exceptions
2023-07-03 09:10:56,085:INFO:Importing libraries
2023-07-03 09:10:56,085:INFO:Copying training dataset
2023-07-03 09:10:56,090:INFO:Defining folds
2023-07-03 09:10:56,090:INFO:Declaring metric variables
2023-07-03 09:10:56,093:INFO:Importing untrained model
2023-07-03 09:10:56,096:INFO:SVM - Linear Kernel Imported successfully
2023-07-03 09:10:56,101:INFO:Starting cross validation
2023-07-03 09:10:56,103:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:10:56,105:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2023-07-03 09:10:56,450:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 09:10:56,451:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:56,451:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 09:10:56,452:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:56,452:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:56,453:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:56,453:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:56,454:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:56,454:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:56,456:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:56,456:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:56,456:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:10:56,457:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:56,458:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:10:56,461:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 09:10:56,462:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:56,463:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:56,464:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:56,464:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 09:10:56,465:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:56,465:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 09:10:56,465:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:56,466:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:56,466:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:56,467:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:10:56,467:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:56,467:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:56,468:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:56,468:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:56,469:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:56,469:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:56,470:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:56,470:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:56,471:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:10:56,471:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:10:56,483:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 09:10:56,484:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:56,486:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:56,487:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:56,488:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:56,489:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:56,490:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:10:56,501:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 09:10:56,502:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:56,503:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:56,504:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:56,505:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 09:10:56,506:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:56,506:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:56,507:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:56,507:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:56,508:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:10:56,509:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:56,510:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:56,511:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:56,512:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:10:56,522:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 09:10:56,522:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 09:10:56,523:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:56,523:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:56,524:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:56,525:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:56,525:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:56,526:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:56,527:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:56,527:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:56,527:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:56,529:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:10:57,362:INFO:Calculating mean and std
2023-07-03 09:10:57,363:INFO:Creating metrics dataframe
2023-07-03 09:10:57,514:INFO:Uploading results into container
2023-07-03 09:10:57,515:INFO:Uploading model into container now
2023-07-03 09:10:57,515:INFO:_master_model_container: 5
2023-07-03 09:10:57,515:INFO:_display_container: 2
2023-07-03 09:10:57,516:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-07-03 09:10:57,516:INFO:create_model() successfully completed......................................
2023-07-03 09:10:57,658:INFO:SubProcess create_model() end ==================================
2023-07-03 09:10:57,658:INFO:Creating metrics dataframe
2023-07-03 09:10:57,668:INFO:Initializing Ridge Classifier
2023-07-03 09:10:57,668:INFO:Total runtime is 0.23244285583496094 minutes
2023-07-03 09:10:57,671:INFO:SubProcess create_model() called ==================================
2023-07-03 09:10:57,671:INFO:Initializing create_model()
2023-07-03 09:10:57,671:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000132A2C66CB0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000132A2B07A90>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:10:57,671:INFO:Checking exceptions
2023-07-03 09:10:57,671:INFO:Importing libraries
2023-07-03 09:10:57,672:INFO:Copying training dataset
2023-07-03 09:10:57,676:INFO:Defining folds
2023-07-03 09:10:57,676:INFO:Declaring metric variables
2023-07-03 09:10:57,679:INFO:Importing untrained model
2023-07-03 09:10:57,682:INFO:Ridge Classifier Imported successfully
2023-07-03 09:10:57,690:INFO:Starting cross validation
2023-07-03 09:10:57,693:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:10:57,694:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2023-07-03 09:10:58,000:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 09:10:58,001:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:58,002:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:58,003:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:58,004:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:58,005:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:58,006:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:10:58,037:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 09:10:58,037:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:58,039:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:58,040:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:58,041:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:58,042:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:58,043:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:10:58,046:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 09:10:58,046:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 09:10:58,047:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:58,047:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:58,048:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:58,048:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:58,049:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:58,049:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:58,050:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:58,051:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:58,051:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:58,052:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:58,052:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:10:58,053:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:10:58,056:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 09:10:58,057:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:58,059:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:58,060:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:58,061:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:58,062:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:58,063:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:10:58,076:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 09:10:58,077:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:58,079:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:58,081:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:58,081:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 09:10:58,082:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:58,082:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:58,083:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:58,084:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:58,085:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:58,086:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:58,088:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:10:58,090:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 09:10:58,090:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 09:10:58,091:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:58,091:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:58,092:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:58,092:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:58,093:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:58,093:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:58,094:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:58,094:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:58,095:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:58,095:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:58,096:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:10:58,096:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:10:58,103:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 09:10:58,104:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:58,105:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:58,106:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:58,108:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:58,109:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:58,110:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:10:58,913:INFO:Calculating mean and std
2023-07-03 09:10:58,914:INFO:Creating metrics dataframe
2023-07-03 09:10:59,070:INFO:Uploading results into container
2023-07-03 09:10:59,071:INFO:Uploading model into container now
2023-07-03 09:10:59,071:INFO:_master_model_container: 6
2023-07-03 09:10:59,071:INFO:_display_container: 2
2023-07-03 09:10:59,072:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-07-03 09:10:59,072:INFO:create_model() successfully completed......................................
2023-07-03 09:10:59,215:INFO:SubProcess create_model() end ==================================
2023-07-03 09:10:59,215:INFO:Creating metrics dataframe
2023-07-03 09:10:59,224:INFO:Initializing Random Forest Classifier
2023-07-03 09:10:59,224:INFO:Total runtime is 0.25836982727050783 minutes
2023-07-03 09:10:59,227:INFO:SubProcess create_model() called ==================================
2023-07-03 09:10:59,227:INFO:Initializing create_model()
2023-07-03 09:10:59,227:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000132A2C66CB0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000132A2B07A90>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:10:59,227:INFO:Checking exceptions
2023-07-03 09:10:59,227:INFO:Importing libraries
2023-07-03 09:10:59,227:INFO:Copying training dataset
2023-07-03 09:10:59,231:INFO:Defining folds
2023-07-03 09:10:59,231:INFO:Declaring metric variables
2023-07-03 09:10:59,234:INFO:Importing untrained model
2023-07-03 09:10:59,237:INFO:Random Forest Classifier Imported successfully
2023-07-03 09:10:59,243:INFO:Starting cross validation
2023-07-03 09:10:59,245:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:10:59,247:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2023-07-03 09:10:59,764:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:10:59,765:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:59,766:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:59,767:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:59,768:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:59,769:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:59,770:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:10:59,849:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:10:59,850:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:59,851:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:59,852:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:59,853:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:59,854:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:59,855:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:10:59,858:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:10:59,859:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:59,860:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:59,861:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:59,862:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:59,863:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:59,863:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:10:59,864:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:59,864:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:10:59,865:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:59,866:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:59,867:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:59,868:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:59,869:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:10:59,870:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:10:59,871:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:59,872:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:59,873:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:59,874:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:59,875:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:59,876:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:10:59,890:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:10:59,890:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:10:59,891:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:59,891:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:59,892:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:59,892:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:59,892:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:59,893:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:59,894:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:59,894:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:59,895:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:59,895:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:59,896:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:10:59,896:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:10:59,916:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:10:59,917:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:59,919:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:59,920:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:59,921:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:59,922:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:10:59,922:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:59,923:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:59,923:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:10:59,924:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:59,925:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:59,927:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:59,928:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:59,929:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:10:59,940:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:10:59,941:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:59,944:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:10:59,945:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:10:59,946:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:00,707:INFO:Calculating mean and std
2023-07-03 09:11:00,708:INFO:Creating metrics dataframe
2023-07-03 09:11:00,859:INFO:Uploading results into container
2023-07-03 09:11:00,860:INFO:Uploading model into container now
2023-07-03 09:11:00,860:INFO:_master_model_container: 7
2023-07-03 09:11:00,860:INFO:_display_container: 2
2023-07-03 09:11:00,861:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-07-03 09:11:00,861:INFO:create_model() successfully completed......................................
2023-07-03 09:11:01,004:INFO:SubProcess create_model() end ==================================
2023-07-03 09:11:01,004:INFO:Creating metrics dataframe
2023-07-03 09:11:01,014:INFO:Initializing Quadratic Discriminant Analysis
2023-07-03 09:11:01,014:INFO:Total runtime is 0.2882081111272176 minutes
2023-07-03 09:11:01,017:INFO:SubProcess create_model() called ==================================
2023-07-03 09:11:01,017:INFO:Initializing create_model()
2023-07-03 09:11:01,017:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000132A2C66CB0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000132A2B07A90>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:11:01,017:INFO:Checking exceptions
2023-07-03 09:11:01,017:INFO:Importing libraries
2023-07-03 09:11:01,017:INFO:Copying training dataset
2023-07-03 09:11:01,021:INFO:Defining folds
2023-07-03 09:11:01,021:INFO:Declaring metric variables
2023-07-03 09:11:01,024:INFO:Importing untrained model
2023-07-03 09:11:01,028:INFO:Quadratic Discriminant Analysis Imported successfully
2023-07-03 09:11:01,037:INFO:Starting cross validation
2023-07-03 09:11:01,040:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:11:01,042:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2023-07-03 09:11:01,329:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-03 09:11:01,351:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-03 09:11:01,353:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-03 09:11:01,365:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-03 09:11:01,371:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-03 09:11:01,382:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-03 09:11:01,393:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-03 09:11:01,406:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-03 09:11:01,409:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-03 09:11:01,422:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-03 09:11:01,683:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:01,683:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:01,685:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:01,685:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:01,686:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:02,242:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:378: FitFailedWarning: 
9 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
9 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py", line 917, in fit
    raise ValueError(
ValueError: y has only 1 sample in class 1, covariance is ill defined.

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2023-07-03 09:11:02,242:INFO:Calculating mean and std
2023-07-03 09:11:02,243:INFO:Creating metrics dataframe
2023-07-03 09:11:02,392:INFO:Uploading results into container
2023-07-03 09:11:02,393:INFO:Uploading model into container now
2023-07-03 09:11:02,393:INFO:_master_model_container: 8
2023-07-03 09:11:02,394:INFO:_display_container: 2
2023-07-03 09:11:02,394:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-07-03 09:11:02,394:INFO:create_model() successfully completed......................................
2023-07-03 09:11:02,537:WARNING:create_model() for QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001) raised an exception or returned all 0.0, trying without fit_kwargs:
2023-07-03 09:11:02,539:WARNING:Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

2023-07-03 09:11:02,539:INFO:Initializing create_model()
2023-07-03 09:11:02,539:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000132A2C66CB0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000132A2B07A90>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:11:02,539:INFO:Checking exceptions
2023-07-03 09:11:02,539:INFO:Importing libraries
2023-07-03 09:11:02,539:INFO:Copying training dataset
2023-07-03 09:11:02,543:INFO:Defining folds
2023-07-03 09:11:02,543:INFO:Declaring metric variables
2023-07-03 09:11:02,546:INFO:Importing untrained model
2023-07-03 09:11:02,549:INFO:Quadratic Discriminant Analysis Imported successfully
2023-07-03 09:11:02,554:INFO:Starting cross validation
2023-07-03 09:11:02,556:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:11:02,558:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2023-07-03 09:11:02,827:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-03 09:11:02,843:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-03 09:11:02,845:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-03 09:11:02,873:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-03 09:11:02,877:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-03 09:11:02,883:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-03 09:11:02,899:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-03 09:11:02,919:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-03 09:11:02,926:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-03 09:11:02,928:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-03 09:11:03,014:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:03,015:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:03,016:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:03,017:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:03,018:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:03,727:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:378: FitFailedWarning: 
9 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
9 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py", line 917, in fit
    raise ValueError(
ValueError: y has only 1 sample in class 1, covariance is ill defined.

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2023-07-03 09:11:03,728:INFO:Calculating mean and std
2023-07-03 09:11:03,729:INFO:Creating metrics dataframe
2023-07-03 09:11:03,887:INFO:Uploading results into container
2023-07-03 09:11:03,888:INFO:Uploading model into container now
2023-07-03 09:11:03,889:INFO:_master_model_container: 9
2023-07-03 09:11:03,889:INFO:_display_container: 2
2023-07-03 09:11:03,889:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-07-03 09:11:03,889:INFO:create_model() successfully completed......................................
2023-07-03 09:11:04,033:ERROR:create_model() for QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001) raised an exception or returned all 0.0:
2023-07-03 09:11:04,033:ERROR:Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 811, in compare_models
    np.sum(
AssertionError

2023-07-03 09:11:04,033:INFO:Initializing Ada Boost Classifier
2023-07-03 09:11:04,033:INFO:Total runtime is 0.33851033051808677 minutes
2023-07-03 09:11:04,035:INFO:SubProcess create_model() called ==================================
2023-07-03 09:11:04,036:INFO:Initializing create_model()
2023-07-03 09:11:04,036:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000132A2C66CB0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000132A2B07A90>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:11:04,036:INFO:Checking exceptions
2023-07-03 09:11:04,036:INFO:Importing libraries
2023-07-03 09:11:04,036:INFO:Copying training dataset
2023-07-03 09:11:04,040:INFO:Defining folds
2023-07-03 09:11:04,040:INFO:Declaring metric variables
2023-07-03 09:11:04,043:INFO:Importing untrained model
2023-07-03 09:11:04,045:INFO:Ada Boost Classifier Imported successfully
2023-07-03 09:11:04,051:INFO:Starting cross validation
2023-07-03 09:11:04,053:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:11:04,054:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2023-07-03 09:11:04,500:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:04,500:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:04,501:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:04,502:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:04,502:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:04,503:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:04,503:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:04,524:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:04,525:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:04,525:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:04,526:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:04,527:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:04,528:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:04,528:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:04,529:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:04,529:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:04,530:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:04,531:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:04,533:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:04,554:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:04,555:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:04,555:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:04,556:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:04,556:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:04,557:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:04,557:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:04,558:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:04,558:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:04,559:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:04,560:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:04,560:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:04,624:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:04,624:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:04,625:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:04,625:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:04,626:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:04,626:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:04,626:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:04,627:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:04,627:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:04,627:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:04,628:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:04,628:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:04,629:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:04,629:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:04,629:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:04,630:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:04,630:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:04,631:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:04,631:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:04,632:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:04,634:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:04,662:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:04,663:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:04,664:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:04,665:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:04,666:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:04,667:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:04,669:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:04,722:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:04,722:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:04,723:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:04,724:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:04,724:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:04,725:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:04,725:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:05,404:INFO:Calculating mean and std
2023-07-03 09:11:05,405:INFO:Creating metrics dataframe
2023-07-03 09:11:05,561:INFO:Uploading results into container
2023-07-03 09:11:05,562:INFO:Uploading model into container now
2023-07-03 09:11:05,562:INFO:_master_model_container: 10
2023-07-03 09:11:05,562:INFO:_display_container: 2
2023-07-03 09:11:05,563:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-07-03 09:11:05,563:INFO:create_model() successfully completed......................................
2023-07-03 09:11:05,704:INFO:SubProcess create_model() end ==================================
2023-07-03 09:11:05,705:INFO:Creating metrics dataframe
2023-07-03 09:11:05,714:INFO:Initializing Gradient Boosting Classifier
2023-07-03 09:11:05,714:INFO:Total runtime is 0.3665296276410421 minutes
2023-07-03 09:11:05,717:INFO:SubProcess create_model() called ==================================
2023-07-03 09:11:05,717:INFO:Initializing create_model()
2023-07-03 09:11:05,718:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000132A2C66CB0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000132A2B07A90>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:11:05,718:INFO:Checking exceptions
2023-07-03 09:11:05,718:INFO:Importing libraries
2023-07-03 09:11:05,718:INFO:Copying training dataset
2023-07-03 09:11:05,722:INFO:Defining folds
2023-07-03 09:11:05,722:INFO:Declaring metric variables
2023-07-03 09:11:05,725:INFO:Importing untrained model
2023-07-03 09:11:05,728:INFO:Gradient Boosting Classifier Imported successfully
2023-07-03 09:11:05,732:INFO:Starting cross validation
2023-07-03 09:11:05,734:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:11:05,736:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2023-07-03 09:11:06,357:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:06,357:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:06,359:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:06,360:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:06,360:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:06,378:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:06,379:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:06,380:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:06,382:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:06,383:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:06,384:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:06,385:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:06,386:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:06,387:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:06,388:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:06,389:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:06,390:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:06,391:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:06,392:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:06,398:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:06,399:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:06,401:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:06,402:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:06,403:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:06,404:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:06,405:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:06,434:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:06,435:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:06,436:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:06,436:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:06,437:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:06,437:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:06,438:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:06,439:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:06,439:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:06,440:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:06,441:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:06,442:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:06,453:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:06,453:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:06,455:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:06,456:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:06,457:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:06,458:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:06,459:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:06,463:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:06,464:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:06,465:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:06,466:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:06,468:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:06,477:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:06,478:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:06,479:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:06,480:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:06,481:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:06,482:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:06,484:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:06,496:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:06,497:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:06,499:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:06,500:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:06,501:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:06,502:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:06,503:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:07,265:INFO:Calculating mean and std
2023-07-03 09:11:07,267:INFO:Creating metrics dataframe
2023-07-03 09:11:07,421:INFO:Uploading results into container
2023-07-03 09:11:07,422:INFO:Uploading model into container now
2023-07-03 09:11:07,422:INFO:_master_model_container: 11
2023-07-03 09:11:07,423:INFO:_display_container: 2
2023-07-03 09:11:07,423:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-03 09:11:07,423:INFO:create_model() successfully completed......................................
2023-07-03 09:11:07,573:INFO:SubProcess create_model() end ==================================
2023-07-03 09:11:07,573:INFO:Creating metrics dataframe
2023-07-03 09:11:07,585:INFO:Initializing Linear Discriminant Analysis
2023-07-03 09:11:07,585:INFO:Total runtime is 0.3977184851964315 minutes
2023-07-03 09:11:07,588:INFO:SubProcess create_model() called ==================================
2023-07-03 09:11:07,588:INFO:Initializing create_model()
2023-07-03 09:11:07,589:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000132A2C66CB0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000132A2B07A90>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:11:07,589:INFO:Checking exceptions
2023-07-03 09:11:07,589:INFO:Importing libraries
2023-07-03 09:11:07,589:INFO:Copying training dataset
2023-07-03 09:11:07,593:INFO:Defining folds
2023-07-03 09:11:07,594:INFO:Declaring metric variables
2023-07-03 09:11:07,596:INFO:Importing untrained model
2023-07-03 09:11:07,600:INFO:Linear Discriminant Analysis Imported successfully
2023-07-03 09:11:07,606:INFO:Starting cross validation
2023-07-03 09:11:07,608:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:11:07,609:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2023-07-03 09:11:07,960:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:07,960:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:07,962:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:07,962:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:07,964:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:07,964:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:07,966:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:07,974:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:07,975:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:07,975:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:07,975:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:07,976:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:07,977:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:07,977:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:07,977:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:07,978:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:07,978:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:07,978:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:07,979:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:07,979:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:07,980:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:07,999:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:08,000:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:08,001:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:08,002:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:08,004:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:08,010:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:08,011:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:08,014:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:08,014:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:08,015:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:08,015:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:08,016:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:08,016:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:08,017:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:08,018:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:08,019:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:08,020:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:08,032:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:08,033:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:08,034:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:08,035:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:08,036:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:08,037:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:08,039:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:08,041:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:08,042:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:08,044:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:08,045:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:08,047:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:08,053:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:08,054:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:08,055:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:08,055:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:08,057:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:08,068:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:08,069:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:08,070:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:08,071:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:08,073:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:08,074:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:08,075:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:08,872:INFO:Calculating mean and std
2023-07-03 09:11:08,873:INFO:Creating metrics dataframe
2023-07-03 09:11:09,028:INFO:Uploading results into container
2023-07-03 09:11:09,029:INFO:Uploading model into container now
2023-07-03 09:11:09,030:INFO:_master_model_container: 12
2023-07-03 09:11:09,030:INFO:_display_container: 2
2023-07-03 09:11:09,030:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-07-03 09:11:09,030:INFO:create_model() successfully completed......................................
2023-07-03 09:11:09,173:INFO:SubProcess create_model() end ==================================
2023-07-03 09:11:09,173:INFO:Creating metrics dataframe
2023-07-03 09:11:09,184:INFO:Initializing Extra Trees Classifier
2023-07-03 09:11:09,184:INFO:Total runtime is 0.4243642807006836 minutes
2023-07-03 09:11:09,187:INFO:SubProcess create_model() called ==================================
2023-07-03 09:11:09,187:INFO:Initializing create_model()
2023-07-03 09:11:09,187:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000132A2C66CB0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000132A2B07A90>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:11:09,188:INFO:Checking exceptions
2023-07-03 09:11:09,188:INFO:Importing libraries
2023-07-03 09:11:09,188:INFO:Copying training dataset
2023-07-03 09:11:09,192:INFO:Defining folds
2023-07-03 09:11:09,192:INFO:Declaring metric variables
2023-07-03 09:11:09,196:INFO:Importing untrained model
2023-07-03 09:11:09,199:INFO:Extra Trees Classifier Imported successfully
2023-07-03 09:11:09,205:INFO:Starting cross validation
2023-07-03 09:11:09,207:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:11:09,209:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2023-07-03 09:11:09,759:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:09,760:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:09,762:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:09,762:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:09,764:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:09,764:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:09,766:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:09,770:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:09,771:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:09,772:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:09,773:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:09,774:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:09,775:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:09,776:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:09,817:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:09,819:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:09,820:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:09,820:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:09,821:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:09,821:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:09,822:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:09,822:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:09,823:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:09,823:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:09,824:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:09,824:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:09,825:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:09,826:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:09,828:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:09,829:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:09,830:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:09,831:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:09,832:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:09,833:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:09,834:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:09,841:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:09,842:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:09,844:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:09,845:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:09,846:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:09,847:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:09,849:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:09,850:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:09,851:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:09,852:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:09,853:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:09,855:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:09,856:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:09,857:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:09,885:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:09,886:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:09,888:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:09,888:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:09,889:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:09,889:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:09,890:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:09,890:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:09,891:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:09,892:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:09,893:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:09,893:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:09,894:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:09,895:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:09,905:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:09,906:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:09,908:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:09,909:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:09,910:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:10,687:INFO:Calculating mean and std
2023-07-03 09:11:10,689:INFO:Creating metrics dataframe
2023-07-03 09:11:10,843:INFO:Uploading results into container
2023-07-03 09:11:10,844:INFO:Uploading model into container now
2023-07-03 09:11:10,845:INFO:_master_model_container: 13
2023-07-03 09:11:10,845:INFO:_display_container: 2
2023-07-03 09:11:10,845:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-07-03 09:11:10,845:INFO:create_model() successfully completed......................................
2023-07-03 09:11:10,988:INFO:SubProcess create_model() end ==================================
2023-07-03 09:11:10,988:INFO:Creating metrics dataframe
2023-07-03 09:11:10,998:INFO:Initializing Light Gradient Boosting Machine
2023-07-03 09:11:10,998:INFO:Total runtime is 0.4545983672142029 minutes
2023-07-03 09:11:11,001:INFO:SubProcess create_model() called ==================================
2023-07-03 09:11:11,001:INFO:Initializing create_model()
2023-07-03 09:11:11,002:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000132A2C66CB0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000132A2B07A90>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:11:11,002:INFO:Checking exceptions
2023-07-03 09:11:11,002:INFO:Importing libraries
2023-07-03 09:11:11,002:INFO:Copying training dataset
2023-07-03 09:11:11,006:INFO:Defining folds
2023-07-03 09:11:11,006:INFO:Declaring metric variables
2023-07-03 09:11:11,009:INFO:Importing untrained model
2023-07-03 09:11:11,012:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-03 09:11:11,018:INFO:Starting cross validation
2023-07-03 09:11:11,020:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:11:11,022:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2023-07-03 09:11:12,407:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:12,408:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:12,408:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:12,409:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:12,410:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:12,410:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:12,411:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:12,411:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:12,412:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:12,413:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:12,414:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:12,415:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:12,416:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:12,417:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:12,484:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:12,485:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:12,486:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:12,487:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:12,488:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:12,489:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:12,490:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:12,543:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:12,544:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:12,545:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:12,546:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:12,547:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:12,548:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:12,549:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:12,572:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:12,573:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:12,574:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:12,575:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:12,576:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:12,577:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:12,578:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:12,584:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:12,585:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:12,588:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:12,589:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:12,590:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:12,600:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:12,600:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:12,601:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:12,602:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:12,602:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:12,603:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:12,603:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:12,604:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:12,604:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:12,605:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:12,605:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:12,606:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:12,607:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:12,608:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:12,608:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:12,609:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:12,610:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:12,611:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:12,612:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:12,613:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:12,614:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:12,655:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:12,656:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:12,658:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:12,659:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:12,660:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:12,661:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:12,662:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:13,352:INFO:Calculating mean and std
2023-07-03 09:11:13,353:INFO:Creating metrics dataframe
2023-07-03 09:11:13,507:INFO:Uploading results into container
2023-07-03 09:11:13,508:INFO:Uploading model into container now
2023-07-03 09:11:13,509:INFO:_master_model_container: 14
2023-07-03 09:11:13,509:INFO:_display_container: 2
2023-07-03 09:11:13,509:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-07-03 09:11:13,509:INFO:create_model() successfully completed......................................
2023-07-03 09:11:13,652:INFO:SubProcess create_model() end ==================================
2023-07-03 09:11:13,652:INFO:Creating metrics dataframe
2023-07-03 09:11:13,662:INFO:Initializing Dummy Classifier
2023-07-03 09:11:13,662:INFO:Total runtime is 0.49900973240534463 minutes
2023-07-03 09:11:13,665:INFO:SubProcess create_model() called ==================================
2023-07-03 09:11:13,666:INFO:Initializing create_model()
2023-07-03 09:11:13,666:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000132A2C66CB0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000132A2B07A90>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:11:13,666:INFO:Checking exceptions
2023-07-03 09:11:13,666:INFO:Importing libraries
2023-07-03 09:11:13,666:INFO:Copying training dataset
2023-07-03 09:11:13,670:INFO:Defining folds
2023-07-03 09:11:13,670:INFO:Declaring metric variables
2023-07-03 09:11:13,673:INFO:Importing untrained model
2023-07-03 09:11:13,675:INFO:Dummy Classifier Imported successfully
2023-07-03 09:11:13,681:INFO:Starting cross validation
2023-07-03 09:11:13,683:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:11:13,685:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2023-07-03 09:11:14,024:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:14,024:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:14,025:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:14,026:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:14,026:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:14,027:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:14,027:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:14,042:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:14,042:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:14,043:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:14,044:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:14,044:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:14,045:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:14,046:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:14,054:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:14,055:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:14,056:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:14,057:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:14,057:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:14,058:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:14,058:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:14,058:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:14,059:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:14,059:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:14,060:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:14,061:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:14,061:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:14,063:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:14,066:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:14,067:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:14,068:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:14,069:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:14,070:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:14,071:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:14,072:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:14,085:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:14,086:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:14,087:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:14,088:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:14,089:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:14,090:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:14,091:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:14,096:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:14,097:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:14,099:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:14,100:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:14,101:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:14,117:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:14,118:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:14,119:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:14,120:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:14,121:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:14,123:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:14,123:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:14,124:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:14,124:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:14,125:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:14,126:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:14,127:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:14,128:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:14,130:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:14,137:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:14,138:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:14,139:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:14,140:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:14,141:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:14,142:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:14,144:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:14,939:INFO:Calculating mean and std
2023-07-03 09:11:14,944:INFO:Creating metrics dataframe
2023-07-03 09:11:15,094:INFO:Uploading results into container
2023-07-03 09:11:15,095:INFO:Uploading model into container now
2023-07-03 09:11:15,095:INFO:_master_model_container: 15
2023-07-03 09:11:15,095:INFO:_display_container: 2
2023-07-03 09:11:15,096:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-07-03 09:11:15,096:INFO:create_model() successfully completed......................................
2023-07-03 09:11:15,239:INFO:SubProcess create_model() end ==================================
2023-07-03 09:11:15,239:INFO:Creating metrics dataframe
2023-07-03 09:11:15,257:INFO:Initializing create_model()
2023-07-03 09:11:15,258:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000132A2C66CB0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:11:15,258:INFO:Checking exceptions
2023-07-03 09:11:15,259:INFO:Importing libraries
2023-07-03 09:11:15,259:INFO:Copying training dataset
2023-07-03 09:11:15,262:INFO:Defining folds
2023-07-03 09:11:15,262:INFO:Declaring metric variables
2023-07-03 09:11:15,262:INFO:Importing untrained model
2023-07-03 09:11:15,263:INFO:Declaring custom model
2023-07-03 09:11:15,263:INFO:Random Forest Classifier Imported successfully
2023-07-03 09:11:15,265:INFO:Cross validation set to False
2023-07-03 09:11:15,265:INFO:Fitting Model
2023-07-03 09:11:15,541:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-07-03 09:11:15,541:INFO:create_model() successfully completed......................................
2023-07-03 09:11:15,697:INFO:_master_model_container: 15
2023-07-03 09:11:15,697:INFO:_display_container: 2
2023-07-03 09:11:15,698:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-07-03 09:11:15,698:INFO:compare_models() successfully completed......................................
2023-07-03 09:11:15,710:INFO:Initializing create_model()
2023-07-03 09:11:15,710:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000132A2C66CB0>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:11:15,711:INFO:Checking exceptions
2023-07-03 09:11:15,725:INFO:Importing libraries
2023-07-03 09:11:15,725:INFO:Copying training dataset
2023-07-03 09:11:15,728:INFO:Defining folds
2023-07-03 09:11:15,728:INFO:Declaring metric variables
2023-07-03 09:11:15,731:INFO:Importing untrained model
2023-07-03 09:11:15,734:INFO:Random Forest Classifier Imported successfully
2023-07-03 09:11:15,740:INFO:Starting cross validation
2023-07-03 09:11:15,742:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:11:15,744:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2023-07-03 09:11:16,284:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:16,285:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:16,286:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:16,287:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:16,288:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:16,289:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:16,290:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:16,326:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:16,327:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:16,329:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:16,330:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:16,331:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:16,332:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:16,333:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:16,335:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:16,336:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:16,337:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:16,338:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:16,339:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:16,340:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:16,341:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:16,344:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:16,345:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:16,346:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:16,347:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:16,348:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:16,349:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:16,350:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:16,352:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:16,353:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:16,354:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:16,355:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:16,356:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:16,357:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:16,357:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:16,358:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:16,358:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:16,359:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:16,360:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:16,361:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:16,362:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:16,363:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:16,400:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:16,401:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:16,403:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:16,404:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:16,405:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:16,406:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:16,408:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:16,427:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:16,428:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:16,430:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:16,431:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:16,432:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:16,433:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:16,434:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:16,443:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:16,444:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:16,446:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:16,447:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:16,448:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:16,538:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:16,539:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:16,540:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:16,541:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:16,542:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:16,543:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:16,545:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:17,225:INFO:Calculating mean and std
2023-07-03 09:11:17,226:INFO:Creating metrics dataframe
2023-07-03 09:11:17,232:INFO:Finalizing model
2023-07-03 09:11:17,583:INFO:Uploading results into container
2023-07-03 09:11:17,584:INFO:Uploading model into container now
2023-07-03 09:11:17,591:INFO:_master_model_container: 16
2023-07-03 09:11:17,591:INFO:_display_container: 3
2023-07-03 09:11:17,592:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-07-03 09:11:17,592:INFO:create_model() successfully completed......................................
2023-07-03 09:11:17,762:INFO:Initializing tune_model()
2023-07-03 09:11:17,762:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000132A2C66CB0>)
2023-07-03 09:11:17,762:INFO:Checking exceptions
2023-07-03 09:11:17,777:INFO:Copying training dataset
2023-07-03 09:11:17,780:INFO:Checking base model
2023-07-03 09:11:17,780:INFO:Base model : Random Forest Classifier
2023-07-03 09:11:17,783:INFO:Declaring metric variables
2023-07-03 09:11:17,786:INFO:Defining Hyperparameters
2023-07-03 09:11:17,930:INFO:Tuning with n_jobs=-1
2023-07-03 09:11:17,931:INFO:Initializing RandomizedSearchCV
2023-07-03 09:11:17,935:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2023-07-03 09:11:29,617:INFO:best_params: {'actual_estimator__n_estimators': 190, 'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0.001, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 6, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': 'balanced_subsample', 'actual_estimator__bootstrap': False}
2023-07-03 09:11:29,619:INFO:Hyperparameter search completed
2023-07-03 09:11:29,619:INFO:SubProcess create_model() called ==================================
2023-07-03 09:11:29,619:INFO:Initializing create_model()
2023-07-03 09:11:29,619:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000132A2C66CB0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000132A2B06D70>, model_only=True, return_train_score=False, kwargs={'n_estimators': 190, 'min_samples_split': 9, 'min_samples_leaf': 6, 'min_impurity_decrease': 0.001, 'max_features': 'log2', 'max_depth': 6, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'bootstrap': False})
2023-07-03 09:11:29,619:INFO:Checking exceptions
2023-07-03 09:11:29,620:INFO:Importing libraries
2023-07-03 09:11:29,620:INFO:Copying training dataset
2023-07-03 09:11:29,624:INFO:Defining folds
2023-07-03 09:11:29,624:INFO:Declaring metric variables
2023-07-03 09:11:29,627:INFO:Importing untrained model
2023-07-03 09:11:29,628:INFO:Declaring custom model
2023-07-03 09:11:29,631:INFO:Random Forest Classifier Imported successfully
2023-07-03 09:11:29,636:INFO:Starting cross validation
2023-07-03 09:11:29,638:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:11:29,639:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2023-07-03 09:11:30,358:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:30,359:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:30,360:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:30,361:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:30,361:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:30,362:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:30,363:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:30,441:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:30,442:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:30,442:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:30,443:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:30,443:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:30,444:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:30,444:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:30,445:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:30,445:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:30,446:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:30,446:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:30,447:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:30,447:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:30,448:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:30,452:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:30,452:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:30,453:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:30,453:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:30,454:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:30,455:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:30,455:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:30,456:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:30,457:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:30,457:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:30,458:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:30,458:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:30,459:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:30,460:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:30,478:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:30,478:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:30,480:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:30,481:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:30,482:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:30,483:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:30,484:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:30,485:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:30,486:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:30,487:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:30,488:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:30,489:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:30,512:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:30,513:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:30,515:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:30,516:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:30,517:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:30,518:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:30,519:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:30,543:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:30,545:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:30,546:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:30,547:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:30,548:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:30,549:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:30,551:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:30,623:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:30,624:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:30,625:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:30,625:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:30,626:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:30,627:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:30,627:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:31,297:INFO:Calculating mean and std
2023-07-03 09:11:31,298:INFO:Creating metrics dataframe
2023-07-03 09:11:31,303:INFO:Finalizing model
2023-07-03 09:11:31,680:INFO:Uploading results into container
2023-07-03 09:11:31,680:INFO:Uploading model into container now
2023-07-03 09:11:31,681:INFO:_master_model_container: 17
2023-07-03 09:11:31,681:INFO:_display_container: 4
2023-07-03 09:11:31,681:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='gini',
                       max_depth=6, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.001,
                       min_samples_leaf=6, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, n_estimators=190,
                       n_jobs=-1, oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2023-07-03 09:11:31,681:INFO:create_model() successfully completed......................................
2023-07-03 09:11:31,824:INFO:SubProcess create_model() end ==================================
2023-07-03 09:11:31,824:INFO:choose_better activated
2023-07-03 09:11:31,827:INFO:SubProcess create_model() called ==================================
2023-07-03 09:11:31,828:INFO:Initializing create_model()
2023-07-03 09:11:31,828:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000132A2C66CB0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:11:31,828:INFO:Checking exceptions
2023-07-03 09:11:31,829:INFO:Importing libraries
2023-07-03 09:11:31,829:INFO:Copying training dataset
2023-07-03 09:11:31,833:INFO:Defining folds
2023-07-03 09:11:31,833:INFO:Declaring metric variables
2023-07-03 09:11:31,833:INFO:Importing untrained model
2023-07-03 09:11:31,834:INFO:Declaring custom model
2023-07-03 09:11:31,834:INFO:Random Forest Classifier Imported successfully
2023-07-03 09:11:31,834:INFO:Starting cross validation
2023-07-03 09:11:31,836:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:11:31,837:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2023-07-03 09:11:32,407:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:32,408:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:32,410:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:32,410:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:32,412:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:32,413:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:32,414:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:32,433:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:32,435:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:32,436:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:32,437:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:32,439:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:32,440:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:32,441:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:32,442:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:32,443:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:32,444:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:32,445:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:32,446:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:32,447:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:32,447:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:32,448:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:32,448:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:32,449:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:32,449:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:32,451:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:32,451:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:32,452:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:32,475:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:32,476:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:32,478:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:32,479:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:32,479:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:32,480:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:32,480:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:32,481:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:32,481:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:32,482:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:32,482:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:32,483:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:32,485:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:32,491:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:32,493:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:32,494:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:32,496:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:32,496:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:32,503:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:32,504:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:32,505:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:32,506:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:32,508:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:32,509:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:32,510:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:32,529:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:32,530:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:32,531:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:32,532:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:32,534:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:32,535:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:32,536:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:32,621:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:32,623:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:32,624:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:32,625:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:32,626:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:32,627:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:32,629:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:33,337:INFO:Calculating mean and std
2023-07-03 09:11:33,338:INFO:Creating metrics dataframe
2023-07-03 09:11:33,340:INFO:Finalizing model
2023-07-03 09:11:33,686:INFO:Uploading results into container
2023-07-03 09:11:33,687:INFO:Uploading model into container now
2023-07-03 09:11:33,687:INFO:_master_model_container: 18
2023-07-03 09:11:33,687:INFO:_display_container: 5
2023-07-03 09:11:33,687:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-07-03 09:11:33,687:INFO:create_model() successfully completed......................................
2023-07-03 09:11:33,829:INFO:SubProcess create_model() end ==================================
2023-07-03 09:11:33,830:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False) result for Accuracy is 0.9964
2023-07-03 09:11:33,830:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='gini',
                       max_depth=6, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.001,
                       min_samples_leaf=6, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, n_estimators=190,
                       n_jobs=-1, oob_score=False, random_state=123, verbose=0,
                       warm_start=False) result for Accuracy is 0.9964
2023-07-03 09:11:33,831:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False) is best model
2023-07-03 09:11:33,831:INFO:choose_better completed
2023-07-03 09:11:33,831:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-07-03 09:11:33,846:INFO:_master_model_container: 18
2023-07-03 09:11:33,846:INFO:_display_container: 4
2023-07-03 09:11:33,847:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-07-03 09:11:33,847:INFO:tune_model() successfully completed......................................
2023-07-03 09:11:34,104:INFO:Initializing tune_model()
2023-07-03 09:11:34,104:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=True, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000132A2C66CB0>)
2023-07-03 09:11:34,104:INFO:Checking exceptions
2023-07-03 09:11:34,120:INFO:Copying training dataset
2023-07-03 09:11:34,123:INFO:Checking base model
2023-07-03 09:11:34,123:INFO:Base model : Random Forest Classifier
2023-07-03 09:11:34,126:INFO:Declaring metric variables
2023-07-03 09:11:34,129:INFO:Defining Hyperparameters
2023-07-03 09:11:34,273:INFO:Tuning with n_jobs=-1
2023-07-03 09:11:34,273:INFO:Initializing RandomizedSearchCV
2023-07-03 09:11:34,278:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2023-07-03 09:11:45,997:INFO:best_params: {'actual_estimator__n_estimators': 190, 'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0.001, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 6, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': 'balanced_subsample', 'actual_estimator__bootstrap': False}
2023-07-03 09:11:45,998:INFO:Hyperparameter search completed
2023-07-03 09:11:45,998:INFO:SubProcess create_model() called ==================================
2023-07-03 09:11:45,999:INFO:Initializing create_model()
2023-07-03 09:11:45,999:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000132A2C66CB0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000132A77B15D0>, model_only=True, return_train_score=False, kwargs={'n_estimators': 190, 'min_samples_split': 9, 'min_samples_leaf': 6, 'min_impurity_decrease': 0.001, 'max_features': 'log2', 'max_depth': 6, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'bootstrap': False})
2023-07-03 09:11:45,999:INFO:Checking exceptions
2023-07-03 09:11:45,999:INFO:Importing libraries
2023-07-03 09:11:45,999:INFO:Copying training dataset
2023-07-03 09:11:46,004:INFO:Defining folds
2023-07-03 09:11:46,004:INFO:Declaring metric variables
2023-07-03 09:11:46,007:INFO:Importing untrained model
2023-07-03 09:11:46,007:INFO:Declaring custom model
2023-07-03 09:11:46,010:INFO:Random Forest Classifier Imported successfully
2023-07-03 09:11:46,015:INFO:Starting cross validation
2023-07-03 09:11:46,016:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:11:46,018:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2023-07-03 09:11:46,735:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:46,736:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

ric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:46,737:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:46,737:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:46,738:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:46,738:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:46,739:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:46,739:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:46,740:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:46,740:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:46,741:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:46,741:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:46,742:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:46,758:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:46,759:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:46,761:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:46,762:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:46,763:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:46,764:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:46,765:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:46,812:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:46,812:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:46,813:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:46,813:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:46,814:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:46,815:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:46,815:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:46,815:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:46,816:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:46,817:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:46,817:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:46,817:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:46,818:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:46,818:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:46,883:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:46,884:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:46,885:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:46,886:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:46,886:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:46,887:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:46,888:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:46,888:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:46,889:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:46,889:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:46,890:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:46,890:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:46,891:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:46,892:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:46,922:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:46,923:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:46,924:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:46,925:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:46,925:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:46,926:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:46,926:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:46,927:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:46,927:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:46,928:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:46,929:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:46,929:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:46,946:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:46,947:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:46,949:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:46,950:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:46,951:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:46,952:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:46,953:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:47,683:INFO:Calculating mean and std
2023-07-03 09:11:47,684:INFO:Creating metrics dataframe
2023-07-03 09:11:47,689:INFO:Finalizing model
2023-07-03 09:11:48,066:INFO:Uploading results into container
2023-07-03 09:11:48,067:INFO:Uploading model into container now
2023-07-03 09:11:48,067:INFO:_master_model_container: 19
2023-07-03 09:11:48,067:INFO:_display_container: 5
2023-07-03 09:11:48,067:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='gini',
                       max_depth=6, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.001,
                       min_samples_leaf=6, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, n_estimators=190,
                       n_jobs=-1, oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2023-07-03 09:11:48,067:INFO:create_model() successfully completed......................................
2023-07-03 09:11:48,214:INFO:SubProcess create_model() end ==================================
2023-07-03 09:11:48,214:INFO:choose_better activated
2023-07-03 09:11:48,217:INFO:SubProcess create_model() called ==================================
2023-07-03 09:11:48,218:INFO:Initializing create_model()
2023-07-03 09:11:48,218:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000132A2C66CB0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:11:48,218:INFO:Checking exceptions
2023-07-03 09:11:48,219:INFO:Importing libraries
2023-07-03 09:11:48,219:INFO:Copying training dataset
2023-07-03 09:11:48,223:INFO:Defining folds
2023-07-03 09:11:48,224:INFO:Declaring metric variables
2023-07-03 09:11:48,224:INFO:Importing untrained model
2023-07-03 09:11:48,224:INFO:Declaring custom model
2023-07-03 09:11:48,224:INFO:Random Forest Classifier Imported successfully
2023-07-03 09:11:48,224:INFO:Starting cross validation
2023-07-03 09:11:48,226:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:11:48,227:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2023-07-03 09:11:48,779:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:48,780:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:48,781:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:48,782:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:48,783:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:48,784:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:48,785:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:48,794:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:48,794:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:48,795:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:48,795:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:48,796:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:48,796:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:48,797:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:48,797:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:48,798:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:48,798:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:48,799:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:48,799:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:48,800:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:48,800:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:48,837:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:48,838:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:48,839:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:48,840:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:48,841:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:48,842:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:48,843:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:48,874:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:48,875:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:48,876:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:48,877:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:48,877:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:48,877:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:48,878:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:48,878:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:48,878:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:48,879:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:48,879:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:48,879:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:48,880:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:48,880:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:48,881:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:48,881:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:48,882:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:48,882:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:48,883:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:48,883:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:48,884:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:48,909:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:48,910:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:48,911:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:48,912:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:48,914:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:48,915:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:48,916:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:48,917:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:48,918:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:48,919:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:48,921:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:48,922:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:48,923:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:48,924:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-07-03 09:11:48,924:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 683, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-07-03 09:11:48,926:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:48,928:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:48,929:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:48,930:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:49,707:INFO:Calculating mean and std
2023-07-03 09:11:49,708:INFO:Creating metrics dataframe
2023-07-03 09:11:49,710:INFO:Finalizing model
2023-07-03 09:11:50,053:INFO:Uploading results into container
2023-07-03 09:11:50,054:INFO:Uploading model into container now
2023-07-03 09:11:50,054:INFO:_master_model_container: 20
2023-07-03 09:11:50,054:INFO:_display_container: 6
2023-07-03 09:11:50,054:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-07-03 09:11:50,054:INFO:create_model() successfully completed......................................
2023-07-03 09:11:50,201:INFO:SubProcess create_model() end ==================================
2023-07-03 09:11:50,201:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False) result for Accuracy is 0.9964
2023-07-03 09:11:50,202:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='gini',
                       max_depth=6, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.001,
                       min_samples_leaf=6, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, n_estimators=190,
                       n_jobs=-1, oob_score=False, random_state=123, verbose=0,
                       warm_start=False) result for Accuracy is 0.9964
2023-07-03 09:11:50,202:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False) is best model
2023-07-03 09:11:50,202:INFO:choose_better completed
2023-07-03 09:11:50,202:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-07-03 09:11:50,210:INFO:_master_model_container: 20
2023-07-03 09:11:50,211:INFO:_display_container: 5
2023-07-03 09:11:50,211:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-07-03 09:11:50,211:INFO:tune_model() successfully completed......................................
2023-07-03 09:11:50,762:INFO:Initializing plot_model()
2023-07-03 09:11:50,763:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000132A2C66CB0>, system=True)
2023-07-03 09:11:50,763:INFO:Checking exceptions
2023-07-03 09:11:50,779:INFO:Preloading libraries
2023-07-03 09:11:50,785:INFO:Copying training dataset
2023-07-03 09:11:50,785:INFO:Plot type: confusion_matrix
2023-07-03 09:11:51,181:INFO:Fitting Model
2023-07-03 09:11:51,182:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\base.py:420: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2023-07-03 09:11:51,182:INFO:Scoring test/hold-out set
2023-07-03 09:11:51,313:INFO:Visual Rendered Successfully
2023-07-03 09:11:51,458:INFO:plot_model() successfully completed......................................
2023-07-03 09:11:51,477:INFO:Initializing plot_model()
2023-07-03 09:11:51,478:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000132A2C66CB0>, system=True)
2023-07-03 09:11:51,478:INFO:Checking exceptions
2023-07-03 09:11:51,492:INFO:Preloading libraries
2023-07-03 09:11:51,499:INFO:Copying training dataset
2023-07-03 09:11:51,499:INFO:Plot type: auc
2023-07-03 09:11:51,891:INFO:Fitting Model
2023-07-03 09:11:51,892:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\base.py:420: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2023-07-03 09:11:51,892:INFO:Scoring test/hold-out set
2023-07-03 09:11:52,081:INFO:Visual Rendered Successfully
2023-07-03 09:11:52,226:INFO:plot_model() successfully completed......................................
2023-07-03 09:11:52,237:INFO:Initializing plot_model()
2023-07-03 09:11:52,238:INFO:plot_model(plot=class_report, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000132A2C66CB0>, system=True)
2023-07-03 09:11:52,238:INFO:Checking exceptions
2023-07-03 09:11:52,252:INFO:Preloading libraries
2023-07-03 09:11:52,260:INFO:Copying training dataset
2023-07-03 09:11:52,260:INFO:Plot type: class_report
2023-07-03 09:11:52,662:INFO:Fitting Model
2023-07-03 09:11:52,662:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\base.py:420: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2023-07-03 09:11:52,662:INFO:Scoring test/hold-out set
2023-07-03 09:11:52,694:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:52,860:INFO:Visual Rendered Successfully
2023-07-03 09:11:53,005:INFO:plot_model() successfully completed......................................
2023-07-03 09:11:53,019:INFO:Initializing plot_model()
2023-07-03 09:11:53,020:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000132A2C66CB0>, system=True)
2023-07-03 09:11:53,020:INFO:Checking exceptions
2023-07-03 09:11:53,034:INFO:Preloading libraries
2023-07-03 09:11:53,042:INFO:Copying training dataset
2023-07-03 09:11:53,042:INFO:Plot type: feature
2023-07-03 09:11:53,042:WARNING:No coef_ found. Trying feature_importances_
2023-07-03 09:11:53,264:INFO:Visual Rendered Successfully
2023-07-03 09:11:53,410:INFO:plot_model() successfully completed......................................
2023-07-03 09:11:53,417:INFO:Initializing evaluate_model()
2023-07-03 09:11:53,417:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000132A2C66CB0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-07-03 09:11:53,450:INFO:Initializing plot_model()
2023-07-03 09:11:53,450:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000132A2C66CB0>, system=True)
2023-07-03 09:11:53,450:INFO:Checking exceptions
2023-07-03 09:11:53,462:INFO:Preloading libraries
2023-07-03 09:11:53,468:INFO:Copying training dataset
2023-07-03 09:11:53,468:INFO:Plot type: pipeline
2023-07-03 09:11:53,630:INFO:Visual Rendered Successfully
2023-07-03 09:11:53,768:INFO:plot_model() successfully completed......................................
2023-07-03 09:11:53,781:INFO:Initializing finalize_model()
2023-07-03 09:11:53,781:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000132A2C66CB0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-07-03 09:11:53,781:INFO:Finalizing RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-07-03 09:11:53,784:INFO:Initializing create_model()
2023-07-03 09:11:53,784:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000132A2C66CB0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-07-03 09:11:53,784:INFO:Checking exceptions
2023-07-03 09:11:53,786:INFO:Importing libraries
2023-07-03 09:11:53,786:INFO:Copying training dataset
2023-07-03 09:11:53,786:INFO:Defining folds
2023-07-03 09:11:53,786:INFO:Declaring metric variables
2023-07-03 09:11:53,786:INFO:Importing untrained model
2023-07-03 09:11:53,786:INFO:Declaring custom model
2023-07-03 09:11:53,787:INFO:Random Forest Classifier Imported successfully
2023-07-03 09:11:53,789:INFO:Cross validation set to False
2023-07-03 09:11:53,789:INFO:Fitting Model
2023-07-03 09:11:54,040:INFO:Pipeline(memory=FastMemory(location=C:\Users\JHossain\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['id', 'age', 'bp', 'sg', 'al',
                                             'su', 'bgr', 'bu', 'sc', 'sod',
                                             'pot', 'hemo'],
                                    transformer=SimpleImputer(add_...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='sqrt',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        n_estimators=100, n_jobs=-1,
                                        oob_score=False, random_state=123,
                                        verbose=0, warm_start=False))],
         verbose=False)
2023-07-03 09:11:54,040:INFO:create_model() successfully completed......................................
2023-07-03 09:11:54,184:INFO:_master_model_container: 20
2023-07-03 09:11:54,184:INFO:_display_container: 5
2023-07-03 09:11:54,245:INFO:Pipeline(memory=FastMemory(location=C:\Users\JHossain\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['id', 'age', 'bp', 'sg', 'al',
                                             'su', 'bgr', 'bu', 'sc', 'sod',
                                             'pot', 'hemo'],
                                    transformer=SimpleImputer(add_...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='sqrt',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        n_estimators=100, n_jobs=-1,
                                        oob_score=False, random_state=123,
                                        verbose=0, warm_start=False))],
         verbose=False)
2023-07-03 09:11:54,245:INFO:finalize_model() successfully completed......................................
2023-07-03 09:11:54,572:INFO:Initializing predict_model()
2023-07-03 09:11:54,572:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000132A2C66CB0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000132AA2B4A60>)
2023-07-03 09:11:54,572:INFO:Checking exceptions
2023-07-03 09:11:54,572:INFO:Preloading libraries
2023-07-03 09:11:54,829:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\utils\generic.py:586: UserWarning: Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 580, in _calculate_metric
    calculated_metric = score_func(y_test, target, sample_weight=weights, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 638, in _multiclass_roc_auc_score
    if not np.allclose(1, y_score.sum(axis=1)):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\numpy\core\_methods.py", line 48, in _sum
    return umr_sum(a, axis, dtype, out, keepdims, initial, where)
numpy.AxisError: axis 1 is out of bounds for array of dimension 1

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 584, in _calculate_metric
    calculated_metric = score_func(y_test, target, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 566, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 638, in _multiclass_roc_auc_score
    if not np.allclose(1, y_score.sum(axis=1)):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\numpy\core\_methods.py", line 48, in _sum
    return umr_sum(a, axis, dtype, out, keepdims, initial, where)
numpy.AxisError: axis 1 is out of bounds for array of dimension 1

  warnings.warn(traceback.format_exc())

2023-07-03 09:11:54,830:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:54,831:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:54,832:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 09:11:54,832:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-07-03 09:11:55,065:INFO:Initializing predict_model()
2023-07-03 09:11:55,066:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000132A2C66CB0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000132AA525870>)
2023-07-03 09:11:55,066:INFO:Checking exceptions
2023-07-03 09:11:55,066:INFO:Preloading libraries
2023-07-03 09:11:55,067:INFO:Set up data.
2023-07-03 09:11:55,075:INFO:Set up index.
2023-07-03 09:11:55,363:INFO:Initializing save_model()
2023-07-03 09:11:55,363:INFO:save_model(model=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), model_name=../models/chronic_kidney, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JHossain\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['id', 'age', 'bp', 'sg', 'al',
                                             'su', 'bgr', 'bu', 'sc', 'sod',
                                             'pot', 'hemo'],
                                    transformer=SimpleImputer(add_...
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['pcv', 'wc', 'rc'],
                                    transformer=TargetEncoder(cols=['pcv', 'wc',
                                                                    'rc'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-07-03 09:11:55,363:INFO:Adding model into prep_pipe
2023-07-03 09:18:41,178:INFO:Initializing save_model()
2023-07-03 09:18:41,178:INFO:save_model(model=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), model_name=chronic_kidney, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JHossain\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['id', 'age', 'bp', 'sg', 'al',
                                             'su', 'bgr', 'bu', 'sc', 'sod',
                                             'pot', 'hemo'],
                                    transformer=SimpleImputer(add_...
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['pcv', 'wc', 'rc'],
                                    transformer=TargetEncoder(cols=['pcv', 'wc',
                                                                    'rc'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-07-03 09:18:41,178:INFO:Adding model into prep_pipe
2023-07-03 09:18:41,224:INFO:chronic_kidney.pkl saved in current working directory
2023-07-03 09:18:41,284:INFO:Pipeline(memory=FastMemory(location=C:\Users\JHossain\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['id', 'age', 'bp', 'sg', 'al',
                                             'su', 'bgr', 'bu', 'sc', 'sod',
                                             'pot', 'hemo'],
                                    transformer=SimpleImputer(add_...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='sqrt',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        n_estimators=100, n_jobs=-1,
                                        oob_score=False, random_state=123,
                                        verbose=0, warm_start=False))],
         verbose=False)
2023-07-03 09:18:41,284:INFO:save_model() successfully completed......................................
2023-07-03 09:19:32,271:INFO:Initializing save_model()
2023-07-03 09:19:32,271:INFO:save_model(model=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), model_name=../models/chronic_kidney, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JHossain\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['id', 'age', 'bp', 'sg', 'al',
                                             'su', 'bgr', 'bu', 'sc', 'sod',
                                             'pot', 'hemo'],
                                    transformer=SimpleImputer(add_...
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['pcv', 'wc', 'rc'],
                                    transformer=TargetEncoder(cols=['pcv', 'wc',
                                                                    'rc'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-07-03 09:19:32,271:INFO:Adding model into prep_pipe
2023-07-03 09:19:32,316:INFO:../models/chronic_kidney.pkl saved in current working directory
2023-07-03 09:19:32,376:INFO:Pipeline(memory=FastMemory(location=C:\Users\JHossain\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['id', 'age', 'bp', 'sg', 'al',
                                             'su', 'bgr', 'bu', 'sc', 'sod',
                                             'pot', 'hemo'],
                                    transformer=SimpleImputer(add_...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='sqrt',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        n_estimators=100, n_jobs=-1,
                                        oob_score=False, random_state=123,
                                        verbose=0, warm_start=False))],
         verbose=False)
2023-07-03 09:19:32,376:INFO:save_model() successfully completed......................................
2023-07-03 09:19:35,680:INFO:Initializing load_model()
2023-07-03 09:19:35,680:INFO:load_model(model_name=../models/chronic_kidney, platform=None, authentication=None, verbose=True)
2023-07-03 09:39:03,801:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-03 09:39:03,801:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-03 09:39:03,801:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-03 09:39:03,801:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-03 09:39:04,620:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-07-03 09:39:04,865:INFO:PyCaret RegressionExperiment
2023-07-03 09:39:04,865:INFO:Logging name: reg-default-name
2023-07-03 09:39:04,865:INFO:ML Usecase: MLUsecase.REGRESSION
2023-07-03 09:39:04,865:INFO:version 3.0.2
2023-07-03 09:39:04,865:INFO:Initializing setup()
2023-07-03 09:39:04,865:INFO:self.USI: 4a56
2023-07-03 09:39:04,866:INFO:self._variable_keys: {'pipeline', 'exp_name_log', 'seed', 'y_test', 'log_plots_param', 'exp_id', '_ml_usecase', 'fold_shuffle_param', 'fold_groups_param', 'logging_param', 'gpu_param', 'memory', 'fold_generator', 'html_param', '_available_plots', 'target_param', 'y_train', 'n_jobs_param', 'X_test', 'X_train', 'transform_target_param', 'X', 'y', 'data', 'USI', 'idx', 'gpu_n_jobs_param'}
2023-07-03 09:39:04,866:INFO:Checking environment
2023-07-03 09:39:04,866:INFO:python_version: 3.10.9
2023-07-03 09:39:04,866:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2023-07-03 09:39:04,866:INFO:machine: AMD64
2023-07-03 09:39:04,866:INFO:platform: Windows-10-10.0.22621-SP0
2023-07-03 09:39:04,869:INFO:Memory: svmem(total=33664483328, available=22464835584, percent=33.3, used=11199647744, free=22464835584)
2023-07-03 09:39:04,869:INFO:Physical Core: 6
2023-07-03 09:39:04,869:INFO:Logical Core: 12
2023-07-03 09:39:04,869:INFO:Checking libraries
2023-07-03 09:39:04,869:INFO:System:
2023-07-03 09:39:04,869:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2023-07-03 09:39:04,869:INFO:executable: C:\Users\JHossain\anaconda3\python.exe
2023-07-03 09:39:04,869:INFO:   machine: Windows-10-10.0.22621-SP0
2023-07-03 09:39:04,869:INFO:PyCaret required dependencies:
2023-07-03 09:39:04,870:INFO:                 pip: 22.3.1
2023-07-03 09:39:04,870:INFO:          setuptools: 65.6.3
2023-07-03 09:39:04,870:INFO:             pycaret: 3.0.2
2023-07-03 09:39:04,870:INFO:             IPython: 8.10.0
2023-07-03 09:39:04,870:INFO:          ipywidgets: 7.6.5
2023-07-03 09:39:04,870:INFO:                tqdm: 4.64.1
2023-07-03 09:39:04,870:INFO:               numpy: 1.23.5
2023-07-03 09:39:04,870:INFO:              pandas: 1.5.3
2023-07-03 09:39:04,870:INFO:              jinja2: 3.1.2
2023-07-03 09:39:04,870:INFO:               scipy: 1.10.0
2023-07-03 09:39:04,870:INFO:              joblib: 1.2.0
2023-07-03 09:39:04,870:INFO:             sklearn: 1.2.1
2023-07-03 09:39:04,870:INFO:                pyod: 1.0.9
2023-07-03 09:39:04,870:INFO:            imblearn: 0.10.1
2023-07-03 09:39:04,870:INFO:   category_encoders: 2.6.1
2023-07-03 09:39:04,870:INFO:            lightgbm: 3.3.5
2023-07-03 09:39:04,870:INFO:               numba: 0.56.4
2023-07-03 09:39:04,870:INFO:            requests: 2.28.1
2023-07-03 09:39:04,870:INFO:          matplotlib: 3.7.0
2023-07-03 09:39:04,870:INFO:          scikitplot: 0.3.7
2023-07-03 09:39:04,870:INFO:         yellowbrick: 1.5
2023-07-03 09:39:04,870:INFO:              plotly: 5.9.0
2023-07-03 09:39:04,870:INFO:             kaleido: 0.2.1
2023-07-03 09:39:04,870:INFO:         statsmodels: 0.13.5
2023-07-03 09:39:04,870:INFO:              sktime: 0.17.0
2023-07-03 09:39:04,870:INFO:               tbats: 1.1.3
2023-07-03 09:39:04,870:INFO:            pmdarima: 2.0.3
2023-07-03 09:39:04,870:INFO:              psutil: 5.9.0
2023-07-03 09:39:04,870:INFO:PyCaret optional dependencies:
2023-07-03 09:39:05,843:INFO:                shap: Not installed
2023-07-03 09:39:05,843:INFO:           interpret: Not installed
2023-07-03 09:39:05,843:INFO:                umap: Not installed
2023-07-03 09:39:05,843:INFO:    pandas_profiling: Not installed
2023-07-03 09:39:05,843:INFO:  explainerdashboard: Not installed
2023-07-03 09:39:05,843:INFO:             autoviz: Not installed
2023-07-03 09:39:05,843:INFO:           fairlearn: Not installed
2023-07-03 09:39:05,843:INFO:             xgboost: Not installed
2023-07-03 09:39:05,843:INFO:            catboost: Not installed
2023-07-03 09:39:05,843:INFO:              kmodes: Not installed
2023-07-03 09:39:05,843:INFO:             mlxtend: Not installed
2023-07-03 09:39:05,843:INFO:       statsforecast: Not installed
2023-07-03 09:39:05,843:INFO:        tune_sklearn: Not installed
2023-07-03 09:39:05,843:INFO:                 ray: Not installed
2023-07-03 09:39:05,843:INFO:            hyperopt: Not installed
2023-07-03 09:39:05,843:INFO:              optuna: Not installed
2023-07-03 09:39:05,843:INFO:               skopt: Not installed
2023-07-03 09:39:05,843:INFO:              mlflow: Not installed
2023-07-03 09:39:05,843:INFO:              gradio: 3.35.2
2023-07-03 09:39:05,843:INFO:             fastapi: 0.99.0
2023-07-03 09:39:05,843:INFO:             uvicorn: 0.22.0
2023-07-03 09:39:05,843:INFO:              m2cgen: Not installed
2023-07-03 09:39:05,843:INFO:           evidently: Not installed
2023-07-03 09:39:05,844:INFO:               fugue: Not installed
2023-07-03 09:39:05,844:INFO:           streamlit: Not installed
2023-07-03 09:39:05,844:INFO:             prophet: Not installed
2023-07-03 09:39:05,844:INFO:None
2023-07-03 09:39:05,844:INFO:Set up data.
2023-07-03 09:39:05,847:INFO:Set up train/test split.
2023-07-03 09:39:05,849:INFO:Set up index.
2023-07-03 09:39:05,849:INFO:Set up folding strategy.
2023-07-03 09:39:05,849:INFO:Assigning column types.
2023-07-03 09:39:05,852:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-07-03 09:39:05,852:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-07-03 09:39:05,856:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-07-03 09:39:05,860:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-03 09:39:05,923:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-03 09:39:05,964:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-03 09:39:05,966:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:39:06,117:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:39:06,117:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-07-03 09:39:06,121:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-07-03 09:39:06,124:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-03 09:39:06,171:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-03 09:39:06,208:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-03 09:39:06,209:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:39:06,209:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:39:06,209:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-07-03 09:39:06,213:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-07-03 09:39:06,216:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-03 09:39:06,262:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-03 09:39:06,301:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-03 09:39:06,301:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:39:06,302:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:39:06,306:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-07-03 09:39:06,310:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-03 09:39:06,356:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-03 09:39:06,393:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-03 09:39:06,393:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:39:06,393:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:39:06,394:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-07-03 09:39:06,401:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-03 09:39:06,448:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-03 09:39:06,484:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-03 09:39:06,484:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:39:06,484:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:39:06,492:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-03 09:39:06,539:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-03 09:39:06,576:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-03 09:39:06,576:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:39:06,576:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:39:06,577:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-07-03 09:39:06,630:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-03 09:39:06,666:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-03 09:39:06,667:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:39:06,667:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:39:06,721:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-03 09:39:06,757:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-03 09:39:06,758:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:39:06,760:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:39:06,761:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-07-03 09:39:06,815:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-03 09:39:06,852:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:39:06,852:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:39:06,907:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-03 09:39:06,944:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:39:06,944:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:39:06,944:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-07-03 09:39:07,035:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:39:07,035:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:39:07,127:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:39:07,127:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:39:07,129:INFO:Preparing preprocessing pipeline...
2023-07-03 09:39:07,129:INFO:Set up simple imputation.
2023-07-03 09:39:07,143:INFO:Finished creating preprocessing pipeline.
2023-07-03 09:39:07,146:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\JHossain\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MolLogP', 'MolWt',
                                             'NumRotatableBonds',
                                             'AromaticProportion'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2023-07-03 09:39:07,146:INFO:Creating final display dataframe.
2023-07-03 09:39:07,190:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target              logS
2                   Target type        Regression
3           Original data shape         (1144, 5)
4        Transformed data shape         (1144, 5)
5   Transformed train set shape           (91, 5)
6    Transformed test set shape         (1053, 5)
7              Numeric features                 4
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              4a56
2023-07-03 09:39:07,288:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:39:07,288:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:39:07,380:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:39:07,380:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:39:07,381:INFO:setup() successfully completed in 2.61s...............
2023-07-03 09:39:12,882:INFO:Initializing compare_models()
2023-07-03 09:39:12,882:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244DE0C7AF0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000244DE0C7AF0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-07-03 09:39:12,882:INFO:Checking exceptions
2023-07-03 09:39:12,884:INFO:Preparing display monitor
2023-07-03 09:39:12,905:INFO:Initializing Linear Regression
2023-07-03 09:39:12,905:INFO:Total runtime is 0.0 minutes
2023-07-03 09:39:12,908:INFO:SubProcess create_model() called ==================================
2023-07-03 09:39:12,908:INFO:Initializing create_model()
2023-07-03 09:39:12,909:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244DE0C7AF0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000244E71956F0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:39:12,909:INFO:Checking exceptions
2023-07-03 09:39:12,909:INFO:Importing libraries
2023-07-03 09:39:12,909:INFO:Copying training dataset
2023-07-03 09:39:12,912:INFO:Defining folds
2023-07-03 09:39:12,912:INFO:Declaring metric variables
2023-07-03 09:39:12,915:INFO:Importing untrained model
2023-07-03 09:39:12,918:INFO:Linear Regression Imported successfully
2023-07-03 09:39:12,923:INFO:Starting cross validation
2023-07-03 09:39:12,929:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:39:19,689:INFO:Calculating mean and std
2023-07-03 09:39:19,690:INFO:Creating metrics dataframe
2023-07-03 09:39:19,845:INFO:Uploading results into container
2023-07-03 09:39:19,846:INFO:Uploading model into container now
2023-07-03 09:39:19,847:INFO:_master_model_container: 1
2023-07-03 09:39:19,847:INFO:_display_container: 2
2023-07-03 09:39:19,847:INFO:LinearRegression(n_jobs=-1)
2023-07-03 09:39:19,847:INFO:create_model() successfully completed......................................
2023-07-03 09:39:20,118:INFO:SubProcess create_model() end ==================================
2023-07-03 09:39:20,118:INFO:Creating metrics dataframe
2023-07-03 09:39:20,126:INFO:Initializing Lasso Regression
2023-07-03 09:39:20,126:INFO:Total runtime is 0.12035270531972249 minutes
2023-07-03 09:39:20,130:INFO:SubProcess create_model() called ==================================
2023-07-03 09:39:20,130:INFO:Initializing create_model()
2023-07-03 09:39:20,130:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244DE0C7AF0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000244E71956F0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:39:20,130:INFO:Checking exceptions
2023-07-03 09:39:20,130:INFO:Importing libraries
2023-07-03 09:39:20,130:INFO:Copying training dataset
2023-07-03 09:39:20,133:INFO:Defining folds
2023-07-03 09:39:20,133:INFO:Declaring metric variables
2023-07-03 09:39:20,137:INFO:Importing untrained model
2023-07-03 09:39:20,139:INFO:Lasso Regression Imported successfully
2023-07-03 09:39:20,145:INFO:Starting cross validation
2023-07-03 09:39:20,145:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:39:22,408:INFO:Calculating mean and std
2023-07-03 09:39:22,409:INFO:Creating metrics dataframe
2023-07-03 09:39:22,573:INFO:Uploading results into container
2023-07-03 09:39:22,574:INFO:Uploading model into container now
2023-07-03 09:39:22,575:INFO:_master_model_container: 2
2023-07-03 09:39:22,575:INFO:_display_container: 2
2023-07-03 09:39:22,575:INFO:Lasso(random_state=123)
2023-07-03 09:39:22,576:INFO:create_model() successfully completed......................................
2023-07-03 09:39:22,851:INFO:SubProcess create_model() end ==================================
2023-07-03 09:39:22,852:INFO:Creating metrics dataframe
2023-07-03 09:39:22,860:INFO:Initializing Ridge Regression
2023-07-03 09:39:22,860:INFO:Total runtime is 0.1659095287322998 minutes
2023-07-03 09:39:22,862:INFO:SubProcess create_model() called ==================================
2023-07-03 09:39:22,863:INFO:Initializing create_model()
2023-07-03 09:39:22,863:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244DE0C7AF0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000244E71956F0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:39:22,863:INFO:Checking exceptions
2023-07-03 09:39:22,863:INFO:Importing libraries
2023-07-03 09:39:22,863:INFO:Copying training dataset
2023-07-03 09:39:22,866:INFO:Defining folds
2023-07-03 09:39:22,866:INFO:Declaring metric variables
2023-07-03 09:39:22,869:INFO:Importing untrained model
2023-07-03 09:39:22,872:INFO:Ridge Regression Imported successfully
2023-07-03 09:39:22,877:INFO:Starting cross validation
2023-07-03 09:39:22,878:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:39:23,872:INFO:Calculating mean and std
2023-07-03 09:39:23,873:INFO:Creating metrics dataframe
2023-07-03 09:39:24,031:INFO:Uploading results into container
2023-07-03 09:39:24,032:INFO:Uploading model into container now
2023-07-03 09:39:24,032:INFO:_master_model_container: 3
2023-07-03 09:39:24,032:INFO:_display_container: 2
2023-07-03 09:39:24,033:INFO:Ridge(random_state=123)
2023-07-03 09:39:24,033:INFO:create_model() successfully completed......................................
2023-07-03 09:39:24,308:INFO:SubProcess create_model() end ==================================
2023-07-03 09:39:24,308:INFO:Creating metrics dataframe
2023-07-03 09:39:24,317:INFO:Initializing Elastic Net
2023-07-03 09:39:24,318:INFO:Total runtime is 0.1902125080426534 minutes
2023-07-03 09:39:24,320:INFO:SubProcess create_model() called ==================================
2023-07-03 09:39:24,321:INFO:Initializing create_model()
2023-07-03 09:39:24,321:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244DE0C7AF0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000244E71956F0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:39:24,321:INFO:Checking exceptions
2023-07-03 09:39:24,321:INFO:Importing libraries
2023-07-03 09:39:24,321:INFO:Copying training dataset
2023-07-03 09:39:24,324:INFO:Defining folds
2023-07-03 09:39:24,325:INFO:Declaring metric variables
2023-07-03 09:39:24,327:INFO:Importing untrained model
2023-07-03 09:39:24,330:INFO:Elastic Net Imported successfully
2023-07-03 09:39:24,336:INFO:Starting cross validation
2023-07-03 09:39:24,337:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:39:25,316:INFO:Calculating mean and std
2023-07-03 09:39:25,317:INFO:Creating metrics dataframe
2023-07-03 09:39:25,483:INFO:Uploading results into container
2023-07-03 09:39:25,483:INFO:Uploading model into container now
2023-07-03 09:39:25,484:INFO:_master_model_container: 4
2023-07-03 09:39:25,484:INFO:_display_container: 2
2023-07-03 09:39:25,484:INFO:ElasticNet(random_state=123)
2023-07-03 09:39:25,484:INFO:create_model() successfully completed......................................
2023-07-03 09:39:25,752:INFO:SubProcess create_model() end ==================================
2023-07-03 09:39:25,753:INFO:Creating metrics dataframe
2023-07-03 09:39:25,762:INFO:Initializing Least Angle Regression
2023-07-03 09:39:25,762:INFO:Total runtime is 0.2142780661582947 minutes
2023-07-03 09:39:25,765:INFO:SubProcess create_model() called ==================================
2023-07-03 09:39:25,765:INFO:Initializing create_model()
2023-07-03 09:39:25,765:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244DE0C7AF0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000244E71956F0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:39:25,765:INFO:Checking exceptions
2023-07-03 09:39:25,765:INFO:Importing libraries
2023-07-03 09:39:25,765:INFO:Copying training dataset
2023-07-03 09:39:25,769:INFO:Defining folds
2023-07-03 09:39:25,769:INFO:Declaring metric variables
2023-07-03 09:39:25,772:INFO:Importing untrained model
2023-07-03 09:39:25,776:INFO:Least Angle Regression Imported successfully
2023-07-03 09:39:25,781:INFO:Starting cross validation
2023-07-03 09:39:25,782:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:39:26,766:INFO:Calculating mean and std
2023-07-03 09:39:26,767:INFO:Creating metrics dataframe
2023-07-03 09:39:26,920:INFO:Uploading results into container
2023-07-03 09:39:26,921:INFO:Uploading model into container now
2023-07-03 09:39:26,921:INFO:_master_model_container: 5
2023-07-03 09:39:26,921:INFO:_display_container: 2
2023-07-03 09:39:26,922:INFO:Lars(random_state=123)
2023-07-03 09:39:26,922:INFO:create_model() successfully completed......................................
2023-07-03 09:39:27,198:INFO:SubProcess create_model() end ==================================
2023-07-03 09:39:27,199:INFO:Creating metrics dataframe
2023-07-03 09:39:27,207:INFO:Initializing Lasso Least Angle Regression
2023-07-03 09:39:27,207:INFO:Total runtime is 0.23836738268534344 minutes
2023-07-03 09:39:27,210:INFO:SubProcess create_model() called ==================================
2023-07-03 09:39:27,211:INFO:Initializing create_model()
2023-07-03 09:39:27,211:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244DE0C7AF0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000244E71956F0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:39:27,211:INFO:Checking exceptions
2023-07-03 09:39:27,211:INFO:Importing libraries
2023-07-03 09:39:27,211:INFO:Copying training dataset
2023-07-03 09:39:27,213:INFO:Defining folds
2023-07-03 09:39:27,215:INFO:Declaring metric variables
2023-07-03 09:39:27,217:INFO:Importing untrained model
2023-07-03 09:39:27,220:INFO:Lasso Least Angle Regression Imported successfully
2023-07-03 09:39:27,225:INFO:Starting cross validation
2023-07-03 09:39:27,226:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:39:28,212:INFO:Calculating mean and std
2023-07-03 09:39:28,213:INFO:Creating metrics dataframe
2023-07-03 09:39:28,368:INFO:Uploading results into container
2023-07-03 09:39:28,369:INFO:Uploading model into container now
2023-07-03 09:39:28,369:INFO:_master_model_container: 6
2023-07-03 09:39:28,370:INFO:_display_container: 2
2023-07-03 09:39:28,370:INFO:LassoLars(random_state=123)
2023-07-03 09:39:28,370:INFO:create_model() successfully completed......................................
2023-07-03 09:39:28,644:INFO:SubProcess create_model() end ==================================
2023-07-03 09:39:28,645:INFO:Creating metrics dataframe
2023-07-03 09:39:28,654:INFO:Initializing Orthogonal Matching Pursuit
2023-07-03 09:39:28,654:INFO:Total runtime is 0.2624914129575094 minutes
2023-07-03 09:39:28,658:INFO:SubProcess create_model() called ==================================
2023-07-03 09:39:28,659:INFO:Initializing create_model()
2023-07-03 09:39:28,659:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244DE0C7AF0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000244E71956F0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:39:28,659:INFO:Checking exceptions
2023-07-03 09:39:28,659:INFO:Importing libraries
2023-07-03 09:39:28,659:INFO:Copying training dataset
2023-07-03 09:39:28,662:INFO:Defining folds
2023-07-03 09:39:28,662:INFO:Declaring metric variables
2023-07-03 09:39:28,665:INFO:Importing untrained model
2023-07-03 09:39:28,668:INFO:Orthogonal Matching Pursuit Imported successfully
2023-07-03 09:39:28,673:INFO:Starting cross validation
2023-07-03 09:39:28,675:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:39:29,649:INFO:Calculating mean and std
2023-07-03 09:39:29,651:INFO:Creating metrics dataframe
2023-07-03 09:39:29,806:INFO:Uploading results into container
2023-07-03 09:39:29,807:INFO:Uploading model into container now
2023-07-03 09:39:29,808:INFO:_master_model_container: 7
2023-07-03 09:39:29,808:INFO:_display_container: 2
2023-07-03 09:39:29,808:INFO:OrthogonalMatchingPursuit()
2023-07-03 09:39:29,808:INFO:create_model() successfully completed......................................
2023-07-03 09:39:30,085:INFO:SubProcess create_model() end ==================================
2023-07-03 09:39:30,085:INFO:Creating metrics dataframe
2023-07-03 09:39:30,093:INFO:Initializing Bayesian Ridge
2023-07-03 09:39:30,093:INFO:Total runtime is 0.2864693880081177 minutes
2023-07-03 09:39:30,097:INFO:SubProcess create_model() called ==================================
2023-07-03 09:39:30,097:INFO:Initializing create_model()
2023-07-03 09:39:30,097:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244DE0C7AF0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000244E71956F0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:39:30,097:INFO:Checking exceptions
2023-07-03 09:39:30,097:INFO:Importing libraries
2023-07-03 09:39:30,097:INFO:Copying training dataset
2023-07-03 09:39:30,100:INFO:Defining folds
2023-07-03 09:39:30,100:INFO:Declaring metric variables
2023-07-03 09:39:30,103:INFO:Importing untrained model
2023-07-03 09:39:30,106:INFO:Bayesian Ridge Imported successfully
2023-07-03 09:39:30,111:INFO:Starting cross validation
2023-07-03 09:39:30,111:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:39:31,086:INFO:Calculating mean and std
2023-07-03 09:39:31,087:INFO:Creating metrics dataframe
2023-07-03 09:39:31,243:INFO:Uploading results into container
2023-07-03 09:39:31,245:INFO:Uploading model into container now
2023-07-03 09:39:31,245:INFO:_master_model_container: 8
2023-07-03 09:39:31,246:INFO:_display_container: 2
2023-07-03 09:39:31,246:INFO:BayesianRidge()
2023-07-03 09:39:31,246:INFO:create_model() successfully completed......................................
2023-07-03 09:39:31,523:INFO:SubProcess create_model() end ==================================
2023-07-03 09:39:31,523:INFO:Creating metrics dataframe
2023-07-03 09:39:31,533:INFO:Initializing Passive Aggressive Regressor
2023-07-03 09:39:31,533:INFO:Total runtime is 0.310462236404419 minutes
2023-07-03 09:39:31,536:INFO:SubProcess create_model() called ==================================
2023-07-03 09:39:31,536:INFO:Initializing create_model()
2023-07-03 09:39:31,536:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244DE0C7AF0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000244E71956F0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:39:31,536:INFO:Checking exceptions
2023-07-03 09:39:31,536:INFO:Importing libraries
2023-07-03 09:39:31,536:INFO:Copying training dataset
2023-07-03 09:39:31,540:INFO:Defining folds
2023-07-03 09:39:31,540:INFO:Declaring metric variables
2023-07-03 09:39:31,543:INFO:Importing untrained model
2023-07-03 09:39:31,546:INFO:Passive Aggressive Regressor Imported successfully
2023-07-03 09:39:31,551:INFO:Starting cross validation
2023-07-03 09:39:31,552:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:39:32,524:INFO:Calculating mean and std
2023-07-03 09:39:32,525:INFO:Creating metrics dataframe
2023-07-03 09:39:32,679:INFO:Uploading results into container
2023-07-03 09:39:32,680:INFO:Uploading model into container now
2023-07-03 09:39:32,680:INFO:_master_model_container: 9
2023-07-03 09:39:32,680:INFO:_display_container: 2
2023-07-03 09:39:32,681:INFO:PassiveAggressiveRegressor(random_state=123)
2023-07-03 09:39:32,681:INFO:create_model() successfully completed......................................
2023-07-03 09:39:32,956:INFO:SubProcess create_model() end ==================================
2023-07-03 09:39:32,956:INFO:Creating metrics dataframe
2023-07-03 09:39:32,966:INFO:Initializing Huber Regressor
2023-07-03 09:39:32,967:INFO:Total runtime is 0.3343650937080384 minutes
2023-07-03 09:39:32,969:INFO:SubProcess create_model() called ==================================
2023-07-03 09:39:32,970:INFO:Initializing create_model()
2023-07-03 09:39:32,970:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244DE0C7AF0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000244E71956F0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:39:32,970:INFO:Checking exceptions
2023-07-03 09:39:32,970:INFO:Importing libraries
2023-07-03 09:39:32,970:INFO:Copying training dataset
2023-07-03 09:39:32,973:INFO:Defining folds
2023-07-03 09:39:32,973:INFO:Declaring metric variables
2023-07-03 09:39:32,976:INFO:Importing untrained model
2023-07-03 09:39:32,978:INFO:Huber Regressor Imported successfully
2023-07-03 09:39:32,983:INFO:Starting cross validation
2023-07-03 09:39:32,984:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:39:33,974:INFO:Calculating mean and std
2023-07-03 09:39:33,975:INFO:Creating metrics dataframe
2023-07-03 09:39:34,128:INFO:Uploading results into container
2023-07-03 09:39:34,129:INFO:Uploading model into container now
2023-07-03 09:39:34,129:INFO:_master_model_container: 10
2023-07-03 09:39:34,129:INFO:_display_container: 2
2023-07-03 09:39:34,130:INFO:HuberRegressor()
2023-07-03 09:39:34,130:INFO:create_model() successfully completed......................................
2023-07-03 09:39:34,405:INFO:SubProcess create_model() end ==================================
2023-07-03 09:39:34,405:INFO:Creating metrics dataframe
2023-07-03 09:39:34,416:INFO:Initializing K Neighbors Regressor
2023-07-03 09:39:34,417:INFO:Total runtime is 0.35853110551834116 minutes
2023-07-03 09:39:34,419:INFO:SubProcess create_model() called ==================================
2023-07-03 09:39:34,420:INFO:Initializing create_model()
2023-07-03 09:39:34,420:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244DE0C7AF0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000244E71956F0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:39:34,420:INFO:Checking exceptions
2023-07-03 09:39:34,420:INFO:Importing libraries
2023-07-03 09:39:34,420:INFO:Copying training dataset
2023-07-03 09:39:34,423:INFO:Defining folds
2023-07-03 09:39:34,423:INFO:Declaring metric variables
2023-07-03 09:39:34,426:INFO:Importing untrained model
2023-07-03 09:39:34,429:INFO:K Neighbors Regressor Imported successfully
2023-07-03 09:39:34,434:INFO:Starting cross validation
2023-07-03 09:39:34,435:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:39:35,437:INFO:Calculating mean and std
2023-07-03 09:39:35,438:INFO:Creating metrics dataframe
2023-07-03 09:39:35,598:INFO:Uploading results into container
2023-07-03 09:39:35,599:INFO:Uploading model into container now
2023-07-03 09:39:35,600:INFO:_master_model_container: 11
2023-07-03 09:39:35,600:INFO:_display_container: 2
2023-07-03 09:39:35,600:INFO:KNeighborsRegressor(n_jobs=-1)
2023-07-03 09:39:35,600:INFO:create_model() successfully completed......................................
2023-07-03 09:39:35,877:INFO:SubProcess create_model() end ==================================
2023-07-03 09:39:35,877:INFO:Creating metrics dataframe
2023-07-03 09:39:35,888:INFO:Initializing Decision Tree Regressor
2023-07-03 09:39:35,888:INFO:Total runtime is 0.38304771582285574 minutes
2023-07-03 09:39:35,891:INFO:SubProcess create_model() called ==================================
2023-07-03 09:39:35,891:INFO:Initializing create_model()
2023-07-03 09:39:35,891:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244DE0C7AF0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000244E71956F0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:39:35,891:INFO:Checking exceptions
2023-07-03 09:39:35,892:INFO:Importing libraries
2023-07-03 09:39:35,892:INFO:Copying training dataset
2023-07-03 09:39:35,895:INFO:Defining folds
2023-07-03 09:39:35,895:INFO:Declaring metric variables
2023-07-03 09:39:35,898:INFO:Importing untrained model
2023-07-03 09:39:35,901:INFO:Decision Tree Regressor Imported successfully
2023-07-03 09:39:35,906:INFO:Starting cross validation
2023-07-03 09:39:35,907:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:39:36,882:INFO:Calculating mean and std
2023-07-03 09:39:36,883:INFO:Creating metrics dataframe
2023-07-03 09:39:37,036:INFO:Uploading results into container
2023-07-03 09:39:37,037:INFO:Uploading model into container now
2023-07-03 09:39:37,037:INFO:_master_model_container: 12
2023-07-03 09:39:37,037:INFO:_display_container: 2
2023-07-03 09:39:37,038:INFO:DecisionTreeRegressor(random_state=123)
2023-07-03 09:39:37,038:INFO:create_model() successfully completed......................................
2023-07-03 09:39:37,316:INFO:SubProcess create_model() end ==================================
2023-07-03 09:39:37,316:INFO:Creating metrics dataframe
2023-07-03 09:39:37,326:INFO:Initializing Random Forest Regressor
2023-07-03 09:39:37,326:INFO:Total runtime is 0.40702201128005994 minutes
2023-07-03 09:39:37,329:INFO:SubProcess create_model() called ==================================
2023-07-03 09:39:37,330:INFO:Initializing create_model()
2023-07-03 09:39:37,330:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244DE0C7AF0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000244E71956F0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:39:37,330:INFO:Checking exceptions
2023-07-03 09:39:37,330:INFO:Importing libraries
2023-07-03 09:39:37,330:INFO:Copying training dataset
2023-07-03 09:39:37,333:INFO:Defining folds
2023-07-03 09:39:37,333:INFO:Declaring metric variables
2023-07-03 09:39:37,336:INFO:Importing untrained model
2023-07-03 09:39:37,339:INFO:Random Forest Regressor Imported successfully
2023-07-03 09:39:37,343:INFO:Starting cross validation
2023-07-03 09:39:37,344:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:39:38,738:INFO:Calculating mean and std
2023-07-03 09:39:38,740:INFO:Creating metrics dataframe
2023-07-03 09:39:38,903:INFO:Uploading results into container
2023-07-03 09:39:38,903:INFO:Uploading model into container now
2023-07-03 09:39:38,904:INFO:_master_model_container: 13
2023-07-03 09:39:38,904:INFO:_display_container: 2
2023-07-03 09:39:38,904:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-07-03 09:39:38,904:INFO:create_model() successfully completed......................................
2023-07-03 09:39:39,182:INFO:SubProcess create_model() end ==================================
2023-07-03 09:39:39,182:INFO:Creating metrics dataframe
2023-07-03 09:39:39,192:INFO:Initializing Extra Trees Regressor
2023-07-03 09:39:39,192:INFO:Total runtime is 0.43811713059743257 minutes
2023-07-03 09:39:39,195:INFO:SubProcess create_model() called ==================================
2023-07-03 09:39:39,195:INFO:Initializing create_model()
2023-07-03 09:39:39,195:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244DE0C7AF0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000244E71956F0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:39:39,195:INFO:Checking exceptions
2023-07-03 09:39:39,195:INFO:Importing libraries
2023-07-03 09:39:39,195:INFO:Copying training dataset
2023-07-03 09:39:39,199:INFO:Defining folds
2023-07-03 09:39:39,199:INFO:Declaring metric variables
2023-07-03 09:39:39,202:INFO:Importing untrained model
2023-07-03 09:39:39,204:INFO:Extra Trees Regressor Imported successfully
2023-07-03 09:39:39,209:INFO:Starting cross validation
2023-07-03 09:39:39,210:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:39:40,604:INFO:Calculating mean and std
2023-07-03 09:39:40,605:INFO:Creating metrics dataframe
2023-07-03 09:39:40,763:INFO:Uploading results into container
2023-07-03 09:39:40,763:INFO:Uploading model into container now
2023-07-03 09:39:40,764:INFO:_master_model_container: 14
2023-07-03 09:39:40,764:INFO:_display_container: 2
2023-07-03 09:39:40,764:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-07-03 09:39:40,764:INFO:create_model() successfully completed......................................
2023-07-03 09:39:41,042:INFO:SubProcess create_model() end ==================================
2023-07-03 09:39:41,042:INFO:Creating metrics dataframe
2023-07-03 09:39:41,053:INFO:Initializing AdaBoost Regressor
2023-07-03 09:39:41,053:INFO:Total runtime is 0.4691345016161602 minutes
2023-07-03 09:39:41,056:INFO:SubProcess create_model() called ==================================
2023-07-03 09:39:41,057:INFO:Initializing create_model()
2023-07-03 09:39:41,057:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244DE0C7AF0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000244E71956F0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:39:41,057:INFO:Checking exceptions
2023-07-03 09:39:41,057:INFO:Importing libraries
2023-07-03 09:39:41,057:INFO:Copying training dataset
2023-07-03 09:39:41,060:INFO:Defining folds
2023-07-03 09:39:41,060:INFO:Declaring metric variables
2023-07-03 09:39:41,063:INFO:Importing untrained model
2023-07-03 09:39:41,065:INFO:AdaBoost Regressor Imported successfully
2023-07-03 09:39:41,071:INFO:Starting cross validation
2023-07-03 09:39:41,072:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:39:42,180:INFO:Calculating mean and std
2023-07-03 09:39:42,181:INFO:Creating metrics dataframe
2023-07-03 09:39:42,349:INFO:Uploading results into container
2023-07-03 09:39:42,349:INFO:Uploading model into container now
2023-07-03 09:39:42,350:INFO:_master_model_container: 15
2023-07-03 09:39:42,350:INFO:_display_container: 2
2023-07-03 09:39:42,350:INFO:AdaBoostRegressor(random_state=123)
2023-07-03 09:39:42,350:INFO:create_model() successfully completed......................................
2023-07-03 09:39:42,628:INFO:SubProcess create_model() end ==================================
2023-07-03 09:39:42,628:INFO:Creating metrics dataframe
2023-07-03 09:39:42,639:INFO:Initializing Gradient Boosting Regressor
2023-07-03 09:39:42,639:INFO:Total runtime is 0.4955688357353212 minutes
2023-07-03 09:39:42,642:INFO:SubProcess create_model() called ==================================
2023-07-03 09:39:42,643:INFO:Initializing create_model()
2023-07-03 09:39:42,643:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244DE0C7AF0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000244E71956F0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:39:42,643:INFO:Checking exceptions
2023-07-03 09:39:42,643:INFO:Importing libraries
2023-07-03 09:39:42,643:INFO:Copying training dataset
2023-07-03 09:39:42,646:INFO:Defining folds
2023-07-03 09:39:42,646:INFO:Declaring metric variables
2023-07-03 09:39:42,649:INFO:Importing untrained model
2023-07-03 09:39:42,653:INFO:Gradient Boosting Regressor Imported successfully
2023-07-03 09:39:42,660:INFO:Starting cross validation
2023-07-03 09:39:42,661:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:39:43,839:INFO:Calculating mean and std
2023-07-03 09:39:43,840:INFO:Creating metrics dataframe
2023-07-03 09:39:44,008:INFO:Uploading results into container
2023-07-03 09:39:44,009:INFO:Uploading model into container now
2023-07-03 09:39:44,009:INFO:_master_model_container: 16
2023-07-03 09:39:44,009:INFO:_display_container: 2
2023-07-03 09:39:44,010:INFO:GradientBoostingRegressor(random_state=123)
2023-07-03 09:39:44,010:INFO:create_model() successfully completed......................................
2023-07-03 09:39:44,287:INFO:SubProcess create_model() end ==================================
2023-07-03 09:39:44,287:INFO:Creating metrics dataframe
2023-07-03 09:39:44,297:INFO:Initializing Light Gradient Boosting Machine
2023-07-03 09:39:44,297:INFO:Total runtime is 0.523206122716268 minutes
2023-07-03 09:39:44,301:INFO:SubProcess create_model() called ==================================
2023-07-03 09:39:44,301:INFO:Initializing create_model()
2023-07-03 09:39:44,301:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244DE0C7AF0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000244E71956F0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:39:44,301:INFO:Checking exceptions
2023-07-03 09:39:44,301:INFO:Importing libraries
2023-07-03 09:39:44,301:INFO:Copying training dataset
2023-07-03 09:39:44,304:INFO:Defining folds
2023-07-03 09:39:44,304:INFO:Declaring metric variables
2023-07-03 09:39:44,307:INFO:Importing untrained model
2023-07-03 09:39:44,309:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-03 09:39:44,316:INFO:Starting cross validation
2023-07-03 09:39:44,317:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:39:46,611:INFO:Calculating mean and std
2023-07-03 09:39:46,612:INFO:Creating metrics dataframe
2023-07-03 09:39:46,780:INFO:Uploading results into container
2023-07-03 09:39:46,780:INFO:Uploading model into container now
2023-07-03 09:39:46,781:INFO:_master_model_container: 17
2023-07-03 09:39:46,781:INFO:_display_container: 2
2023-07-03 09:39:46,781:INFO:LGBMRegressor(random_state=123)
2023-07-03 09:39:46,781:INFO:create_model() successfully completed......................................
2023-07-03 09:39:47,061:INFO:SubProcess create_model() end ==================================
2023-07-03 09:39:47,062:INFO:Creating metrics dataframe
2023-07-03 09:39:47,072:INFO:Initializing Dummy Regressor
2023-07-03 09:39:47,073:INFO:Total runtime is 0.569472098350525 minutes
2023-07-03 09:39:47,076:INFO:SubProcess create_model() called ==================================
2023-07-03 09:39:47,076:INFO:Initializing create_model()
2023-07-03 09:39:47,077:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244DE0C7AF0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000244E71956F0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:39:47,077:INFO:Checking exceptions
2023-07-03 09:39:47,077:INFO:Importing libraries
2023-07-03 09:39:47,077:INFO:Copying training dataset
2023-07-03 09:39:47,080:INFO:Defining folds
2023-07-03 09:39:47,081:INFO:Declaring metric variables
2023-07-03 09:39:47,083:INFO:Importing untrained model
2023-07-03 09:39:47,085:INFO:Dummy Regressor Imported successfully
2023-07-03 09:39:47,091:INFO:Starting cross validation
2023-07-03 09:39:47,092:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:39:48,157:INFO:Calculating mean and std
2023-07-03 09:39:48,158:INFO:Creating metrics dataframe
2023-07-03 09:39:48,325:INFO:Uploading results into container
2023-07-03 09:39:48,325:INFO:Uploading model into container now
2023-07-03 09:39:48,326:INFO:_master_model_container: 18
2023-07-03 09:39:48,326:INFO:_display_container: 2
2023-07-03 09:39:48,326:INFO:DummyRegressor()
2023-07-03 09:39:48,326:INFO:create_model() successfully completed......................................
2023-07-03 09:39:48,605:INFO:SubProcess create_model() end ==================================
2023-07-03 09:39:48,605:INFO:Creating metrics dataframe
2023-07-03 09:39:48,623:INFO:Initializing create_model()
2023-07-03 09:39:48,623:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244DE0C7AF0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:39:48,623:INFO:Checking exceptions
2023-07-03 09:39:48,625:INFO:Importing libraries
2023-07-03 09:39:48,625:INFO:Copying training dataset
2023-07-03 09:39:48,628:INFO:Defining folds
2023-07-03 09:39:48,628:INFO:Declaring metric variables
2023-07-03 09:39:48,628:INFO:Importing untrained model
2023-07-03 09:39:48,628:INFO:Declaring custom model
2023-07-03 09:39:48,629:INFO:Extra Trees Regressor Imported successfully
2023-07-03 09:39:48,629:INFO:Cross validation set to False
2023-07-03 09:39:48,629:INFO:Fitting Model
2023-07-03 09:39:48,829:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-07-03 09:39:48,829:INFO:create_model() successfully completed......................................
2023-07-03 09:39:49,138:INFO:_master_model_container: 18
2023-07-03 09:39:49,138:INFO:_display_container: 2
2023-07-03 09:39:49,138:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-07-03 09:39:49,139:INFO:compare_models() successfully completed......................................
2023-07-03 09:40:06,467:INFO:PyCaret RegressionExperiment
2023-07-03 09:40:06,467:INFO:Logging name: reg-default-name
2023-07-03 09:40:06,467:INFO:ML Usecase: MLUsecase.REGRESSION
2023-07-03 09:40:06,467:INFO:version 3.0.2
2023-07-03 09:40:06,467:INFO:Initializing setup()
2023-07-03 09:40:06,468:INFO:self.USI: 2fcb
2023-07-03 09:40:06,468:INFO:self._variable_keys: {'pipeline', 'exp_name_log', 'seed', 'y_test', 'log_plots_param', 'exp_id', '_ml_usecase', 'fold_shuffle_param', 'fold_groups_param', 'logging_param', 'gpu_param', 'memory', 'fold_generator', 'html_param', '_available_plots', 'target_param', 'y_train', 'n_jobs_param', 'X_test', 'X_train', 'transform_target_param', 'X', 'y', 'data', 'USI', 'idx', 'gpu_n_jobs_param'}
2023-07-03 09:40:06,468:INFO:Checking environment
2023-07-03 09:40:06,468:INFO:python_version: 3.10.9
2023-07-03 09:40:06,468:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2023-07-03 09:40:06,468:INFO:machine: AMD64
2023-07-03 09:40:06,468:INFO:platform: Windows-10-10.0.22621-SP0
2023-07-03 09:40:06,471:INFO:Memory: svmem(total=33664483328, available=20666273792, percent=38.6, used=12998209536, free=20666273792)
2023-07-03 09:40:06,471:INFO:Physical Core: 6
2023-07-03 09:40:06,471:INFO:Logical Core: 12
2023-07-03 09:40:06,471:INFO:Checking libraries
2023-07-03 09:40:06,471:INFO:System:
2023-07-03 09:40:06,471:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2023-07-03 09:40:06,471:INFO:executable: C:\Users\JHossain\anaconda3\python.exe
2023-07-03 09:40:06,471:INFO:   machine: Windows-10-10.0.22621-SP0
2023-07-03 09:40:06,472:INFO:PyCaret required dependencies:
2023-07-03 09:40:06,472:INFO:                 pip: 22.3.1
2023-07-03 09:40:06,472:INFO:          setuptools: 65.6.3
2023-07-03 09:40:06,472:INFO:             pycaret: 3.0.2
2023-07-03 09:40:06,472:INFO:             IPython: 8.10.0
2023-07-03 09:40:06,472:INFO:          ipywidgets: 7.6.5
2023-07-03 09:40:06,472:INFO:                tqdm: 4.64.1
2023-07-03 09:40:06,472:INFO:               numpy: 1.23.5
2023-07-03 09:40:06,472:INFO:              pandas: 1.5.3
2023-07-03 09:40:06,472:INFO:              jinja2: 3.1.2
2023-07-03 09:40:06,472:INFO:               scipy: 1.10.0
2023-07-03 09:40:06,472:INFO:              joblib: 1.2.0
2023-07-03 09:40:06,472:INFO:             sklearn: 1.2.1
2023-07-03 09:40:06,472:INFO:                pyod: 1.0.9
2023-07-03 09:40:06,472:INFO:            imblearn: 0.10.1
2023-07-03 09:40:06,472:INFO:   category_encoders: 2.6.1
2023-07-03 09:40:06,472:INFO:            lightgbm: 3.3.5
2023-07-03 09:40:06,472:INFO:               numba: 0.56.4
2023-07-03 09:40:06,472:INFO:            requests: 2.28.1
2023-07-03 09:40:06,472:INFO:          matplotlib: 3.7.0
2023-07-03 09:40:06,472:INFO:          scikitplot: 0.3.7
2023-07-03 09:40:06,472:INFO:         yellowbrick: 1.5
2023-07-03 09:40:06,472:INFO:              plotly: 5.9.0
2023-07-03 09:40:06,472:INFO:             kaleido: 0.2.1
2023-07-03 09:40:06,472:INFO:         statsmodels: 0.13.5
2023-07-03 09:40:06,472:INFO:              sktime: 0.17.0
2023-07-03 09:40:06,472:INFO:               tbats: 1.1.3
2023-07-03 09:40:06,472:INFO:            pmdarima: 2.0.3
2023-07-03 09:40:06,473:INFO:              psutil: 5.9.0
2023-07-03 09:40:06,473:INFO:PyCaret optional dependencies:
2023-07-03 09:40:06,473:INFO:                shap: Not installed
2023-07-03 09:40:06,473:INFO:           interpret: Not installed
2023-07-03 09:40:06,473:INFO:                umap: Not installed
2023-07-03 09:40:06,473:INFO:    pandas_profiling: Not installed
2023-07-03 09:40:06,473:INFO:  explainerdashboard: Not installed
2023-07-03 09:40:06,473:INFO:             autoviz: Not installed
2023-07-03 09:40:06,473:INFO:           fairlearn: Not installed
2023-07-03 09:40:06,473:INFO:             xgboost: Not installed
2023-07-03 09:40:06,473:INFO:            catboost: Not installed
2023-07-03 09:40:06,473:INFO:              kmodes: Not installed
2023-07-03 09:40:06,473:INFO:             mlxtend: Not installed
2023-07-03 09:40:06,473:INFO:       statsforecast: Not installed
2023-07-03 09:40:06,473:INFO:        tune_sklearn: Not installed
2023-07-03 09:40:06,473:INFO:                 ray: Not installed
2023-07-03 09:40:06,473:INFO:            hyperopt: Not installed
2023-07-03 09:40:06,473:INFO:              optuna: Not installed
2023-07-03 09:40:06,473:INFO:               skopt: Not installed
2023-07-03 09:40:06,473:INFO:              mlflow: Not installed
2023-07-03 09:40:06,473:INFO:              gradio: 3.35.2
2023-07-03 09:40:06,473:INFO:             fastapi: 0.99.0
2023-07-03 09:40:06,473:INFO:             uvicorn: 0.22.0
2023-07-03 09:40:06,473:INFO:              m2cgen: Not installed
2023-07-03 09:40:06,473:INFO:           evidently: Not installed
2023-07-03 09:40:06,473:INFO:               fugue: Not installed
2023-07-03 09:40:06,473:INFO:           streamlit: Not installed
2023-07-03 09:40:06,473:INFO:             prophet: Not installed
2023-07-03 09:40:06,473:INFO:None
2023-07-03 09:40:06,473:INFO:Set up data.
2023-07-03 09:40:06,476:INFO:Set up train/test split.
2023-07-03 09:40:06,478:INFO:Set up index.
2023-07-03 09:40:06,478:INFO:Set up folding strategy.
2023-07-03 09:40:06,478:INFO:Assigning column types.
2023-07-03 09:40:06,480:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-07-03 09:40:06,481:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-07-03 09:40:06,485:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-07-03 09:40:06,489:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-03 09:40:06,534:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-03 09:40:06,570:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-03 09:40:06,571:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:40:06,571:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:40:06,571:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-07-03 09:40:06,576:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-07-03 09:40:06,579:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-03 09:40:06,625:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-03 09:40:06,661:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-03 09:40:06,661:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:40:06,661:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:40:06,662:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-07-03 09:40:06,666:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-07-03 09:40:06,670:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-03 09:40:06,716:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-03 09:40:06,751:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-03 09:40:06,752:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:40:06,752:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:40:06,756:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-07-03 09:40:06,760:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-03 09:40:06,806:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-03 09:40:06,843:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-03 09:40:06,843:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:40:06,843:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:40:06,843:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-07-03 09:40:06,851:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-03 09:40:06,897:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-03 09:40:06,933:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-03 09:40:06,934:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:40:06,934:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:40:06,941:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-03 09:40:06,988:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-03 09:40:07,024:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-03 09:40:07,028:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:40:07,028:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:40:07,028:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-07-03 09:40:07,081:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-03 09:40:07,118:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-03 09:40:07,119:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:40:07,119:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:40:07,172:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-03 09:40:07,209:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-03 09:40:07,210:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:40:07,210:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:40:07,210:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-07-03 09:40:07,265:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-03 09:40:07,301:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:40:07,302:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:40:07,356:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-03 09:40:07,394:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:40:07,394:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:40:07,394:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-07-03 09:40:07,485:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:40:07,485:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:40:07,576:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:40:07,576:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:40:07,577:INFO:Preparing preprocessing pipeline...
2023-07-03 09:40:07,577:INFO:Set up simple imputation.
2023-07-03 09:40:07,591:INFO:Finished creating preprocessing pipeline.
2023-07-03 09:40:07,594:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\JHossain\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MolLogP', 'MolWt',
                                             'NumRotatableBonds',
                                             'AromaticProportion'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2023-07-03 09:40:07,594:INFO:Creating final display dataframe.
2023-07-03 09:40:07,638:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target              logS
2                   Target type        Regression
3           Original data shape         (1144, 5)
4        Transformed data shape         (1144, 5)
5   Transformed train set shape           (91, 5)
6    Transformed test set shape         (1053, 5)
7              Numeric features                 4
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              2fcb
2023-07-03 09:40:07,737:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:40:07,737:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:40:07,855:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:40:07,855:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:40:07,856:INFO:setup() successfully completed in 1.49s...............
2023-07-03 09:40:11,457:INFO:Initializing compare_models()
2023-07-03 09:40:11,457:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244E2340BE0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000244E2340BE0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-07-03 09:40:11,457:INFO:Checking exceptions
2023-07-03 09:40:11,459:INFO:Preparing display monitor
2023-07-03 09:40:11,478:INFO:Initializing Linear Regression
2023-07-03 09:40:11,478:INFO:Total runtime is 0.0 minutes
2023-07-03 09:40:11,481:INFO:SubProcess create_model() called ==================================
2023-07-03 09:40:11,481:INFO:Initializing create_model()
2023-07-03 09:40:11,481:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244E2340BE0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000244E2343AC0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:40:11,481:INFO:Checking exceptions
2023-07-03 09:40:11,481:INFO:Importing libraries
2023-07-03 09:40:11,482:INFO:Copying training dataset
2023-07-03 09:40:11,485:INFO:Defining folds
2023-07-03 09:40:11,485:INFO:Declaring metric variables
2023-07-03 09:40:11,489:INFO:Importing untrained model
2023-07-03 09:40:11,492:INFO:Linear Regression Imported successfully
2023-07-03 09:40:11,498:INFO:Starting cross validation
2023-07-03 09:40:11,499:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:40:12,532:INFO:Calculating mean and std
2023-07-03 09:40:12,533:INFO:Creating metrics dataframe
2023-07-03 09:40:12,701:INFO:Uploading results into container
2023-07-03 09:40:12,701:INFO:Uploading model into container now
2023-07-03 09:40:12,702:INFO:_master_model_container: 1
2023-07-03 09:40:12,702:INFO:_display_container: 2
2023-07-03 09:40:12,702:INFO:LinearRegression(n_jobs=-1)
2023-07-03 09:40:12,702:INFO:create_model() successfully completed......................................
2023-07-03 09:40:12,984:INFO:SubProcess create_model() end ==================================
2023-07-03 09:40:12,984:INFO:Creating metrics dataframe
2023-07-03 09:40:12,992:INFO:Initializing Lasso Regression
2023-07-03 09:40:12,992:INFO:Total runtime is 0.025216889381408692 minutes
2023-07-03 09:40:12,994:INFO:SubProcess create_model() called ==================================
2023-07-03 09:40:12,994:INFO:Initializing create_model()
2023-07-03 09:40:12,994:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244E2340BE0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000244E2343AC0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:40:12,994:INFO:Checking exceptions
2023-07-03 09:40:12,995:INFO:Importing libraries
2023-07-03 09:40:12,995:INFO:Copying training dataset
2023-07-03 09:40:12,997:INFO:Defining folds
2023-07-03 09:40:12,998:INFO:Declaring metric variables
2023-07-03 09:40:13,001:INFO:Importing untrained model
2023-07-03 09:40:13,005:INFO:Lasso Regression Imported successfully
2023-07-03 09:40:13,010:INFO:Starting cross validation
2023-07-03 09:40:13,011:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:40:14,063:INFO:Calculating mean and std
2023-07-03 09:40:14,064:INFO:Creating metrics dataframe
2023-07-03 09:40:14,231:INFO:Uploading results into container
2023-07-03 09:40:14,232:INFO:Uploading model into container now
2023-07-03 09:40:14,232:INFO:_master_model_container: 2
2023-07-03 09:40:14,232:INFO:_display_container: 2
2023-07-03 09:40:14,233:INFO:Lasso(random_state=123)
2023-07-03 09:40:14,233:INFO:create_model() successfully completed......................................
2023-07-03 09:40:14,520:INFO:SubProcess create_model() end ==================================
2023-07-03 09:40:14,521:INFO:Creating metrics dataframe
2023-07-03 09:40:14,530:INFO:Initializing Ridge Regression
2023-07-03 09:40:14,530:INFO:Total runtime is 0.0508509357770284 minutes
2023-07-03 09:40:14,533:INFO:SubProcess create_model() called ==================================
2023-07-03 09:40:14,534:INFO:Initializing create_model()
2023-07-03 09:40:14,534:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244E2340BE0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000244E2343AC0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:40:14,534:INFO:Checking exceptions
2023-07-03 09:40:14,534:INFO:Importing libraries
2023-07-03 09:40:14,534:INFO:Copying training dataset
2023-07-03 09:40:14,537:INFO:Defining folds
2023-07-03 09:40:14,537:INFO:Declaring metric variables
2023-07-03 09:40:14,541:INFO:Importing untrained model
2023-07-03 09:40:14,544:INFO:Ridge Regression Imported successfully
2023-07-03 09:40:14,551:INFO:Starting cross validation
2023-07-03 09:40:14,552:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:40:15,602:INFO:Calculating mean and std
2023-07-03 09:40:15,603:INFO:Creating metrics dataframe
2023-07-03 09:40:15,766:INFO:Uploading results into container
2023-07-03 09:40:15,766:INFO:Uploading model into container now
2023-07-03 09:40:15,767:INFO:_master_model_container: 3
2023-07-03 09:40:15,767:INFO:_display_container: 2
2023-07-03 09:40:15,767:INFO:Ridge(random_state=123)
2023-07-03 09:40:15,767:INFO:create_model() successfully completed......................................
2023-07-03 09:40:16,051:INFO:SubProcess create_model() end ==================================
2023-07-03 09:40:16,051:INFO:Creating metrics dataframe
2023-07-03 09:40:16,060:INFO:Initializing Elastic Net
2023-07-03 09:40:16,060:INFO:Total runtime is 0.07635481754938761 minutes
2023-07-03 09:40:16,063:INFO:SubProcess create_model() called ==================================
2023-07-03 09:40:16,063:INFO:Initializing create_model()
2023-07-03 09:40:16,063:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244E2340BE0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000244E2343AC0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:40:16,063:INFO:Checking exceptions
2023-07-03 09:40:16,063:INFO:Importing libraries
2023-07-03 09:40:16,063:INFO:Copying training dataset
2023-07-03 09:40:16,066:INFO:Defining folds
2023-07-03 09:40:16,067:INFO:Declaring metric variables
2023-07-03 09:40:16,070:INFO:Importing untrained model
2023-07-03 09:40:16,073:INFO:Elastic Net Imported successfully
2023-07-03 09:40:16,078:INFO:Starting cross validation
2023-07-03 09:40:16,079:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:40:17,173:INFO:Calculating mean and std
2023-07-03 09:40:17,174:INFO:Creating metrics dataframe
2023-07-03 09:40:17,343:INFO:Uploading results into container
2023-07-03 09:40:17,343:INFO:Uploading model into container now
2023-07-03 09:40:17,344:INFO:_master_model_container: 4
2023-07-03 09:40:17,344:INFO:_display_container: 2
2023-07-03 09:40:17,344:INFO:ElasticNet(random_state=123)
2023-07-03 09:40:17,344:INFO:create_model() successfully completed......................................
2023-07-03 09:40:17,628:INFO:SubProcess create_model() end ==================================
2023-07-03 09:40:17,628:INFO:Creating metrics dataframe
2023-07-03 09:40:17,636:INFO:Initializing Least Angle Regression
2023-07-03 09:40:17,636:INFO:Total runtime is 0.10262559254964193 minutes
2023-07-03 09:40:17,639:INFO:SubProcess create_model() called ==================================
2023-07-03 09:40:17,640:INFO:Initializing create_model()
2023-07-03 09:40:17,640:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244E2340BE0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000244E2343AC0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:40:17,640:INFO:Checking exceptions
2023-07-03 09:40:17,640:INFO:Importing libraries
2023-07-03 09:40:17,640:INFO:Copying training dataset
2023-07-03 09:40:17,644:INFO:Defining folds
2023-07-03 09:40:17,644:INFO:Declaring metric variables
2023-07-03 09:40:17,647:INFO:Importing untrained model
2023-07-03 09:40:17,649:INFO:Least Angle Regression Imported successfully
2023-07-03 09:40:17,654:INFO:Starting cross validation
2023-07-03 09:40:17,654:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:40:18,689:INFO:Calculating mean and std
2023-07-03 09:40:18,691:INFO:Creating metrics dataframe
2023-07-03 09:40:18,859:INFO:Uploading results into container
2023-07-03 09:40:18,860:INFO:Uploading model into container now
2023-07-03 09:40:18,860:INFO:_master_model_container: 5
2023-07-03 09:40:18,860:INFO:_display_container: 2
2023-07-03 09:40:18,861:INFO:Lars(random_state=123)
2023-07-03 09:40:18,861:INFO:create_model() successfully completed......................................
2023-07-03 09:40:19,164:INFO:SubProcess create_model() end ==================================
2023-07-03 09:40:19,164:INFO:Creating metrics dataframe
2023-07-03 09:40:19,174:INFO:Initializing Lasso Least Angle Regression
2023-07-03 09:40:19,174:INFO:Total runtime is 0.12825137376785278 minutes
2023-07-03 09:40:19,176:INFO:SubProcess create_model() called ==================================
2023-07-03 09:40:19,177:INFO:Initializing create_model()
2023-07-03 09:40:19,177:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244E2340BE0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000244E2343AC0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:40:19,177:INFO:Checking exceptions
2023-07-03 09:40:19,177:INFO:Importing libraries
2023-07-03 09:40:19,177:INFO:Copying training dataset
2023-07-03 09:40:19,180:INFO:Defining folds
2023-07-03 09:40:19,180:INFO:Declaring metric variables
2023-07-03 09:40:19,182:INFO:Importing untrained model
2023-07-03 09:40:19,186:INFO:Lasso Least Angle Regression Imported successfully
2023-07-03 09:40:19,191:INFO:Starting cross validation
2023-07-03 09:40:19,192:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:40:20,224:INFO:Calculating mean and std
2023-07-03 09:40:20,226:INFO:Creating metrics dataframe
2023-07-03 09:40:20,394:INFO:Uploading results into container
2023-07-03 09:40:20,395:INFO:Uploading model into container now
2023-07-03 09:40:20,395:INFO:_master_model_container: 6
2023-07-03 09:40:20,396:INFO:_display_container: 2
2023-07-03 09:40:20,396:INFO:LassoLars(random_state=123)
2023-07-03 09:40:20,396:INFO:create_model() successfully completed......................................
2023-07-03 09:40:20,678:INFO:SubProcess create_model() end ==================================
2023-07-03 09:40:20,678:INFO:Creating metrics dataframe
2023-07-03 09:40:20,687:INFO:Initializing Orthogonal Matching Pursuit
2023-07-03 09:40:20,688:INFO:Total runtime is 0.15348823070526124 minutes
2023-07-03 09:40:20,690:INFO:SubProcess create_model() called ==================================
2023-07-03 09:40:20,690:INFO:Initializing create_model()
2023-07-03 09:40:20,690:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244E2340BE0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000244E2343AC0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:40:20,690:INFO:Checking exceptions
2023-07-03 09:40:20,691:INFO:Importing libraries
2023-07-03 09:40:20,691:INFO:Copying training dataset
2023-07-03 09:40:20,693:INFO:Defining folds
2023-07-03 09:40:20,693:INFO:Declaring metric variables
2023-07-03 09:40:20,696:INFO:Importing untrained model
2023-07-03 09:40:20,699:INFO:Orthogonal Matching Pursuit Imported successfully
2023-07-03 09:40:20,705:INFO:Starting cross validation
2023-07-03 09:40:20,705:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:40:21,788:INFO:Calculating mean and std
2023-07-03 09:40:21,789:INFO:Creating metrics dataframe
2023-07-03 09:40:21,949:INFO:Uploading results into container
2023-07-03 09:40:21,949:INFO:Uploading model into container now
2023-07-03 09:40:21,950:INFO:_master_model_container: 7
2023-07-03 09:40:21,950:INFO:_display_container: 2
2023-07-03 09:40:21,950:INFO:OrthogonalMatchingPursuit()
2023-07-03 09:40:21,950:INFO:create_model() successfully completed......................................
2023-07-03 09:40:22,236:INFO:SubProcess create_model() end ==================================
2023-07-03 09:40:22,236:INFO:Creating metrics dataframe
2023-07-03 09:40:22,246:INFO:Initializing Bayesian Ridge
2023-07-03 09:40:22,246:INFO:Total runtime is 0.17945874929428102 minutes
2023-07-03 09:40:22,250:INFO:SubProcess create_model() called ==================================
2023-07-03 09:40:22,250:INFO:Initializing create_model()
2023-07-03 09:40:22,250:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244E2340BE0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000244E2343AC0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:40:22,250:INFO:Checking exceptions
2023-07-03 09:40:22,250:INFO:Importing libraries
2023-07-03 09:40:22,250:INFO:Copying training dataset
2023-07-03 09:40:22,254:INFO:Defining folds
2023-07-03 09:40:22,254:INFO:Declaring metric variables
2023-07-03 09:40:22,258:INFO:Importing untrained model
2023-07-03 09:40:22,261:INFO:Bayesian Ridge Imported successfully
2023-07-03 09:40:22,267:INFO:Starting cross validation
2023-07-03 09:40:22,268:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:40:23,401:INFO:Calculating mean and std
2023-07-03 09:40:23,402:INFO:Creating metrics dataframe
2023-07-03 09:40:23,564:INFO:Uploading results into container
2023-07-03 09:40:23,565:INFO:Uploading model into container now
2023-07-03 09:40:23,565:INFO:_master_model_container: 8
2023-07-03 09:40:23,566:INFO:_display_container: 2
2023-07-03 09:40:23,566:INFO:BayesianRidge()
2023-07-03 09:40:23,566:INFO:create_model() successfully completed......................................
2023-07-03 09:40:23,847:INFO:SubProcess create_model() end ==================================
2023-07-03 09:40:23,848:INFO:Creating metrics dataframe
2023-07-03 09:40:23,856:INFO:Initializing Passive Aggressive Regressor
2023-07-03 09:40:23,856:INFO:Total runtime is 0.2062957207361857 minutes
2023-07-03 09:40:23,860:INFO:SubProcess create_model() called ==================================
2023-07-03 09:40:23,860:INFO:Initializing create_model()
2023-07-03 09:40:23,860:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244E2340BE0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000244E2343AC0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:40:23,860:INFO:Checking exceptions
2023-07-03 09:40:23,860:INFO:Importing libraries
2023-07-03 09:40:23,860:INFO:Copying training dataset
2023-07-03 09:40:23,864:INFO:Defining folds
2023-07-03 09:40:23,864:INFO:Declaring metric variables
2023-07-03 09:40:23,867:INFO:Importing untrained model
2023-07-03 09:40:23,870:INFO:Passive Aggressive Regressor Imported successfully
2023-07-03 09:40:23,874:INFO:Starting cross validation
2023-07-03 09:40:23,875:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:40:24,978:INFO:Calculating mean and std
2023-07-03 09:40:24,979:INFO:Creating metrics dataframe
2023-07-03 09:40:25,140:INFO:Uploading results into container
2023-07-03 09:40:25,140:INFO:Uploading model into container now
2023-07-03 09:40:25,141:INFO:_master_model_container: 9
2023-07-03 09:40:25,141:INFO:_display_container: 2
2023-07-03 09:40:25,141:INFO:PassiveAggressiveRegressor(random_state=123)
2023-07-03 09:40:25,141:INFO:create_model() successfully completed......................................
2023-07-03 09:40:25,426:INFO:SubProcess create_model() end ==================================
2023-07-03 09:40:25,426:INFO:Creating metrics dataframe
2023-07-03 09:40:25,437:INFO:Initializing Huber Regressor
2023-07-03 09:40:25,437:INFO:Total runtime is 0.23264903624852498 minutes
2023-07-03 09:40:25,440:INFO:SubProcess create_model() called ==================================
2023-07-03 09:40:25,440:INFO:Initializing create_model()
2023-07-03 09:40:25,440:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244E2340BE0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000244E2343AC0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:40:25,441:INFO:Checking exceptions
2023-07-03 09:40:25,441:INFO:Importing libraries
2023-07-03 09:40:25,441:INFO:Copying training dataset
2023-07-03 09:40:25,444:INFO:Defining folds
2023-07-03 09:40:25,444:INFO:Declaring metric variables
2023-07-03 09:40:25,447:INFO:Importing untrained model
2023-07-03 09:40:25,450:INFO:Huber Regressor Imported successfully
2023-07-03 09:40:25,455:INFO:Starting cross validation
2023-07-03 09:40:25,455:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:40:26,549:INFO:Calculating mean and std
2023-07-03 09:40:26,550:INFO:Creating metrics dataframe
2023-07-03 09:40:26,711:INFO:Uploading results into container
2023-07-03 09:40:26,712:INFO:Uploading model into container now
2023-07-03 09:40:26,712:INFO:_master_model_container: 10
2023-07-03 09:40:26,712:INFO:_display_container: 2
2023-07-03 09:40:26,712:INFO:HuberRegressor()
2023-07-03 09:40:26,713:INFO:create_model() successfully completed......................................
2023-07-03 09:40:26,994:INFO:SubProcess create_model() end ==================================
2023-07-03 09:40:26,994:INFO:Creating metrics dataframe
2023-07-03 09:40:27,005:INFO:Initializing K Neighbors Regressor
2023-07-03 09:40:27,005:INFO:Total runtime is 0.25877336661020917 minutes
2023-07-03 09:40:27,008:INFO:SubProcess create_model() called ==================================
2023-07-03 09:40:27,008:INFO:Initializing create_model()
2023-07-03 09:40:27,008:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244E2340BE0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000244E2343AC0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:40:27,008:INFO:Checking exceptions
2023-07-03 09:40:27,009:INFO:Importing libraries
2023-07-03 09:40:27,009:INFO:Copying training dataset
2023-07-03 09:40:27,012:INFO:Defining folds
2023-07-03 09:40:27,012:INFO:Declaring metric variables
2023-07-03 09:40:27,015:INFO:Importing untrained model
2023-07-03 09:40:27,018:INFO:K Neighbors Regressor Imported successfully
2023-07-03 09:40:27,024:INFO:Starting cross validation
2023-07-03 09:40:27,025:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:40:28,086:INFO:Calculating mean and std
2023-07-03 09:40:28,088:INFO:Creating metrics dataframe
2023-07-03 09:40:28,247:INFO:Uploading results into container
2023-07-03 09:40:28,248:INFO:Uploading model into container now
2023-07-03 09:40:28,248:INFO:_master_model_container: 11
2023-07-03 09:40:28,248:INFO:_display_container: 2
2023-07-03 09:40:28,249:INFO:KNeighborsRegressor(n_jobs=-1)
2023-07-03 09:40:28,249:INFO:create_model() successfully completed......................................
2023-07-03 09:40:28,536:INFO:SubProcess create_model() end ==================================
2023-07-03 09:40:28,536:INFO:Creating metrics dataframe
2023-07-03 09:40:28,548:INFO:Initializing Decision Tree Regressor
2023-07-03 09:40:28,548:INFO:Total runtime is 0.28449011643727623 minutes
2023-07-03 09:40:28,551:INFO:SubProcess create_model() called ==================================
2023-07-03 09:40:28,551:INFO:Initializing create_model()
2023-07-03 09:40:28,551:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244E2340BE0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000244E2343AC0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:40:28,552:INFO:Checking exceptions
2023-07-03 09:40:28,552:INFO:Importing libraries
2023-07-03 09:40:28,552:INFO:Copying training dataset
2023-07-03 09:40:28,555:INFO:Defining folds
2023-07-03 09:40:28,555:INFO:Declaring metric variables
2023-07-03 09:40:28,559:INFO:Importing untrained model
2023-07-03 09:40:28,562:INFO:Decision Tree Regressor Imported successfully
2023-07-03 09:40:28,569:INFO:Starting cross validation
2023-07-03 09:40:28,571:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:40:29,617:INFO:Calculating mean and std
2023-07-03 09:40:29,618:INFO:Creating metrics dataframe
2023-07-03 09:40:29,783:INFO:Uploading results into container
2023-07-03 09:40:29,783:INFO:Uploading model into container now
2023-07-03 09:40:29,784:INFO:_master_model_container: 12
2023-07-03 09:40:29,784:INFO:_display_container: 2
2023-07-03 09:40:29,784:INFO:DecisionTreeRegressor(random_state=123)
2023-07-03 09:40:29,784:INFO:create_model() successfully completed......................................
2023-07-03 09:40:30,067:INFO:SubProcess create_model() end ==================================
2023-07-03 09:40:30,068:INFO:Creating metrics dataframe
2023-07-03 09:40:30,078:INFO:Initializing Random Forest Regressor
2023-07-03 09:40:30,078:INFO:Total runtime is 0.30998417536417644 minutes
2023-07-03 09:40:30,081:INFO:SubProcess create_model() called ==================================
2023-07-03 09:40:30,081:INFO:Initializing create_model()
2023-07-03 09:40:30,082:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244E2340BE0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000244E2343AC0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:40:30,082:INFO:Checking exceptions
2023-07-03 09:40:30,082:INFO:Importing libraries
2023-07-03 09:40:30,082:INFO:Copying training dataset
2023-07-03 09:40:30,084:INFO:Defining folds
2023-07-03 09:40:30,084:INFO:Declaring metric variables
2023-07-03 09:40:30,087:INFO:Importing untrained model
2023-07-03 09:40:30,090:INFO:Random Forest Regressor Imported successfully
2023-07-03 09:40:30,095:INFO:Starting cross validation
2023-07-03 09:40:30,095:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:40:31,241:INFO:Calculating mean and std
2023-07-03 09:40:31,243:INFO:Creating metrics dataframe
2023-07-03 09:40:31,405:INFO:Uploading results into container
2023-07-03 09:40:31,406:INFO:Uploading model into container now
2023-07-03 09:40:31,407:INFO:_master_model_container: 13
2023-07-03 09:40:31,407:INFO:_display_container: 2
2023-07-03 09:40:31,407:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-07-03 09:40:31,407:INFO:create_model() successfully completed......................................
2023-07-03 09:40:31,691:INFO:SubProcess create_model() end ==================================
2023-07-03 09:40:31,691:INFO:Creating metrics dataframe
2023-07-03 09:40:31,701:INFO:Initializing Extra Trees Regressor
2023-07-03 09:40:31,701:INFO:Total runtime is 0.33704735040664674 minutes
2023-07-03 09:40:31,705:INFO:SubProcess create_model() called ==================================
2023-07-03 09:40:31,705:INFO:Initializing create_model()
2023-07-03 09:40:31,705:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244E2340BE0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000244E2343AC0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:40:31,705:INFO:Checking exceptions
2023-07-03 09:40:31,705:INFO:Importing libraries
2023-07-03 09:40:31,705:INFO:Copying training dataset
2023-07-03 09:40:31,708:INFO:Defining folds
2023-07-03 09:40:31,708:INFO:Declaring metric variables
2023-07-03 09:40:31,711:INFO:Importing untrained model
2023-07-03 09:40:31,713:INFO:Extra Trees Regressor Imported successfully
2023-07-03 09:40:31,718:INFO:Starting cross validation
2023-07-03 09:40:31,719:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:40:32,883:INFO:Calculating mean and std
2023-07-03 09:40:32,884:INFO:Creating metrics dataframe
2023-07-03 09:40:33,049:INFO:Uploading results into container
2023-07-03 09:40:33,049:INFO:Uploading model into container now
2023-07-03 09:40:33,050:INFO:_master_model_container: 14
2023-07-03 09:40:33,050:INFO:_display_container: 2
2023-07-03 09:40:33,050:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-07-03 09:40:33,050:INFO:create_model() successfully completed......................................
2023-07-03 09:40:33,337:INFO:SubProcess create_model() end ==================================
2023-07-03 09:40:33,337:INFO:Creating metrics dataframe
2023-07-03 09:40:33,348:INFO:Initializing AdaBoost Regressor
2023-07-03 09:40:33,348:INFO:Total runtime is 0.3644982099533081 minutes
2023-07-03 09:40:33,351:INFO:SubProcess create_model() called ==================================
2023-07-03 09:40:33,352:INFO:Initializing create_model()
2023-07-03 09:40:33,352:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244E2340BE0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000244E2343AC0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:40:33,352:INFO:Checking exceptions
2023-07-03 09:40:33,352:INFO:Importing libraries
2023-07-03 09:40:33,352:INFO:Copying training dataset
2023-07-03 09:40:33,356:INFO:Defining folds
2023-07-03 09:40:33,356:INFO:Declaring metric variables
2023-07-03 09:40:33,359:INFO:Importing untrained model
2023-07-03 09:40:33,362:INFO:AdaBoost Regressor Imported successfully
2023-07-03 09:40:33,367:INFO:Starting cross validation
2023-07-03 09:40:33,368:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:40:34,547:INFO:Calculating mean and std
2023-07-03 09:40:34,548:INFO:Creating metrics dataframe
2023-07-03 09:40:34,714:INFO:Uploading results into container
2023-07-03 09:40:34,715:INFO:Uploading model into container now
2023-07-03 09:40:34,716:INFO:_master_model_container: 15
2023-07-03 09:40:34,716:INFO:_display_container: 2
2023-07-03 09:40:34,716:INFO:AdaBoostRegressor(random_state=123)
2023-07-03 09:40:34,716:INFO:create_model() successfully completed......................................
2023-07-03 09:40:35,009:INFO:SubProcess create_model() end ==================================
2023-07-03 09:40:35,009:INFO:Creating metrics dataframe
2023-07-03 09:40:35,019:INFO:Initializing Gradient Boosting Regressor
2023-07-03 09:40:35,019:INFO:Total runtime is 0.3923457185427348 minutes
2023-07-03 09:40:35,022:INFO:SubProcess create_model() called ==================================
2023-07-03 09:40:35,023:INFO:Initializing create_model()
2023-07-03 09:40:35,023:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244E2340BE0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000244E2343AC0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:40:35,023:INFO:Checking exceptions
2023-07-03 09:40:35,023:INFO:Importing libraries
2023-07-03 09:40:35,023:INFO:Copying training dataset
2023-07-03 09:40:35,026:INFO:Defining folds
2023-07-03 09:40:35,027:INFO:Declaring metric variables
2023-07-03 09:40:35,030:INFO:Importing untrained model
2023-07-03 09:40:35,032:INFO:Gradient Boosting Regressor Imported successfully
2023-07-03 09:40:35,037:INFO:Starting cross validation
2023-07-03 09:40:35,038:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:40:36,192:INFO:Calculating mean and std
2023-07-03 09:40:36,193:INFO:Creating metrics dataframe
2023-07-03 09:40:36,363:INFO:Uploading results into container
2023-07-03 09:40:36,364:INFO:Uploading model into container now
2023-07-03 09:40:36,365:INFO:_master_model_container: 16
2023-07-03 09:40:36,365:INFO:_display_container: 2
2023-07-03 09:40:36,365:INFO:GradientBoostingRegressor(random_state=123)
2023-07-03 09:40:36,365:INFO:create_model() successfully completed......................................
2023-07-03 09:40:36,637:INFO:SubProcess create_model() end ==================================
2023-07-03 09:40:36,637:INFO:Creating metrics dataframe
2023-07-03 09:40:36,648:INFO:Initializing Light Gradient Boosting Machine
2023-07-03 09:40:36,648:INFO:Total runtime is 0.41949855089187627 minutes
2023-07-03 09:40:36,651:INFO:SubProcess create_model() called ==================================
2023-07-03 09:40:36,651:INFO:Initializing create_model()
2023-07-03 09:40:36,651:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244E2340BE0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000244E2343AC0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:40:36,651:INFO:Checking exceptions
2023-07-03 09:40:36,651:INFO:Importing libraries
2023-07-03 09:40:36,651:INFO:Copying training dataset
2023-07-03 09:40:36,655:INFO:Defining folds
2023-07-03 09:40:36,655:INFO:Declaring metric variables
2023-07-03 09:40:36,659:INFO:Importing untrained model
2023-07-03 09:40:36,661:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-03 09:40:36,667:INFO:Starting cross validation
2023-07-03 09:40:36,667:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:40:37,774:INFO:Calculating mean and std
2023-07-03 09:40:37,776:INFO:Creating metrics dataframe
2023-07-03 09:40:37,941:INFO:Uploading results into container
2023-07-03 09:40:37,941:INFO:Uploading model into container now
2023-07-03 09:40:37,942:INFO:_master_model_container: 17
2023-07-03 09:40:37,942:INFO:_display_container: 2
2023-07-03 09:40:37,943:INFO:LGBMRegressor(random_state=123)
2023-07-03 09:40:37,943:INFO:create_model() successfully completed......................................
2023-07-03 09:40:38,223:INFO:SubProcess create_model() end ==================================
2023-07-03 09:40:38,223:INFO:Creating metrics dataframe
2023-07-03 09:40:38,235:INFO:Initializing Dummy Regressor
2023-07-03 09:40:38,235:INFO:Total runtime is 0.4459367235501608 minutes
2023-07-03 09:40:38,238:INFO:SubProcess create_model() called ==================================
2023-07-03 09:40:38,238:INFO:Initializing create_model()
2023-07-03 09:40:38,238:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244E2340BE0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000244E2343AC0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:40:38,238:INFO:Checking exceptions
2023-07-03 09:40:38,239:INFO:Importing libraries
2023-07-03 09:40:38,239:INFO:Copying training dataset
2023-07-03 09:40:38,242:INFO:Defining folds
2023-07-03 09:40:38,242:INFO:Declaring metric variables
2023-07-03 09:40:38,245:INFO:Importing untrained model
2023-07-03 09:40:38,247:INFO:Dummy Regressor Imported successfully
2023-07-03 09:40:38,254:INFO:Starting cross validation
2023-07-03 09:40:38,255:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:40:39,275:INFO:Calculating mean and std
2023-07-03 09:40:39,277:INFO:Creating metrics dataframe
2023-07-03 09:40:39,444:INFO:Uploading results into container
2023-07-03 09:40:39,446:INFO:Uploading model into container now
2023-07-03 09:40:39,446:INFO:_master_model_container: 18
2023-07-03 09:40:39,446:INFO:_display_container: 2
2023-07-03 09:40:39,447:INFO:DummyRegressor()
2023-07-03 09:40:39,447:INFO:create_model() successfully completed......................................
2023-07-03 09:40:39,723:INFO:SubProcess create_model() end ==================================
2023-07-03 09:40:39,723:INFO:Creating metrics dataframe
2023-07-03 09:40:39,743:INFO:Initializing create_model()
2023-07-03 09:40:39,743:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244E2340BE0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:40:39,743:INFO:Checking exceptions
2023-07-03 09:40:39,745:INFO:Importing libraries
2023-07-03 09:40:39,745:INFO:Copying training dataset
2023-07-03 09:40:39,746:INFO:Defining folds
2023-07-03 09:40:39,746:INFO:Declaring metric variables
2023-07-03 09:40:39,747:INFO:Importing untrained model
2023-07-03 09:40:39,747:INFO:Declaring custom model
2023-07-03 09:40:39,747:INFO:Extra Trees Regressor Imported successfully
2023-07-03 09:40:39,748:INFO:Cross validation set to False
2023-07-03 09:40:39,748:INFO:Fitting Model
2023-07-03 09:40:39,946:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-07-03 09:40:39,946:INFO:create_model() successfully completed......................................
2023-07-03 09:40:40,261:INFO:_master_model_container: 18
2023-07-03 09:40:40,261:INFO:_display_container: 2
2023-07-03 09:40:40,262:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-07-03 09:40:40,262:INFO:compare_models() successfully completed......................................
2023-07-03 09:40:51,193:INFO:Initializing create_model()
2023-07-03 09:40:51,193:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244E2340BE0>, estimator=et, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:40:51,193:INFO:Checking exceptions
2023-07-03 09:40:51,206:INFO:Importing libraries
2023-07-03 09:40:51,207:INFO:Copying training dataset
2023-07-03 09:40:51,209:INFO:Defining folds
2023-07-03 09:40:51,209:INFO:Declaring metric variables
2023-07-03 09:40:51,211:INFO:Importing untrained model
2023-07-03 09:40:51,215:INFO:Extra Trees Regressor Imported successfully
2023-07-03 09:40:51,221:INFO:Starting cross validation
2023-07-03 09:40:51,222:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:40:52,355:INFO:Calculating mean and std
2023-07-03 09:40:52,356:INFO:Creating metrics dataframe
2023-07-03 09:40:52,361:INFO:Finalizing model
2023-07-03 09:40:52,625:INFO:Uploading results into container
2023-07-03 09:40:52,625:INFO:Uploading model into container now
2023-07-03 09:40:52,633:INFO:_master_model_container: 19
2023-07-03 09:40:52,633:INFO:_display_container: 3
2023-07-03 09:40:52,633:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-07-03 09:40:52,633:INFO:create_model() successfully completed......................................
2023-07-03 09:41:10,640:INFO:Initializing tune_model()
2023-07-03 09:41:10,640:INFO:tune_model(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244E2340BE0>)
2023-07-03 09:41:10,640:INFO:Checking exceptions
2023-07-03 09:41:10,654:INFO:Copying training dataset
2023-07-03 09:41:10,656:INFO:Checking base model
2023-07-03 09:41:10,658:INFO:Base model : Extra Trees Regressor
2023-07-03 09:41:10,661:INFO:Declaring metric variables
2023-07-03 09:41:10,663:INFO:Defining Hyperparameters
2023-07-03 09:41:10,935:INFO:Tuning with n_jobs=-1
2023-07-03 09:41:10,936:INFO:Initializing RandomizedSearchCV
2023-07-03 09:41:27,689:INFO:best_params: {'actual_estimator__n_estimators': 100, 'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.1, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'squared_error', 'actual_estimator__bootstrap': True}
2023-07-03 09:41:27,690:INFO:Hyperparameter search completed
2023-07-03 09:41:27,691:INFO:SubProcess create_model() called ==================================
2023-07-03 09:41:27,691:INFO:Initializing create_model()
2023-07-03 09:41:27,691:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244E2340BE0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000244DBB97BB0>, model_only=True, return_train_score=False, kwargs={'n_estimators': 100, 'min_samples_split': 7, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.1, 'max_features': 1.0, 'max_depth': 9, 'criterion': 'squared_error', 'bootstrap': True})
2023-07-03 09:41:27,691:INFO:Checking exceptions
2023-07-03 09:41:27,691:INFO:Importing libraries
2023-07-03 09:41:27,691:INFO:Copying training dataset
2023-07-03 09:41:27,694:INFO:Defining folds
2023-07-03 09:41:27,694:INFO:Declaring metric variables
2023-07-03 09:41:27,697:INFO:Importing untrained model
2023-07-03 09:41:27,697:INFO:Declaring custom model
2023-07-03 09:41:27,700:INFO:Extra Trees Regressor Imported successfully
2023-07-03 09:41:27,705:INFO:Starting cross validation
2023-07-03 09:41:27,706:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:41:29,118:INFO:Calculating mean and std
2023-07-03 09:41:29,120:INFO:Creating metrics dataframe
2023-07-03 09:41:29,124:INFO:Finalizing model
2023-07-03 09:41:29,522:INFO:Uploading results into container
2023-07-03 09:41:29,523:INFO:Uploading model into container now
2023-07-03 09:41:29,523:INFO:_master_model_container: 20
2023-07-03 09:41:29,523:INFO:_display_container: 4
2023-07-03 09:41:29,524:INFO:ExtraTreesRegressor(bootstrap=True, max_depth=9, min_impurity_decrease=0.1,
                    min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                    random_state=123)
2023-07-03 09:41:29,524:INFO:create_model() successfully completed......................................
2023-07-03 09:41:29,809:INFO:SubProcess create_model() end ==================================
2023-07-03 09:41:29,809:INFO:choose_better activated
2023-07-03 09:41:29,813:INFO:SubProcess create_model() called ==================================
2023-07-03 09:41:29,814:INFO:Initializing create_model()
2023-07-03 09:41:29,814:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244E2340BE0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:41:29,814:INFO:Checking exceptions
2023-07-03 09:41:29,815:INFO:Importing libraries
2023-07-03 09:41:29,816:INFO:Copying training dataset
2023-07-03 09:41:29,818:INFO:Defining folds
2023-07-03 09:41:29,818:INFO:Declaring metric variables
2023-07-03 09:41:29,818:INFO:Importing untrained model
2023-07-03 09:41:29,818:INFO:Declaring custom model
2023-07-03 09:41:29,818:INFO:Extra Trees Regressor Imported successfully
2023-07-03 09:41:29,819:INFO:Starting cross validation
2023-07-03 09:41:29,819:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:41:31,309:INFO:Calculating mean and std
2023-07-03 09:41:31,310:INFO:Creating metrics dataframe
2023-07-03 09:41:31,312:INFO:Finalizing model
2023-07-03 09:41:31,613:INFO:Uploading results into container
2023-07-03 09:41:31,614:INFO:Uploading model into container now
2023-07-03 09:41:31,614:INFO:_master_model_container: 21
2023-07-03 09:41:31,614:INFO:_display_container: 5
2023-07-03 09:41:31,615:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-07-03 09:41:31,615:INFO:create_model() successfully completed......................................
2023-07-03 09:41:31,904:INFO:SubProcess create_model() end ==================================
2023-07-03 09:41:31,905:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) result for R2 is 0.739
2023-07-03 09:41:31,905:INFO:ExtraTreesRegressor(bootstrap=True, max_depth=9, min_impurity_decrease=0.1,
                    min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                    random_state=123) result for R2 is 0.6127
2023-07-03 09:41:31,905:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) is best model
2023-07-03 09:41:31,905:INFO:choose_better completed
2023-07-03 09:41:31,906:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-07-03 09:41:31,913:INFO:_master_model_container: 21
2023-07-03 09:41:31,913:INFO:_display_container: 4
2023-07-03 09:41:31,914:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-07-03 09:41:31,914:INFO:tune_model() successfully completed......................................
2023-07-03 09:41:32,316:INFO:Initializing tune_model()
2023-07-03 09:41:32,316:INFO:tune_model(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244E2340BE0>)
2023-07-03 09:41:32,316:INFO:Checking exceptions
2023-07-03 09:41:32,330:INFO:Copying training dataset
2023-07-03 09:41:32,333:INFO:Checking base model
2023-07-03 09:41:32,334:INFO:Base model : Extra Trees Regressor
2023-07-03 09:41:32,337:INFO:Declaring metric variables
2023-07-03 09:41:32,340:INFO:Defining Hyperparameters
2023-07-03 09:41:32,618:INFO:Tuning with n_jobs=-1
2023-07-03 09:41:32,618:INFO:Initializing RandomizedSearchCV
2023-07-03 09:41:46,946:INFO:best_params: {'actual_estimator__n_estimators': 100, 'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.1, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'squared_error', 'actual_estimator__bootstrap': True}
2023-07-03 09:41:46,948:INFO:Hyperparameter search completed
2023-07-03 09:41:46,948:INFO:SubProcess create_model() called ==================================
2023-07-03 09:41:46,948:INFO:Initializing create_model()
2023-07-03 09:41:46,948:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244E2340BE0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000244DD9BD450>, model_only=True, return_train_score=False, kwargs={'n_estimators': 100, 'min_samples_split': 7, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.1, 'max_features': 1.0, 'max_depth': 9, 'criterion': 'squared_error', 'bootstrap': True})
2023-07-03 09:41:46,949:INFO:Checking exceptions
2023-07-03 09:41:46,949:INFO:Importing libraries
2023-07-03 09:41:46,949:INFO:Copying training dataset
2023-07-03 09:41:46,951:INFO:Defining folds
2023-07-03 09:41:46,951:INFO:Declaring metric variables
2023-07-03 09:41:46,954:INFO:Importing untrained model
2023-07-03 09:41:46,954:INFO:Declaring custom model
2023-07-03 09:41:46,957:INFO:Extra Trees Regressor Imported successfully
2023-07-03 09:41:46,964:INFO:Starting cross validation
2023-07-03 09:41:46,964:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:41:48,341:INFO:Calculating mean and std
2023-07-03 09:41:48,342:INFO:Creating metrics dataframe
2023-07-03 09:41:48,347:INFO:Finalizing model
2023-07-03 09:41:48,582:INFO:Uploading results into container
2023-07-03 09:41:48,583:INFO:Uploading model into container now
2023-07-03 09:41:48,584:INFO:_master_model_container: 22
2023-07-03 09:41:48,584:INFO:_display_container: 5
2023-07-03 09:41:48,584:INFO:ExtraTreesRegressor(bootstrap=True, max_depth=9, min_impurity_decrease=0.1,
                    min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                    random_state=123)
2023-07-03 09:41:48,584:INFO:create_model() successfully completed......................................
2023-07-03 09:41:48,868:INFO:SubProcess create_model() end ==================================
2023-07-03 09:41:48,868:INFO:choose_better activated
2023-07-03 09:41:48,871:INFO:SubProcess create_model() called ==================================
2023-07-03 09:41:48,872:INFO:Initializing create_model()
2023-07-03 09:41:48,872:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244E2340BE0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:41:48,872:INFO:Checking exceptions
2023-07-03 09:41:48,873:INFO:Importing libraries
2023-07-03 09:41:48,874:INFO:Copying training dataset
2023-07-03 09:41:48,876:INFO:Defining folds
2023-07-03 09:41:48,876:INFO:Declaring metric variables
2023-07-03 09:41:48,876:INFO:Importing untrained model
2023-07-03 09:41:48,876:INFO:Declaring custom model
2023-07-03 09:41:48,877:INFO:Extra Trees Regressor Imported successfully
2023-07-03 09:41:48,877:INFO:Starting cross validation
2023-07-03 09:41:48,877:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:41:50,269:INFO:Calculating mean and std
2023-07-03 09:41:50,269:INFO:Creating metrics dataframe
2023-07-03 09:41:50,272:INFO:Finalizing model
2023-07-03 09:41:50,561:INFO:Uploading results into container
2023-07-03 09:41:50,562:INFO:Uploading model into container now
2023-07-03 09:41:50,562:INFO:_master_model_container: 23
2023-07-03 09:41:50,562:INFO:_display_container: 6
2023-07-03 09:41:50,563:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-07-03 09:41:50,563:INFO:create_model() successfully completed......................................
2023-07-03 09:41:50,843:INFO:SubProcess create_model() end ==================================
2023-07-03 09:41:50,843:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) result for R2 is 0.739
2023-07-03 09:41:50,844:INFO:ExtraTreesRegressor(bootstrap=True, max_depth=9, min_impurity_decrease=0.1,
                    min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                    random_state=123) result for R2 is 0.6127
2023-07-03 09:41:50,844:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) is best model
2023-07-03 09:41:50,844:INFO:choose_better completed
2023-07-03 09:41:50,844:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-07-03 09:41:50,853:INFO:_master_model_container: 23
2023-07-03 09:41:50,853:INFO:_display_container: 5
2023-07-03 09:41:50,853:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-07-03 09:41:50,853:INFO:tune_model() successfully completed......................................
2023-07-03 09:42:06,156:INFO:Initializing tune_model()
2023-07-03 09:42:06,157:INFO:tune_model(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=True, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244E2340BE0>)
2023-07-03 09:42:06,157:INFO:Checking exceptions
2023-07-03 09:42:06,171:INFO:Copying training dataset
2023-07-03 09:42:06,173:INFO:Checking base model
2023-07-03 09:42:06,174:INFO:Base model : Extra Trees Regressor
2023-07-03 09:42:06,177:INFO:Declaring metric variables
2023-07-03 09:42:06,181:INFO:Defining Hyperparameters
2023-07-03 09:42:06,458:INFO:Tuning with n_jobs=-1
2023-07-03 09:42:06,459:INFO:Initializing RandomizedSearchCV
2023-07-03 09:42:20,750:INFO:best_params: {'actual_estimator__n_estimators': 100, 'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.1, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'squared_error', 'actual_estimator__bootstrap': True}
2023-07-03 09:42:20,751:INFO:Hyperparameter search completed
2023-07-03 09:42:20,751:INFO:SubProcess create_model() called ==================================
2023-07-03 09:42:20,752:INFO:Initializing create_model()
2023-07-03 09:42:20,752:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244E2340BE0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000244DDB50640>, model_only=True, return_train_score=False, kwargs={'n_estimators': 100, 'min_samples_split': 7, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.1, 'max_features': 1.0, 'max_depth': 9, 'criterion': 'squared_error', 'bootstrap': True})
2023-07-03 09:42:20,752:INFO:Checking exceptions
2023-07-03 09:42:20,752:INFO:Importing libraries
2023-07-03 09:42:20,752:INFO:Copying training dataset
2023-07-03 09:42:20,755:INFO:Defining folds
2023-07-03 09:42:20,755:INFO:Declaring metric variables
2023-07-03 09:42:20,758:INFO:Importing untrained model
2023-07-03 09:42:20,758:INFO:Declaring custom model
2023-07-03 09:42:20,763:INFO:Extra Trees Regressor Imported successfully
2023-07-03 09:42:20,768:INFO:Starting cross validation
2023-07-03 09:42:20,769:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:42:22,153:INFO:Calculating mean and std
2023-07-03 09:42:22,154:INFO:Creating metrics dataframe
2023-07-03 09:42:22,159:INFO:Finalizing model
2023-07-03 09:42:22,398:INFO:Uploading results into container
2023-07-03 09:42:22,399:INFO:Uploading model into container now
2023-07-03 09:42:22,400:INFO:_master_model_container: 24
2023-07-03 09:42:22,400:INFO:_display_container: 6
2023-07-03 09:42:22,401:INFO:ExtraTreesRegressor(bootstrap=True, max_depth=9, min_impurity_decrease=0.1,
                    min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                    random_state=123)
2023-07-03 09:42:22,401:INFO:create_model() successfully completed......................................
2023-07-03 09:42:22,682:INFO:SubProcess create_model() end ==================================
2023-07-03 09:42:22,683:INFO:choose_better activated
2023-07-03 09:42:22,686:INFO:SubProcess create_model() called ==================================
2023-07-03 09:42:22,687:INFO:Initializing create_model()
2023-07-03 09:42:22,687:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244E2340BE0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:42:22,687:INFO:Checking exceptions
2023-07-03 09:42:22,688:INFO:Importing libraries
2023-07-03 09:42:22,688:INFO:Copying training dataset
2023-07-03 09:42:22,691:INFO:Defining folds
2023-07-03 09:42:22,691:INFO:Declaring metric variables
2023-07-03 09:42:22,691:INFO:Importing untrained model
2023-07-03 09:42:22,691:INFO:Declaring custom model
2023-07-03 09:42:22,692:INFO:Extra Trees Regressor Imported successfully
2023-07-03 09:42:22,692:INFO:Starting cross validation
2023-07-03 09:42:22,692:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:42:24,073:INFO:Calculating mean and std
2023-07-03 09:42:24,073:INFO:Creating metrics dataframe
2023-07-03 09:42:24,075:INFO:Finalizing model
2023-07-03 09:42:24,379:INFO:Uploading results into container
2023-07-03 09:42:24,379:INFO:Uploading model into container now
2023-07-03 09:42:24,381:INFO:_master_model_container: 25
2023-07-03 09:42:24,381:INFO:_display_container: 7
2023-07-03 09:42:24,381:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-07-03 09:42:24,381:INFO:create_model() successfully completed......................................
2023-07-03 09:42:24,659:INFO:SubProcess create_model() end ==================================
2023-07-03 09:42:24,661:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) result for R2 is 0.739
2023-07-03 09:42:24,661:INFO:ExtraTreesRegressor(bootstrap=True, max_depth=9, min_impurity_decrease=0.1,
                    min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                    random_state=123) result for R2 is 0.6127
2023-07-03 09:42:24,661:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) is best model
2023-07-03 09:42:24,662:INFO:choose_better completed
2023-07-03 09:42:24,662:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-07-03 09:42:24,671:INFO:_master_model_container: 25
2023-07-03 09:42:24,671:INFO:_display_container: 6
2023-07-03 09:42:24,671:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-07-03 09:42:24,671:INFO:tune_model() successfully completed......................................
2023-07-03 09:43:18,895:INFO:Initializing tune_model()
2023-07-03 09:43:18,895:INFO:tune_model(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=50, custom_grid=None, optimize=mae, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244E2340BE0>)
2023-07-03 09:43:18,895:INFO:Checking exceptions
2023-07-03 09:43:18,909:INFO:Copying training dataset
2023-07-03 09:43:18,912:INFO:Checking base model
2023-07-03 09:43:18,912:INFO:Base model : Extra Trees Regressor
2023-07-03 09:43:18,914:INFO:Declaring metric variables
2023-07-03 09:43:18,917:INFO:Defining Hyperparameters
2023-07-03 09:43:19,192:INFO:Tuning with n_jobs=-1
2023-07-03 09:43:19,193:INFO:Initializing RandomizedSearchCV
2023-07-03 09:45:04,132:INFO:best_params: {'actual_estimator__n_estimators': 180, 'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 3, 'actual_estimator__min_impurity_decrease': 0.005, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 8, 'actual_estimator__criterion': 'absolute_error', 'actual_estimator__bootstrap': False}
2023-07-03 09:45:04,133:INFO:Hyperparameter search completed
2023-07-03 09:45:04,133:INFO:SubProcess create_model() called ==================================
2023-07-03 09:45:04,134:INFO:Initializing create_model()
2023-07-03 09:45:04,134:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244E2340BE0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000244DF8300A0>, model_only=True, return_train_score=False, kwargs={'n_estimators': 180, 'min_samples_split': 7, 'min_samples_leaf': 3, 'min_impurity_decrease': 0.005, 'max_features': 1.0, 'max_depth': 8, 'criterion': 'absolute_error', 'bootstrap': False})
2023-07-03 09:45:04,134:INFO:Checking exceptions
2023-07-03 09:45:04,134:INFO:Importing libraries
2023-07-03 09:45:04,134:INFO:Copying training dataset
2023-07-03 09:45:04,137:INFO:Defining folds
2023-07-03 09:45:04,137:INFO:Declaring metric variables
2023-07-03 09:45:04,140:INFO:Importing untrained model
2023-07-03 09:45:04,140:INFO:Declaring custom model
2023-07-03 09:45:04,143:INFO:Extra Trees Regressor Imported successfully
2023-07-03 09:45:04,149:INFO:Starting cross validation
2023-07-03 09:45:04,149:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:45:06,388:INFO:Calculating mean and std
2023-07-03 09:45:06,389:INFO:Creating metrics dataframe
2023-07-03 09:45:06,395:INFO:Finalizing model
2023-07-03 09:45:07,061:INFO:Uploading results into container
2023-07-03 09:45:07,062:INFO:Uploading model into container now
2023-07-03 09:45:07,062:INFO:_master_model_container: 26
2023-07-03 09:45:07,063:INFO:_display_container: 7
2023-07-03 09:45:07,063:INFO:ExtraTreesRegressor(criterion='absolute_error', max_depth=8,
                    min_impurity_decrease=0.005, min_samples_leaf=3,
                    min_samples_split=7, n_estimators=180, n_jobs=-1,
                    random_state=123)
2023-07-03 09:45:07,063:INFO:create_model() successfully completed......................................
2023-07-03 09:45:07,345:INFO:SubProcess create_model() end ==================================
2023-07-03 09:45:07,345:INFO:choose_better activated
2023-07-03 09:45:07,348:INFO:SubProcess create_model() called ==================================
2023-07-03 09:45:07,349:INFO:Initializing create_model()
2023-07-03 09:45:07,349:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244E2340BE0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:45:07,349:INFO:Checking exceptions
2023-07-03 09:45:07,350:INFO:Importing libraries
2023-07-03 09:45:07,350:INFO:Copying training dataset
2023-07-03 09:45:07,353:INFO:Defining folds
2023-07-03 09:45:07,353:INFO:Declaring metric variables
2023-07-03 09:45:07,353:INFO:Importing untrained model
2023-07-03 09:45:07,353:INFO:Declaring custom model
2023-07-03 09:45:07,354:INFO:Extra Trees Regressor Imported successfully
2023-07-03 09:45:07,354:INFO:Starting cross validation
2023-07-03 09:45:07,355:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:45:09,449:INFO:Calculating mean and std
2023-07-03 09:45:09,450:INFO:Creating metrics dataframe
2023-07-03 09:45:09,452:INFO:Finalizing model
2023-07-03 09:45:09,869:INFO:Uploading results into container
2023-07-03 09:45:09,869:INFO:Uploading model into container now
2023-07-03 09:45:09,870:INFO:_master_model_container: 27
2023-07-03 09:45:09,870:INFO:_display_container: 8
2023-07-03 09:45:09,870:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-07-03 09:45:09,870:INFO:create_model() successfully completed......................................
2023-07-03 09:45:10,148:INFO:SubProcess create_model() end ==================================
2023-07-03 09:45:10,149:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) result for MAE is 0.5937
2023-07-03 09:45:10,150:INFO:ExtraTreesRegressor(criterion='absolute_error', max_depth=8,
                    min_impurity_decrease=0.005, min_samples_leaf=3,
                    min_samples_split=7, n_estimators=180, n_jobs=-1,
                    random_state=123) result for MAE is 0.7323
2023-07-03 09:45:10,150:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) is best model
2023-07-03 09:45:10,150:INFO:choose_better completed
2023-07-03 09:45:10,150:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-07-03 09:45:10,158:INFO:_master_model_container: 27
2023-07-03 09:45:10,159:INFO:_display_container: 7
2023-07-03 09:45:10,159:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-07-03 09:45:10,159:INFO:tune_model() successfully completed......................................
2023-07-03 09:45:10,641:INFO:Initializing plot_model()
2023-07-03 09:45:10,642:INFO:plot_model(plot=residuals, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244E2340BE0>, system=True)
2023-07-03 09:45:10,642:INFO:Checking exceptions
2023-07-03 09:45:10,656:INFO:Preloading libraries
2023-07-03 09:45:10,663:INFO:Copying training dataset
2023-07-03 09:45:10,663:INFO:Plot type: residuals
2023-07-03 09:45:10,750:INFO:Fitting Model
2023-07-03 09:45:10,751:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\base.py:420: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
2023-07-03 09:45:10,751:WARNING:  warnings.warn(
2023-07-03 09:45:10,806:INFO:Scoring test/hold-out set
2023-07-03 09:45:11,204:INFO:Visual Rendered Successfully
2023-07-03 09:45:11,496:INFO:plot_model() successfully completed......................................
2023-07-03 09:46:07,039:INFO:Initializing tune_model()
2023-07-03 09:46:07,040:INFO:tune_model(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=True, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244E2340BE0>)
2023-07-03 09:46:07,040:INFO:Checking exceptions
2023-07-03 09:46:07,058:INFO:Copying training dataset
2023-07-03 09:46:07,061:INFO:Checking base model
2023-07-03 09:46:07,061:INFO:Base model : Extra Trees Regressor
2023-07-03 09:46:07,065:INFO:Declaring metric variables
2023-07-03 09:46:07,070:INFO:Defining Hyperparameters
2023-07-03 09:46:07,345:INFO:Tuning with n_jobs=-1
2023-07-03 09:46:07,345:INFO:Initializing RandomizedSearchCV
2023-07-03 09:46:29,875:INFO:best_params: {'actual_estimator__n_estimators': 100, 'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.1, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'squared_error', 'actual_estimator__bootstrap': True}
2023-07-03 09:46:29,876:INFO:Hyperparameter search completed
2023-07-03 09:46:29,877:INFO:SubProcess create_model() called ==================================
2023-07-03 09:46:29,877:INFO:Initializing create_model()
2023-07-03 09:46:29,877:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244E2340BE0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000244E74B8880>, model_only=True, return_train_score=False, kwargs={'n_estimators': 100, 'min_samples_split': 7, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.1, 'max_features': 1.0, 'max_depth': 9, 'criterion': 'squared_error', 'bootstrap': True})
2023-07-03 09:46:29,877:INFO:Checking exceptions
2023-07-03 09:46:29,878:INFO:Importing libraries
2023-07-03 09:46:29,878:INFO:Copying training dataset
2023-07-03 09:46:29,881:INFO:Defining folds
2023-07-03 09:46:29,881:INFO:Declaring metric variables
2023-07-03 09:46:29,884:INFO:Importing untrained model
2023-07-03 09:46:29,884:INFO:Declaring custom model
2023-07-03 09:46:29,888:INFO:Extra Trees Regressor Imported successfully
2023-07-03 09:46:29,893:INFO:Starting cross validation
2023-07-03 09:46:29,893:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:46:32,012:INFO:Calculating mean and std
2023-07-03 09:46:32,014:INFO:Creating metrics dataframe
2023-07-03 09:46:32,021:INFO:Finalizing model
2023-07-03 09:46:32,389:INFO:Uploading results into container
2023-07-03 09:46:32,390:INFO:Uploading model into container now
2023-07-03 09:46:32,390:INFO:_master_model_container: 28
2023-07-03 09:46:32,390:INFO:_display_container: 8
2023-07-03 09:46:32,391:INFO:ExtraTreesRegressor(bootstrap=True, max_depth=9, min_impurity_decrease=0.1,
                    min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                    random_state=123)
2023-07-03 09:46:32,391:INFO:create_model() successfully completed......................................
2023-07-03 09:46:32,678:INFO:SubProcess create_model() end ==================================
2023-07-03 09:46:32,678:INFO:choose_better activated
2023-07-03 09:46:32,681:INFO:SubProcess create_model() called ==================================
2023-07-03 09:46:32,682:INFO:Initializing create_model()
2023-07-03 09:46:32,682:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244E2340BE0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:46:32,682:INFO:Checking exceptions
2023-07-03 09:46:32,684:INFO:Importing libraries
2023-07-03 09:46:32,684:INFO:Copying training dataset
2023-07-03 09:46:32,686:INFO:Defining folds
2023-07-03 09:46:32,686:INFO:Declaring metric variables
2023-07-03 09:46:32,686:INFO:Importing untrained model
2023-07-03 09:46:32,686:INFO:Declaring custom model
2023-07-03 09:46:32,686:INFO:Extra Trees Regressor Imported successfully
2023-07-03 09:46:32,687:INFO:Starting cross validation
2023-07-03 09:46:32,687:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:46:34,827:INFO:Calculating mean and std
2023-07-03 09:46:34,828:INFO:Creating metrics dataframe
2023-07-03 09:46:34,829:INFO:Finalizing model
2023-07-03 09:46:35,253:INFO:Uploading results into container
2023-07-03 09:46:35,254:INFO:Uploading model into container now
2023-07-03 09:46:35,254:INFO:_master_model_container: 29
2023-07-03 09:46:35,254:INFO:_display_container: 9
2023-07-03 09:46:35,254:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-07-03 09:46:35,254:INFO:create_model() successfully completed......................................
2023-07-03 09:46:35,541:INFO:SubProcess create_model() end ==================================
2023-07-03 09:46:35,541:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) result for R2 is 0.739
2023-07-03 09:46:35,542:INFO:ExtraTreesRegressor(bootstrap=True, max_depth=9, min_impurity_decrease=0.1,
                    min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                    random_state=123) result for R2 is 0.6127
2023-07-03 09:46:35,542:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) is best model
2023-07-03 09:46:35,542:INFO:choose_better completed
2023-07-03 09:46:35,542:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-07-03 09:46:35,551:INFO:_master_model_container: 29
2023-07-03 09:46:35,551:INFO:_display_container: 8
2023-07-03 09:46:35,551:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-07-03 09:46:35,552:INFO:tune_model() successfully completed......................................
2023-07-03 09:46:41,838:INFO:Initializing plot_model()
2023-07-03 09:46:41,838:INFO:plot_model(plot=residuals, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244E2340BE0>, system=True)
2023-07-03 09:46:41,838:INFO:Checking exceptions
2023-07-03 09:46:41,853:INFO:Preloading libraries
2023-07-03 09:46:41,860:INFO:Copying training dataset
2023-07-03 09:46:41,860:INFO:Plot type: residuals
2023-07-03 09:46:41,922:INFO:Fitting Model
2023-07-03 09:46:41,922:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\base.py:420: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
2023-07-03 09:46:41,922:WARNING:  warnings.warn(
2023-07-03 09:46:41,978:INFO:Scoring test/hold-out set
2023-07-03 09:46:42,308:INFO:Visual Rendered Successfully
2023-07-03 09:46:42,595:INFO:plot_model() successfully completed......................................
2023-07-03 09:46:44,814:INFO:Initializing plot_model()
2023-07-03 09:46:44,814:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244E2340BE0>, system=True)
2023-07-03 09:46:44,814:INFO:Checking exceptions
2023-07-03 09:46:44,829:INFO:Preloading libraries
2023-07-03 09:46:44,835:INFO:Copying training dataset
2023-07-03 09:46:44,835:INFO:Plot type: error
2023-07-03 09:46:44,880:INFO:Fitting Model
2023-07-03 09:46:44,880:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\base.py:420: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
2023-07-03 09:46:44,880:WARNING:  warnings.warn(
2023-07-03 09:46:44,881:INFO:Scoring test/hold-out set
2023-07-03 09:46:45,101:INFO:Visual Rendered Successfully
2023-07-03 09:46:45,372:INFO:plot_model() successfully completed......................................
2023-07-03 09:46:47,606:INFO:Initializing plot_model()
2023-07-03 09:46:47,606:INFO:plot_model(plot=cooks, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244E2340BE0>, system=True)
2023-07-03 09:46:47,606:INFO:Checking exceptions
2023-07-03 09:46:47,621:INFO:Preloading libraries
2023-07-03 09:46:47,626:INFO:Copying training dataset
2023-07-03 09:46:47,626:INFO:Plot type: cooks
2023-07-03 09:46:47,670:INFO:Fitting Model
2023-07-03 09:46:47,838:INFO:Visual Rendered Successfully
2023-07-03 09:46:48,117:INFO:plot_model() successfully completed......................................
2023-07-03 09:46:50,165:INFO:Initializing plot_model()
2023-07-03 09:46:50,165:INFO:plot_model(plot=rfe, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244E2340BE0>, system=True)
2023-07-03 09:46:50,165:INFO:Checking exceptions
2023-07-03 09:46:50,179:INFO:Preloading libraries
2023-07-03 09:46:50,186:INFO:Copying training dataset
2023-07-03 09:46:50,186:INFO:Plot type: rfe
2023-07-03 09:46:50,238:INFO:Fitting Model
2023-07-03 09:47:12,126:INFO:Visual Rendered Successfully
2023-07-03 09:47:12,424:INFO:plot_model() successfully completed......................................
2023-07-03 09:47:17,349:INFO:Initializing plot_model()
2023-07-03 09:47:17,350:INFO:plot_model(plot=learning, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244E2340BE0>, system=True)
2023-07-03 09:47:17,350:INFO:Checking exceptions
2023-07-03 09:47:17,363:INFO:Preloading libraries
2023-07-03 09:47:17,371:INFO:Copying training dataset
2023-07-03 09:47:17,371:INFO:Plot type: learning
2023-07-03 09:47:17,423:INFO:Fitting Model
2023-07-03 09:47:19,310:INFO:Visual Rendered Successfully
2023-07-03 09:47:19,586:INFO:plot_model() successfully completed......................................
2023-07-03 09:47:28,962:INFO:Initializing plot_model()
2023-07-03 09:47:28,962:INFO:plot_model(plot=vc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244E2340BE0>, system=True)
2023-07-03 09:47:28,963:INFO:Checking exceptions
2023-07-03 09:47:28,976:INFO:Preloading libraries
2023-07-03 09:47:28,982:INFO:Copying training dataset
2023-07-03 09:47:28,982:INFO:Plot type: vc
2023-07-03 09:47:28,983:INFO:Determining param_name
2023-07-03 09:47:28,983:INFO:param_name: max_depth
2023-07-03 09:47:29,039:INFO:Fitting Model
2023-07-03 09:47:30,911:INFO:Visual Rendered Successfully
2023-07-03 09:47:31,183:INFO:plot_model() successfully completed......................................
2023-07-03 09:47:56,777:INFO:Initializing plot_model()
2023-07-03 09:47:56,777:INFO:plot_model(plot=manifold, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244E2340BE0>, system=True)
2023-07-03 09:47:56,777:INFO:Checking exceptions
2023-07-03 09:47:56,792:INFO:Preloading libraries
2023-07-03 09:47:56,800:INFO:Copying training dataset
2023-07-03 09:47:56,800:INFO:Plot type: manifold
2023-07-03 09:47:56,865:INFO:Fitting & Transforming Model
2023-07-03 09:47:57,322:INFO:Visual Rendered Successfully
2023-07-03 09:47:57,604:INFO:plot_model() successfully completed......................................
2023-07-03 09:48:03,140:INFO:Initializing plot_model()
2023-07-03 09:48:03,141:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244E2340BE0>, system=True)
2023-07-03 09:48:03,141:INFO:Checking exceptions
2023-07-03 09:48:03,155:INFO:Preloading libraries
2023-07-03 09:48:03,162:INFO:Copying training dataset
2023-07-03 09:48:03,162:INFO:Plot type: feature
2023-07-03 09:48:03,162:WARNING:No coef_ found. Trying feature_importances_
2023-07-03 09:48:03,284:INFO:Visual Rendered Successfully
2023-07-03 09:48:03,559:INFO:plot_model() successfully completed......................................
2023-07-03 09:48:19,821:INFO:Initializing evaluate_model()
2023-07-03 09:48:19,821:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244E2340BE0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-07-03 09:48:19,832:INFO:Initializing plot_model()
2023-07-03 09:48:19,832:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244E2340BE0>, system=True)
2023-07-03 09:48:19,832:INFO:Checking exceptions
2023-07-03 09:48:19,844:INFO:Preloading libraries
2023-07-03 09:48:19,852:INFO:Copying training dataset
2023-07-03 09:48:19,852:INFO:Plot type: pipeline
2023-07-03 09:48:19,936:INFO:Visual Rendered Successfully
2023-07-03 09:48:20,215:INFO:plot_model() successfully completed......................................
2023-07-03 09:48:23,016:INFO:Initializing plot_model()
2023-07-03 09:48:23,016:INFO:plot_model(plot=vc, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244E2340BE0>, system=True)
2023-07-03 09:48:23,016:INFO:Checking exceptions
2023-07-03 09:48:23,028:INFO:Preloading libraries
2023-07-03 09:48:23,035:INFO:Copying training dataset
2023-07-03 09:48:23,035:INFO:Plot type: vc
2023-07-03 09:48:23,035:INFO:Determining param_name
2023-07-03 09:48:23,035:INFO:param_name: max_depth
2023-07-03 09:48:23,075:INFO:Fitting Model
2023-07-03 09:48:24,946:INFO:Visual Rendered Successfully
2023-07-03 09:48:25,227:INFO:plot_model() successfully completed......................................
2023-07-03 09:48:28,179:INFO:Initializing plot_model()
2023-07-03 09:48:28,179:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244E2340BE0>, system=True)
2023-07-03 09:48:28,179:INFO:Checking exceptions
2023-07-03 09:48:28,192:INFO:Preloading libraries
2023-07-03 09:48:28,199:INFO:Copying training dataset
2023-07-03 09:48:28,199:INFO:Plot type: residuals
2023-07-03 09:48:28,259:INFO:Fitting Model
2023-07-03 09:48:28,259:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\base.py:420: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
2023-07-03 09:48:28,259:WARNING:  warnings.warn(
2023-07-03 09:48:28,315:INFO:Scoring test/hold-out set
2023-07-03 09:48:28,648:INFO:Visual Rendered Successfully
2023-07-03 09:48:28,940:INFO:plot_model() successfully completed......................................
2023-07-03 09:48:33,709:INFO:Initializing plot_model()
2023-07-03 09:48:33,709:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244E2340BE0>, system=True)
2023-07-03 09:48:33,709:INFO:Checking exceptions
2023-07-03 09:48:33,721:INFO:Preloading libraries
2023-07-03 09:48:33,728:INFO:Copying training dataset
2023-07-03 09:48:33,728:INFO:Plot type: pipeline
2023-07-03 09:48:33,786:INFO:Visual Rendered Successfully
2023-07-03 09:48:34,062:INFO:plot_model() successfully completed......................................
2023-07-03 09:48:39,519:INFO:Initializing plot_model()
2023-07-03 09:48:39,519:INFO:plot_model(plot=learning, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244E2340BE0>, system=True)
2023-07-03 09:48:39,519:INFO:Checking exceptions
2023-07-03 09:48:39,531:INFO:Preloading libraries
2023-07-03 09:48:39,538:INFO:Copying training dataset
2023-07-03 09:48:39,538:INFO:Plot type: learning
2023-07-03 09:48:39,580:INFO:Fitting Model
2023-07-03 09:48:41,487:INFO:Visual Rendered Successfully
2023-07-03 09:48:41,766:INFO:plot_model() successfully completed......................................
2023-07-03 09:48:49,761:INFO:Initializing finalize_model()
2023-07-03 09:48:49,761:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244E2340BE0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-07-03 09:48:49,761:INFO:Finalizing ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-07-03 09:48:49,764:INFO:Initializing create_model()
2023-07-03 09:48:49,764:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244E2340BE0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-07-03 09:48:49,764:INFO:Checking exceptions
2023-07-03 09:48:49,765:INFO:Importing libraries
2023-07-03 09:48:49,766:INFO:Copying training dataset
2023-07-03 09:48:49,766:INFO:Defining folds
2023-07-03 09:48:49,766:INFO:Declaring metric variables
2023-07-03 09:48:49,766:INFO:Importing untrained model
2023-07-03 09:48:49,766:INFO:Declaring custom model
2023-07-03 09:48:49,767:INFO:Extra Trees Regressor Imported successfully
2023-07-03 09:48:49,768:INFO:Cross validation set to False
2023-07-03 09:48:49,768:INFO:Fitting Model
2023-07-03 09:48:49,881:INFO:Pipeline(memory=FastMemory(location=C:\Users\JHossain\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MolLogP', 'MolWt',
                                             'NumRotatableBonds',
                                             'AromaticProportion'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))])
2023-07-03 09:48:49,881:INFO:create_model() successfully completed......................................
2023-07-03 09:48:50,157:INFO:_master_model_container: 29
2023-07-03 09:48:50,157:INFO:_display_container: 8
2023-07-03 09:48:50,162:INFO:Pipeline(memory=FastMemory(location=C:\Users\JHossain\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MolLogP', 'MolWt',
                                             'NumRotatableBonds',
                                             'AromaticProportion'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))])
2023-07-03 09:48:50,162:INFO:finalize_model() successfully completed......................................
2023-07-03 09:48:56,796:INFO:Initializing predict_model()
2023-07-03 09:48:56,796:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244E2340BE0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000244E7CC5CF0>)
2023-07-03 09:48:56,796:INFO:Checking exceptions
2023-07-03 09:48:56,797:INFO:Preloading libraries
2023-07-03 09:49:25,404:INFO:Initializing predict_model()
2023-07-03 09:49:25,404:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244E2340BE0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000244E7CC5CF0>)
2023-07-03 09:49:25,404:INFO:Checking exceptions
2023-07-03 09:49:25,404:INFO:Preloading libraries
2023-07-03 09:49:25,406:INFO:Set up data.
2023-07-03 09:49:25,408:INFO:Set up index.
2023-07-03 09:50:21,256:INFO:Initializing interpret_model()
2023-07-03 09:50:21,256:INFO:interpret_model(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244E2340BE0>)
2023-07-03 09:50:21,257:INFO:Checking exceptions
2023-07-03 09:50:21,257:ERROR:
'shap' is a soft dependency and not included in the pycaret installation. Please run: `pip install shap` to install.
Alternately, you can install this by running `pip install pycaret[analysis]`
NoneType: None
2023-07-03 09:50:44,528:INFO:Initializing interpret_model()
2023-07-03 09:50:44,529:INFO:interpret_model(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244E2340BE0>)
2023-07-03 09:50:44,529:INFO:Checking exceptions
2023-07-03 09:50:44,529:ERROR:
'shap' is a soft dependency and not included in the pycaret installation. Please run: `pip install shap` to install.
Alternately, you can install this by running `pip install pycaret[analysis]`
NoneType: None
2023-07-03 09:51:11,321:INFO:Initializing interpret_model()
2023-07-03 09:51:11,321:INFO:interpret_model(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244E2340BE0>)
2023-07-03 09:51:11,321:INFO:Checking exceptions
2023-07-03 09:51:11,321:ERROR:
'shap' is a soft dependency and not included in the pycaret installation. Please run: `pip install shap` to install.
Alternately, you can install this by running `pip install pycaret[analysis]`
NoneType: None
2023-07-03 09:54:02,701:INFO:Initializing interpret_model()
2023-07-03 09:54:02,702:INFO:interpret_model(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000244E2340BE0>)
2023-07-03 09:54:02,702:INFO:Checking exceptions
2023-07-03 09:54:02,702:ERROR:
'shap' is a soft dependency and not included in the pycaret installation. Please run: `pip install shap` to install.
Alternately, you can install this by running `pip install pycaret[analysis]`
NoneType: None
2023-07-03 09:54:20,173:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-03 09:54:20,173:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-03 09:54:20,174:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-03 09:54:20,174:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-03 09:54:20,964:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-07-03 09:54:21,564:INFO:PyCaret RegressionExperiment
2023-07-03 09:54:21,564:INFO:Logging name: reg-default-name
2023-07-03 09:54:21,564:INFO:ML Usecase: MLUsecase.REGRESSION
2023-07-03 09:54:21,564:INFO:version 3.0.2
2023-07-03 09:54:21,564:INFO:Initializing setup()
2023-07-03 09:54:21,564:INFO:self.USI: 939a
2023-07-03 09:54:21,565:INFO:self._variable_keys: {'transform_target_param', 'html_param', 'exp_name_log', 'seed', '_ml_usecase', 'pipeline', 'n_jobs_param', 'fold_shuffle_param', 'y', 'gpu_n_jobs_param', 'X_test', 'memory', 'logging_param', '_available_plots', 'y_train', 'data', 'gpu_param', 'target_param', 'idx', 'y_test', 'X_train', 'USI', 'exp_id', 'X', 'fold_generator', 'log_plots_param', 'fold_groups_param'}
2023-07-03 09:54:21,565:INFO:Checking environment
2023-07-03 09:54:21,565:INFO:python_version: 3.10.9
2023-07-03 09:54:21,565:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2023-07-03 09:54:21,565:INFO:machine: AMD64
2023-07-03 09:54:21,565:INFO:platform: Windows-10-10.0.22621-SP0
2023-07-03 09:54:21,568:INFO:Memory: svmem(total=33664483328, available=21485506560, percent=36.2, used=12178976768, free=21485506560)
2023-07-03 09:54:21,568:INFO:Physical Core: 6
2023-07-03 09:54:21,568:INFO:Logical Core: 12
2023-07-03 09:54:21,568:INFO:Checking libraries
2023-07-03 09:54:21,569:INFO:System:
2023-07-03 09:54:21,569:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2023-07-03 09:54:21,569:INFO:executable: C:\Users\JHossain\anaconda3\python.exe
2023-07-03 09:54:21,569:INFO:   machine: Windows-10-10.0.22621-SP0
2023-07-03 09:54:21,569:INFO:PyCaret required dependencies:
2023-07-03 09:54:21,569:INFO:                 pip: 22.3.1
2023-07-03 09:54:21,569:INFO:          setuptools: 65.6.3
2023-07-03 09:54:21,569:INFO:             pycaret: 3.0.2
2023-07-03 09:54:21,569:INFO:             IPython: 8.10.0
2023-07-03 09:54:21,569:INFO:          ipywidgets: 7.6.5
2023-07-03 09:54:21,569:INFO:                tqdm: 4.64.1
2023-07-03 09:54:21,569:INFO:               numpy: 1.23.5
2023-07-03 09:54:21,569:INFO:              pandas: 1.5.3
2023-07-03 09:54:21,569:INFO:              jinja2: 3.1.2
2023-07-03 09:54:21,569:INFO:               scipy: 1.10.0
2023-07-03 09:54:21,569:INFO:              joblib: 1.2.0
2023-07-03 09:54:21,569:INFO:             sklearn: 1.2.1
2023-07-03 09:54:21,569:INFO:                pyod: 1.0.9
2023-07-03 09:54:21,569:INFO:            imblearn: 0.10.1
2023-07-03 09:54:21,569:INFO:   category_encoders: 2.6.1
2023-07-03 09:54:21,569:INFO:            lightgbm: 3.3.5
2023-07-03 09:54:21,569:INFO:               numba: 0.56.4
2023-07-03 09:54:21,569:INFO:            requests: 2.28.1
2023-07-03 09:54:21,569:INFO:          matplotlib: 3.7.0
2023-07-03 09:54:21,569:INFO:          scikitplot: 0.3.7
2023-07-03 09:54:21,569:INFO:         yellowbrick: 1.5
2023-07-03 09:54:21,569:INFO:              plotly: 5.9.0
2023-07-03 09:54:21,570:INFO:             kaleido: 0.2.1
2023-07-03 09:54:21,570:INFO:         statsmodels: 0.13.5
2023-07-03 09:54:21,570:INFO:              sktime: 0.17.0
2023-07-03 09:54:21,570:INFO:               tbats: 1.1.3
2023-07-03 09:54:21,570:INFO:            pmdarima: 2.0.3
2023-07-03 09:54:21,570:INFO:              psutil: 5.9.0
2023-07-03 09:54:21,570:INFO:PyCaret optional dependencies:
2023-07-03 09:54:22,535:INFO:                shap: 0.41.0
2023-07-03 09:54:22,535:INFO:           interpret: 0.4.2
2023-07-03 09:54:22,535:INFO:                umap: Not installed
2023-07-03 09:54:22,535:INFO:    pandas_profiling: Not installed
2023-07-03 09:54:22,535:INFO:  explainerdashboard: Not installed
2023-07-03 09:54:22,535:INFO:             autoviz: Not installed
2023-07-03 09:54:22,535:INFO:           fairlearn: Not installed
2023-07-03 09:54:22,535:INFO:             xgboost: Not installed
2023-07-03 09:54:22,535:INFO:            catboost: Not installed
2023-07-03 09:54:22,536:INFO:              kmodes: Not installed
2023-07-03 09:54:22,536:INFO:             mlxtend: Not installed
2023-07-03 09:54:22,536:INFO:       statsforecast: Not installed
2023-07-03 09:54:22,536:INFO:        tune_sklearn: Not installed
2023-07-03 09:54:22,536:INFO:                 ray: Not installed
2023-07-03 09:54:22,536:INFO:            hyperopt: Not installed
2023-07-03 09:54:22,536:INFO:              optuna: Not installed
2023-07-03 09:54:22,536:INFO:               skopt: Not installed
2023-07-03 09:54:22,536:INFO:              mlflow: Not installed
2023-07-03 09:54:22,536:INFO:              gradio: 3.35.2
2023-07-03 09:54:22,536:INFO:             fastapi: 0.99.0
2023-07-03 09:54:22,536:INFO:             uvicorn: 0.22.0
2023-07-03 09:54:22,536:INFO:              m2cgen: Not installed
2023-07-03 09:54:22,536:INFO:           evidently: Not installed
2023-07-03 09:54:22,536:INFO:               fugue: Not installed
2023-07-03 09:54:22,536:INFO:           streamlit: Not installed
2023-07-03 09:54:22,536:INFO:             prophet: Not installed
2023-07-03 09:54:22,536:INFO:None
2023-07-03 09:54:22,536:INFO:Set up data.
2023-07-03 09:54:22,540:INFO:Set up train/test split.
2023-07-03 09:54:22,542:INFO:Set up index.
2023-07-03 09:54:22,542:INFO:Set up folding strategy.
2023-07-03 09:54:22,542:INFO:Assigning column types.
2023-07-03 09:54:22,544:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-07-03 09:54:22,544:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-07-03 09:54:22,548:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-07-03 09:54:22,552:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-03 09:54:22,600:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-03 09:54:22,637:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-03 09:54:22,638:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:54:22,793:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:54:22,793:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-07-03 09:54:22,797:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-07-03 09:54:22,801:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-03 09:54:22,849:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-03 09:54:22,887:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-03 09:54:22,888:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:54:22,888:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:54:22,888:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-07-03 09:54:22,892:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-07-03 09:54:22,896:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-03 09:54:22,943:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-03 09:54:22,979:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-03 09:54:22,979:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:54:22,979:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:54:22,984:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-07-03 09:54:22,987:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-03 09:54:23,035:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-03 09:54:23,073:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-03 09:54:23,074:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:54:23,074:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:54:23,074:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-07-03 09:54:23,082:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-03 09:54:23,128:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-03 09:54:23,165:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-03 09:54:23,165:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:54:23,166:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:54:23,173:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-03 09:54:23,220:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-03 09:54:23,257:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-03 09:54:23,257:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:54:23,257:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:54:23,257:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-07-03 09:54:23,311:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-03 09:54:23,348:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-03 09:54:23,351:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:54:23,351:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:54:23,405:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-03 09:54:23,441:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-03 09:54:23,442:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:54:23,442:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:54:23,442:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-07-03 09:54:23,662:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-03 09:54:23,699:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:54:23,699:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:54:23,753:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-03 09:54:23,790:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:54:23,790:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:54:23,791:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-07-03 09:54:23,881:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:54:23,882:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:54:23,973:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:54:23,973:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:54:23,975:INFO:Preparing preprocessing pipeline...
2023-07-03 09:54:23,975:INFO:Set up simple imputation.
2023-07-03 09:54:23,989:INFO:Finished creating preprocessing pipeline.
2023-07-03 09:54:23,993:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\JHossain\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MolLogP', 'MolWt',
                                             'NumRotatableBonds',
                                             'AromaticProportion'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2023-07-03 09:54:23,993:INFO:Creating final display dataframe.
2023-07-03 09:54:24,034:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target              logS
2                   Target type        Regression
3           Original data shape         (1144, 5)
4        Transformed data shape         (1144, 5)
5   Transformed train set shape           (91, 5)
6    Transformed test set shape         (1053, 5)
7              Numeric features                 4
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              939a
2023-07-03 09:54:24,130:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:54:24,131:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:54:24,224:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:54:24,225:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 09:54:24,225:INFO:setup() successfully completed in 2.93s...............
2023-07-03 09:54:24,246:INFO:Initializing compare_models()
2023-07-03 09:54:24,246:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000234B3F52F80>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000234B3F52F80>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-07-03 09:54:24,246:INFO:Checking exceptions
2023-07-03 09:54:24,248:INFO:Preparing display monitor
2023-07-03 09:54:24,268:INFO:Initializing Linear Regression
2023-07-03 09:54:24,268:INFO:Total runtime is 0.0 minutes
2023-07-03 09:54:24,271:INFO:SubProcess create_model() called ==================================
2023-07-03 09:54:24,272:INFO:Initializing create_model()
2023-07-03 09:54:24,272:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000234B3F52F80>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000234BB1F52A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:54:24,272:INFO:Checking exceptions
2023-07-03 09:54:24,272:INFO:Importing libraries
2023-07-03 09:54:24,272:INFO:Copying training dataset
2023-07-03 09:54:24,274:INFO:Defining folds
2023-07-03 09:54:24,275:INFO:Declaring metric variables
2023-07-03 09:54:24,278:INFO:Importing untrained model
2023-07-03 09:54:24,281:INFO:Linear Regression Imported successfully
2023-07-03 09:54:24,287:INFO:Starting cross validation
2023-07-03 09:54:24,291:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:54:31,122:INFO:Calculating mean and std
2023-07-03 09:54:31,123:INFO:Creating metrics dataframe
2023-07-03 09:54:31,446:INFO:Uploading results into container
2023-07-03 09:54:31,447:INFO:Uploading model into container now
2023-07-03 09:54:31,447:INFO:_master_model_container: 1
2023-07-03 09:54:31,448:INFO:_display_container: 2
2023-07-03 09:54:31,448:INFO:LinearRegression(n_jobs=-1)
2023-07-03 09:54:31,448:INFO:create_model() successfully completed......................................
2023-07-03 09:54:31,590:INFO:SubProcess create_model() end ==================================
2023-07-03 09:54:31,590:INFO:Creating metrics dataframe
2023-07-03 09:54:31,597:INFO:Initializing Lasso Regression
2023-07-03 09:54:31,598:INFO:Total runtime is 0.12217422723770141 minutes
2023-07-03 09:54:31,600:INFO:SubProcess create_model() called ==================================
2023-07-03 09:54:31,601:INFO:Initializing create_model()
2023-07-03 09:54:31,601:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000234B3F52F80>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000234BB1F52A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:54:31,601:INFO:Checking exceptions
2023-07-03 09:54:31,601:INFO:Importing libraries
2023-07-03 09:54:31,601:INFO:Copying training dataset
2023-07-03 09:54:31,604:INFO:Defining folds
2023-07-03 09:54:31,604:INFO:Declaring metric variables
2023-07-03 09:54:31,607:INFO:Importing untrained model
2023-07-03 09:54:31,610:INFO:Lasso Regression Imported successfully
2023-07-03 09:54:31,615:INFO:Starting cross validation
2023-07-03 09:54:31,616:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:54:33,836:INFO:Calculating mean and std
2023-07-03 09:54:33,838:INFO:Creating metrics dataframe
2023-07-03 09:54:34,165:INFO:Uploading results into container
2023-07-03 09:54:34,166:INFO:Uploading model into container now
2023-07-03 09:54:34,167:INFO:_master_model_container: 2
2023-07-03 09:54:34,167:INFO:_display_container: 2
2023-07-03 09:54:34,167:INFO:Lasso(random_state=123)
2023-07-03 09:54:34,167:INFO:create_model() successfully completed......................................
2023-07-03 09:54:34,307:INFO:SubProcess create_model() end ==================================
2023-07-03 09:54:34,308:INFO:Creating metrics dataframe
2023-07-03 09:54:34,315:INFO:Initializing Ridge Regression
2023-07-03 09:54:34,315:INFO:Total runtime is 0.16746119260787962 minutes
2023-07-03 09:54:34,318:INFO:SubProcess create_model() called ==================================
2023-07-03 09:54:34,319:INFO:Initializing create_model()
2023-07-03 09:54:34,319:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000234B3F52F80>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000234BB1F52A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:54:34,319:INFO:Checking exceptions
2023-07-03 09:54:34,319:INFO:Importing libraries
2023-07-03 09:54:34,319:INFO:Copying training dataset
2023-07-03 09:54:34,322:INFO:Defining folds
2023-07-03 09:54:34,322:INFO:Declaring metric variables
2023-07-03 09:54:34,325:INFO:Importing untrained model
2023-07-03 09:54:34,328:INFO:Ridge Regression Imported successfully
2023-07-03 09:54:34,336:INFO:Starting cross validation
2023-07-03 09:54:34,337:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:54:36,320:INFO:Calculating mean and std
2023-07-03 09:54:36,322:INFO:Creating metrics dataframe
2023-07-03 09:54:36,649:INFO:Uploading results into container
2023-07-03 09:54:36,650:INFO:Uploading model into container now
2023-07-03 09:54:36,650:INFO:_master_model_container: 3
2023-07-03 09:54:36,650:INFO:_display_container: 2
2023-07-03 09:54:36,651:INFO:Ridge(random_state=123)
2023-07-03 09:54:36,651:INFO:create_model() successfully completed......................................
2023-07-03 09:54:36,792:INFO:SubProcess create_model() end ==================================
2023-07-03 09:54:36,792:INFO:Creating metrics dataframe
2023-07-03 09:54:36,800:INFO:Initializing Elastic Net
2023-07-03 09:54:36,800:INFO:Total runtime is 0.20887528260548907 minutes
2023-07-03 09:54:36,803:INFO:SubProcess create_model() called ==================================
2023-07-03 09:54:36,803:INFO:Initializing create_model()
2023-07-03 09:54:36,803:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000234B3F52F80>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000234BB1F52A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:54:36,803:INFO:Checking exceptions
2023-07-03 09:54:36,803:INFO:Importing libraries
2023-07-03 09:54:36,803:INFO:Copying training dataset
2023-07-03 09:54:36,806:INFO:Defining folds
2023-07-03 09:54:36,806:INFO:Declaring metric variables
2023-07-03 09:54:36,810:INFO:Importing untrained model
2023-07-03 09:54:36,812:INFO:Elastic Net Imported successfully
2023-07-03 09:54:36,819:INFO:Starting cross validation
2023-07-03 09:54:36,820:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:54:38,824:INFO:Calculating mean and std
2023-07-03 09:54:38,825:INFO:Creating metrics dataframe
2023-07-03 09:54:39,153:INFO:Uploading results into container
2023-07-03 09:54:39,154:INFO:Uploading model into container now
2023-07-03 09:54:39,155:INFO:_master_model_container: 4
2023-07-03 09:54:39,155:INFO:_display_container: 2
2023-07-03 09:54:39,155:INFO:ElasticNet(random_state=123)
2023-07-03 09:54:39,155:INFO:create_model() successfully completed......................................
2023-07-03 09:54:39,297:INFO:SubProcess create_model() end ==================================
2023-07-03 09:54:39,298:INFO:Creating metrics dataframe
2023-07-03 09:54:39,308:INFO:Initializing Least Angle Regression
2023-07-03 09:54:39,308:INFO:Total runtime is 0.2506647944450378 minutes
2023-07-03 09:54:39,311:INFO:SubProcess create_model() called ==================================
2023-07-03 09:54:39,311:INFO:Initializing create_model()
2023-07-03 09:54:39,311:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000234B3F52F80>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000234BB1F52A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:54:39,311:INFO:Checking exceptions
2023-07-03 09:54:39,312:INFO:Importing libraries
2023-07-03 09:54:39,312:INFO:Copying training dataset
2023-07-03 09:54:39,314:INFO:Defining folds
2023-07-03 09:54:39,315:INFO:Declaring metric variables
2023-07-03 09:54:39,317:INFO:Importing untrained model
2023-07-03 09:54:39,320:INFO:Least Angle Regression Imported successfully
2023-07-03 09:54:39,326:INFO:Starting cross validation
2023-07-03 09:54:39,327:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:54:41,364:INFO:Calculating mean and std
2023-07-03 09:54:41,365:INFO:Creating metrics dataframe
2023-07-03 09:54:41,696:INFO:Uploading results into container
2023-07-03 09:54:41,696:INFO:Uploading model into container now
2023-07-03 09:54:41,697:INFO:_master_model_container: 5
2023-07-03 09:54:41,697:INFO:_display_container: 2
2023-07-03 09:54:41,697:INFO:Lars(random_state=123)
2023-07-03 09:54:41,698:INFO:create_model() successfully completed......................................
2023-07-03 09:54:41,842:INFO:SubProcess create_model() end ==================================
2023-07-03 09:54:41,842:INFO:Creating metrics dataframe
2023-07-03 09:54:41,850:INFO:Initializing Lasso Least Angle Regression
2023-07-03 09:54:41,851:INFO:Total runtime is 0.29305479526519773 minutes
2023-07-03 09:54:41,853:INFO:SubProcess create_model() called ==================================
2023-07-03 09:54:41,854:INFO:Initializing create_model()
2023-07-03 09:54:41,854:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000234B3F52F80>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000234BB1F52A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:54:41,854:INFO:Checking exceptions
2023-07-03 09:54:41,854:INFO:Importing libraries
2023-07-03 09:54:41,854:INFO:Copying training dataset
2023-07-03 09:54:41,857:INFO:Defining folds
2023-07-03 09:54:41,857:INFO:Declaring metric variables
2023-07-03 09:54:41,860:INFO:Importing untrained model
2023-07-03 09:54:41,863:INFO:Lasso Least Angle Regression Imported successfully
2023-07-03 09:54:41,869:INFO:Starting cross validation
2023-07-03 09:54:41,870:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:54:43,868:INFO:Calculating mean and std
2023-07-03 09:54:43,869:INFO:Creating metrics dataframe
2023-07-03 09:54:44,192:INFO:Uploading results into container
2023-07-03 09:54:44,193:INFO:Uploading model into container now
2023-07-03 09:54:44,193:INFO:_master_model_container: 6
2023-07-03 09:54:44,193:INFO:_display_container: 2
2023-07-03 09:54:44,194:INFO:LassoLars(random_state=123)
2023-07-03 09:54:44,194:INFO:create_model() successfully completed......................................
2023-07-03 09:54:44,337:INFO:SubProcess create_model() end ==================================
2023-07-03 09:54:44,337:INFO:Creating metrics dataframe
2023-07-03 09:54:44,345:INFO:Initializing Orthogonal Matching Pursuit
2023-07-03 09:54:44,345:INFO:Total runtime is 0.3346219062805176 minutes
2023-07-03 09:54:44,348:INFO:SubProcess create_model() called ==================================
2023-07-03 09:54:44,348:INFO:Initializing create_model()
2023-07-03 09:54:44,348:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000234B3F52F80>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000234BB1F52A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:54:44,348:INFO:Checking exceptions
2023-07-03 09:54:44,348:INFO:Importing libraries
2023-07-03 09:54:44,348:INFO:Copying training dataset
2023-07-03 09:54:44,351:INFO:Defining folds
2023-07-03 09:54:44,351:INFO:Declaring metric variables
2023-07-03 09:54:44,354:INFO:Importing untrained model
2023-07-03 09:54:44,357:INFO:Orthogonal Matching Pursuit Imported successfully
2023-07-03 09:54:44,363:INFO:Starting cross validation
2023-07-03 09:54:44,363:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:54:46,360:INFO:Calculating mean and std
2023-07-03 09:54:46,362:INFO:Creating metrics dataframe
2023-07-03 09:54:46,693:INFO:Uploading results into container
2023-07-03 09:54:46,694:INFO:Uploading model into container now
2023-07-03 09:54:46,694:INFO:_master_model_container: 7
2023-07-03 09:54:46,694:INFO:_display_container: 2
2023-07-03 09:54:46,694:INFO:OrthogonalMatchingPursuit()
2023-07-03 09:54:46,694:INFO:create_model() successfully completed......................................
2023-07-03 09:54:46,839:INFO:SubProcess create_model() end ==================================
2023-07-03 09:54:46,839:INFO:Creating metrics dataframe
2023-07-03 09:54:46,849:INFO:Initializing Bayesian Ridge
2023-07-03 09:54:46,849:INFO:Total runtime is 0.37635488112767534 minutes
2023-07-03 09:54:46,852:INFO:SubProcess create_model() called ==================================
2023-07-03 09:54:46,852:INFO:Initializing create_model()
2023-07-03 09:54:46,852:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000234B3F52F80>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000234BB1F52A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:54:46,852:INFO:Checking exceptions
2023-07-03 09:54:46,852:INFO:Importing libraries
2023-07-03 09:54:46,852:INFO:Copying training dataset
2023-07-03 09:54:46,855:INFO:Defining folds
2023-07-03 09:54:46,855:INFO:Declaring metric variables
2023-07-03 09:54:46,858:INFO:Importing untrained model
2023-07-03 09:54:46,861:INFO:Bayesian Ridge Imported successfully
2023-07-03 09:54:46,866:INFO:Starting cross validation
2023-07-03 09:54:46,867:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:54:48,912:INFO:Calculating mean and std
2023-07-03 09:54:48,913:INFO:Creating metrics dataframe
2023-07-03 09:54:49,247:INFO:Uploading results into container
2023-07-03 09:54:49,248:INFO:Uploading model into container now
2023-07-03 09:54:49,249:INFO:_master_model_container: 8
2023-07-03 09:54:49,249:INFO:_display_container: 2
2023-07-03 09:54:49,249:INFO:BayesianRidge()
2023-07-03 09:54:49,249:INFO:create_model() successfully completed......................................
2023-07-03 09:54:49,392:INFO:SubProcess create_model() end ==================================
2023-07-03 09:54:49,392:INFO:Creating metrics dataframe
2023-07-03 09:54:49,401:INFO:Initializing Passive Aggressive Regressor
2023-07-03 09:54:49,401:INFO:Total runtime is 0.4188882191975911 minutes
2023-07-03 09:54:49,404:INFO:SubProcess create_model() called ==================================
2023-07-03 09:54:49,404:INFO:Initializing create_model()
2023-07-03 09:54:49,405:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000234B3F52F80>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000234BB1F52A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:54:49,405:INFO:Checking exceptions
2023-07-03 09:54:49,405:INFO:Importing libraries
2023-07-03 09:54:49,405:INFO:Copying training dataset
2023-07-03 09:54:49,408:INFO:Defining folds
2023-07-03 09:54:49,408:INFO:Declaring metric variables
2023-07-03 09:54:49,411:INFO:Importing untrained model
2023-07-03 09:54:49,414:INFO:Passive Aggressive Regressor Imported successfully
2023-07-03 09:54:49,419:INFO:Starting cross validation
2023-07-03 09:54:49,419:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:54:51,425:INFO:Calculating mean and std
2023-07-03 09:54:51,426:INFO:Creating metrics dataframe
2023-07-03 09:54:51,757:INFO:Uploading results into container
2023-07-03 09:54:51,758:INFO:Uploading model into container now
2023-07-03 09:54:51,758:INFO:_master_model_container: 9
2023-07-03 09:54:51,758:INFO:_display_container: 2
2023-07-03 09:54:51,759:INFO:PassiveAggressiveRegressor(random_state=123)
2023-07-03 09:54:51,759:INFO:create_model() successfully completed......................................
2023-07-03 09:54:51,900:INFO:SubProcess create_model() end ==================================
2023-07-03 09:54:51,900:INFO:Creating metrics dataframe
2023-07-03 09:54:51,909:INFO:Initializing Huber Regressor
2023-07-03 09:54:51,909:INFO:Total runtime is 0.46068752606709795 minutes
2023-07-03 09:54:51,912:INFO:SubProcess create_model() called ==================================
2023-07-03 09:54:51,913:INFO:Initializing create_model()
2023-07-03 09:54:51,913:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000234B3F52F80>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000234BB1F52A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:54:51,913:INFO:Checking exceptions
2023-07-03 09:54:51,913:INFO:Importing libraries
2023-07-03 09:54:51,913:INFO:Copying training dataset
2023-07-03 09:54:51,916:INFO:Defining folds
2023-07-03 09:54:51,916:INFO:Declaring metric variables
2023-07-03 09:54:51,919:INFO:Importing untrained model
2023-07-03 09:54:51,922:INFO:Huber Regressor Imported successfully
2023-07-03 09:54:51,927:INFO:Starting cross validation
2023-07-03 09:54:51,928:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:54:53,958:INFO:Calculating mean and std
2023-07-03 09:54:53,959:INFO:Creating metrics dataframe
2023-07-03 09:54:54,284:INFO:Uploading results into container
2023-07-03 09:54:54,285:INFO:Uploading model into container now
2023-07-03 09:54:54,285:INFO:_master_model_container: 10
2023-07-03 09:54:54,285:INFO:_display_container: 2
2023-07-03 09:54:54,285:INFO:HuberRegressor()
2023-07-03 09:54:54,285:INFO:create_model() successfully completed......................................
2023-07-03 09:54:54,430:INFO:SubProcess create_model() end ==================================
2023-07-03 09:54:54,430:INFO:Creating metrics dataframe
2023-07-03 09:54:54,440:INFO:Initializing K Neighbors Regressor
2023-07-03 09:54:54,440:INFO:Total runtime is 0.5028651396433512 minutes
2023-07-03 09:54:54,443:INFO:SubProcess create_model() called ==================================
2023-07-03 09:54:54,443:INFO:Initializing create_model()
2023-07-03 09:54:54,444:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000234B3F52F80>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000234BB1F52A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:54:54,444:INFO:Checking exceptions
2023-07-03 09:54:54,444:INFO:Importing libraries
2023-07-03 09:54:54,444:INFO:Copying training dataset
2023-07-03 09:54:54,447:INFO:Defining folds
2023-07-03 09:54:54,447:INFO:Declaring metric variables
2023-07-03 09:54:54,450:INFO:Importing untrained model
2023-07-03 09:54:54,453:INFO:K Neighbors Regressor Imported successfully
2023-07-03 09:54:54,458:INFO:Starting cross validation
2023-07-03 09:54:54,459:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:54:56,470:INFO:Calculating mean and std
2023-07-03 09:54:56,471:INFO:Creating metrics dataframe
2023-07-03 09:54:56,790:INFO:Uploading results into container
2023-07-03 09:54:56,790:INFO:Uploading model into container now
2023-07-03 09:54:56,791:INFO:_master_model_container: 11
2023-07-03 09:54:56,791:INFO:_display_container: 2
2023-07-03 09:54:56,791:INFO:KNeighborsRegressor(n_jobs=-1)
2023-07-03 09:54:56,791:INFO:create_model() successfully completed......................................
2023-07-03 09:54:56,933:INFO:SubProcess create_model() end ==================================
2023-07-03 09:54:56,934:INFO:Creating metrics dataframe
2023-07-03 09:54:56,944:INFO:Initializing Decision Tree Regressor
2023-07-03 09:54:56,944:INFO:Total runtime is 0.5446084459622701 minutes
2023-07-03 09:54:56,947:INFO:SubProcess create_model() called ==================================
2023-07-03 09:54:56,947:INFO:Initializing create_model()
2023-07-03 09:54:56,947:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000234B3F52F80>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000234BB1F52A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:54:56,947:INFO:Checking exceptions
2023-07-03 09:54:56,947:INFO:Importing libraries
2023-07-03 09:54:56,948:INFO:Copying training dataset
2023-07-03 09:54:56,951:INFO:Defining folds
2023-07-03 09:54:56,951:INFO:Declaring metric variables
2023-07-03 09:54:56,955:INFO:Importing untrained model
2023-07-03 09:54:56,957:INFO:Decision Tree Regressor Imported successfully
2023-07-03 09:54:56,963:INFO:Starting cross validation
2023-07-03 09:54:56,964:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:54:58,973:INFO:Calculating mean and std
2023-07-03 09:54:58,974:INFO:Creating metrics dataframe
2023-07-03 09:54:59,300:INFO:Uploading results into container
2023-07-03 09:54:59,301:INFO:Uploading model into container now
2023-07-03 09:54:59,301:INFO:_master_model_container: 12
2023-07-03 09:54:59,301:INFO:_display_container: 2
2023-07-03 09:54:59,301:INFO:DecisionTreeRegressor(random_state=123)
2023-07-03 09:54:59,302:INFO:create_model() successfully completed......................................
2023-07-03 09:54:59,443:INFO:SubProcess create_model() end ==================================
2023-07-03 09:54:59,443:INFO:Creating metrics dataframe
2023-07-03 09:54:59,453:INFO:Initializing Random Forest Regressor
2023-07-03 09:54:59,453:INFO:Total runtime is 0.5864280740420024 minutes
2023-07-03 09:54:59,456:INFO:SubProcess create_model() called ==================================
2023-07-03 09:54:59,457:INFO:Initializing create_model()
2023-07-03 09:54:59,457:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000234B3F52F80>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000234BB1F52A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:54:59,457:INFO:Checking exceptions
2023-07-03 09:54:59,457:INFO:Importing libraries
2023-07-03 09:54:59,457:INFO:Copying training dataset
2023-07-03 09:54:59,460:INFO:Defining folds
2023-07-03 09:54:59,460:INFO:Declaring metric variables
2023-07-03 09:54:59,463:INFO:Importing untrained model
2023-07-03 09:54:59,466:INFO:Random Forest Regressor Imported successfully
2023-07-03 09:54:59,471:INFO:Starting cross validation
2023-07-03 09:54:59,472:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:55:01,556:INFO:Calculating mean and std
2023-07-03 09:55:01,557:INFO:Creating metrics dataframe
2023-07-03 09:55:01,886:INFO:Uploading results into container
2023-07-03 09:55:01,886:INFO:Uploading model into container now
2023-07-03 09:55:01,887:INFO:_master_model_container: 13
2023-07-03 09:55:01,887:INFO:_display_container: 2
2023-07-03 09:55:01,887:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-07-03 09:55:01,887:INFO:create_model() successfully completed......................................
2023-07-03 09:55:02,029:INFO:SubProcess create_model() end ==================================
2023-07-03 09:55:02,029:INFO:Creating metrics dataframe
2023-07-03 09:55:02,040:INFO:Initializing Extra Trees Regressor
2023-07-03 09:55:02,040:INFO:Total runtime is 0.6295387983322144 minutes
2023-07-03 09:55:02,043:INFO:SubProcess create_model() called ==================================
2023-07-03 09:55:02,043:INFO:Initializing create_model()
2023-07-03 09:55:02,043:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000234B3F52F80>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000234BB1F52A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:55:02,043:INFO:Checking exceptions
2023-07-03 09:55:02,043:INFO:Importing libraries
2023-07-03 09:55:02,043:INFO:Copying training dataset
2023-07-03 09:55:02,046:INFO:Defining folds
2023-07-03 09:55:02,046:INFO:Declaring metric variables
2023-07-03 09:55:02,049:INFO:Importing untrained model
2023-07-03 09:55:02,052:INFO:Extra Trees Regressor Imported successfully
2023-07-03 09:55:02,057:INFO:Starting cross validation
2023-07-03 09:55:02,058:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:55:04,172:INFO:Calculating mean and std
2023-07-03 09:55:04,174:INFO:Creating metrics dataframe
2023-07-03 09:55:04,499:INFO:Uploading results into container
2023-07-03 09:55:04,499:INFO:Uploading model into container now
2023-07-03 09:55:04,500:INFO:_master_model_container: 14
2023-07-03 09:55:04,500:INFO:_display_container: 2
2023-07-03 09:55:04,500:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-07-03 09:55:04,500:INFO:create_model() successfully completed......................................
2023-07-03 09:55:04,642:INFO:SubProcess create_model() end ==================================
2023-07-03 09:55:04,642:INFO:Creating metrics dataframe
2023-07-03 09:55:04,653:INFO:Initializing AdaBoost Regressor
2023-07-03 09:55:04,653:INFO:Total runtime is 0.6730933268864949 minutes
2023-07-03 09:55:04,656:INFO:SubProcess create_model() called ==================================
2023-07-03 09:55:04,656:INFO:Initializing create_model()
2023-07-03 09:55:04,656:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000234B3F52F80>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000234BB1F52A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:55:04,657:INFO:Checking exceptions
2023-07-03 09:55:04,657:INFO:Importing libraries
2023-07-03 09:55:04,657:INFO:Copying training dataset
2023-07-03 09:55:04,660:INFO:Defining folds
2023-07-03 09:55:04,660:INFO:Declaring metric variables
2023-07-03 09:55:04,663:INFO:Importing untrained model
2023-07-03 09:55:04,665:INFO:AdaBoost Regressor Imported successfully
2023-07-03 09:55:04,670:INFO:Starting cross validation
2023-07-03 09:55:04,671:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:55:06,741:INFO:Calculating mean and std
2023-07-03 09:55:06,742:INFO:Creating metrics dataframe
2023-07-03 09:55:07,063:INFO:Uploading results into container
2023-07-03 09:55:07,064:INFO:Uploading model into container now
2023-07-03 09:55:07,065:INFO:_master_model_container: 15
2023-07-03 09:55:07,065:INFO:_display_container: 2
2023-07-03 09:55:07,065:INFO:AdaBoostRegressor(random_state=123)
2023-07-03 09:55:07,065:INFO:create_model() successfully completed......................................
2023-07-03 09:55:07,206:INFO:SubProcess create_model() end ==================================
2023-07-03 09:55:07,207:INFO:Creating metrics dataframe
2023-07-03 09:55:07,221:INFO:Initializing Gradient Boosting Regressor
2023-07-03 09:55:07,222:INFO:Total runtime is 0.7159084200859069 minutes
2023-07-03 09:55:07,226:INFO:SubProcess create_model() called ==================================
2023-07-03 09:55:07,227:INFO:Initializing create_model()
2023-07-03 09:55:07,227:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000234B3F52F80>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000234BB1F52A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:55:07,227:INFO:Checking exceptions
2023-07-03 09:55:07,227:INFO:Importing libraries
2023-07-03 09:55:07,227:INFO:Copying training dataset
2023-07-03 09:55:07,232:INFO:Defining folds
2023-07-03 09:55:07,232:INFO:Declaring metric variables
2023-07-03 09:55:07,235:INFO:Importing untrained model
2023-07-03 09:55:07,240:INFO:Gradient Boosting Regressor Imported successfully
2023-07-03 09:55:07,248:INFO:Starting cross validation
2023-07-03 09:55:07,249:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:55:09,320:INFO:Calculating mean and std
2023-07-03 09:55:09,321:INFO:Creating metrics dataframe
2023-07-03 09:55:09,646:INFO:Uploading results into container
2023-07-03 09:55:09,646:INFO:Uploading model into container now
2023-07-03 09:55:09,647:INFO:_master_model_container: 16
2023-07-03 09:55:09,647:INFO:_display_container: 2
2023-07-03 09:55:09,647:INFO:GradientBoostingRegressor(random_state=123)
2023-07-03 09:55:09,647:INFO:create_model() successfully completed......................................
2023-07-03 09:55:09,790:INFO:SubProcess create_model() end ==================================
2023-07-03 09:55:09,790:INFO:Creating metrics dataframe
2023-07-03 09:55:09,802:INFO:Initializing Light Gradient Boosting Machine
2023-07-03 09:55:09,802:INFO:Total runtime is 0.7588999390602111 minutes
2023-07-03 09:55:09,804:INFO:SubProcess create_model() called ==================================
2023-07-03 09:55:09,805:INFO:Initializing create_model()
2023-07-03 09:55:09,805:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000234B3F52F80>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000234BB1F52A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:55:09,805:INFO:Checking exceptions
2023-07-03 09:55:09,805:INFO:Importing libraries
2023-07-03 09:55:09,805:INFO:Copying training dataset
2023-07-03 09:55:09,808:INFO:Defining folds
2023-07-03 09:55:09,808:INFO:Declaring metric variables
2023-07-03 09:55:09,811:INFO:Importing untrained model
2023-07-03 09:55:09,814:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-03 09:55:09,819:INFO:Starting cross validation
2023-07-03 09:55:09,820:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:55:12,824:INFO:Calculating mean and std
2023-07-03 09:55:12,825:INFO:Creating metrics dataframe
2023-07-03 09:55:13,156:INFO:Uploading results into container
2023-07-03 09:55:13,157:INFO:Uploading model into container now
2023-07-03 09:55:13,157:INFO:_master_model_container: 17
2023-07-03 09:55:13,157:INFO:_display_container: 2
2023-07-03 09:55:13,158:INFO:LGBMRegressor(random_state=123)
2023-07-03 09:55:13,158:INFO:create_model() successfully completed......................................
2023-07-03 09:55:13,300:INFO:SubProcess create_model() end ==================================
2023-07-03 09:55:13,300:INFO:Creating metrics dataframe
2023-07-03 09:55:13,311:INFO:Initializing Dummy Regressor
2023-07-03 09:55:13,311:INFO:Total runtime is 0.8173860549926757 minutes
2023-07-03 09:55:13,314:INFO:SubProcess create_model() called ==================================
2023-07-03 09:55:13,315:INFO:Initializing create_model()
2023-07-03 09:55:13,315:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000234B3F52F80>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000234BB1F52A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:55:13,315:INFO:Checking exceptions
2023-07-03 09:55:13,315:INFO:Importing libraries
2023-07-03 09:55:13,315:INFO:Copying training dataset
2023-07-03 09:55:13,318:INFO:Defining folds
2023-07-03 09:55:13,318:INFO:Declaring metric variables
2023-07-03 09:55:13,321:INFO:Importing untrained model
2023-07-03 09:55:13,324:INFO:Dummy Regressor Imported successfully
2023-07-03 09:55:13,329:INFO:Starting cross validation
2023-07-03 09:55:13,330:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:55:15,318:INFO:Calculating mean and std
2023-07-03 09:55:15,319:INFO:Creating metrics dataframe
2023-07-03 09:55:15,645:INFO:Uploading results into container
2023-07-03 09:55:15,646:INFO:Uploading model into container now
2023-07-03 09:55:15,646:INFO:_master_model_container: 18
2023-07-03 09:55:15,646:INFO:_display_container: 2
2023-07-03 09:55:15,647:INFO:DummyRegressor()
2023-07-03 09:55:15,647:INFO:create_model() successfully completed......................................
2023-07-03 09:55:15,789:INFO:SubProcess create_model() end ==================================
2023-07-03 09:55:15,789:INFO:Creating metrics dataframe
2023-07-03 09:55:15,808:INFO:Initializing create_model()
2023-07-03 09:55:15,808:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000234B3F52F80>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:55:15,808:INFO:Checking exceptions
2023-07-03 09:55:15,809:INFO:Importing libraries
2023-07-03 09:55:15,809:INFO:Copying training dataset
2023-07-03 09:55:15,811:INFO:Defining folds
2023-07-03 09:55:15,812:INFO:Declaring metric variables
2023-07-03 09:55:15,812:INFO:Importing untrained model
2023-07-03 09:55:15,812:INFO:Declaring custom model
2023-07-03 09:55:15,812:INFO:Extra Trees Regressor Imported successfully
2023-07-03 09:55:15,813:INFO:Cross validation set to False
2023-07-03 09:55:15,813:INFO:Fitting Model
2023-07-03 09:55:16,111:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-07-03 09:55:16,111:INFO:create_model() successfully completed......................................
2023-07-03 09:55:16,278:INFO:_master_model_container: 18
2023-07-03 09:55:16,278:INFO:_display_container: 2
2023-07-03 09:55:16,278:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-07-03 09:55:16,278:INFO:compare_models() successfully completed......................................
2023-07-03 09:55:16,298:INFO:Initializing create_model()
2023-07-03 09:55:16,298:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000234B3F52F80>, estimator=et, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:55:16,298:INFO:Checking exceptions
2023-07-03 09:55:16,312:INFO:Importing libraries
2023-07-03 09:55:16,312:INFO:Copying training dataset
2023-07-03 09:55:16,314:INFO:Defining folds
2023-07-03 09:55:16,315:INFO:Declaring metric variables
2023-07-03 09:55:16,317:INFO:Importing untrained model
2023-07-03 09:55:16,320:INFO:Extra Trees Regressor Imported successfully
2023-07-03 09:55:16,325:INFO:Starting cross validation
2023-07-03 09:55:16,326:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:55:18,422:INFO:Calculating mean and std
2023-07-03 09:55:18,423:INFO:Creating metrics dataframe
2023-07-03 09:55:18,428:INFO:Finalizing model
2023-07-03 09:55:18,845:INFO:Uploading results into container
2023-07-03 09:55:18,846:INFO:Uploading model into container now
2023-07-03 09:55:18,853:INFO:_master_model_container: 19
2023-07-03 09:55:18,854:INFO:_display_container: 3
2023-07-03 09:55:18,854:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-07-03 09:55:18,854:INFO:create_model() successfully completed......................................
2023-07-03 09:55:19,022:INFO:Initializing tune_model()
2023-07-03 09:55:19,022:INFO:tune_model(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=50, custom_grid=None, optimize=mae, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000234B3F52F80>)
2023-07-03 09:55:19,023:INFO:Checking exceptions
2023-07-03 09:55:19,036:INFO:Copying training dataset
2023-07-03 09:55:19,039:INFO:Checking base model
2023-07-03 09:55:19,039:INFO:Base model : Extra Trees Regressor
2023-07-03 09:55:19,042:INFO:Declaring metric variables
2023-07-03 09:55:19,045:INFO:Defining Hyperparameters
2023-07-03 09:55:19,187:INFO:Tuning with n_jobs=-1
2023-07-03 09:55:19,187:INFO:Initializing RandomizedSearchCV
2023-07-03 09:57:28,914:INFO:best_params: {'actual_estimator__n_estimators': 180, 'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 3, 'actual_estimator__min_impurity_decrease': 0.005, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 8, 'actual_estimator__criterion': 'absolute_error', 'actual_estimator__bootstrap': False}
2023-07-03 09:57:28,915:INFO:Hyperparameter search completed
2023-07-03 09:57:28,915:INFO:SubProcess create_model() called ==================================
2023-07-03 09:57:28,916:INFO:Initializing create_model()
2023-07-03 09:57:28,916:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000234B3F52F80>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000234AD240670>, model_only=True, return_train_score=False, kwargs={'n_estimators': 180, 'min_samples_split': 7, 'min_samples_leaf': 3, 'min_impurity_decrease': 0.005, 'max_features': 1.0, 'max_depth': 8, 'criterion': 'absolute_error', 'bootstrap': False})
2023-07-03 09:57:28,916:INFO:Checking exceptions
2023-07-03 09:57:28,916:INFO:Importing libraries
2023-07-03 09:57:28,916:INFO:Copying training dataset
2023-07-03 09:57:28,920:INFO:Defining folds
2023-07-03 09:57:28,920:INFO:Declaring metric variables
2023-07-03 09:57:28,923:INFO:Importing untrained model
2023-07-03 09:57:28,923:INFO:Declaring custom model
2023-07-03 09:57:28,927:INFO:Extra Trees Regressor Imported successfully
2023-07-03 09:57:28,933:INFO:Starting cross validation
2023-07-03 09:57:28,934:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:57:31,359:INFO:Calculating mean and std
2023-07-03 09:57:31,361:INFO:Creating metrics dataframe
2023-07-03 09:57:31,366:INFO:Finalizing model
2023-07-03 09:57:31,886:INFO:Uploading results into container
2023-07-03 09:57:31,887:INFO:Uploading model into container now
2023-07-03 09:57:31,888:INFO:_master_model_container: 20
2023-07-03 09:57:31,888:INFO:_display_container: 4
2023-07-03 09:57:31,889:INFO:ExtraTreesRegressor(criterion='absolute_error', max_depth=8,
                    min_impurity_decrease=0.005, min_samples_leaf=3,
                    min_samples_split=7, n_estimators=180, n_jobs=-1,
                    random_state=123)
2023-07-03 09:57:31,889:INFO:create_model() successfully completed......................................
2023-07-03 09:57:32,036:INFO:SubProcess create_model() end ==================================
2023-07-03 09:57:32,036:INFO:choose_better activated
2023-07-03 09:57:32,039:INFO:SubProcess create_model() called ==================================
2023-07-03 09:57:32,040:INFO:Initializing create_model()
2023-07-03 09:57:32,040:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000234B3F52F80>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:57:32,040:INFO:Checking exceptions
2023-07-03 09:57:32,042:INFO:Importing libraries
2023-07-03 09:57:32,042:INFO:Copying training dataset
2023-07-03 09:57:32,044:INFO:Defining folds
2023-07-03 09:57:32,044:INFO:Declaring metric variables
2023-07-03 09:57:32,045:INFO:Importing untrained model
2023-07-03 09:57:32,045:INFO:Declaring custom model
2023-07-03 09:57:32,045:INFO:Extra Trees Regressor Imported successfully
2023-07-03 09:57:32,045:INFO:Starting cross validation
2023-07-03 09:57:32,046:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:57:34,353:INFO:Calculating mean and std
2023-07-03 09:57:34,354:INFO:Creating metrics dataframe
2023-07-03 09:57:34,357:INFO:Finalizing model
2023-07-03 09:57:35,030:INFO:Uploading results into container
2023-07-03 09:57:35,031:INFO:Uploading model into container now
2023-07-03 09:57:35,031:INFO:_master_model_container: 21
2023-07-03 09:57:35,031:INFO:_display_container: 5
2023-07-03 09:57:35,031:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-07-03 09:57:35,031:INFO:create_model() successfully completed......................................
2023-07-03 09:57:35,177:INFO:SubProcess create_model() end ==================================
2023-07-03 09:57:35,178:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) result for MAE is 0.5937
2023-07-03 09:57:35,179:INFO:ExtraTreesRegressor(criterion='absolute_error', max_depth=8,
                    min_impurity_decrease=0.005, min_samples_leaf=3,
                    min_samples_split=7, n_estimators=180, n_jobs=-1,
                    random_state=123) result for MAE is 0.7323
2023-07-03 09:57:35,179:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) is best model
2023-07-03 09:57:35,179:INFO:choose_better completed
2023-07-03 09:57:35,179:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-07-03 09:57:35,188:INFO:_master_model_container: 21
2023-07-03 09:57:35,188:INFO:_display_container: 4
2023-07-03 09:57:35,188:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-07-03 09:57:35,189:INFO:tune_model() successfully completed......................................
2023-07-03 09:57:35,583:INFO:Initializing tune_model()
2023-07-03 09:57:35,583:INFO:tune_model(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=True, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000234B3F52F80>)
2023-07-03 09:57:35,583:INFO:Checking exceptions
2023-07-03 09:57:35,598:INFO:Copying training dataset
2023-07-03 09:57:35,600:INFO:Checking base model
2023-07-03 09:57:35,600:INFO:Base model : Extra Trees Regressor
2023-07-03 09:57:35,604:INFO:Declaring metric variables
2023-07-03 09:57:35,607:INFO:Defining Hyperparameters
2023-07-03 09:57:35,766:INFO:Tuning with n_jobs=-1
2023-07-03 09:57:35,766:INFO:Initializing RandomizedSearchCV
2023-07-03 09:58:02,749:INFO:best_params: {'actual_estimator__n_estimators': 100, 'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.1, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'squared_error', 'actual_estimator__bootstrap': True}
2023-07-03 09:58:02,751:INFO:Hyperparameter search completed
2023-07-03 09:58:02,751:INFO:SubProcess create_model() called ==================================
2023-07-03 09:58:02,752:INFO:Initializing create_model()
2023-07-03 09:58:02,752:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000234B3F52F80>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000234B4626830>, model_only=True, return_train_score=False, kwargs={'n_estimators': 100, 'min_samples_split': 7, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.1, 'max_features': 1.0, 'max_depth': 9, 'criterion': 'squared_error', 'bootstrap': True})
2023-07-03 09:58:02,752:INFO:Checking exceptions
2023-07-03 09:58:02,752:INFO:Importing libraries
2023-07-03 09:58:02,752:INFO:Copying training dataset
2023-07-03 09:58:02,756:INFO:Defining folds
2023-07-03 09:58:02,756:INFO:Declaring metric variables
2023-07-03 09:58:02,758:INFO:Importing untrained model
2023-07-03 09:58:02,759:INFO:Declaring custom model
2023-07-03 09:58:02,762:INFO:Extra Trees Regressor Imported successfully
2023-07-03 09:58:02,767:INFO:Starting cross validation
2023-07-03 09:58:02,768:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:58:04,982:INFO:Calculating mean and std
2023-07-03 09:58:04,983:INFO:Creating metrics dataframe
2023-07-03 09:58:04,988:INFO:Finalizing model
2023-07-03 09:58:05,484:INFO:Uploading results into container
2023-07-03 09:58:05,485:INFO:Uploading model into container now
2023-07-03 09:58:05,485:INFO:_master_model_container: 22
2023-07-03 09:58:05,485:INFO:_display_container: 5
2023-07-03 09:58:05,486:INFO:ExtraTreesRegressor(bootstrap=True, max_depth=9, min_impurity_decrease=0.1,
                    min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                    random_state=123)
2023-07-03 09:58:05,486:INFO:create_model() successfully completed......................................
2023-07-03 09:58:05,628:INFO:SubProcess create_model() end ==================================
2023-07-03 09:58:05,628:INFO:choose_better activated
2023-07-03 09:58:05,631:INFO:SubProcess create_model() called ==================================
2023-07-03 09:58:05,632:INFO:Initializing create_model()
2023-07-03 09:58:05,632:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000234B3F52F80>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-03 09:58:05,632:INFO:Checking exceptions
2023-07-03 09:58:05,634:INFO:Importing libraries
2023-07-03 09:58:05,634:INFO:Copying training dataset
2023-07-03 09:58:05,636:INFO:Defining folds
2023-07-03 09:58:05,636:INFO:Declaring metric variables
2023-07-03 09:58:05,636:INFO:Importing untrained model
2023-07-03 09:58:05,636:INFO:Declaring custom model
2023-07-03 09:58:05,637:INFO:Extra Trees Regressor Imported successfully
2023-07-03 09:58:05,637:INFO:Starting cross validation
2023-07-03 09:58:05,637:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 09:58:07,859:INFO:Calculating mean and std
2023-07-03 09:58:07,859:INFO:Creating metrics dataframe
2023-07-03 09:58:07,861:INFO:Finalizing model
2023-07-03 09:58:08,361:INFO:Uploading results into container
2023-07-03 09:58:08,362:INFO:Uploading model into container now
2023-07-03 09:58:08,362:INFO:_master_model_container: 23
2023-07-03 09:58:08,362:INFO:_display_container: 6
2023-07-03 09:58:08,363:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-07-03 09:58:08,363:INFO:create_model() successfully completed......................................
2023-07-03 09:58:08,504:INFO:SubProcess create_model() end ==================================
2023-07-03 09:58:08,504:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) result for R2 is 0.739
2023-07-03 09:58:08,505:INFO:ExtraTreesRegressor(bootstrap=True, max_depth=9, min_impurity_decrease=0.1,
                    min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                    random_state=123) result for R2 is 0.6127
2023-07-03 09:58:08,505:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) is best model
2023-07-03 09:58:08,505:INFO:choose_better completed
2023-07-03 09:58:08,505:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-07-03 09:58:08,514:INFO:_master_model_container: 23
2023-07-03 09:58:08,515:INFO:_display_container: 5
2023-07-03 09:58:08,515:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-07-03 09:58:08,515:INFO:tune_model() successfully completed......................................
2023-07-03 09:58:08,737:INFO:Initializing plot_model()
2023-07-03 09:58:08,737:INFO:plot_model(plot=residuals, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000234B3F52F80>, system=True)
2023-07-03 09:58:08,737:INFO:Checking exceptions
2023-07-03 09:58:08,752:INFO:Preloading libraries
2023-07-03 09:58:08,759:INFO:Copying training dataset
2023-07-03 09:58:08,759:INFO:Plot type: residuals
2023-07-03 09:58:08,837:INFO:Fitting Model
2023-07-03 09:58:08,838:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\base.py:420: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2023-07-03 09:58:08,898:INFO:Scoring test/hold-out set
2023-07-03 09:58:09,299:INFO:Visual Rendered Successfully
2023-07-03 09:58:09,446:INFO:plot_model() successfully completed......................................
2023-07-03 09:58:09,465:INFO:Initializing plot_model()
2023-07-03 09:58:09,465:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000234B3F52F80>, system=True)
2023-07-03 09:58:09,465:INFO:Checking exceptions
2023-07-03 09:58:09,481:INFO:Preloading libraries
2023-07-03 09:58:09,488:INFO:Copying training dataset
2023-07-03 09:58:09,488:INFO:Plot type: error
2023-07-03 09:58:09,528:INFO:Fitting Model
2023-07-03 09:58:09,529:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\base.py:420: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2023-07-03 09:58:09,529:INFO:Scoring test/hold-out set
2023-07-03 09:58:09,793:INFO:Visual Rendered Successfully
2023-07-03 09:58:09,937:INFO:plot_model() successfully completed......................................
2023-07-03 09:58:09,943:INFO:Initializing plot_model()
2023-07-03 09:58:09,943:INFO:plot_model(plot=cooks, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000234B3F52F80>, system=True)
2023-07-03 09:58:09,943:INFO:Checking exceptions
2023-07-03 09:58:09,959:INFO:Preloading libraries
2023-07-03 09:58:09,966:INFO:Copying training dataset
2023-07-03 09:58:09,967:INFO:Plot type: cooks
2023-07-03 09:58:10,007:INFO:Fitting Model
2023-07-03 09:58:10,206:INFO:Visual Rendered Successfully
2023-07-03 09:58:10,346:INFO:plot_model() successfully completed......................................
2023-07-03 09:58:10,357:INFO:Initializing plot_model()
2023-07-03 09:58:10,357:INFO:plot_model(plot=rfe, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000234B3F52F80>, system=True)
2023-07-03 09:58:10,357:INFO:Checking exceptions
2023-07-03 09:58:10,373:INFO:Preloading libraries
2023-07-03 09:58:10,379:INFO:Copying training dataset
2023-07-03 09:58:10,379:INFO:Plot type: rfe
2023-07-03 09:58:10,424:INFO:Fitting Model
2023-07-03 09:58:38,757:INFO:Visual Rendered Successfully
2023-07-03 09:58:38,985:INFO:plot_model() successfully completed......................................
2023-07-03 09:58:38,995:INFO:Initializing plot_model()
2023-07-03 09:58:38,996:INFO:plot_model(plot=learning, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000234B3F52F80>, system=True)
2023-07-03 09:58:38,996:INFO:Checking exceptions
2023-07-03 09:58:39,027:INFO:Preloading libraries
2023-07-03 09:58:39,037:INFO:Copying training dataset
2023-07-03 09:58:39,038:INFO:Plot type: learning
2023-07-03 09:58:39,101:INFO:Fitting Model
2023-07-03 09:58:41,775:INFO:Visual Rendered Successfully
2023-07-03 09:58:41,952:INFO:plot_model() successfully completed......................................
2023-07-03 09:58:41,962:INFO:Initializing plot_model()
2023-07-03 09:58:41,962:INFO:plot_model(plot=vc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000234B3F52F80>, system=True)
2023-07-03 09:58:41,962:INFO:Checking exceptions
2023-07-03 09:58:41,980:INFO:Preloading libraries
2023-07-03 09:58:41,986:INFO:Copying training dataset
2023-07-03 09:58:41,987:INFO:Plot type: vc
2023-07-03 09:58:41,987:INFO:Determining param_name
2023-07-03 09:58:41,987:INFO:param_name: max_depth
2023-07-03 09:58:42,036:INFO:Fitting Model
2023-07-03 09:58:44,315:INFO:Visual Rendered Successfully
2023-07-03 09:58:44,491:INFO:plot_model() successfully completed......................................
2023-07-03 09:58:44,506:INFO:Initializing plot_model()
2023-07-03 09:58:44,507:INFO:plot_model(plot=manifold, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000234B3F52F80>, system=True)
2023-07-03 09:58:44,507:INFO:Checking exceptions
2023-07-03 09:58:44,523:INFO:Preloading libraries
2023-07-03 09:58:44,530:INFO:Copying training dataset
2023-07-03 09:58:44,530:INFO:Plot type: manifold
2023-07-03 09:58:44,594:INFO:Fitting & Transforming Model
2023-07-03 09:58:45,111:INFO:Visual Rendered Successfully
2023-07-03 09:58:45,290:INFO:plot_model() successfully completed......................................
2023-07-03 09:58:45,309:INFO:Initializing plot_model()
2023-07-03 09:58:45,309:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000234B3F52F80>, system=True)
2023-07-03 09:58:45,309:INFO:Checking exceptions
2023-07-03 09:58:45,326:INFO:Preloading libraries
2023-07-03 09:58:45,333:INFO:Copying training dataset
2023-07-03 09:58:45,333:INFO:Plot type: feature
2023-07-03 09:58:45,334:WARNING:No coef_ found. Trying feature_importances_
2023-07-03 09:58:45,474:INFO:Visual Rendered Successfully
2023-07-03 09:58:45,660:INFO:plot_model() successfully completed......................................
2023-07-03 09:58:45,673:INFO:Initializing evaluate_model()
2023-07-03 09:58:45,674:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000234B3F52F80>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-07-03 09:58:45,687:INFO:Initializing plot_model()
2023-07-03 09:58:45,687:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000234B3F52F80>, system=True)
2023-07-03 09:58:45,687:INFO:Checking exceptions
2023-07-03 09:58:45,706:INFO:Preloading libraries
2023-07-03 09:58:45,712:INFO:Copying training dataset
2023-07-03 09:58:45,713:INFO:Plot type: pipeline
2023-07-03 09:58:45,816:INFO:Visual Rendered Successfully
2023-07-03 09:58:46,009:INFO:plot_model() successfully completed......................................
2023-07-03 09:58:46,016:INFO:Initializing finalize_model()
2023-07-03 09:58:46,016:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000234B3F52F80>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-07-03 09:58:46,017:INFO:Finalizing ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-07-03 09:58:46,020:INFO:Initializing create_model()
2023-07-03 09:58:46,020:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000234B3F52F80>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-07-03 09:58:46,020:INFO:Checking exceptions
2023-07-03 09:58:46,023:INFO:Importing libraries
2023-07-03 09:58:46,023:INFO:Copying training dataset
2023-07-03 09:58:46,023:INFO:Defining folds
2023-07-03 09:58:46,023:INFO:Declaring metric variables
2023-07-03 09:58:46,023:INFO:Importing untrained model
2023-07-03 09:58:46,023:INFO:Declaring custom model
2023-07-03 09:58:46,024:INFO:Extra Trees Regressor Imported successfully
2023-07-03 09:58:46,025:INFO:Cross validation set to False
2023-07-03 09:58:46,025:INFO:Fitting Model
2023-07-03 09:58:46,228:INFO:Pipeline(memory=FastMemory(location=C:\Users\JHossain\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MolLogP', 'MolWt',
                                             'NumRotatableBonds',
                                             'AromaticProportion'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))])
2023-07-03 09:58:46,228:INFO:create_model() successfully completed......................................
2023-07-03 09:58:46,407:INFO:_master_model_container: 23
2023-07-03 09:58:46,408:INFO:_display_container: 5
2023-07-03 09:58:46,412:INFO:Pipeline(memory=FastMemory(location=C:\Users\JHossain\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MolLogP', 'MolWt',
                                             'NumRotatableBonds',
                                             'AromaticProportion'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))])
2023-07-03 09:58:46,412:INFO:finalize_model() successfully completed......................................
2023-07-03 09:58:46,616:INFO:Initializing predict_model()
2023-07-03 09:58:46,617:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000234B3F52F80>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000234BB530AF0>)
2023-07-03 09:58:46,617:INFO:Checking exceptions
2023-07-03 09:58:46,617:INFO:Preloading libraries
2023-07-03 09:58:46,916:INFO:Initializing predict_model()
2023-07-03 09:58:46,916:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000234B3F52F80>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000234BB531120>)
2023-07-03 09:58:46,916:INFO:Checking exceptions
2023-07-03 09:58:46,916:INFO:Preloading libraries
2023-07-03 09:58:46,918:INFO:Set up data.
2023-07-03 09:58:46,921:INFO:Set up index.
2023-07-03 09:58:47,150:INFO:Initializing interpret_model()
2023-07-03 09:58:47,151:INFO:interpret_model(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000234B3F52F80>)
2023-07-03 09:58:47,151:INFO:Checking exceptions
2023-07-03 09:58:47,151:INFO:Soft dependency imported: shap: 0.41.0
2023-07-03 09:58:48,976:INFO:plot type: summary
2023-07-03 09:58:48,976:INFO:Creating TreeExplainer
2023-07-03 09:58:48,981:INFO:Compiling shap values
2023-07-03 09:58:49,800:WARNING:No data for colormapping provided via 'c'. Parameters 'vmin', 'vmax' will be ignored

2023-07-03 09:58:49,989:INFO:Visual Rendered Successfully
2023-07-03 09:58:49,989:INFO:interpret_model() successfully completed......................................
2023-07-03 09:58:50,216:INFO:Initializing save_model()
2023-07-03 09:58:50,217:INFO:save_model(model=ExtraTreesRegressor(n_jobs=-1, random_state=123), model_name=../models/esol, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JHossain\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MolLogP', 'MolWt',
                                             'NumRotatableBonds',
                                             'AromaticProportion'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-07-03 09:58:50,217:INFO:Adding model into prep_pipe
2023-07-03 09:58:50,249:INFO:../models/esol.pkl saved in current working directory
2023-07-03 09:58:50,254:INFO:Pipeline(memory=FastMemory(location=C:\Users\JHossain\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MolLogP', 'MolWt',
                                             'NumRotatableBonds',
                                             'AromaticProportion'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('trained_model',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))])
2023-07-03 09:58:50,255:INFO:save_model() successfully completed......................................
2023-07-03 09:58:50,473:INFO:Initializing load_model()
2023-07-03 09:58:50,473:INFO:load_model(model_name=../models/chronic_kidney, platform=None, authentication=None, verbose=True)
2023-07-03 10:29:57,823:INFO:Initializing interpret_model()
2023-07-03 10:29:57,823:INFO:interpret_model(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=correlation, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000234B3F52F80>)
2023-07-03 10:29:57,823:INFO:Checking exceptions
2023-07-03 10:29:57,823:INFO:Soft dependency imported: shap: 0.41.0
2023-07-03 10:29:57,835:INFO:plot type: correlation
2023-07-03 10:29:57,836:WARNING:No feature passed. Default value of feature used for correlation plot: MolLogP
2023-07-03 10:29:57,836:INFO:Creating TreeExplainer
2023-07-03 10:29:57,839:INFO:Compiling shap values
2023-07-03 10:29:58,587:INFO:model type detected: type 2
2023-07-03 10:29:58,744:INFO:Visual Rendered Successfully
2023-07-03 10:29:58,744:INFO:interpret_model() successfully completed......................................
2023-07-03 10:30:25,166:INFO:Initializing interpret_model()
2023-07-03 10:30:25,166:INFO:interpret_model(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=10, plot=reason, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000234B3F52F80>)
2023-07-03 10:30:25,166:INFO:Checking exceptions
2023-07-03 10:30:25,166:INFO:Soft dependency imported: shap: 0.41.0
2023-07-03 10:30:25,180:INFO:plot type: reason
2023-07-03 10:30:25,180:INFO:model type detected: type 2
2023-07-03 10:30:25,180:INFO:Creating TreeExplainer
2023-07-03 10:30:25,183:INFO:Compiling shap values
2023-07-03 10:30:25,943:INFO:Visual Rendered Successfully
2023-07-03 10:30:25,943:INFO:interpret_model() successfully completed......................................
2023-07-03 10:31:46,440:INFO:Initializing save_model()
2023-07-03 10:31:46,440:INFO:save_model(model=ExtraTreesRegressor(n_jobs=-1, random_state=123), model_name=../models/esol, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JHossain\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MolLogP', 'MolWt',
                                             'NumRotatableBonds',
                                             'AromaticProportion'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-07-03 10:31:46,440:INFO:Adding model into prep_pipe
2023-07-03 10:31:46,478:INFO:../models/esol.pkl saved in current working directory
2023-07-03 10:31:46,483:INFO:Pipeline(memory=FastMemory(location=C:\Users\JHossain\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MolLogP', 'MolWt',
                                             'NumRotatableBonds',
                                             'AromaticProportion'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('trained_model',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))])
2023-07-03 10:31:46,483:INFO:save_model() successfully completed......................................
2023-07-03 10:31:52,085:INFO:Initializing load_model()
2023-07-03 10:31:52,085:INFO:load_model(model_name=../models/esol, platform=None, authentication=None, verbose=True)
2023-07-03 10:32:02,107:INFO:Initializing save_model()
2023-07-03 10:32:02,107:INFO:save_model(model=ExtraTreesRegressor(n_jobs=-1, random_state=123), model_name=../models/esol, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JHossain\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MolLogP', 'MolWt',
                                             'NumRotatableBonds',
                                             'AromaticProportion'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-07-03 10:32:02,107:INFO:Adding model into prep_pipe
2023-07-03 10:32:02,137:INFO:../models/esol.pkl saved in current working directory
2023-07-03 10:32:02,141:INFO:Pipeline(memory=FastMemory(location=C:\Users\JHossain\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MolLogP', 'MolWt',
                                             'NumRotatableBonds',
                                             'AromaticProportion'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('trained_model',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))])
2023-07-03 10:32:02,142:INFO:save_model() successfully completed......................................
2023-07-03 10:32:06,810:INFO:Initializing load_model()
2023-07-03 10:32:06,810:INFO:load_model(model_name=../models/esol, platform=None, authentication=None, verbose=True)
2023-07-03 10:32:31,510:INFO:Initializing predict_model()
2023-07-03 10:32:31,510:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000234B3F52F80>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000234BB8F7130>)
2023-07-03 10:32:31,510:INFO:Checking exceptions
2023-07-03 10:32:31,510:INFO:Preloading libraries
2023-07-03 10:57:13,983:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-03 10:57:13,983:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-03 10:57:13,983:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-03 10:57:13,983:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-03 10:57:14,545:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-07-03 10:57:14,968:INFO:PyCaret RegressionExperiment
2023-07-03 10:57:14,968:INFO:Logging name: reg-default-name
2023-07-03 10:57:14,968:INFO:ML Usecase: MLUsecase.REGRESSION
2023-07-03 10:57:14,968:INFO:version 3.0.2
2023-07-03 10:57:14,968:INFO:Initializing setup()
2023-07-03 10:57:14,968:INFO:self.USI: f9a6
2023-07-03 10:57:14,968:INFO:self._variable_keys: {'pipeline', 'seed', 'gpu_param', 'X_train', 'exp_id', 'transform_target_param', 'target_param', 'data', 'exp_name_log', '_ml_usecase', 'idx', 'n_jobs_param', 'USI', 'X_test', 'y', 'y_train', 'html_param', '_available_plots', 'y_test', 'log_plots_param', 'logging_param', 'memory', 'fold_generator', 'gpu_n_jobs_param', 'fold_groups_param', 'fold_shuffle_param', 'X'}
2023-07-03 10:57:14,968:INFO:Checking environment
2023-07-03 10:57:14,968:INFO:python_version: 3.10.9
2023-07-03 10:57:14,968:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2023-07-03 10:57:14,968:INFO:machine: AMD64
2023-07-03 10:57:14,968:INFO:platform: Windows-10-10.0.22621-SP0
2023-07-03 10:57:14,972:INFO:Memory: svmem(total=33664483328, available=20585934848, percent=38.8, used=13078548480, free=20585934848)
2023-07-03 10:57:14,972:INFO:Physical Core: 6
2023-07-03 10:57:14,972:INFO:Logical Core: 12
2023-07-03 10:57:14,972:INFO:Checking libraries
2023-07-03 10:57:14,972:INFO:System:
2023-07-03 10:57:14,973:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2023-07-03 10:57:14,973:INFO:executable: C:\Users\JHossain\anaconda3\python.exe
2023-07-03 10:57:14,973:INFO:   machine: Windows-10-10.0.22621-SP0
2023-07-03 10:57:14,973:INFO:PyCaret required dependencies:
2023-07-03 10:57:14,973:INFO:                 pip: 22.3.1
2023-07-03 10:57:14,973:INFO:          setuptools: 65.6.3
2023-07-03 10:57:14,973:INFO:             pycaret: 3.0.2
2023-07-03 10:57:14,973:INFO:             IPython: 8.10.0
2023-07-03 10:57:14,973:INFO:          ipywidgets: 7.6.5
2023-07-03 10:57:14,973:INFO:                tqdm: 4.64.1
2023-07-03 10:57:14,973:INFO:               numpy: 1.23.5
2023-07-03 10:57:14,973:INFO:              pandas: 1.5.3
2023-07-03 10:57:14,973:INFO:              jinja2: 3.1.2
2023-07-03 10:57:14,973:INFO:               scipy: 1.10.0
2023-07-03 10:57:14,973:INFO:              joblib: 1.2.0
2023-07-03 10:57:14,973:INFO:             sklearn: 1.2.1
2023-07-03 10:57:14,973:INFO:                pyod: 1.0.9
2023-07-03 10:57:14,973:INFO:            imblearn: 0.10.1
2023-07-03 10:57:14,973:INFO:   category_encoders: 2.6.1
2023-07-03 10:57:14,973:INFO:            lightgbm: 3.3.5
2023-07-03 10:57:14,973:INFO:               numba: 0.56.4
2023-07-03 10:57:14,973:INFO:            requests: 2.28.1
2023-07-03 10:57:14,973:INFO:          matplotlib: 3.7.0
2023-07-03 10:57:14,973:INFO:          scikitplot: 0.3.7
2023-07-03 10:57:14,973:INFO:         yellowbrick: 1.5
2023-07-03 10:57:14,973:INFO:              plotly: 5.9.0
2023-07-03 10:57:14,973:INFO:             kaleido: 0.2.1
2023-07-03 10:57:14,973:INFO:         statsmodels: 0.13.5
2023-07-03 10:57:14,973:INFO:              sktime: 0.17.0
2023-07-03 10:57:14,974:INFO:               tbats: 1.1.3
2023-07-03 10:57:14,974:INFO:            pmdarima: 2.0.3
2023-07-03 10:57:14,974:INFO:              psutil: 5.9.0
2023-07-03 10:57:14,974:INFO:PyCaret optional dependencies:
2023-07-03 10:57:15,909:INFO:                shap: 0.41.0
2023-07-03 10:57:15,909:INFO:           interpret: 0.4.2
2023-07-03 10:57:15,909:INFO:                umap: Not installed
2023-07-03 10:57:15,909:INFO:    pandas_profiling: Not installed
2023-07-03 10:57:15,909:INFO:  explainerdashboard: Not installed
2023-07-03 10:57:15,909:INFO:             autoviz: Not installed
2023-07-03 10:57:15,909:INFO:           fairlearn: Not installed
2023-07-03 10:57:15,909:INFO:             xgboost: Not installed
2023-07-03 10:57:15,909:INFO:            catboost: Not installed
2023-07-03 10:57:15,909:INFO:              kmodes: Not installed
2023-07-03 10:57:15,909:INFO:             mlxtend: Not installed
2023-07-03 10:57:15,909:INFO:       statsforecast: Not installed
2023-07-03 10:57:15,909:INFO:        tune_sklearn: Not installed
2023-07-03 10:57:15,909:INFO:                 ray: Not installed
2023-07-03 10:57:15,909:INFO:            hyperopt: Not installed
2023-07-03 10:57:15,909:INFO:              optuna: Not installed
2023-07-03 10:57:15,909:INFO:               skopt: Not installed
2023-07-03 10:57:15,909:INFO:              mlflow: Not installed
2023-07-03 10:57:15,909:INFO:              gradio: 3.35.2
2023-07-03 10:57:15,909:INFO:             fastapi: 0.99.0
2023-07-03 10:57:15,909:INFO:             uvicorn: 0.22.0
2023-07-03 10:57:15,909:INFO:              m2cgen: Not installed
2023-07-03 10:57:15,909:INFO:           evidently: Not installed
2023-07-03 10:57:15,909:INFO:               fugue: Not installed
2023-07-03 10:57:15,909:INFO:           streamlit: Not installed
2023-07-03 10:57:15,910:INFO:             prophet: Not installed
2023-07-03 10:57:15,910:INFO:None
2023-07-03 10:57:15,910:INFO:Set up data.
2023-07-03 10:57:15,916:INFO:Set up train/test split.
2023-07-03 10:57:15,920:INFO:Set up index.
2023-07-03 10:57:15,921:INFO:Set up folding strategy.
2023-07-03 10:57:15,921:INFO:Assigning column types.
2023-07-03 10:57:15,924:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-07-03 10:57:15,924:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-07-03 10:57:15,928:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-07-03 10:57:15,932:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-03 10:57:15,983:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-03 10:57:16,022:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-03 10:57:16,023:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 10:57:16,179:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 10:57:16,179:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-07-03 10:57:16,183:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-07-03 10:57:16,187:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-03 10:57:16,234:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-03 10:57:16,270:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-03 10:57:16,272:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 10:57:16,273:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 10:57:16,273:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-07-03 10:57:16,277:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-07-03 10:57:16,280:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-03 10:57:16,328:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-03 10:57:16,364:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-03 10:57:16,364:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 10:57:16,364:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 10:57:16,368:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-07-03 10:57:16,372:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-03 10:57:16,419:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-03 10:57:16,454:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-03 10:57:16,455:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 10:57:16,455:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 10:57:16,455:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-07-03 10:57:16,463:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-03 10:57:16,509:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-03 10:57:16,545:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-03 10:57:16,545:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 10:57:16,545:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 10:57:16,553:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-03 10:57:16,599:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-03 10:57:16,635:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-03 10:57:16,636:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 10:57:16,636:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 10:57:16,636:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-07-03 10:57:16,690:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-03 10:57:16,726:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-03 10:57:16,727:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 10:57:16,727:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 10:57:16,783:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-03 10:57:16,819:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-03 10:57:16,819:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 10:57:16,820:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 10:57:16,820:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-07-03 10:57:16,873:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-03 10:57:16,910:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 10:57:16,910:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 10:57:16,964:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-03 10:57:17,001:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 10:57:17,001:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 10:57:17,001:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-07-03 10:57:17,091:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 10:57:17,091:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 10:57:17,181:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 10:57:17,181:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 10:57:17,183:INFO:Preparing preprocessing pipeline...
2023-07-03 10:57:17,184:INFO:Set up simple imputation.
2023-07-03 10:57:17,186:INFO:Set up encoding of ordinal features.
2023-07-03 10:57:17,187:INFO:Set up encoding of categorical features.
2023-07-03 10:57:17,219:INFO:Finished creating preprocessing pipeline.
2023-07-03 10:57:17,234:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\JHossain\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['User_ID', 'Age', 'Height',
                                             'Weight', 'Duration', 'Heart_Rate',
                                             'Body_Temp'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 TransformerWrapper(include=['Gender'],
                                    transformer=OrdinalEncoder(cols=['Gender'],
                                                               handle_missing='return_nan',
                                                               mapping=[{'col': 'Gender',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': female    0
male      1
NaN      -1
dtype: int64}])))])
2023-07-03 10:57:17,235:INFO:Creating final display dataframe.
2023-07-03 10:57:17,359:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          Calories
2                   Target type        Regression
3           Original data shape        (15000, 9)
4        Transformed data shape        (15000, 9)
5   Transformed train set shape         (1200, 9)
6    Transformed test set shape        (13800, 9)
7              Ordinal features                 1
8              Numeric features                 7
9          Categorical features                 1
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              f9a6
2023-07-03 10:57:17,458:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 10:57:17,458:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 10:57:17,551:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 10:57:17,551:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 10:57:17,551:INFO:setup() successfully completed in 2.85s...............
2023-07-03 10:57:22,797:INFO:Initializing compare_models()
2023-07-03 10:57:22,797:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021553A88AF0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000021553A88AF0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-07-03 10:57:22,797:INFO:Checking exceptions
2023-07-03 10:57:22,800:INFO:Preparing display monitor
2023-07-03 10:57:22,821:INFO:Initializing Linear Regression
2023-07-03 10:57:22,822:INFO:Total runtime is 1.666545867919922e-05 minutes
2023-07-03 10:57:22,824:INFO:SubProcess create_model() called ==================================
2023-07-03 10:57:22,825:INFO:Initializing create_model()
2023-07-03 10:57:22,825:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021553A88AF0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002155448E830>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 10:57:22,825:INFO:Checking exceptions
2023-07-03 10:57:22,825:INFO:Importing libraries
2023-07-03 10:57:22,825:INFO:Copying training dataset
2023-07-03 10:57:22,830:INFO:Defining folds
2023-07-03 10:57:22,830:INFO:Declaring metric variables
2023-07-03 10:57:22,833:INFO:Importing untrained model
2023-07-03 10:57:22,836:INFO:Linear Regression Imported successfully
2023-07-03 10:57:22,840:INFO:Starting cross validation
2023-07-03 10:57:22,845:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 10:57:30,183:INFO:Calculating mean and std
2023-07-03 10:57:30,184:INFO:Creating metrics dataframe
2023-07-03 10:57:30,519:INFO:Uploading results into container
2023-07-03 10:57:30,520:INFO:Uploading model into container now
2023-07-03 10:57:30,520:INFO:_master_model_container: 1
2023-07-03 10:57:30,520:INFO:_display_container: 2
2023-07-03 10:57:30,520:INFO:LinearRegression(n_jobs=-1)
2023-07-03 10:57:30,520:INFO:create_model() successfully completed......................................
2023-07-03 10:57:30,818:INFO:SubProcess create_model() end ==================================
2023-07-03 10:57:30,818:INFO:Creating metrics dataframe
2023-07-03 10:57:30,825:INFO:Initializing Lasso Regression
2023-07-03 10:57:30,826:INFO:Total runtime is 0.13341634273529054 minutes
2023-07-03 10:57:30,828:INFO:SubProcess create_model() called ==================================
2023-07-03 10:57:30,829:INFO:Initializing create_model()
2023-07-03 10:57:30,829:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021553A88AF0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002155448E830>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 10:57:30,829:INFO:Checking exceptions
2023-07-03 10:57:30,829:INFO:Importing libraries
2023-07-03 10:57:30,829:INFO:Copying training dataset
2023-07-03 10:57:30,833:INFO:Defining folds
2023-07-03 10:57:30,833:INFO:Declaring metric variables
2023-07-03 10:57:30,836:INFO:Importing untrained model
2023-07-03 10:57:30,839:INFO:Lasso Regression Imported successfully
2023-07-03 10:57:30,843:INFO:Starting cross validation
2023-07-03 10:57:30,844:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 10:57:33,222:INFO:Calculating mean and std
2023-07-03 10:57:33,224:INFO:Creating metrics dataframe
2023-07-03 10:57:33,560:INFO:Uploading results into container
2023-07-03 10:57:33,561:INFO:Uploading model into container now
2023-07-03 10:57:33,561:INFO:_master_model_container: 2
2023-07-03 10:57:33,561:INFO:_display_container: 2
2023-07-03 10:57:33,562:INFO:Lasso(random_state=123)
2023-07-03 10:57:33,562:INFO:create_model() successfully completed......................................
2023-07-03 10:57:33,859:INFO:SubProcess create_model() end ==================================
2023-07-03 10:57:33,859:INFO:Creating metrics dataframe
2023-07-03 10:57:33,866:INFO:Initializing Ridge Regression
2023-07-03 10:57:33,866:INFO:Total runtime is 0.1840845068295797 minutes
2023-07-03 10:57:33,869:INFO:SubProcess create_model() called ==================================
2023-07-03 10:57:33,869:INFO:Initializing create_model()
2023-07-03 10:57:33,869:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021553A88AF0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002155448E830>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 10:57:33,870:INFO:Checking exceptions
2023-07-03 10:57:33,870:INFO:Importing libraries
2023-07-03 10:57:33,870:INFO:Copying training dataset
2023-07-03 10:57:33,874:INFO:Defining folds
2023-07-03 10:57:33,874:INFO:Declaring metric variables
2023-07-03 10:57:33,877:INFO:Importing untrained model
2023-07-03 10:57:33,879:INFO:Ridge Regression Imported successfully
2023-07-03 10:57:33,885:INFO:Starting cross validation
2023-07-03 10:57:33,886:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 10:57:36,021:INFO:Calculating mean and std
2023-07-03 10:57:36,023:INFO:Creating metrics dataframe
2023-07-03 10:57:36,361:INFO:Uploading results into container
2023-07-03 10:57:36,362:INFO:Uploading model into container now
2023-07-03 10:57:36,362:INFO:_master_model_container: 3
2023-07-03 10:57:36,362:INFO:_display_container: 2
2023-07-03 10:57:36,363:INFO:Ridge(random_state=123)
2023-07-03 10:57:36,363:INFO:create_model() successfully completed......................................
2023-07-03 10:57:36,650:INFO:SubProcess create_model() end ==================================
2023-07-03 10:57:36,650:INFO:Creating metrics dataframe
2023-07-03 10:57:36,658:INFO:Initializing Elastic Net
2023-07-03 10:57:36,659:INFO:Total runtime is 0.23064084450403852 minutes
2023-07-03 10:57:36,661:INFO:SubProcess create_model() called ==================================
2023-07-03 10:57:36,662:INFO:Initializing create_model()
2023-07-03 10:57:36,662:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021553A88AF0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002155448E830>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 10:57:36,662:INFO:Checking exceptions
2023-07-03 10:57:36,662:INFO:Importing libraries
2023-07-03 10:57:36,662:INFO:Copying training dataset
2023-07-03 10:57:36,666:INFO:Defining folds
2023-07-03 10:57:36,666:INFO:Declaring metric variables
2023-07-03 10:57:36,669:INFO:Importing untrained model
2023-07-03 10:57:36,671:INFO:Elastic Net Imported successfully
2023-07-03 10:57:36,677:INFO:Starting cross validation
2023-07-03 10:57:36,678:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 10:57:38,776:INFO:Calculating mean and std
2023-07-03 10:57:38,777:INFO:Creating metrics dataframe
2023-07-03 10:57:39,114:INFO:Uploading results into container
2023-07-03 10:57:39,115:INFO:Uploading model into container now
2023-07-03 10:57:39,115:INFO:_master_model_container: 4
2023-07-03 10:57:39,115:INFO:_display_container: 2
2023-07-03 10:57:39,115:INFO:ElasticNet(random_state=123)
2023-07-03 10:57:39,116:INFO:create_model() successfully completed......................................
2023-07-03 10:57:39,412:INFO:SubProcess create_model() end ==================================
2023-07-03 10:57:39,412:INFO:Creating metrics dataframe
2023-07-03 10:57:39,420:INFO:Initializing Least Angle Regression
2023-07-03 10:57:39,420:INFO:Total runtime is 0.276648493607839 minutes
2023-07-03 10:57:39,423:INFO:SubProcess create_model() called ==================================
2023-07-03 10:57:39,423:INFO:Initializing create_model()
2023-07-03 10:57:39,423:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021553A88AF0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002155448E830>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 10:57:39,423:INFO:Checking exceptions
2023-07-03 10:57:39,423:INFO:Importing libraries
2023-07-03 10:57:39,423:INFO:Copying training dataset
2023-07-03 10:57:39,427:INFO:Defining folds
2023-07-03 10:57:39,427:INFO:Declaring metric variables
2023-07-03 10:57:39,430:INFO:Importing untrained model
2023-07-03 10:57:39,432:INFO:Least Angle Regression Imported successfully
2023-07-03 10:57:39,437:INFO:Starting cross validation
2023-07-03 10:57:39,438:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 10:57:41,560:INFO:Calculating mean and std
2023-07-03 10:57:41,561:INFO:Creating metrics dataframe
2023-07-03 10:57:41,898:INFO:Uploading results into container
2023-07-03 10:57:41,899:INFO:Uploading model into container now
2023-07-03 10:57:41,899:INFO:_master_model_container: 5
2023-07-03 10:57:41,899:INFO:_display_container: 2
2023-07-03 10:57:41,900:INFO:Lars(random_state=123)
2023-07-03 10:57:41,900:INFO:create_model() successfully completed......................................
2023-07-03 10:57:42,190:INFO:SubProcess create_model() end ==================================
2023-07-03 10:57:42,191:INFO:Creating metrics dataframe
2023-07-03 10:57:42,199:INFO:Initializing Lasso Least Angle Regression
2023-07-03 10:57:42,200:INFO:Total runtime is 0.3229774594306946 minutes
2023-07-03 10:57:42,202:INFO:SubProcess create_model() called ==================================
2023-07-03 10:57:42,203:INFO:Initializing create_model()
2023-07-03 10:57:42,203:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021553A88AF0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002155448E830>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 10:57:42,203:INFO:Checking exceptions
2023-07-03 10:57:42,203:INFO:Importing libraries
2023-07-03 10:57:42,203:INFO:Copying training dataset
2023-07-03 10:57:42,207:INFO:Defining folds
2023-07-03 10:57:42,208:INFO:Declaring metric variables
2023-07-03 10:57:42,211:INFO:Importing untrained model
2023-07-03 10:57:42,214:INFO:Lasso Least Angle Regression Imported successfully
2023-07-03 10:57:42,220:INFO:Starting cross validation
2023-07-03 10:57:42,221:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 10:57:44,371:INFO:Calculating mean and std
2023-07-03 10:57:44,372:INFO:Creating metrics dataframe
2023-07-03 10:57:44,716:INFO:Uploading results into container
2023-07-03 10:57:44,716:INFO:Uploading model into container now
2023-07-03 10:57:44,717:INFO:_master_model_container: 6
2023-07-03 10:57:44,717:INFO:_display_container: 2
2023-07-03 10:57:44,717:INFO:LassoLars(random_state=123)
2023-07-03 10:57:44,717:INFO:create_model() successfully completed......................................
2023-07-03 10:57:45,007:INFO:SubProcess create_model() end ==================================
2023-07-03 10:57:45,007:INFO:Creating metrics dataframe
2023-07-03 10:57:45,015:INFO:Initializing Orthogonal Matching Pursuit
2023-07-03 10:57:45,015:INFO:Total runtime is 0.3699073870976766 minutes
2023-07-03 10:57:45,018:INFO:SubProcess create_model() called ==================================
2023-07-03 10:57:45,019:INFO:Initializing create_model()
2023-07-03 10:57:45,019:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021553A88AF0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002155448E830>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 10:57:45,019:INFO:Checking exceptions
2023-07-03 10:57:45,019:INFO:Importing libraries
2023-07-03 10:57:45,019:INFO:Copying training dataset
2023-07-03 10:57:45,023:INFO:Defining folds
2023-07-03 10:57:45,023:INFO:Declaring metric variables
2023-07-03 10:57:45,026:INFO:Importing untrained model
2023-07-03 10:57:45,028:INFO:Orthogonal Matching Pursuit Imported successfully
2023-07-03 10:57:45,033:INFO:Starting cross validation
2023-07-03 10:57:45,034:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 10:57:47,146:INFO:Calculating mean and std
2023-07-03 10:57:47,147:INFO:Creating metrics dataframe
2023-07-03 10:57:47,482:INFO:Uploading results into container
2023-07-03 10:57:47,483:INFO:Uploading model into container now
2023-07-03 10:57:47,484:INFO:_master_model_container: 7
2023-07-03 10:57:47,484:INFO:_display_container: 2
2023-07-03 10:57:47,484:INFO:OrthogonalMatchingPursuit()
2023-07-03 10:57:47,484:INFO:create_model() successfully completed......................................
2023-07-03 10:57:47,782:INFO:SubProcess create_model() end ==================================
2023-07-03 10:57:47,782:INFO:Creating metrics dataframe
2023-07-03 10:57:47,791:INFO:Initializing Bayesian Ridge
2023-07-03 10:57:47,791:INFO:Total runtime is 0.41616512934366867 minutes
2023-07-03 10:57:47,794:INFO:SubProcess create_model() called ==================================
2023-07-03 10:57:47,795:INFO:Initializing create_model()
2023-07-03 10:57:47,795:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021553A88AF0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002155448E830>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 10:57:47,795:INFO:Checking exceptions
2023-07-03 10:57:47,795:INFO:Importing libraries
2023-07-03 10:57:47,795:INFO:Copying training dataset
2023-07-03 10:57:47,799:INFO:Defining folds
2023-07-03 10:57:47,799:INFO:Declaring metric variables
2023-07-03 10:57:47,802:INFO:Importing untrained model
2023-07-03 10:57:47,804:INFO:Bayesian Ridge Imported successfully
2023-07-03 10:57:47,809:INFO:Starting cross validation
2023-07-03 10:57:47,810:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 10:57:49,934:INFO:Calculating mean and std
2023-07-03 10:57:49,935:INFO:Creating metrics dataframe
2023-07-03 10:57:50,273:INFO:Uploading results into container
2023-07-03 10:57:50,274:INFO:Uploading model into container now
2023-07-03 10:57:50,274:INFO:_master_model_container: 8
2023-07-03 10:57:50,274:INFO:_display_container: 2
2023-07-03 10:57:50,274:INFO:BayesianRidge()
2023-07-03 10:57:50,274:INFO:create_model() successfully completed......................................
2023-07-03 10:57:50,564:INFO:SubProcess create_model() end ==================================
2023-07-03 10:57:50,565:INFO:Creating metrics dataframe
2023-07-03 10:57:50,573:INFO:Initializing Passive Aggressive Regressor
2023-07-03 10:57:50,573:INFO:Total runtime is 0.46253863573074344 minutes
2023-07-03 10:57:50,575:INFO:SubProcess create_model() called ==================================
2023-07-03 10:57:50,576:INFO:Initializing create_model()
2023-07-03 10:57:50,576:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021553A88AF0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002155448E830>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 10:57:50,576:INFO:Checking exceptions
2023-07-03 10:57:50,576:INFO:Importing libraries
2023-07-03 10:57:50,576:INFO:Copying training dataset
2023-07-03 10:57:50,580:INFO:Defining folds
2023-07-03 10:57:50,580:INFO:Declaring metric variables
2023-07-03 10:57:50,583:INFO:Importing untrained model
2023-07-03 10:57:50,586:INFO:Passive Aggressive Regressor Imported successfully
2023-07-03 10:57:50,590:INFO:Starting cross validation
2023-07-03 10:57:50,591:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 10:57:52,736:INFO:Calculating mean and std
2023-07-03 10:57:52,738:INFO:Creating metrics dataframe
2023-07-03 10:57:53,072:INFO:Uploading results into container
2023-07-03 10:57:53,073:INFO:Uploading model into container now
2023-07-03 10:57:53,073:INFO:_master_model_container: 9
2023-07-03 10:57:53,074:INFO:_display_container: 2
2023-07-03 10:57:53,074:INFO:PassiveAggressiveRegressor(random_state=123)
2023-07-03 10:57:53,074:INFO:create_model() successfully completed......................................
2023-07-03 10:57:53,372:INFO:SubProcess create_model() end ==================================
2023-07-03 10:57:53,372:INFO:Creating metrics dataframe
2023-07-03 10:57:53,381:INFO:Initializing Huber Regressor
2023-07-03 10:57:53,381:INFO:Total runtime is 0.509337600072225 minutes
2023-07-03 10:57:53,384:INFO:SubProcess create_model() called ==================================
2023-07-03 10:57:53,384:INFO:Initializing create_model()
2023-07-03 10:57:53,384:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021553A88AF0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002155448E830>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 10:57:53,384:INFO:Checking exceptions
2023-07-03 10:57:53,385:INFO:Importing libraries
2023-07-03 10:57:53,385:INFO:Copying training dataset
2023-07-03 10:57:53,389:INFO:Defining folds
2023-07-03 10:57:53,389:INFO:Declaring metric variables
2023-07-03 10:57:53,392:INFO:Importing untrained model
2023-07-03 10:57:53,395:INFO:Huber Regressor Imported successfully
2023-07-03 10:57:53,400:INFO:Starting cross validation
2023-07-03 10:57:53,401:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 10:57:55,544:INFO:Calculating mean and std
2023-07-03 10:57:55,545:INFO:Creating metrics dataframe
2023-07-03 10:57:55,885:INFO:Uploading results into container
2023-07-03 10:57:55,886:INFO:Uploading model into container now
2023-07-03 10:57:55,886:INFO:_master_model_container: 10
2023-07-03 10:57:55,887:INFO:_display_container: 2
2023-07-03 10:57:55,887:INFO:HuberRegressor()
2023-07-03 10:57:55,887:INFO:create_model() successfully completed......................................
2023-07-03 10:57:56,182:INFO:SubProcess create_model() end ==================================
2023-07-03 10:57:56,182:INFO:Creating metrics dataframe
2023-07-03 10:57:56,192:INFO:Initializing K Neighbors Regressor
2023-07-03 10:57:56,192:INFO:Total runtime is 0.5561872641245524 minutes
2023-07-03 10:57:56,194:INFO:SubProcess create_model() called ==================================
2023-07-03 10:57:56,194:INFO:Initializing create_model()
2023-07-03 10:57:56,195:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021553A88AF0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002155448E830>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 10:57:56,195:INFO:Checking exceptions
2023-07-03 10:57:56,195:INFO:Importing libraries
2023-07-03 10:57:56,195:INFO:Copying training dataset
2023-07-03 10:57:56,199:INFO:Defining folds
2023-07-03 10:57:56,199:INFO:Declaring metric variables
2023-07-03 10:57:56,201:INFO:Importing untrained model
2023-07-03 10:57:56,204:INFO:K Neighbors Regressor Imported successfully
2023-07-03 10:57:56,209:INFO:Starting cross validation
2023-07-03 10:57:56,211:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 10:57:58,332:INFO:Calculating mean and std
2023-07-03 10:57:58,333:INFO:Creating metrics dataframe
2023-07-03 10:57:58,667:INFO:Uploading results into container
2023-07-03 10:57:58,668:INFO:Uploading model into container now
2023-07-03 10:57:58,668:INFO:_master_model_container: 11
2023-07-03 10:57:58,668:INFO:_display_container: 2
2023-07-03 10:57:58,668:INFO:KNeighborsRegressor(n_jobs=-1)
2023-07-03 10:57:58,669:INFO:create_model() successfully completed......................................
2023-07-03 10:57:58,958:INFO:SubProcess create_model() end ==================================
2023-07-03 10:57:58,958:INFO:Creating metrics dataframe
2023-07-03 10:57:58,968:INFO:Initializing Decision Tree Regressor
2023-07-03 10:57:58,968:INFO:Total runtime is 0.6024461547533672 minutes
2023-07-03 10:57:58,970:INFO:SubProcess create_model() called ==================================
2023-07-03 10:57:58,970:INFO:Initializing create_model()
2023-07-03 10:57:58,970:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021553A88AF0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002155448E830>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 10:57:58,971:INFO:Checking exceptions
2023-07-03 10:57:58,971:INFO:Importing libraries
2023-07-03 10:57:58,971:INFO:Copying training dataset
2023-07-03 10:57:58,975:INFO:Defining folds
2023-07-03 10:57:58,975:INFO:Declaring metric variables
2023-07-03 10:57:58,978:INFO:Importing untrained model
2023-07-03 10:57:58,981:INFO:Decision Tree Regressor Imported successfully
2023-07-03 10:57:58,986:INFO:Starting cross validation
2023-07-03 10:57:58,987:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 10:58:01,114:INFO:Calculating mean and std
2023-07-03 10:58:01,115:INFO:Creating metrics dataframe
2023-07-03 10:58:01,450:INFO:Uploading results into container
2023-07-03 10:58:01,451:INFO:Uploading model into container now
2023-07-03 10:58:01,451:INFO:_master_model_container: 12
2023-07-03 10:58:01,452:INFO:_display_container: 2
2023-07-03 10:58:01,452:INFO:DecisionTreeRegressor(random_state=123)
2023-07-03 10:58:01,452:INFO:create_model() successfully completed......................................
2023-07-03 10:58:01,741:INFO:SubProcess create_model() end ==================================
2023-07-03 10:58:01,741:INFO:Creating metrics dataframe
2023-07-03 10:58:01,752:INFO:Initializing Random Forest Regressor
2023-07-03 10:58:01,752:INFO:Total runtime is 0.6488437771797181 minutes
2023-07-03 10:58:01,755:INFO:SubProcess create_model() called ==================================
2023-07-03 10:58:01,755:INFO:Initializing create_model()
2023-07-03 10:58:01,755:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021553A88AF0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002155448E830>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 10:58:01,755:INFO:Checking exceptions
2023-07-03 10:58:01,755:INFO:Importing libraries
2023-07-03 10:58:01,755:INFO:Copying training dataset
2023-07-03 10:58:01,759:INFO:Defining folds
2023-07-03 10:58:01,760:INFO:Declaring metric variables
2023-07-03 10:58:01,762:INFO:Importing untrained model
2023-07-03 10:58:01,765:INFO:Random Forest Regressor Imported successfully
2023-07-03 10:58:01,770:INFO:Starting cross validation
2023-07-03 10:58:01,771:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 10:58:04,641:INFO:Calculating mean and std
2023-07-03 10:58:04,643:INFO:Creating metrics dataframe
2023-07-03 10:58:04,978:INFO:Uploading results into container
2023-07-03 10:58:04,979:INFO:Uploading model into container now
2023-07-03 10:58:04,979:INFO:_master_model_container: 13
2023-07-03 10:58:04,979:INFO:_display_container: 2
2023-07-03 10:58:04,980:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-07-03 10:58:04,980:INFO:create_model() successfully completed......................................
2023-07-03 10:58:05,276:INFO:SubProcess create_model() end ==================================
2023-07-03 10:58:05,277:INFO:Creating metrics dataframe
2023-07-03 10:58:05,286:INFO:Initializing Extra Trees Regressor
2023-07-03 10:58:05,286:INFO:Total runtime is 0.707744586467743 minutes
2023-07-03 10:58:05,289:INFO:SubProcess create_model() called ==================================
2023-07-03 10:58:05,289:INFO:Initializing create_model()
2023-07-03 10:58:05,289:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021553A88AF0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002155448E830>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 10:58:05,290:INFO:Checking exceptions
2023-07-03 10:58:05,290:INFO:Importing libraries
2023-07-03 10:58:05,290:INFO:Copying training dataset
2023-07-03 10:58:05,294:INFO:Defining folds
2023-07-03 10:58:05,294:INFO:Declaring metric variables
2023-07-03 10:58:05,297:INFO:Importing untrained model
2023-07-03 10:58:05,300:INFO:Extra Trees Regressor Imported successfully
2023-07-03 10:58:05,304:INFO:Starting cross validation
2023-07-03 10:58:05,305:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 10:58:08,078:INFO:Calculating mean and std
2023-07-03 10:58:08,079:INFO:Creating metrics dataframe
2023-07-03 10:58:08,429:INFO:Uploading results into container
2023-07-03 10:58:08,430:INFO:Uploading model into container now
2023-07-03 10:58:08,430:INFO:_master_model_container: 14
2023-07-03 10:58:08,430:INFO:_display_container: 2
2023-07-03 10:58:08,431:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-07-03 10:58:08,431:INFO:create_model() successfully completed......................................
2023-07-03 10:58:08,722:INFO:SubProcess create_model() end ==================================
2023-07-03 10:58:08,722:INFO:Creating metrics dataframe
2023-07-03 10:58:08,733:INFO:Initializing AdaBoost Regressor
2023-07-03 10:58:08,733:INFO:Total runtime is 0.7651921192804972 minutes
2023-07-03 10:58:08,736:INFO:SubProcess create_model() called ==================================
2023-07-03 10:58:08,737:INFO:Initializing create_model()
2023-07-03 10:58:08,737:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021553A88AF0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002155448E830>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 10:58:08,737:INFO:Checking exceptions
2023-07-03 10:58:08,737:INFO:Importing libraries
2023-07-03 10:58:08,737:INFO:Copying training dataset
2023-07-03 10:58:08,741:INFO:Defining folds
2023-07-03 10:58:08,742:INFO:Declaring metric variables
2023-07-03 10:58:08,745:INFO:Importing untrained model
2023-07-03 10:58:08,747:INFO:AdaBoost Regressor Imported successfully
2023-07-03 10:58:08,752:INFO:Starting cross validation
2023-07-03 10:58:08,753:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 10:58:11,180:INFO:Calculating mean and std
2023-07-03 10:58:11,181:INFO:Creating metrics dataframe
2023-07-03 10:58:11,536:INFO:Uploading results into container
2023-07-03 10:58:11,537:INFO:Uploading model into container now
2023-07-03 10:58:11,537:INFO:_master_model_container: 15
2023-07-03 10:58:11,537:INFO:_display_container: 2
2023-07-03 10:58:11,537:INFO:AdaBoostRegressor(random_state=123)
2023-07-03 10:58:11,537:INFO:create_model() successfully completed......................................
2023-07-03 10:58:11,827:INFO:SubProcess create_model() end ==================================
2023-07-03 10:58:11,827:INFO:Creating metrics dataframe
2023-07-03 10:58:11,838:INFO:Initializing Gradient Boosting Regressor
2023-07-03 10:58:11,838:INFO:Total runtime is 0.8169431845347087 minutes
2023-07-03 10:58:11,841:INFO:SubProcess create_model() called ==================================
2023-07-03 10:58:11,841:INFO:Initializing create_model()
2023-07-03 10:58:11,841:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021553A88AF0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002155448E830>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 10:58:11,841:INFO:Checking exceptions
2023-07-03 10:58:11,841:INFO:Importing libraries
2023-07-03 10:58:11,841:INFO:Copying training dataset
2023-07-03 10:58:11,845:INFO:Defining folds
2023-07-03 10:58:11,845:INFO:Declaring metric variables
2023-07-03 10:58:11,848:INFO:Importing untrained model
2023-07-03 10:58:11,851:INFO:Gradient Boosting Regressor Imported successfully
2023-07-03 10:58:11,856:INFO:Starting cross validation
2023-07-03 10:58:11,857:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 10:58:14,421:INFO:Calculating mean and std
2023-07-03 10:58:14,423:INFO:Creating metrics dataframe
2023-07-03 10:58:14,783:INFO:Uploading results into container
2023-07-03 10:58:14,784:INFO:Uploading model into container now
2023-07-03 10:58:14,785:INFO:_master_model_container: 16
2023-07-03 10:58:14,785:INFO:_display_container: 2
2023-07-03 10:58:14,785:INFO:GradientBoostingRegressor(random_state=123)
2023-07-03 10:58:14,785:INFO:create_model() successfully completed......................................
2023-07-03 10:58:15,083:INFO:SubProcess create_model() end ==================================
2023-07-03 10:58:15,083:INFO:Creating metrics dataframe
2023-07-03 10:58:15,093:INFO:Initializing Light Gradient Boosting Machine
2023-07-03 10:58:15,093:INFO:Total runtime is 0.8712076783180237 minutes
2023-07-03 10:58:15,095:INFO:SubProcess create_model() called ==================================
2023-07-03 10:58:15,096:INFO:Initializing create_model()
2023-07-03 10:58:15,096:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021553A88AF0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002155448E830>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 10:58:15,096:INFO:Checking exceptions
2023-07-03 10:58:15,096:INFO:Importing libraries
2023-07-03 10:58:15,096:INFO:Copying training dataset
2023-07-03 10:58:15,100:INFO:Defining folds
2023-07-03 10:58:15,101:INFO:Declaring metric variables
2023-07-03 10:58:15,104:INFO:Importing untrained model
2023-07-03 10:58:15,106:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-03 10:58:15,111:INFO:Starting cross validation
2023-07-03 10:58:15,112:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 10:58:18,517:INFO:Calculating mean and std
2023-07-03 10:58:18,518:INFO:Creating metrics dataframe
2023-07-03 10:58:18,886:INFO:Uploading results into container
2023-07-03 10:58:18,887:INFO:Uploading model into container now
2023-07-03 10:58:18,888:INFO:_master_model_container: 17
2023-07-03 10:58:18,888:INFO:_display_container: 2
2023-07-03 10:58:18,888:INFO:LGBMRegressor(random_state=123)
2023-07-03 10:58:18,888:INFO:create_model() successfully completed......................................
2023-07-03 10:58:19,191:INFO:SubProcess create_model() end ==================================
2023-07-03 10:58:19,191:INFO:Creating metrics dataframe
2023-07-03 10:58:19,202:INFO:Initializing Dummy Regressor
2023-07-03 10:58:19,202:INFO:Total runtime is 0.9396899342536926 minutes
2023-07-03 10:58:19,205:INFO:SubProcess create_model() called ==================================
2023-07-03 10:58:19,205:INFO:Initializing create_model()
2023-07-03 10:58:19,206:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021553A88AF0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002155448E830>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 10:58:19,206:INFO:Checking exceptions
2023-07-03 10:58:19,206:INFO:Importing libraries
2023-07-03 10:58:19,206:INFO:Copying training dataset
2023-07-03 10:58:19,210:INFO:Defining folds
2023-07-03 10:58:19,210:INFO:Declaring metric variables
2023-07-03 10:58:19,213:INFO:Importing untrained model
2023-07-03 10:58:19,216:INFO:Dummy Regressor Imported successfully
2023-07-03 10:58:19,221:INFO:Starting cross validation
2023-07-03 10:58:19,222:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 10:58:21,506:INFO:Calculating mean and std
2023-07-03 10:58:21,507:INFO:Creating metrics dataframe
2023-07-03 10:58:21,874:INFO:Uploading results into container
2023-07-03 10:58:21,874:INFO:Uploading model into container now
2023-07-03 10:58:21,875:INFO:_master_model_container: 18
2023-07-03 10:58:21,875:INFO:_display_container: 2
2023-07-03 10:58:21,876:INFO:DummyRegressor()
2023-07-03 10:58:21,876:INFO:create_model() successfully completed......................................
2023-07-03 10:58:22,167:INFO:SubProcess create_model() end ==================================
2023-07-03 10:58:22,167:INFO:Creating metrics dataframe
2023-07-03 10:58:22,185:INFO:Initializing create_model()
2023-07-03 10:58:22,185:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021553A88AF0>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-03 10:58:22,186:INFO:Checking exceptions
2023-07-03 10:58:22,187:INFO:Importing libraries
2023-07-03 10:58:22,187:INFO:Copying training dataset
2023-07-03 10:58:22,190:INFO:Defining folds
2023-07-03 10:58:22,191:INFO:Declaring metric variables
2023-07-03 10:58:22,191:INFO:Importing untrained model
2023-07-03 10:58:22,191:INFO:Declaring custom model
2023-07-03 10:58:22,191:INFO:Gradient Boosting Regressor Imported successfully
2023-07-03 10:58:22,192:INFO:Cross validation set to False
2023-07-03 10:58:22,192:INFO:Fitting Model
2023-07-03 10:58:22,633:INFO:GradientBoostingRegressor(random_state=123)
2023-07-03 10:58:22,633:INFO:create_model() successfully completed......................................
2023-07-03 10:58:22,974:INFO:_master_model_container: 18
2023-07-03 10:58:22,974:INFO:_display_container: 2
2023-07-03 10:58:22,975:INFO:GradientBoostingRegressor(random_state=123)
2023-07-03 10:58:22,975:INFO:compare_models() successfully completed......................................
2023-07-03 10:58:33,622:INFO:Initializing create_model()
2023-07-03 10:58:33,622:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021553A88AF0>, estimator=gbr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-03 10:58:33,623:INFO:Checking exceptions
2023-07-03 10:58:33,635:INFO:Importing libraries
2023-07-03 10:58:33,635:INFO:Copying training dataset
2023-07-03 10:58:33,639:INFO:Defining folds
2023-07-03 10:58:33,639:INFO:Declaring metric variables
2023-07-03 10:58:33,642:INFO:Importing untrained model
2023-07-03 10:58:33,645:INFO:Gradient Boosting Regressor Imported successfully
2023-07-03 10:58:33,650:INFO:Starting cross validation
2023-07-03 10:58:33,651:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 10:58:35,971:INFO:Calculating mean and std
2023-07-03 10:58:35,972:INFO:Creating metrics dataframe
2023-07-03 10:58:35,977:INFO:Finalizing model
2023-07-03 10:58:36,381:INFO:Uploading results into container
2023-07-03 10:58:36,382:INFO:Uploading model into container now
2023-07-03 10:58:36,390:INFO:_master_model_container: 19
2023-07-03 10:58:36,390:INFO:_display_container: 3
2023-07-03 10:58:36,390:INFO:GradientBoostingRegressor(random_state=123)
2023-07-03 10:58:36,391:INFO:create_model() successfully completed......................................
2023-07-03 10:58:49,148:INFO:Initializing tune_model()
2023-07-03 10:58:49,148:INFO:tune_model(estimator=GradientBoostingRegressor(random_state=123), fold=None, round=4, n_iter=50, custom_grid=None, optimize=mae, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021553A88AF0>)
2023-07-03 10:58:49,148:INFO:Checking exceptions
2023-07-03 10:58:49,162:INFO:Copying training dataset
2023-07-03 10:58:49,165:INFO:Checking base model
2023-07-03 10:58:49,166:INFO:Base model : Gradient Boosting Regressor
2023-07-03 10:58:49,169:INFO:Declaring metric variables
2023-07-03 10:58:49,171:INFO:Defining Hyperparameters
2023-07-03 10:58:49,467:INFO:Tuning with n_jobs=-1
2023-07-03 10:58:49,467:INFO:Initializing RandomizedSearchCV
2023-07-03 11:01:53,022:INFO:best_params: {'actual_estimator__subsample': 0.3, 'actual_estimator__n_estimators': 170, 'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 1, 'actual_estimator__min_impurity_decrease': 0.05, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 11, 'actual_estimator__learning_rate': 0.05}
2023-07-03 11:01:53,023:INFO:Hyperparameter search completed
2023-07-03 11:01:53,023:INFO:SubProcess create_model() called ==================================
2023-07-03 11:01:53,024:INFO:Initializing create_model()
2023-07-03 11:01:53,024:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021553A88AF0>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021553B8CA60>, model_only=True, return_train_score=False, kwargs={'subsample': 0.3, 'n_estimators': 170, 'min_samples_split': 7, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.05, 'max_features': 1.0, 'max_depth': 11, 'learning_rate': 0.05})
2023-07-03 11:01:53,024:INFO:Checking exceptions
2023-07-03 11:01:53,024:INFO:Importing libraries
2023-07-03 11:01:53,024:INFO:Copying training dataset
2023-07-03 11:01:53,029:INFO:Defining folds
2023-07-03 11:01:53,029:INFO:Declaring metric variables
2023-07-03 11:01:53,032:INFO:Importing untrained model
2023-07-03 11:01:53,032:INFO:Declaring custom model
2023-07-03 11:01:53,036:INFO:Gradient Boosting Regressor Imported successfully
2023-07-03 11:01:53,044:INFO:Starting cross validation
2023-07-03 11:01:53,045:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 11:01:56,662:INFO:Calculating mean and std
2023-07-03 11:01:56,663:INFO:Creating metrics dataframe
2023-07-03 11:01:56,668:INFO:Finalizing model
2023-07-03 11:01:58,046:INFO:Uploading results into container
2023-07-03 11:01:58,047:INFO:Uploading model into container now
2023-07-03 11:01:58,047:INFO:_master_model_container: 20
2023-07-03 11:01:58,047:INFO:_display_container: 4
2023-07-03 11:01:58,048:INFO:GradientBoostingRegressor(learning_rate=0.05, max_depth=11, max_features=1.0,
                          min_impurity_decrease=0.05, min_samples_split=7,
                          n_estimators=170, random_state=123, subsample=0.3)
2023-07-03 11:01:58,049:INFO:create_model() successfully completed......................................
2023-07-03 11:01:58,404:INFO:SubProcess create_model() end ==================================
2023-07-03 11:01:58,404:INFO:choose_better activated
2023-07-03 11:01:58,407:INFO:SubProcess create_model() called ==================================
2023-07-03 11:01:58,408:INFO:Initializing create_model()
2023-07-03 11:01:58,408:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021553A88AF0>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-03 11:01:58,408:INFO:Checking exceptions
2023-07-03 11:01:58,410:INFO:Importing libraries
2023-07-03 11:01:58,410:INFO:Copying training dataset
2023-07-03 11:01:58,415:INFO:Defining folds
2023-07-03 11:01:58,415:INFO:Declaring metric variables
2023-07-03 11:01:58,415:INFO:Importing untrained model
2023-07-03 11:01:58,415:INFO:Declaring custom model
2023-07-03 11:01:58,416:INFO:Gradient Boosting Regressor Imported successfully
2023-07-03 11:01:58,416:INFO:Starting cross validation
2023-07-03 11:01:58,418:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 11:02:02,000:INFO:Calculating mean and std
2023-07-03 11:02:02,001:INFO:Creating metrics dataframe
2023-07-03 11:02:02,003:INFO:Finalizing model
2023-07-03 11:02:02,683:INFO:Uploading results into container
2023-07-03 11:02:02,684:INFO:Uploading model into container now
2023-07-03 11:02:02,685:INFO:_master_model_container: 21
2023-07-03 11:02:02,685:INFO:_display_container: 5
2023-07-03 11:02:02,685:INFO:GradientBoostingRegressor(random_state=123)
2023-07-03 11:02:02,686:INFO:create_model() successfully completed......................................
2023-07-03 11:02:03,001:INFO:SubProcess create_model() end ==================================
2023-07-03 11:02:03,002:INFO:GradientBoostingRegressor(random_state=123) result for MAE is 3.328
2023-07-03 11:02:03,003:INFO:GradientBoostingRegressor(learning_rate=0.05, max_depth=11, max_features=1.0,
                          min_impurity_decrease=0.05, min_samples_split=7,
                          n_estimators=170, random_state=123, subsample=0.3) result for MAE is 2.5285
2023-07-03 11:02:03,003:INFO:GradientBoostingRegressor(learning_rate=0.05, max_depth=11, max_features=1.0,
                          min_impurity_decrease=0.05, min_samples_split=7,
                          n_estimators=170, random_state=123, subsample=0.3) is best model
2023-07-03 11:02:03,003:INFO:choose_better completed
2023-07-03 11:02:03,014:INFO:_master_model_container: 21
2023-07-03 11:02:03,014:INFO:_display_container: 4
2023-07-03 11:02:03,015:INFO:GradientBoostingRegressor(learning_rate=0.05, max_depth=11, max_features=1.0,
                          min_impurity_decrease=0.05, min_samples_split=7,
                          n_estimators=170, random_state=123, subsample=0.3)
2023-07-03 11:02:03,015:INFO:tune_model() successfully completed......................................
2023-07-03 11:13:01,731:INFO:Initializing tune_model()
2023-07-03 11:13:01,731:INFO:tune_model(estimator=GradientBoostingRegressor(random_state=123), fold=None, round=4, n_iter=50, custom_grid=None, optimize=mae, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021553A88AF0>)
2023-07-03 11:13:01,732:INFO:Checking exceptions
2023-07-03 11:13:01,746:INFO:Copying training dataset
2023-07-03 11:13:01,749:INFO:Checking base model
2023-07-03 11:13:01,749:INFO:Base model : Gradient Boosting Regressor
2023-07-03 11:13:01,752:INFO:Declaring metric variables
2023-07-03 11:13:01,755:INFO:Defining Hyperparameters
2023-07-03 11:13:02,055:INFO:Tuning with n_jobs=-1
2023-07-03 11:13:02,056:INFO:Initializing RandomizedSearchCV
2023-07-03 11:15:56,832:INFO:best_params: {'actual_estimator__subsample': 0.3, 'actual_estimator__n_estimators': 170, 'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 1, 'actual_estimator__min_impurity_decrease': 0.05, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 11, 'actual_estimator__learning_rate': 0.05}
2023-07-03 11:15:56,832:INFO:Hyperparameter search completed
2023-07-03 11:15:56,833:INFO:SubProcess create_model() called ==================================
2023-07-03 11:15:56,833:INFO:Initializing create_model()
2023-07-03 11:15:56,833:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021553A88AF0>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002154D900730>, model_only=True, return_train_score=False, kwargs={'subsample': 0.3, 'n_estimators': 170, 'min_samples_split': 7, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.05, 'max_features': 1.0, 'max_depth': 11, 'learning_rate': 0.05})
2023-07-03 11:15:56,833:INFO:Checking exceptions
2023-07-03 11:15:56,833:INFO:Importing libraries
2023-07-03 11:15:56,834:INFO:Copying training dataset
2023-07-03 11:15:56,838:INFO:Defining folds
2023-07-03 11:15:56,838:INFO:Declaring metric variables
2023-07-03 11:15:56,840:INFO:Importing untrained model
2023-07-03 11:15:56,840:INFO:Declaring custom model
2023-07-03 11:15:56,843:INFO:Gradient Boosting Regressor Imported successfully
2023-07-03 11:15:56,848:INFO:Starting cross validation
2023-07-03 11:15:56,849:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 11:16:00,139:INFO:Calculating mean and std
2023-07-03 11:16:00,140:INFO:Creating metrics dataframe
2023-07-03 11:16:00,145:INFO:Finalizing model
2023-07-03 11:16:00,699:INFO:Uploading results into container
2023-07-03 11:16:00,700:INFO:Uploading model into container now
2023-07-03 11:16:00,701:INFO:_master_model_container: 22
2023-07-03 11:16:00,701:INFO:_display_container: 5
2023-07-03 11:16:00,701:INFO:GradientBoostingRegressor(learning_rate=0.05, max_depth=11, max_features=1.0,
                          min_impurity_decrease=0.05, min_samples_split=7,
                          n_estimators=170, random_state=123, subsample=0.3)
2023-07-03 11:16:00,701:INFO:create_model() successfully completed......................................
2023-07-03 11:16:01,000:INFO:SubProcess create_model() end ==================================
2023-07-03 11:16:01,000:INFO:choose_better activated
2023-07-03 11:16:01,003:INFO:SubProcess create_model() called ==================================
2023-07-03 11:16:01,004:INFO:Initializing create_model()
2023-07-03 11:16:01,004:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021553A88AF0>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-03 11:16:01,004:INFO:Checking exceptions
2023-07-03 11:16:01,005:INFO:Importing libraries
2023-07-03 11:16:01,006:INFO:Copying training dataset
2023-07-03 11:16:01,009:INFO:Defining folds
2023-07-03 11:16:01,009:INFO:Declaring metric variables
2023-07-03 11:16:01,009:INFO:Importing untrained model
2023-07-03 11:16:01,009:INFO:Declaring custom model
2023-07-03 11:16:01,010:INFO:Gradient Boosting Regressor Imported successfully
2023-07-03 11:16:01,010:INFO:Starting cross validation
2023-07-03 11:16:01,011:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 11:16:04,268:INFO:Calculating mean and std
2023-07-03 11:16:04,268:INFO:Creating metrics dataframe
2023-07-03 11:16:04,270:INFO:Finalizing model
2023-07-03 11:16:04,811:INFO:Uploading results into container
2023-07-03 11:16:04,812:INFO:Uploading model into container now
2023-07-03 11:16:04,812:INFO:_master_model_container: 23
2023-07-03 11:16:04,812:INFO:_display_container: 6
2023-07-03 11:16:04,813:INFO:GradientBoostingRegressor(random_state=123)
2023-07-03 11:16:04,813:INFO:create_model() successfully completed......................................
2023-07-03 11:16:05,109:INFO:SubProcess create_model() end ==================================
2023-07-03 11:16:05,110:INFO:GradientBoostingRegressor(random_state=123) result for MAE is 3.328
2023-07-03 11:16:05,111:INFO:GradientBoostingRegressor(learning_rate=0.05, max_depth=11, max_features=1.0,
                          min_impurity_decrease=0.05, min_samples_split=7,
                          n_estimators=170, random_state=123, subsample=0.3) result for MAE is 2.5285
2023-07-03 11:16:05,112:INFO:GradientBoostingRegressor(learning_rate=0.05, max_depth=11, max_features=1.0,
                          min_impurity_decrease=0.05, min_samples_split=7,
                          n_estimators=170, random_state=123, subsample=0.3) is best model
2023-07-03 11:16:05,112:INFO:choose_better completed
2023-07-03 11:16:05,118:INFO:_master_model_container: 23
2023-07-03 11:16:05,118:INFO:_display_container: 5
2023-07-03 11:16:05,119:INFO:GradientBoostingRegressor(learning_rate=0.05, max_depth=11, max_features=1.0,
                          min_impurity_decrease=0.05, min_samples_split=7,
                          n_estimators=170, random_state=123, subsample=0.3)
2023-07-03 11:16:05,119:INFO:tune_model() successfully completed......................................
2023-07-03 11:16:05,735:INFO:Initializing tune_model()
2023-07-03 11:16:05,736:INFO:tune_model(estimator=GradientBoostingRegressor(random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021553A88AF0>)
2023-07-03 11:16:05,736:INFO:Checking exceptions
2023-07-03 11:16:05,751:INFO:Copying training dataset
2023-07-03 11:16:05,754:INFO:Checking base model
2023-07-03 11:16:05,754:INFO:Base model : Gradient Boosting Regressor
2023-07-03 11:16:05,757:INFO:Declaring metric variables
2023-07-03 11:16:05,760:INFO:Defining Hyperparameters
2023-07-03 11:16:06,047:INFO:Tuning with n_jobs=-1
2023-07-03 11:16:06,047:INFO:Initializing RandomizedSearchCV
2023-07-03 11:16:39,928:INFO:best_params: {'actual_estimator__subsample': 0.85, 'actual_estimator__n_estimators': 230, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.02, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 7, 'actual_estimator__learning_rate': 0.15}
2023-07-03 11:16:39,929:INFO:Hyperparameter search completed
2023-07-03 11:16:39,929:INFO:SubProcess create_model() called ==================================
2023-07-03 11:16:39,929:INFO:Initializing create_model()
2023-07-03 11:16:39,929:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021553A88AF0>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021553730AC0>, model_only=True, return_train_score=False, kwargs={'subsample': 0.85, 'n_estimators': 230, 'min_samples_split': 5, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.02, 'max_features': 1.0, 'max_depth': 7, 'learning_rate': 0.15})
2023-07-03 11:16:39,929:INFO:Checking exceptions
2023-07-03 11:16:39,930:INFO:Importing libraries
2023-07-03 11:16:39,930:INFO:Copying training dataset
2023-07-03 11:16:39,934:INFO:Defining folds
2023-07-03 11:16:39,934:INFO:Declaring metric variables
2023-07-03 11:16:39,937:INFO:Importing untrained model
2023-07-03 11:16:39,937:INFO:Declaring custom model
2023-07-03 11:16:39,941:INFO:Gradient Boosting Regressor Imported successfully
2023-07-03 11:16:39,946:INFO:Starting cross validation
2023-07-03 11:16:39,947:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 11:16:43,251:INFO:Calculating mean and std
2023-07-03 11:16:43,252:INFO:Creating metrics dataframe
2023-07-03 11:16:43,257:INFO:Finalizing model
2023-07-03 11:16:44,318:INFO:Uploading results into container
2023-07-03 11:16:44,318:INFO:Uploading model into container now
2023-07-03 11:16:44,319:INFO:_master_model_container: 24
2023-07-03 11:16:44,319:INFO:_display_container: 6
2023-07-03 11:16:44,320:INFO:GradientBoostingRegressor(learning_rate=0.15, max_depth=7, max_features=1.0,
                          min_impurity_decrease=0.02, min_samples_leaf=5,
                          min_samples_split=5, n_estimators=230,
                          random_state=123, subsample=0.85)
2023-07-03 11:16:44,320:INFO:create_model() successfully completed......................................
2023-07-03 11:16:44,606:INFO:SubProcess create_model() end ==================================
2023-07-03 11:16:44,606:INFO:choose_better activated
2023-07-03 11:16:44,610:INFO:SubProcess create_model() called ==================================
2023-07-03 11:16:44,610:INFO:Initializing create_model()
2023-07-03 11:16:44,610:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021553A88AF0>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-03 11:16:44,610:INFO:Checking exceptions
2023-07-03 11:16:44,612:INFO:Importing libraries
2023-07-03 11:16:44,612:INFO:Copying training dataset
2023-07-03 11:16:44,615:INFO:Defining folds
2023-07-03 11:16:44,616:INFO:Declaring metric variables
2023-07-03 11:16:44,616:INFO:Importing untrained model
2023-07-03 11:16:44,616:INFO:Declaring custom model
2023-07-03 11:16:44,616:INFO:Gradient Boosting Regressor Imported successfully
2023-07-03 11:16:44,616:INFO:Starting cross validation
2023-07-03 11:16:44,617:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 11:16:47,884:INFO:Calculating mean and std
2023-07-03 11:16:47,884:INFO:Creating metrics dataframe
2023-07-03 11:16:47,886:INFO:Finalizing model
2023-07-03 11:16:48,428:INFO:Uploading results into container
2023-07-03 11:16:48,429:INFO:Uploading model into container now
2023-07-03 11:16:48,429:INFO:_master_model_container: 25
2023-07-03 11:16:48,430:INFO:_display_container: 7
2023-07-03 11:16:48,430:INFO:GradientBoostingRegressor(random_state=123)
2023-07-03 11:16:48,430:INFO:create_model() successfully completed......................................
2023-07-03 11:16:48,728:INFO:SubProcess create_model() end ==================================
2023-07-03 11:16:48,729:INFO:GradientBoostingRegressor(random_state=123) result for R2 is 0.9941
2023-07-03 11:16:48,729:INFO:GradientBoostingRegressor(learning_rate=0.15, max_depth=7, max_features=1.0,
                          min_impurity_decrease=0.02, min_samples_leaf=5,
                          min_samples_split=5, n_estimators=230,
                          random_state=123, subsample=0.85) result for R2 is 0.994
2023-07-03 11:16:48,729:INFO:GradientBoostingRegressor(random_state=123) is best model
2023-07-03 11:16:48,729:INFO:choose_better completed
2023-07-03 11:16:48,729:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-07-03 11:16:48,737:INFO:_master_model_container: 25
2023-07-03 11:16:48,737:INFO:_display_container: 6
2023-07-03 11:16:48,738:INFO:GradientBoostingRegressor(random_state=123)
2023-07-03 11:16:48,738:INFO:tune_model() successfully completed......................................
2023-07-03 14:36:26,978:INFO:Initializing tune_model()
2023-07-03 14:36:26,979:INFO:tune_model(estimator=GradientBoostingRegressor(random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=True, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021553A88AF0>)
2023-07-03 14:36:26,979:INFO:Checking exceptions
2023-07-03 14:36:26,993:INFO:Copying training dataset
2023-07-03 14:36:26,996:INFO:Checking base model
2023-07-03 14:36:26,997:INFO:Base model : Gradient Boosting Regressor
2023-07-03 14:36:27,000:INFO:Declaring metric variables
2023-07-03 14:36:27,002:INFO:Defining Hyperparameters
2023-07-03 14:36:27,293:INFO:Tuning with n_jobs=-1
2023-07-03 14:36:27,293:INFO:Initializing RandomizedSearchCV
2023-07-03 14:37:08,906:INFO:best_params: {'actual_estimator__subsample': 0.85, 'actual_estimator__n_estimators': 230, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.02, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 7, 'actual_estimator__learning_rate': 0.15}
2023-07-03 14:37:08,907:INFO:Hyperparameter search completed
2023-07-03 14:37:08,907:INFO:SubProcess create_model() called ==================================
2023-07-03 14:37:08,908:INFO:Initializing create_model()
2023-07-03 14:37:08,908:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021553A88AF0>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002155249E110>, model_only=True, return_train_score=False, kwargs={'subsample': 0.85, 'n_estimators': 230, 'min_samples_split': 5, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.02, 'max_features': 1.0, 'max_depth': 7, 'learning_rate': 0.15})
2023-07-03 14:37:08,908:INFO:Checking exceptions
2023-07-03 14:37:08,908:INFO:Importing libraries
2023-07-03 14:37:08,908:INFO:Copying training dataset
2023-07-03 14:37:08,912:INFO:Defining folds
2023-07-03 14:37:08,912:INFO:Declaring metric variables
2023-07-03 14:37:08,915:INFO:Importing untrained model
2023-07-03 14:37:08,915:INFO:Declaring custom model
2023-07-03 14:37:08,918:INFO:Gradient Boosting Regressor Imported successfully
2023-07-03 14:37:08,923:INFO:Starting cross validation
2023-07-03 14:37:08,924:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 14:37:12,408:INFO:Calculating mean and std
2023-07-03 14:37:12,409:INFO:Creating metrics dataframe
2023-07-03 14:37:12,415:INFO:Finalizing model
2023-07-03 14:37:12,991:INFO:Uploading results into container
2023-07-03 14:37:12,992:INFO:Uploading model into container now
2023-07-03 14:37:12,993:INFO:_master_model_container: 26
2023-07-03 14:37:12,993:INFO:_display_container: 7
2023-07-03 14:37:12,994:INFO:GradientBoostingRegressor(learning_rate=0.15, max_depth=7, max_features=1.0,
                          min_impurity_decrease=0.02, min_samples_leaf=5,
                          min_samples_split=5, n_estimators=230,
                          random_state=123, subsample=0.85)
2023-07-03 14:37:12,994:INFO:create_model() successfully completed......................................
2023-07-03 14:37:13,298:INFO:SubProcess create_model() end ==================================
2023-07-03 14:37:13,298:INFO:choose_better activated
2023-07-03 14:37:13,301:INFO:SubProcess create_model() called ==================================
2023-07-03 14:37:13,301:INFO:Initializing create_model()
2023-07-03 14:37:13,301:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021553A88AF0>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-03 14:37:13,301:INFO:Checking exceptions
2023-07-03 14:37:13,303:INFO:Importing libraries
2023-07-03 14:37:13,303:INFO:Copying training dataset
2023-07-03 14:37:13,306:INFO:Defining folds
2023-07-03 14:37:13,306:INFO:Declaring metric variables
2023-07-03 14:37:13,306:INFO:Importing untrained model
2023-07-03 14:37:13,306:INFO:Declaring custom model
2023-07-03 14:37:13,307:INFO:Gradient Boosting Regressor Imported successfully
2023-07-03 14:37:13,307:INFO:Starting cross validation
2023-07-03 14:37:13,308:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 14:37:16,682:INFO:Calculating mean and std
2023-07-03 14:37:16,683:INFO:Creating metrics dataframe
2023-07-03 14:37:16,684:INFO:Finalizing model
2023-07-03 14:37:17,247:INFO:Uploading results into container
2023-07-03 14:37:17,248:INFO:Uploading model into container now
2023-07-03 14:37:17,248:INFO:_master_model_container: 27
2023-07-03 14:37:17,248:INFO:_display_container: 8
2023-07-03 14:37:17,249:INFO:GradientBoostingRegressor(random_state=123)
2023-07-03 14:37:17,249:INFO:create_model() successfully completed......................................
2023-07-03 14:37:17,550:INFO:SubProcess create_model() end ==================================
2023-07-03 14:37:17,551:INFO:GradientBoostingRegressor(random_state=123) result for R2 is 0.9941
2023-07-03 14:37:17,552:INFO:GradientBoostingRegressor(learning_rate=0.15, max_depth=7, max_features=1.0,
                          min_impurity_decrease=0.02, min_samples_leaf=5,
                          min_samples_split=5, n_estimators=230,
                          random_state=123, subsample=0.85) result for R2 is 0.994
2023-07-03 14:37:17,552:INFO:GradientBoostingRegressor(random_state=123) is best model
2023-07-03 14:37:17,552:INFO:choose_better completed
2023-07-03 14:37:17,552:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-07-03 14:37:17,559:INFO:_master_model_container: 27
2023-07-03 14:37:17,559:INFO:_display_container: 7
2023-07-03 14:37:17,560:INFO:GradientBoostingRegressor(random_state=123)
2023-07-03 14:37:17,560:INFO:tune_model() successfully completed......................................
2023-07-03 14:37:37,907:INFO:Initializing plot_model()
2023-07-03 14:37:37,907:INFO:plot_model(plot=residuals, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021553A88AF0>, system=True)
2023-07-03 14:37:37,907:INFO:Checking exceptions
2023-07-03 14:37:37,910:INFO:Preloading libraries
2023-07-03 14:37:37,916:INFO:Copying training dataset
2023-07-03 14:37:37,917:INFO:Plot type: residuals
2023-07-03 14:37:38,087:INFO:Fitting Model
2023-07-03 14:37:38,088:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\base.py:420: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names
  warnings.warn(

2023-07-03 14:37:38,120:INFO:Scoring test/hold-out set
2023-07-03 14:37:38,607:INFO:Visual Rendered Successfully
2023-07-03 14:37:38,908:INFO:plot_model() successfully completed......................................
2023-07-03 14:37:42,378:INFO:Initializing plot_model()
2023-07-03 14:37:42,378:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021553A88AF0>, system=True)
2023-07-03 14:37:42,378:INFO:Checking exceptions
2023-07-03 14:37:42,382:INFO:Preloading libraries
2023-07-03 14:37:42,388:INFO:Copying training dataset
2023-07-03 14:37:42,388:INFO:Plot type: error
2023-07-03 14:37:42,522:INFO:Fitting Model
2023-07-03 14:37:42,523:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\base.py:420: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names
  warnings.warn(

2023-07-03 14:37:42,523:INFO:Scoring test/hold-out set
2023-07-03 14:37:42,841:INFO:Visual Rendered Successfully
2023-07-03 14:37:43,132:INFO:plot_model() successfully completed......................................
2023-07-03 14:37:45,401:INFO:Initializing plot_model()
2023-07-03 14:37:45,402:INFO:plot_model(plot=cooks, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021553A88AF0>, system=True)
2023-07-03 14:37:45,402:INFO:Checking exceptions
2023-07-03 14:37:45,406:INFO:Preloading libraries
2023-07-03 14:37:45,412:INFO:Copying training dataset
2023-07-03 14:37:45,412:INFO:Plot type: cooks
2023-07-03 14:37:45,545:INFO:Fitting Model
2023-07-03 14:37:45,746:INFO:Visual Rendered Successfully
2023-07-03 14:37:46,040:INFO:plot_model() successfully completed......................................
2023-07-03 14:37:48,273:INFO:Initializing plot_model()
2023-07-03 14:37:48,273:INFO:plot_model(plot=rfe, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021553A88AF0>, system=True)
2023-07-03 14:37:48,273:INFO:Checking exceptions
2023-07-03 14:37:48,277:INFO:Preloading libraries
2023-07-03 14:37:48,284:INFO:Copying training dataset
2023-07-03 14:37:48,284:INFO:Plot type: rfe
2023-07-03 14:37:48,418:INFO:Fitting Model
2023-07-03 14:38:23,274:INFO:Visual Rendered Successfully
2023-07-03 14:38:23,558:INFO:plot_model() successfully completed......................................
2023-07-03 14:38:29,784:INFO:Initializing plot_model()
2023-07-03 14:38:29,784:INFO:plot_model(plot=learning, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021553A88AF0>, system=True)
2023-07-03 14:38:29,784:INFO:Checking exceptions
2023-07-03 14:38:29,788:INFO:Preloading libraries
2023-07-03 14:38:29,794:INFO:Copying training dataset
2023-07-03 14:38:29,795:INFO:Plot type: learning
2023-07-03 14:38:29,930:INFO:Fitting Model
2023-07-03 14:38:31,505:INFO:Visual Rendered Successfully
2023-07-03 14:38:31,794:INFO:plot_model() successfully completed......................................
2023-07-03 14:38:35,713:INFO:Initializing plot_model()
2023-07-03 14:38:35,713:INFO:plot_model(plot=vc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021553A88AF0>, system=True)
2023-07-03 14:38:35,713:INFO:Checking exceptions
2023-07-03 14:38:35,717:INFO:Preloading libraries
2023-07-03 14:38:35,724:INFO:Copying training dataset
2023-07-03 14:38:35,724:INFO:Plot type: vc
2023-07-03 14:38:35,724:INFO:Determining param_name
2023-07-03 14:38:35,724:INFO:param_name: alpha
2023-07-03 14:38:35,857:INFO:Fitting Model
2023-07-03 14:38:37,657:INFO:Visual Rendered Successfully
2023-07-03 14:38:37,948:INFO:plot_model() successfully completed......................................
2023-07-03 14:38:42,487:INFO:Initializing plot_model()
2023-07-03 14:38:42,488:INFO:plot_model(plot=manifold, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021553A88AF0>, system=True)
2023-07-03 14:38:42,488:INFO:Checking exceptions
2023-07-03 14:38:42,491:INFO:Preloading libraries
2023-07-03 14:38:42,498:INFO:Copying training dataset
2023-07-03 14:38:42,498:INFO:Plot type: manifold
2023-07-03 14:38:42,647:INFO:Fitting & Transforming Model
2023-07-03 14:38:45,078:INFO:Visual Rendered Successfully
2023-07-03 14:38:45,374:INFO:plot_model() successfully completed......................................
2023-07-03 14:38:51,073:INFO:Initializing plot_model()
2023-07-03 14:38:51,073:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021553A88AF0>, system=True)
2023-07-03 14:38:51,073:INFO:Checking exceptions
2023-07-03 14:38:51,077:INFO:Preloading libraries
2023-07-03 14:38:51,084:INFO:Copying training dataset
2023-07-03 14:38:51,084:INFO:Plot type: feature
2023-07-03 14:38:51,084:WARNING:No coef_ found. Trying feature_importances_
2023-07-03 14:38:51,223:INFO:Visual Rendered Successfully
2023-07-03 14:38:51,519:INFO:plot_model() successfully completed......................................
2023-07-03 14:38:57,940:INFO:Initializing evaluate_model()
2023-07-03 14:38:57,940:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021553A88AF0>, estimator=GradientBoostingRegressor(random_state=123), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-07-03 14:38:57,956:INFO:Initializing plot_model()
2023-07-03 14:38:57,957:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021553A88AF0>, system=True)
2023-07-03 14:38:57,957:INFO:Checking exceptions
2023-07-03 14:38:57,961:INFO:Preloading libraries
2023-07-03 14:38:57,968:INFO:Copying training dataset
2023-07-03 14:38:57,969:INFO:Plot type: pipeline
2023-07-03 14:38:58,082:INFO:Visual Rendered Successfully
2023-07-03 14:38:58,392:INFO:plot_model() successfully completed......................................
2023-07-03 14:39:04,073:INFO:Initializing finalize_model()
2023-07-03 14:39:04,073:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021553A88AF0>, estimator=GradientBoostingRegressor(random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-07-03 14:39:04,073:INFO:Finalizing GradientBoostingRegressor(random_state=123)
2023-07-03 14:39:04,077:INFO:Initializing create_model()
2023-07-03 14:39:04,077:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021553A88AF0>, estimator=GradientBoostingRegressor(random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-07-03 14:39:04,077:INFO:Checking exceptions
2023-07-03 14:39:04,079:INFO:Importing libraries
2023-07-03 14:39:04,079:INFO:Copying training dataset
2023-07-03 14:39:04,079:INFO:Defining folds
2023-07-03 14:39:04,079:INFO:Declaring metric variables
2023-07-03 14:39:04,079:INFO:Importing untrained model
2023-07-03 14:39:04,079:INFO:Declaring custom model
2023-07-03 14:39:04,080:INFO:Gradient Boosting Regressor Imported successfully
2023-07-03 14:39:04,081:INFO:Cross validation set to False
2023-07-03 14:39:04,081:INFO:Fitting Model
2023-07-03 14:39:05,534:INFO:Pipeline(memory=FastMemory(location=C:\Users\JHossain\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['User_ID', 'Age', 'Height',
                                             'Weight', 'Duration', 'Heart_Rate',
                                             'Body_Temp'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 TransformerWrapper(include=['Gender'],
                                    transformer=OrdinalEncoder(cols=['Gender'],
                                                               handle_missing='return_nan',
                                                               mapping=[{'col': 'Gender',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': female    0
male      1
NaN      -1
dtype: int64}]))),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=123))])
2023-07-03 14:39:05,534:INFO:create_model() successfully completed......................................
2023-07-03 14:39:05,821:INFO:_master_model_container: 27
2023-07-03 14:39:05,821:INFO:_display_container: 7
2023-07-03 14:39:05,838:INFO:Pipeline(memory=FastMemory(location=C:\Users\JHossain\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['User_ID', 'Age', 'Height',
                                             'Weight', 'Duration', 'Heart_Rate',
                                             'Body_Temp'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 TransformerWrapper(include=['Gender'],
                                    transformer=OrdinalEncoder(cols=['Gender'],
                                                               handle_missing='return_nan',
                                                               mapping=[{'col': 'Gender',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': female    0
male      1
NaN      -1
dtype: int64}]))),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=123))])
2023-07-03 14:39:05,838:INFO:finalize_model() successfully completed......................................
2023-07-03 14:39:09,445:INFO:Initializing predict_model()
2023-07-03 14:39:09,446:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021553A88AF0>, estimator=GradientBoostingRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002155A873F40>)
2023-07-03 14:39:09,446:INFO:Checking exceptions
2023-07-03 14:39:09,446:INFO:Preloading libraries
2023-07-03 14:39:59,610:INFO:Initializing predict_model()
2023-07-03 14:39:59,611:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021553A88AF0>, estimator=GradientBoostingRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002155A870AF0>)
2023-07-03 14:39:59,611:INFO:Checking exceptions
2023-07-03 14:39:59,611:INFO:Preloading libraries
2023-07-03 14:39:59,613:INFO:Set up data.
2023-07-03 14:39:59,617:INFO:Set up index.
2023-07-03 14:40:07,734:INFO:Initializing interpret_model()
2023-07-03 14:40:07,735:INFO:interpret_model(estimator=GradientBoostingRegressor(random_state=123), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021553A88AF0>)
2023-07-03 14:40:07,735:INFO:Checking exceptions
2023-07-03 14:40:07,735:INFO:Soft dependency imported: shap: 0.41.0
2023-07-03 14:40:51,613:INFO:Initializing interpret_model()
2023-07-03 14:40:51,613:INFO:interpret_model(estimator=GradientBoostingRegressor(random_state=123), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021553A88AF0>)
2023-07-03 14:40:51,613:INFO:Checking exceptions
2023-07-03 14:40:51,613:INFO:Soft dependency imported: shap: 0.41.0
2023-07-03 14:40:59,454:INFO:Initializing interpret_model()
2023-07-03 14:40:59,454:INFO:interpret_model(estimator=GradientBoostingRegressor(random_state=123), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=correlation, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021553A88AF0>)
2023-07-03 14:40:59,454:INFO:Checking exceptions
2023-07-03 14:40:59,454:INFO:Soft dependency imported: shap: 0.41.0
2023-07-03 14:42:51,043:INFO:Initializing save_model()
2023-07-03 14:42:51,043:INFO:save_model(model=GradientBoostingRegressor(random_state=123), model_name=../models/calories, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JHossain\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['User_ID', 'Age', 'Height',
                                             'Weight', 'Duration', 'Heart_Rate',
                                             'Body_Temp'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 TransformerWrapper(include=['Gender'],
                                    transformer=OrdinalEncoder(cols=['Gender'],
                                                               handle_missing='return_nan',
                                                               mapping=[{'col': 'Gender',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': female    0
male      1
NaN      -1
dtype: int64}])))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-07-03 14:42:51,043:INFO:Adding model into prep_pipe
2023-07-03 14:42:51,051:INFO:../models/calories.pkl saved in current working directory
2023-07-03 14:42:51,076:INFO:Pipeline(memory=FastMemory(location=C:\Users\JHossain\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['User_ID', 'Age', 'Height',
                                             'Weight', 'Duration', 'Heart_Rate',
                                             'Body_Temp'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 TransformerWrapper(include=['Gender'],
                                    transformer=OrdinalEncoder(cols=['Gender'],
                                                               handle_missing='return_nan',
                                                               mapping=[{'col': 'Gender',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': female    0
male      1
NaN      -1
dtype: int64}]))),
                ('trained_model', GradientBoostingRegressor(random_state=123))])
2023-07-03 14:42:51,076:INFO:save_model() successfully completed......................................
2023-07-03 14:42:53,998:INFO:Initializing load_model()
2023-07-03 14:42:53,999:INFO:load_model(model_name=../models/calories, platform=None, authentication=None, verbose=True)
2023-07-03 14:43:00,149:INFO:Initializing predict_model()
2023-07-03 14:43:00,149:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021553A88AF0>, estimator=GradientBoostingRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021556A5AA70>)
2023-07-03 14:43:00,149:INFO:Checking exceptions
2023-07-03 14:43:00,149:INFO:Preloading libraries
2023-07-03 14:59:37,930:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-03 14:59:37,930:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-03 14:59:37,930:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-03 14:59:37,930:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-03 14:59:38,829:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-07-03 14:59:39,277:INFO:PyCaret ClassificationExperiment
2023-07-03 14:59:39,278:INFO:Logging name: clf-default-name
2023-07-03 14:59:39,278:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-07-03 14:59:39,278:INFO:version 3.0.2
2023-07-03 14:59:39,278:INFO:Initializing setup()
2023-07-03 14:59:39,278:INFO:self.USI: cfc4
2023-07-03 14:59:39,278:INFO:self._variable_keys: {'y_test', 'pipeline', 'y', 'fix_imbalance', 'X_test', 'fold_groups_param', 'USI', 'n_jobs_param', 'html_param', 'log_plots_param', 'idx', 'exp_name_log', 'gpu_param', 'memory', 'target_param', 'gpu_n_jobs_param', '_ml_usecase', 'fold_generator', 'exp_id', 'data', 'fold_shuffle_param', 'X_train', 'X', 'logging_param', 'seed', 'is_multiclass', '_available_plots', 'y_train'}
2023-07-03 14:59:39,278:INFO:Checking environment
2023-07-03 14:59:39,278:INFO:python_version: 3.10.9
2023-07-03 14:59:39,278:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2023-07-03 14:59:39,278:INFO:machine: AMD64
2023-07-03 14:59:39,278:INFO:platform: Windows-10-10.0.22621-SP0
2023-07-03 14:59:39,282:INFO:Memory: svmem(total=33664483328, available=20940005376, percent=37.8, used=12724477952, free=20940005376)
2023-07-03 14:59:39,282:INFO:Physical Core: 6
2023-07-03 14:59:39,282:INFO:Logical Core: 12
2023-07-03 14:59:39,282:INFO:Checking libraries
2023-07-03 14:59:39,282:INFO:System:
2023-07-03 14:59:39,282:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2023-07-03 14:59:39,282:INFO:executable: C:\Users\JHossain\anaconda3\python.exe
2023-07-03 14:59:39,283:INFO:   machine: Windows-10-10.0.22621-SP0
2023-07-03 14:59:39,283:INFO:PyCaret required dependencies:
2023-07-03 14:59:39,283:INFO:                 pip: 22.3.1
2023-07-03 14:59:39,283:INFO:          setuptools: 65.6.3
2023-07-03 14:59:39,283:INFO:             pycaret: 3.0.2
2023-07-03 14:59:39,283:INFO:             IPython: 8.10.0
2023-07-03 14:59:39,283:INFO:          ipywidgets: 7.6.5
2023-07-03 14:59:39,283:INFO:                tqdm: 4.64.1
2023-07-03 14:59:39,283:INFO:               numpy: 1.23.5
2023-07-03 14:59:39,283:INFO:              pandas: 1.5.3
2023-07-03 14:59:39,283:INFO:              jinja2: 3.1.2
2023-07-03 14:59:39,283:INFO:               scipy: 1.10.0
2023-07-03 14:59:39,283:INFO:              joblib: 1.2.0
2023-07-03 14:59:39,283:INFO:             sklearn: 1.2.1
2023-07-03 14:59:39,283:INFO:                pyod: 1.0.9
2023-07-03 14:59:39,283:INFO:            imblearn: 0.10.1
2023-07-03 14:59:39,283:INFO:   category_encoders: 2.6.1
2023-07-03 14:59:39,283:INFO:            lightgbm: 3.3.5
2023-07-03 14:59:39,283:INFO:               numba: 0.56.4
2023-07-03 14:59:39,283:INFO:            requests: 2.28.1
2023-07-03 14:59:39,283:INFO:          matplotlib: 3.7.0
2023-07-03 14:59:39,283:INFO:          scikitplot: 0.3.7
2023-07-03 14:59:39,283:INFO:         yellowbrick: 1.5
2023-07-03 14:59:39,283:INFO:              plotly: 5.9.0
2023-07-03 14:59:39,283:INFO:             kaleido: 0.2.1
2023-07-03 14:59:39,283:INFO:         statsmodels: 0.13.5
2023-07-03 14:59:39,283:INFO:              sktime: 0.17.0
2023-07-03 14:59:39,284:INFO:               tbats: 1.1.3
2023-07-03 14:59:39,284:INFO:            pmdarima: 2.0.3
2023-07-03 14:59:39,284:INFO:              psutil: 5.9.0
2023-07-03 14:59:39,284:INFO:PyCaret optional dependencies:
2023-07-03 14:59:40,248:INFO:                shap: 0.41.0
2023-07-03 14:59:40,248:INFO:           interpret: 0.4.2
2023-07-03 14:59:40,248:INFO:                umap: Not installed
2023-07-03 14:59:40,248:INFO:    pandas_profiling: Not installed
2023-07-03 14:59:40,248:INFO:  explainerdashboard: Not installed
2023-07-03 14:59:40,248:INFO:             autoviz: Not installed
2023-07-03 14:59:40,248:INFO:           fairlearn: Not installed
2023-07-03 14:59:40,248:INFO:             xgboost: Not installed
2023-07-03 14:59:40,248:INFO:            catboost: Not installed
2023-07-03 14:59:40,248:INFO:              kmodes: Not installed
2023-07-03 14:59:40,248:INFO:             mlxtend: Not installed
2023-07-03 14:59:40,248:INFO:       statsforecast: Not installed
2023-07-03 14:59:40,248:INFO:        tune_sklearn: Not installed
2023-07-03 14:59:40,248:INFO:                 ray: Not installed
2023-07-03 14:59:40,248:INFO:            hyperopt: Not installed
2023-07-03 14:59:40,248:INFO:              optuna: Not installed
2023-07-03 14:59:40,248:INFO:               skopt: Not installed
2023-07-03 14:59:40,248:INFO:              mlflow: Not installed
2023-07-03 14:59:40,249:INFO:              gradio: 3.35.2
2023-07-03 14:59:40,249:INFO:             fastapi: 0.99.0
2023-07-03 14:59:40,249:INFO:             uvicorn: 0.22.0
2023-07-03 14:59:40,249:INFO:              m2cgen: Not installed
2023-07-03 14:59:40,249:INFO:           evidently: Not installed
2023-07-03 14:59:40,249:INFO:               fugue: Not installed
2023-07-03 14:59:40,249:INFO:           streamlit: Not installed
2023-07-03 14:59:40,249:INFO:             prophet: Not installed
2023-07-03 14:59:40,249:INFO:None
2023-07-03 14:59:40,249:INFO:Set up data.
2023-07-03 14:59:40,259:INFO:Set up train/test split.
2023-07-03 14:59:40,263:INFO:Set up index.
2023-07-03 14:59:40,263:INFO:Set up folding strategy.
2023-07-03 14:59:40,263:INFO:Assigning column types.
2023-07-03 14:59:40,266:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-07-03 14:59:40,306:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-03 14:59:40,309:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-03 14:59:40,339:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 14:59:40,498:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 14:59:40,536:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-03 14:59:40,537:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-03 14:59:40,561:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 14:59:40,561:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 14:59:40,561:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-07-03 14:59:40,600:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-03 14:59:40,624:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 14:59:40,624:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 14:59:40,664:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-03 14:59:40,688:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 14:59:40,688:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 14:59:40,688:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-07-03 14:59:40,751:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 14:59:40,751:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 14:59:40,826:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 14:59:40,827:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 14:59:40,829:INFO:Preparing preprocessing pipeline...
2023-07-03 14:59:40,830:INFO:Set up label encoding.
2023-07-03 14:59:40,830:INFO:Set up simple imputation.
2023-07-03 14:59:40,831:INFO:Set up column name cleaning.
2023-07-03 14:59:40,857:INFO:Finished creating preprocessing pipeline.
2023-07-03 14:59:40,863:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\JHossain\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['radius_mean', 'texture_mean',
                                             'perimeter_mean', 'area_mean',
                                             'smoothness_mean',
                                             'compactness_mean',
                                             'c...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-07-03 14:59:40,863:INFO:Creating final display dataframe.
2023-07-03 14:59:40,939:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target         diagnosis
2                   Target type            Binary
3                Target mapping        B: 0, M: 1
4           Original data shape         (569, 31)
5        Transformed data shape         (569, 31)
6   Transformed train set shape         (398, 31)
7    Transformed test set shape         (171, 31)
8              Numeric features                30
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator   StratifiedKFold
14                  Fold Number                10
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  clf-default-name
19                          USI              cfc4
2023-07-03 14:59:41,010:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 14:59:41,011:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 14:59:41,078:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 14:59:41,079:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 14:59:41,079:INFO:setup() successfully completed in 2.13s...............
2023-07-03 15:00:43,634:INFO:Initializing compare_models()
2023-07-03 15:00:43,634:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002224B6EC610>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002224B6EC610>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-07-03 15:00:43,634:INFO:Checking exceptions
2023-07-03 15:00:43,638:INFO:Preparing display monitor
2023-07-03 15:00:43,657:INFO:Initializing Logistic Regression
2023-07-03 15:00:43,658:INFO:Total runtime is 1.666545867919922e-05 minutes
2023-07-03 15:00:43,660:INFO:SubProcess create_model() called ==================================
2023-07-03 15:00:43,661:INFO:Initializing create_model()
2023-07-03 15:00:43,661:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002224B6EC610>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002224B95A8C0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 15:00:43,661:INFO:Checking exceptions
2023-07-03 15:00:43,661:INFO:Importing libraries
2023-07-03 15:00:43,661:INFO:Copying training dataset
2023-07-03 15:00:43,664:INFO:Defining folds
2023-07-03 15:00:43,664:INFO:Declaring metric variables
2023-07-03 15:00:43,667:INFO:Importing untrained model
2023-07-03 15:00:43,671:INFO:Logistic Regression Imported successfully
2023-07-03 15:00:43,676:INFO:Starting cross validation
2023-07-03 15:00:43,677:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 15:00:49,123:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-07-03 15:00:49,142:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-07-03 15:00:49,156:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-07-03 15:00:49,158:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-07-03 15:00:49,165:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-07-03 15:00:49,168:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-07-03 15:00:49,173:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-07-03 15:00:49,182:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-07-03 15:00:49,191:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-07-03 15:00:52,455:INFO:Calculating mean and std
2023-07-03 15:00:52,457:INFO:Creating metrics dataframe
2023-07-03 15:00:52,999:INFO:Uploading results into container
2023-07-03 15:00:53,000:INFO:Uploading model into container now
2023-07-03 15:00:53,000:INFO:_master_model_container: 1
2023-07-03 15:00:53,000:INFO:_display_container: 2
2023-07-03 15:00:53,001:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-03 15:00:53,001:INFO:create_model() successfully completed......................................
2023-07-03 15:00:53,337:INFO:SubProcess create_model() end ==================================
2023-07-03 15:00:53,337:INFO:Creating metrics dataframe
2023-07-03 15:00:53,346:INFO:Initializing K Neighbors Classifier
2023-07-03 15:00:53,346:INFO:Total runtime is 0.16147563457489014 minutes
2023-07-03 15:00:53,349:INFO:SubProcess create_model() called ==================================
2023-07-03 15:00:53,349:INFO:Initializing create_model()
2023-07-03 15:00:53,349:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002224B6EC610>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002224B95A8C0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 15:00:53,350:INFO:Checking exceptions
2023-07-03 15:00:53,350:INFO:Importing libraries
2023-07-03 15:00:53,350:INFO:Copying training dataset
2023-07-03 15:00:53,354:INFO:Defining folds
2023-07-03 15:00:53,354:INFO:Declaring metric variables
2023-07-03 15:00:53,357:INFO:Importing untrained model
2023-07-03 15:00:53,359:INFO:K Neighbors Classifier Imported successfully
2023-07-03 15:00:53,366:INFO:Starting cross validation
2023-07-03 15:00:53,367:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 15:00:57,150:INFO:Calculating mean and std
2023-07-03 15:00:57,151:INFO:Creating metrics dataframe
2023-07-03 15:00:57,683:INFO:Uploading results into container
2023-07-03 15:00:57,683:INFO:Uploading model into container now
2023-07-03 15:00:57,684:INFO:_master_model_container: 2
2023-07-03 15:00:57,684:INFO:_display_container: 2
2023-07-03 15:00:57,684:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-07-03 15:00:57,685:INFO:create_model() successfully completed......................................
2023-07-03 15:00:58,041:INFO:SubProcess create_model() end ==================================
2023-07-03 15:00:58,042:INFO:Creating metrics dataframe
2023-07-03 15:00:58,051:INFO:Initializing Naive Bayes
2023-07-03 15:00:58,051:INFO:Total runtime is 0.23988384803136192 minutes
2023-07-03 15:00:58,054:INFO:SubProcess create_model() called ==================================
2023-07-03 15:00:58,054:INFO:Initializing create_model()
2023-07-03 15:00:58,054:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002224B6EC610>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002224B95A8C0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 15:00:58,054:INFO:Checking exceptions
2023-07-03 15:00:58,054:INFO:Importing libraries
2023-07-03 15:00:58,054:INFO:Copying training dataset
2023-07-03 15:00:58,058:INFO:Defining folds
2023-07-03 15:00:58,058:INFO:Declaring metric variables
2023-07-03 15:00:58,061:INFO:Importing untrained model
2023-07-03 15:00:58,063:INFO:Naive Bayes Imported successfully
2023-07-03 15:00:58,068:INFO:Starting cross validation
2023-07-03 15:00:58,070:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 15:01:01,366:INFO:Calculating mean and std
2023-07-03 15:01:01,367:INFO:Creating metrics dataframe
2023-07-03 15:01:01,901:INFO:Uploading results into container
2023-07-03 15:01:01,902:INFO:Uploading model into container now
2023-07-03 15:01:01,903:INFO:_master_model_container: 3
2023-07-03 15:01:01,903:INFO:_display_container: 2
2023-07-03 15:01:01,903:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-07-03 15:01:01,903:INFO:create_model() successfully completed......................................
2023-07-03 15:01:02,232:INFO:SubProcess create_model() end ==================================
2023-07-03 15:01:02,232:INFO:Creating metrics dataframe
2023-07-03 15:01:02,241:INFO:Initializing Decision Tree Classifier
2023-07-03 15:01:02,241:INFO:Total runtime is 0.3097293853759766 minutes
2023-07-03 15:01:02,243:INFO:SubProcess create_model() called ==================================
2023-07-03 15:01:02,244:INFO:Initializing create_model()
2023-07-03 15:01:02,244:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002224B6EC610>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002224B95A8C0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 15:01:02,244:INFO:Checking exceptions
2023-07-03 15:01:02,244:INFO:Importing libraries
2023-07-03 15:01:02,244:INFO:Copying training dataset
2023-07-03 15:01:02,247:INFO:Defining folds
2023-07-03 15:01:02,247:INFO:Declaring metric variables
2023-07-03 15:01:02,250:INFO:Importing untrained model
2023-07-03 15:01:02,253:INFO:Decision Tree Classifier Imported successfully
2023-07-03 15:01:02,258:INFO:Starting cross validation
2023-07-03 15:01:02,259:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 15:01:05,561:INFO:Calculating mean and std
2023-07-03 15:01:05,562:INFO:Creating metrics dataframe
2023-07-03 15:01:06,099:INFO:Uploading results into container
2023-07-03 15:01:06,100:INFO:Uploading model into container now
2023-07-03 15:01:06,100:INFO:_master_model_container: 4
2023-07-03 15:01:06,100:INFO:_display_container: 2
2023-07-03 15:01:06,100:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-07-03 15:01:06,101:INFO:create_model() successfully completed......................................
2023-07-03 15:01:06,465:INFO:SubProcess create_model() end ==================================
2023-07-03 15:01:06,465:INFO:Creating metrics dataframe
2023-07-03 15:01:06,474:INFO:Initializing SVM - Linear Kernel
2023-07-03 15:01:06,475:INFO:Total runtime is 0.3802878975868226 minutes
2023-07-03 15:01:06,477:INFO:SubProcess create_model() called ==================================
2023-07-03 15:01:06,478:INFO:Initializing create_model()
2023-07-03 15:01:06,478:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002224B6EC610>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002224B95A8C0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 15:01:06,478:INFO:Checking exceptions
2023-07-03 15:01:06,478:INFO:Importing libraries
2023-07-03 15:01:06,478:INFO:Copying training dataset
2023-07-03 15:01:06,482:INFO:Defining folds
2023-07-03 15:01:06,482:INFO:Declaring metric variables
2023-07-03 15:01:06,485:INFO:Importing untrained model
2023-07-03 15:01:06,488:INFO:SVM - Linear Kernel Imported successfully
2023-07-03 15:01:06,493:INFO:Starting cross validation
2023-07-03 15:01:06,494:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 15:01:06,583:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 15:01:06,587:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 15:01:06,587:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 15:01:06,601:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 15:01:06,609:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 15:01:06,615:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 15:01:06,615:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 15:01:06,624:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 15:01:06,630:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 15:01:06,637:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 15:01:09,929:INFO:Calculating mean and std
2023-07-03 15:01:09,930:INFO:Creating metrics dataframe
2023-07-03 15:01:10,458:INFO:Uploading results into container
2023-07-03 15:01:10,459:INFO:Uploading model into container now
2023-07-03 15:01:10,459:INFO:_master_model_container: 5
2023-07-03 15:01:10,459:INFO:_display_container: 2
2023-07-03 15:01:10,460:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-07-03 15:01:10,460:INFO:create_model() successfully completed......................................
2023-07-03 15:01:10,799:INFO:SubProcess create_model() end ==================================
2023-07-03 15:01:10,799:INFO:Creating metrics dataframe
2023-07-03 15:01:10,809:INFO:Initializing Ridge Classifier
2023-07-03 15:01:10,809:INFO:Total runtime is 0.4525204817454021 minutes
2023-07-03 15:01:10,812:INFO:SubProcess create_model() called ==================================
2023-07-03 15:01:10,812:INFO:Initializing create_model()
2023-07-03 15:01:10,812:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002224B6EC610>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002224B95A8C0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 15:01:10,812:INFO:Checking exceptions
2023-07-03 15:01:10,812:INFO:Importing libraries
2023-07-03 15:01:10,813:INFO:Copying training dataset
2023-07-03 15:01:10,816:INFO:Defining folds
2023-07-03 15:01:10,817:INFO:Declaring metric variables
2023-07-03 15:01:10,819:INFO:Importing untrained model
2023-07-03 15:01:10,822:INFO:Ridge Classifier Imported successfully
2023-07-03 15:01:10,827:INFO:Starting cross validation
2023-07-03 15:01:10,828:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 15:01:10,899:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.48848e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-07-03 15:01:10,900:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.07925e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-07-03 15:01:10,900:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.49328e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-07-03 15:01:10,908:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.60935e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-07-03 15:01:10,918:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.32091e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-07-03 15:01:10,924:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.93944e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-07-03 15:01:10,926:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 15:01:10,927:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.69502e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-07-03 15:01:10,927:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 15:01:10,928:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.99677e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-07-03 15:01:10,929:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 15:01:10,936:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.15972e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-07-03 15:01:10,936:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 15:01:10,944:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.68069e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-07-03 15:01:10,947:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 15:01:10,951:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 15:01:10,956:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 15:01:10,957:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 15:01:10,966:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 15:01:10,975:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 15:01:14,214:INFO:Calculating mean and std
2023-07-03 15:01:14,216:INFO:Creating metrics dataframe
2023-07-03 15:01:14,758:INFO:Uploading results into container
2023-07-03 15:01:14,759:INFO:Uploading model into container now
2023-07-03 15:01:14,759:INFO:_master_model_container: 6
2023-07-03 15:01:14,760:INFO:_display_container: 2
2023-07-03 15:01:14,760:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-07-03 15:01:14,760:INFO:create_model() successfully completed......................................
2023-07-03 15:01:15,107:INFO:SubProcess create_model() end ==================================
2023-07-03 15:01:15,108:INFO:Creating metrics dataframe
2023-07-03 15:01:15,118:INFO:Initializing Random Forest Classifier
2023-07-03 15:01:15,118:INFO:Total runtime is 0.524341376622518 minutes
2023-07-03 15:01:15,122:INFO:SubProcess create_model() called ==================================
2023-07-03 15:01:15,123:INFO:Initializing create_model()
2023-07-03 15:01:15,123:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002224B6EC610>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002224B95A8C0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 15:01:15,123:INFO:Checking exceptions
2023-07-03 15:01:15,123:INFO:Importing libraries
2023-07-03 15:01:15,123:INFO:Copying training dataset
2023-07-03 15:01:15,127:INFO:Defining folds
2023-07-03 15:01:15,129:INFO:Declaring metric variables
2023-07-03 15:01:15,132:INFO:Importing untrained model
2023-07-03 15:01:15,135:INFO:Random Forest Classifier Imported successfully
2023-07-03 15:01:15,141:INFO:Starting cross validation
2023-07-03 15:01:15,142:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 15:01:19,165:INFO:Calculating mean and std
2023-07-03 15:01:19,167:INFO:Creating metrics dataframe
2023-07-03 15:01:19,697:INFO:Uploading results into container
2023-07-03 15:01:19,698:INFO:Uploading model into container now
2023-07-03 15:01:19,698:INFO:_master_model_container: 7
2023-07-03 15:01:19,698:INFO:_display_container: 2
2023-07-03 15:01:19,699:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-07-03 15:01:19,699:INFO:create_model() successfully completed......................................
2023-07-03 15:01:20,038:INFO:SubProcess create_model() end ==================================
2023-07-03 15:01:20,038:INFO:Creating metrics dataframe
2023-07-03 15:01:20,047:INFO:Initializing Quadratic Discriminant Analysis
2023-07-03 15:01:20,047:INFO:Total runtime is 0.6064934690793357 minutes
2023-07-03 15:01:20,050:INFO:SubProcess create_model() called ==================================
2023-07-03 15:01:20,050:INFO:Initializing create_model()
2023-07-03 15:01:20,050:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002224B6EC610>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002224B95A8C0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 15:01:20,050:INFO:Checking exceptions
2023-07-03 15:01:20,051:INFO:Importing libraries
2023-07-03 15:01:20,051:INFO:Copying training dataset
2023-07-03 15:01:20,054:INFO:Defining folds
2023-07-03 15:01:20,054:INFO:Declaring metric variables
2023-07-03 15:01:20,057:INFO:Importing untrained model
2023-07-03 15:01:20,060:INFO:Quadratic Discriminant Analysis Imported successfully
2023-07-03 15:01:20,065:INFO:Starting cross validation
2023-07-03 15:01:20,066:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 15:01:23,439:INFO:Calculating mean and std
2023-07-03 15:01:23,440:INFO:Creating metrics dataframe
2023-07-03 15:01:23,988:INFO:Uploading results into container
2023-07-03 15:01:23,989:INFO:Uploading model into container now
2023-07-03 15:01:23,989:INFO:_master_model_container: 8
2023-07-03 15:01:23,989:INFO:_display_container: 2
2023-07-03 15:01:23,990:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-07-03 15:01:23,990:INFO:create_model() successfully completed......................................
2023-07-03 15:01:24,324:INFO:SubProcess create_model() end ==================================
2023-07-03 15:01:24,325:INFO:Creating metrics dataframe
2023-07-03 15:01:24,334:INFO:Initializing Ada Boost Classifier
2023-07-03 15:01:24,334:INFO:Total runtime is 0.6779444376627606 minutes
2023-07-03 15:01:24,336:INFO:SubProcess create_model() called ==================================
2023-07-03 15:01:24,337:INFO:Initializing create_model()
2023-07-03 15:01:24,337:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002224B6EC610>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002224B95A8C0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 15:01:24,337:INFO:Checking exceptions
2023-07-03 15:01:24,337:INFO:Importing libraries
2023-07-03 15:01:24,337:INFO:Copying training dataset
2023-07-03 15:01:24,341:INFO:Defining folds
2023-07-03 15:01:24,341:INFO:Declaring metric variables
2023-07-03 15:01:24,344:INFO:Importing untrained model
2023-07-03 15:01:24,347:INFO:Ada Boost Classifier Imported successfully
2023-07-03 15:01:24,352:INFO:Starting cross validation
2023-07-03 15:01:24,353:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 15:01:28,129:INFO:Calculating mean and std
2023-07-03 15:01:28,131:INFO:Creating metrics dataframe
2023-07-03 15:01:28,690:INFO:Uploading results into container
2023-07-03 15:01:28,691:INFO:Uploading model into container now
2023-07-03 15:01:28,692:INFO:_master_model_container: 9
2023-07-03 15:01:28,692:INFO:_display_container: 2
2023-07-03 15:01:28,692:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-07-03 15:01:28,692:INFO:create_model() successfully completed......................................
2023-07-03 15:01:29,051:INFO:SubProcess create_model() end ==================================
2023-07-03 15:01:29,051:INFO:Creating metrics dataframe
2023-07-03 15:01:29,062:INFO:Initializing Gradient Boosting Classifier
2023-07-03 15:01:29,062:INFO:Total runtime is 0.7567460656166078 minutes
2023-07-03 15:01:29,065:INFO:SubProcess create_model() called ==================================
2023-07-03 15:01:29,065:INFO:Initializing create_model()
2023-07-03 15:01:29,065:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002224B6EC610>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002224B95A8C0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 15:01:29,066:INFO:Checking exceptions
2023-07-03 15:01:29,066:INFO:Importing libraries
2023-07-03 15:01:29,066:INFO:Copying training dataset
2023-07-03 15:01:29,070:INFO:Defining folds
2023-07-03 15:01:29,071:INFO:Declaring metric variables
2023-07-03 15:01:29,074:INFO:Importing untrained model
2023-07-03 15:01:29,077:INFO:Gradient Boosting Classifier Imported successfully
2023-07-03 15:01:29,083:INFO:Starting cross validation
2023-07-03 15:01:29,084:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 15:01:33,232:INFO:Calculating mean and std
2023-07-03 15:01:33,234:INFO:Creating metrics dataframe
2023-07-03 15:01:33,793:INFO:Uploading results into container
2023-07-03 15:01:33,794:INFO:Uploading model into container now
2023-07-03 15:01:33,794:INFO:_master_model_container: 10
2023-07-03 15:01:33,794:INFO:_display_container: 2
2023-07-03 15:01:33,795:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-03 15:01:33,795:INFO:create_model() successfully completed......................................
2023-07-03 15:01:34,141:INFO:SubProcess create_model() end ==================================
2023-07-03 15:01:34,141:INFO:Creating metrics dataframe
2023-07-03 15:01:34,151:INFO:Initializing Linear Discriminant Analysis
2023-07-03 15:01:34,151:INFO:Total runtime is 0.8415645400683087 minutes
2023-07-03 15:01:34,154:INFO:SubProcess create_model() called ==================================
2023-07-03 15:01:34,154:INFO:Initializing create_model()
2023-07-03 15:01:34,154:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002224B6EC610>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002224B95A8C0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 15:01:34,154:INFO:Checking exceptions
2023-07-03 15:01:34,154:INFO:Importing libraries
2023-07-03 15:01:34,155:INFO:Copying training dataset
2023-07-03 15:01:34,158:INFO:Defining folds
2023-07-03 15:01:34,158:INFO:Declaring metric variables
2023-07-03 15:01:34,161:INFO:Importing untrained model
2023-07-03 15:01:34,164:INFO:Linear Discriminant Analysis Imported successfully
2023-07-03 15:01:34,169:INFO:Starting cross validation
2023-07-03 15:01:34,170:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 15:01:37,598:INFO:Calculating mean and std
2023-07-03 15:01:37,600:INFO:Creating metrics dataframe
2023-07-03 15:01:38,149:INFO:Uploading results into container
2023-07-03 15:01:38,150:INFO:Uploading model into container now
2023-07-03 15:01:38,150:INFO:_master_model_container: 11
2023-07-03 15:01:38,150:INFO:_display_container: 2
2023-07-03 15:01:38,151:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-07-03 15:01:38,151:INFO:create_model() successfully completed......................................
2023-07-03 15:01:38,491:INFO:SubProcess create_model() end ==================================
2023-07-03 15:01:38,491:INFO:Creating metrics dataframe
2023-07-03 15:01:38,502:INFO:Initializing Extra Trees Classifier
2023-07-03 15:01:38,502:INFO:Total runtime is 0.9140748222668967 minutes
2023-07-03 15:01:38,505:INFO:SubProcess create_model() called ==================================
2023-07-03 15:01:38,505:INFO:Initializing create_model()
2023-07-03 15:01:38,505:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002224B6EC610>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002224B95A8C0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 15:01:38,505:INFO:Checking exceptions
2023-07-03 15:01:38,505:INFO:Importing libraries
2023-07-03 15:01:38,505:INFO:Copying training dataset
2023-07-03 15:01:38,509:INFO:Defining folds
2023-07-03 15:01:38,509:INFO:Declaring metric variables
2023-07-03 15:01:38,512:INFO:Importing untrained model
2023-07-03 15:01:38,515:INFO:Extra Trees Classifier Imported successfully
2023-07-03 15:01:38,520:INFO:Starting cross validation
2023-07-03 15:01:38,521:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 15:01:42,482:INFO:Calculating mean and std
2023-07-03 15:01:42,483:INFO:Creating metrics dataframe
2023-07-03 15:01:43,044:INFO:Uploading results into container
2023-07-03 15:01:43,046:INFO:Uploading model into container now
2023-07-03 15:01:43,047:INFO:_master_model_container: 12
2023-07-03 15:01:43,047:INFO:_display_container: 2
2023-07-03 15:01:43,047:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-07-03 15:01:43,047:INFO:create_model() successfully completed......................................
2023-07-03 15:01:43,384:INFO:SubProcess create_model() end ==================================
2023-07-03 15:01:43,385:INFO:Creating metrics dataframe
2023-07-03 15:01:43,395:INFO:Initializing Light Gradient Boosting Machine
2023-07-03 15:01:43,395:INFO:Total runtime is 0.9956326087315879 minutes
2023-07-03 15:01:43,398:INFO:SubProcess create_model() called ==================================
2023-07-03 15:01:43,398:INFO:Initializing create_model()
2023-07-03 15:01:43,398:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002224B6EC610>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002224B95A8C0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 15:01:43,398:INFO:Checking exceptions
2023-07-03 15:01:43,398:INFO:Importing libraries
2023-07-03 15:01:43,398:INFO:Copying training dataset
2023-07-03 15:01:43,403:INFO:Defining folds
2023-07-03 15:01:43,403:INFO:Declaring metric variables
2023-07-03 15:01:43,406:INFO:Importing untrained model
2023-07-03 15:01:43,409:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-03 15:01:43,414:INFO:Starting cross validation
2023-07-03 15:01:43,415:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 15:01:48,164:INFO:Calculating mean and std
2023-07-03 15:01:48,165:INFO:Creating metrics dataframe
2023-07-03 15:01:48,729:INFO:Uploading results into container
2023-07-03 15:01:48,729:INFO:Uploading model into container now
2023-07-03 15:01:48,730:INFO:_master_model_container: 13
2023-07-03 15:01:48,730:INFO:_display_container: 2
2023-07-03 15:01:48,730:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-07-03 15:01:48,730:INFO:create_model() successfully completed......................................
2023-07-03 15:01:49,065:INFO:SubProcess create_model() end ==================================
2023-07-03 15:01:49,065:INFO:Creating metrics dataframe
2023-07-03 15:01:49,076:INFO:Initializing Dummy Classifier
2023-07-03 15:01:49,076:INFO:Total runtime is 1.0903098146120709 minutes
2023-07-03 15:01:49,079:INFO:SubProcess create_model() called ==================================
2023-07-03 15:01:49,079:INFO:Initializing create_model()
2023-07-03 15:01:49,079:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002224B6EC610>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002224B95A8C0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 15:01:49,079:INFO:Checking exceptions
2023-07-03 15:01:49,079:INFO:Importing libraries
2023-07-03 15:01:49,079:INFO:Copying training dataset
2023-07-03 15:01:49,083:INFO:Defining folds
2023-07-03 15:01:49,083:INFO:Declaring metric variables
2023-07-03 15:01:49,086:INFO:Importing untrained model
2023-07-03 15:01:49,089:INFO:Dummy Classifier Imported successfully
2023-07-03 15:01:49,094:INFO:Starting cross validation
2023-07-03 15:01:49,095:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 15:01:49,200:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:01:49,205:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:01:49,206:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:01:49,210:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:01:49,222:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:01:49,227:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:01:49,230:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:01:49,245:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:01:49,248:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:01:49,249:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:01:52,519:INFO:Calculating mean and std
2023-07-03 15:01:52,520:INFO:Creating metrics dataframe
2023-07-03 15:01:53,082:INFO:Uploading results into container
2023-07-03 15:01:53,083:INFO:Uploading model into container now
2023-07-03 15:01:53,083:INFO:_master_model_container: 14
2023-07-03 15:01:53,083:INFO:_display_container: 2
2023-07-03 15:01:53,084:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-07-03 15:01:53,084:INFO:create_model() successfully completed......................................
2023-07-03 15:01:53,420:INFO:SubProcess create_model() end ==================================
2023-07-03 15:01:53,420:INFO:Creating metrics dataframe
2023-07-03 15:01:53,438:INFO:Initializing create_model()
2023-07-03 15:01:53,438:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002224B6EC610>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-03 15:01:53,438:INFO:Checking exceptions
2023-07-03 15:01:53,440:INFO:Importing libraries
2023-07-03 15:01:53,440:INFO:Copying training dataset
2023-07-03 15:01:53,443:INFO:Defining folds
2023-07-03 15:01:53,443:INFO:Declaring metric variables
2023-07-03 15:01:53,443:INFO:Importing untrained model
2023-07-03 15:01:53,443:INFO:Declaring custom model
2023-07-03 15:01:53,444:INFO:Extra Trees Classifier Imported successfully
2023-07-03 15:01:53,444:INFO:Cross validation set to False
2023-07-03 15:01:53,445:INFO:Fitting Model
2023-07-03 15:01:54,011:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-07-03 15:01:54,011:INFO:create_model() successfully completed......................................
2023-07-03 15:01:54,370:INFO:_master_model_container: 14
2023-07-03 15:01:54,370:INFO:_display_container: 2
2023-07-03 15:01:54,370:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-07-03 15:01:54,371:INFO:compare_models() successfully completed......................................
2023-07-03 15:42:59,918:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-03 15:42:59,918:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-03 15:42:59,918:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-03 15:42:59,918:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-03 15:43:00,519:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-07-03 15:43:01,201:INFO:PyCaret ClassificationExperiment
2023-07-03 15:43:01,201:INFO:Logging name: clf-default-name
2023-07-03 15:43:01,201:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-07-03 15:43:01,201:INFO:version 3.0.2
2023-07-03 15:43:01,201:INFO:Initializing setup()
2023-07-03 15:43:01,201:INFO:self.USI: d327
2023-07-03 15:43:01,201:INFO:self._variable_keys: {'USI', 'log_plots_param', 'seed', 'X_test', 'memory', 'is_multiclass', 'fold_groups_param', '_available_plots', 'y_train', 'y', 'idx', 'gpu_param', 'fix_imbalance', 'target_param', 'exp_name_log', 'pipeline', 'X', 'exp_id', 'data', 'X_train', '_ml_usecase', 'logging_param', 'fold_shuffle_param', 'n_jobs_param', 'y_test', 'fold_generator', 'html_param', 'gpu_n_jobs_param'}
2023-07-03 15:43:01,201:INFO:Checking environment
2023-07-03 15:43:01,201:INFO:python_version: 3.10.9
2023-07-03 15:43:01,201:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2023-07-03 15:43:01,201:INFO:machine: AMD64
2023-07-03 15:43:01,201:INFO:platform: Windows-10-10.0.22621-SP0
2023-07-03 15:43:01,206:INFO:Memory: svmem(total=33664483328, available=20633751552, percent=38.7, used=13030731776, free=20633751552)
2023-07-03 15:43:01,206:INFO:Physical Core: 6
2023-07-03 15:43:01,206:INFO:Logical Core: 12
2023-07-03 15:43:01,206:INFO:Checking libraries
2023-07-03 15:43:01,206:INFO:System:
2023-07-03 15:43:01,206:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2023-07-03 15:43:01,206:INFO:executable: C:\Users\JHossain\anaconda3\python.exe
2023-07-03 15:43:01,206:INFO:   machine: Windows-10-10.0.22621-SP0
2023-07-03 15:43:01,206:INFO:PyCaret required dependencies:
2023-07-03 15:43:01,206:INFO:                 pip: 22.3.1
2023-07-03 15:43:01,206:INFO:          setuptools: 65.6.3
2023-07-03 15:43:01,206:INFO:             pycaret: 3.0.2
2023-07-03 15:43:01,207:INFO:             IPython: 8.10.0
2023-07-03 15:43:01,207:INFO:          ipywidgets: 7.6.5
2023-07-03 15:43:01,207:INFO:                tqdm: 4.64.1
2023-07-03 15:43:01,207:INFO:               numpy: 1.23.5
2023-07-03 15:43:01,207:INFO:              pandas: 1.5.3
2023-07-03 15:43:01,207:INFO:              jinja2: 3.1.2
2023-07-03 15:43:01,207:INFO:               scipy: 1.10.0
2023-07-03 15:43:01,207:INFO:              joblib: 1.2.0
2023-07-03 15:43:01,207:INFO:             sklearn: 1.2.1
2023-07-03 15:43:01,207:INFO:                pyod: 1.0.9
2023-07-03 15:43:01,207:INFO:            imblearn: 0.10.1
2023-07-03 15:43:01,207:INFO:   category_encoders: 2.6.1
2023-07-03 15:43:01,207:INFO:            lightgbm: 3.3.5
2023-07-03 15:43:01,207:INFO:               numba: 0.56.4
2023-07-03 15:43:01,207:INFO:            requests: 2.28.1
2023-07-03 15:43:01,207:INFO:          matplotlib: 3.7.0
2023-07-03 15:43:01,207:INFO:          scikitplot: 0.3.7
2023-07-03 15:43:01,207:INFO:         yellowbrick: 1.5
2023-07-03 15:43:01,207:INFO:              plotly: 5.9.0
2023-07-03 15:43:01,207:INFO:             kaleido: 0.2.1
2023-07-03 15:43:01,207:INFO:         statsmodels: 0.13.5
2023-07-03 15:43:01,207:INFO:              sktime: 0.17.0
2023-07-03 15:43:01,207:INFO:               tbats: 1.1.3
2023-07-03 15:43:01,207:INFO:            pmdarima: 2.0.3
2023-07-03 15:43:01,207:INFO:              psutil: 5.9.0
2023-07-03 15:43:01,207:INFO:PyCaret optional dependencies:
2023-07-03 15:43:02,198:INFO:                shap: 0.41.0
2023-07-03 15:43:02,198:INFO:           interpret: 0.4.2
2023-07-03 15:43:02,198:INFO:                umap: Not installed
2023-07-03 15:43:02,198:INFO:    pandas_profiling: Not installed
2023-07-03 15:43:02,198:INFO:  explainerdashboard: Not installed
2023-07-03 15:43:02,198:INFO:             autoviz: Not installed
2023-07-03 15:43:02,198:INFO:           fairlearn: Not installed
2023-07-03 15:43:02,198:INFO:             xgboost: Not installed
2023-07-03 15:43:02,198:INFO:            catboost: Not installed
2023-07-03 15:43:02,198:INFO:              kmodes: Not installed
2023-07-03 15:43:02,199:INFO:             mlxtend: Not installed
2023-07-03 15:43:02,199:INFO:       statsforecast: Not installed
2023-07-03 15:43:02,199:INFO:        tune_sklearn: Not installed
2023-07-03 15:43:02,199:INFO:                 ray: Not installed
2023-07-03 15:43:02,199:INFO:            hyperopt: Not installed
2023-07-03 15:43:02,199:INFO:              optuna: Not installed
2023-07-03 15:43:02,199:INFO:               skopt: Not installed
2023-07-03 15:43:02,199:INFO:              mlflow: Not installed
2023-07-03 15:43:02,199:INFO:              gradio: 3.35.2
2023-07-03 15:43:02,199:INFO:             fastapi: 0.99.0
2023-07-03 15:43:02,199:INFO:             uvicorn: 0.22.0
2023-07-03 15:43:02,199:INFO:              m2cgen: Not installed
2023-07-03 15:43:02,199:INFO:           evidently: Not installed
2023-07-03 15:43:02,199:INFO:               fugue: Not installed
2023-07-03 15:43:02,199:INFO:           streamlit: Not installed
2023-07-03 15:43:02,199:INFO:             prophet: Not installed
2023-07-03 15:43:02,199:INFO:None
2023-07-03 15:43:02,199:INFO:Set up data.
2023-07-03 15:43:02,203:INFO:Set up train/test split.
2023-07-03 15:43:02,206:INFO:Set up index.
2023-07-03 15:43:02,206:INFO:Set up folding strategy.
2023-07-03 15:43:02,206:INFO:Assigning column types.
2023-07-03 15:43:02,208:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-07-03 15:43:02,247:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-03 15:43:02,249:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-03 15:43:02,279:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 15:43:02,436:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 15:43:02,473:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-03 15:43:02,474:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-03 15:43:02,497:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 15:43:02,497:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 15:43:02,498:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-07-03 15:43:02,671:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-03 15:43:02,694:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 15:43:02,694:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 15:43:02,731:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-03 15:43:02,754:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 15:43:02,755:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 15:43:02,755:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-07-03 15:43:02,815:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 15:43:02,816:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 15:43:02,876:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 15:43:02,877:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 15:43:02,879:INFO:Preparing preprocessing pipeline...
2023-07-03 15:43:02,880:INFO:Set up label encoding.
2023-07-03 15:43:02,880:INFO:Set up simple imputation.
2023-07-03 15:43:02,881:INFO:Set up encoding of categorical features.
2023-07-03 15:43:02,923:INFO:Finished creating preprocessing pipeline.
2023-07-03 15:43:02,928:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\JHossain\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=Fal...
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['id', 'Sequence'],
                                    transformer=TargetEncoder(cols=['id',
                                                                    'Sequence'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2023-07-03 15:43:02,929:INFO:Creating final display dataframe.
2023-07-03 15:43:03,048:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             Class
2                   Target type            Binary
3                Target mapping        +: 0, -: 1
4           Original data shape          (106, 3)
5        Transformed data shape          (106, 3)
6   Transformed train set shape           (74, 3)
7    Transformed test set shape           (32, 3)
8          Categorical features                 2
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              d327
2023-07-03 15:43:03,115:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 15:43:03,116:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 15:43:03,177:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 15:43:03,177:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 15:43:03,178:INFO:setup() successfully completed in 2.41s...............
2023-07-03 15:43:24,535:INFO:Initializing get_config()
2023-07-03 15:43:24,535:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE28DC6290>, variable=None)
2023-07-03 15:44:08,467:INFO:Initializing get_config()
2023-07-03 15:44:08,467:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE28DC6290>, variable=X_train_transformed)
2023-07-03 15:44:08,503:INFO:Variable: X_train returned as           id  Sequence
74  0.565054  0.565054
84  0.565054  0.565054
41  0.434946  0.434946
18  0.434946  0.434946
5   0.434946  0.434946
..       ...       ...
24  0.434946  0.434946
68  0.565054  0.565054
77  0.565054  0.565054
12  0.434946  0.434946
86  0.565054  0.565054

[74 rows x 2 columns]
2023-07-03 15:44:08,503:INFO:get_config() successfully completed......................................
2023-07-03 15:44:26,248:INFO:Initializing compare_models()
2023-07-03 15:44:26,249:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE28DC6290>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001FE28DC6290>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-07-03 15:44:26,249:INFO:Checking exceptions
2023-07-03 15:44:26,251:INFO:Preparing display monitor
2023-07-03 15:44:26,271:INFO:Initializing Logistic Regression
2023-07-03 15:44:26,271:INFO:Total runtime is 0.0 minutes
2023-07-03 15:44:26,274:INFO:SubProcess create_model() called ==================================
2023-07-03 15:44:26,275:INFO:Initializing create_model()
2023-07-03 15:44:26,275:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE28DC6290>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE2E5AFC10>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 15:44:26,275:INFO:Checking exceptions
2023-07-03 15:44:26,275:INFO:Importing libraries
2023-07-03 15:44:26,275:INFO:Copying training dataset
2023-07-03 15:44:26,278:INFO:Defining folds
2023-07-03 15:44:26,278:INFO:Declaring metric variables
2023-07-03 15:44:26,281:INFO:Importing untrained model
2023-07-03 15:44:26,284:INFO:Logistic Regression Imported successfully
2023-07-03 15:44:26,290:INFO:Starting cross validation
2023-07-03 15:44:26,291:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 15:44:32,102:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:44:32,121:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:44:32,151:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:44:35,456:INFO:Calculating mean and std
2023-07-03 15:44:35,457:INFO:Creating metrics dataframe
2023-07-03 15:44:35,997:INFO:Uploading results into container
2023-07-03 15:44:35,998:INFO:Uploading model into container now
2023-07-03 15:44:35,999:INFO:_master_model_container: 1
2023-07-03 15:44:35,999:INFO:_display_container: 2
2023-07-03 15:44:35,999:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-03 15:44:35,999:INFO:create_model() successfully completed......................................
2023-07-03 15:44:36,161:INFO:SubProcess create_model() end ==================================
2023-07-03 15:44:36,161:INFO:Creating metrics dataframe
2023-07-03 15:44:36,168:INFO:Initializing K Neighbors Classifier
2023-07-03 15:44:36,169:INFO:Total runtime is 0.16494275331497193 minutes
2023-07-03 15:44:36,171:INFO:SubProcess create_model() called ==================================
2023-07-03 15:44:36,172:INFO:Initializing create_model()
2023-07-03 15:44:36,172:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE28DC6290>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE2E5AFC10>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 15:44:36,172:INFO:Checking exceptions
2023-07-03 15:44:36,172:INFO:Importing libraries
2023-07-03 15:44:36,172:INFO:Copying training dataset
2023-07-03 15:44:36,175:INFO:Defining folds
2023-07-03 15:44:36,175:INFO:Declaring metric variables
2023-07-03 15:44:36,178:INFO:Importing untrained model
2023-07-03 15:44:36,180:INFO:K Neighbors Classifier Imported successfully
2023-07-03 15:44:36,186:INFO:Starting cross validation
2023-07-03 15:44:36,187:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 15:44:36,416:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:44:36,417:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:44:36,429:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:44:36,435:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:44:36,442:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:44:38,818:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:44:38,835:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:44:40,038:INFO:Calculating mean and std
2023-07-03 15:44:40,039:INFO:Creating metrics dataframe
2023-07-03 15:44:40,585:INFO:Uploading results into container
2023-07-03 15:44:40,585:INFO:Uploading model into container now
2023-07-03 15:44:40,586:INFO:_master_model_container: 2
2023-07-03 15:44:40,586:INFO:_display_container: 2
2023-07-03 15:44:40,586:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-07-03 15:44:40,586:INFO:create_model() successfully completed......................................
2023-07-03 15:44:40,745:INFO:SubProcess create_model() end ==================================
2023-07-03 15:44:40,746:INFO:Creating metrics dataframe
2023-07-03 15:44:40,754:INFO:Initializing Naive Bayes
2023-07-03 15:44:40,754:INFO:Total runtime is 0.24137557347615562 minutes
2023-07-03 15:44:40,757:INFO:SubProcess create_model() called ==================================
2023-07-03 15:44:40,757:INFO:Initializing create_model()
2023-07-03 15:44:40,757:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE28DC6290>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE2E5AFC10>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 15:44:40,757:INFO:Checking exceptions
2023-07-03 15:44:40,758:INFO:Importing libraries
2023-07-03 15:44:40,758:INFO:Copying training dataset
2023-07-03 15:44:40,761:INFO:Defining folds
2023-07-03 15:44:40,761:INFO:Declaring metric variables
2023-07-03 15:44:40,764:INFO:Importing untrained model
2023-07-03 15:44:40,766:INFO:Naive Bayes Imported successfully
2023-07-03 15:44:40,772:INFO:Starting cross validation
2023-07-03 15:44:40,773:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 15:44:40,955:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:44:40,966:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:44:40,970:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:44:40,974:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:44:40,974:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:44:40,977:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:44:41,003:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:44:44,192:INFO:Calculating mean and std
2023-07-03 15:44:44,193:INFO:Creating metrics dataframe
2023-07-03 15:44:44,748:INFO:Uploading results into container
2023-07-03 15:44:44,749:INFO:Uploading model into container now
2023-07-03 15:44:44,749:INFO:_master_model_container: 3
2023-07-03 15:44:44,750:INFO:_display_container: 2
2023-07-03 15:44:44,750:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-07-03 15:44:44,750:INFO:create_model() successfully completed......................................
2023-07-03 15:44:44,911:INFO:SubProcess create_model() end ==================================
2023-07-03 15:44:44,911:INFO:Creating metrics dataframe
2023-07-03 15:44:44,919:INFO:Initializing Decision Tree Classifier
2023-07-03 15:44:44,919:INFO:Total runtime is 0.31080268621444707 minutes
2023-07-03 15:44:44,922:INFO:SubProcess create_model() called ==================================
2023-07-03 15:44:44,922:INFO:Initializing create_model()
2023-07-03 15:44:44,922:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE28DC6290>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE2E5AFC10>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 15:44:44,922:INFO:Checking exceptions
2023-07-03 15:44:44,922:INFO:Importing libraries
2023-07-03 15:44:44,922:INFO:Copying training dataset
2023-07-03 15:44:44,925:INFO:Defining folds
2023-07-03 15:44:44,926:INFO:Declaring metric variables
2023-07-03 15:44:44,928:INFO:Importing untrained model
2023-07-03 15:44:44,931:INFO:Decision Tree Classifier Imported successfully
2023-07-03 15:44:44,937:INFO:Starting cross validation
2023-07-03 15:44:44,938:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 15:44:45,130:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:44:45,133:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:44:45,137:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:44:45,147:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:44:45,149:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:44:45,150:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:44:45,165:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:44:48,437:INFO:Calculating mean and std
2023-07-03 15:44:48,439:INFO:Creating metrics dataframe
2023-07-03 15:44:48,991:INFO:Uploading results into container
2023-07-03 15:44:48,992:INFO:Uploading model into container now
2023-07-03 15:44:48,993:INFO:_master_model_container: 4
2023-07-03 15:44:48,993:INFO:_display_container: 2
2023-07-03 15:44:48,993:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-07-03 15:44:48,993:INFO:create_model() successfully completed......................................
2023-07-03 15:44:49,154:INFO:SubProcess create_model() end ==================================
2023-07-03 15:44:49,154:INFO:Creating metrics dataframe
2023-07-03 15:44:49,164:INFO:Initializing SVM - Linear Kernel
2023-07-03 15:44:49,164:INFO:Total runtime is 0.3815449476242066 minutes
2023-07-03 15:44:49,167:INFO:SubProcess create_model() called ==================================
2023-07-03 15:44:49,167:INFO:Initializing create_model()
2023-07-03 15:44:49,167:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE28DC6290>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE2E5AFC10>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 15:44:49,167:INFO:Checking exceptions
2023-07-03 15:44:49,167:INFO:Importing libraries
2023-07-03 15:44:49,167:INFO:Copying training dataset
2023-07-03 15:44:49,170:INFO:Defining folds
2023-07-03 15:44:49,171:INFO:Declaring metric variables
2023-07-03 15:44:49,174:INFO:Importing untrained model
2023-07-03 15:44:49,177:INFO:SVM - Linear Kernel Imported successfully
2023-07-03 15:44:49,182:INFO:Starting cross validation
2023-07-03 15:44:49,183:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 15:44:49,325:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 15:44:49,328:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:44:49,329:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 15:44:49,333:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:44:49,342:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 15:44:49,346:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 15:44:49,347:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:44:49,347:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 15:44:49,350:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:44:49,351:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:44:49,352:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 15:44:49,357:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:44:49,368:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 15:44:49,373:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:44:49,378:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 15:44:49,383:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:44:49,384:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 15:44:49,386:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 15:44:49,388:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:44:49,393:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:44:52,740:INFO:Calculating mean and std
2023-07-03 15:44:52,741:INFO:Creating metrics dataframe
2023-07-03 15:44:53,286:INFO:Uploading results into container
2023-07-03 15:44:53,287:INFO:Uploading model into container now
2023-07-03 15:44:53,287:INFO:_master_model_container: 5
2023-07-03 15:44:53,287:INFO:_display_container: 2
2023-07-03 15:44:53,288:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-07-03 15:44:53,288:INFO:create_model() successfully completed......................................
2023-07-03 15:44:53,448:INFO:SubProcess create_model() end ==================================
2023-07-03 15:44:53,448:INFO:Creating metrics dataframe
2023-07-03 15:44:53,458:INFO:Initializing Ridge Classifier
2023-07-03 15:44:53,458:INFO:Total runtime is 0.45311141014099127 minutes
2023-07-03 15:44:53,462:INFO:SubProcess create_model() called ==================================
2023-07-03 15:44:53,462:INFO:Initializing create_model()
2023-07-03 15:44:53,462:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE28DC6290>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE2E5AFC10>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 15:44:53,462:INFO:Checking exceptions
2023-07-03 15:44:53,462:INFO:Importing libraries
2023-07-03 15:44:53,462:INFO:Copying training dataset
2023-07-03 15:44:53,466:INFO:Defining folds
2023-07-03 15:44:53,466:INFO:Declaring metric variables
2023-07-03 15:44:53,469:INFO:Importing untrained model
2023-07-03 15:44:53,473:INFO:Ridge Classifier Imported successfully
2023-07-03 15:44:53,480:INFO:Starting cross validation
2023-07-03 15:44:53,481:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 15:44:53,634:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 15:44:53,638:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:44:53,647:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 15:44:53,648:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 15:44:53,650:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 15:44:53,652:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:44:53,652:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:44:53,653:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:44:53,669:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 15:44:53,670:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 15:44:53,673:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:44:53,675:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:44:53,681:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 15:44:53,685:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:44:53,687:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 15:44:53,691:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 15:44:53,706:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 15:44:57,147:INFO:Calculating mean and std
2023-07-03 15:44:57,148:INFO:Creating metrics dataframe
2023-07-03 15:44:57,934:INFO:Uploading results into container
2023-07-03 15:44:57,935:INFO:Uploading model into container now
2023-07-03 15:44:57,936:INFO:_master_model_container: 6
2023-07-03 15:44:57,936:INFO:_display_container: 2
2023-07-03 15:44:57,936:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-07-03 15:44:57,937:INFO:create_model() successfully completed......................................
2023-07-03 15:44:58,098:INFO:SubProcess create_model() end ==================================
2023-07-03 15:44:58,098:INFO:Creating metrics dataframe
2023-07-03 15:44:58,109:INFO:Initializing Random Forest Classifier
2023-07-03 15:44:58,110:INFO:Total runtime is 0.5306434551874797 minutes
2023-07-03 15:44:58,113:INFO:SubProcess create_model() called ==================================
2023-07-03 15:44:58,113:INFO:Initializing create_model()
2023-07-03 15:44:58,113:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE28DC6290>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE2E5AFC10>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 15:44:58,113:INFO:Checking exceptions
2023-07-03 15:44:58,113:INFO:Importing libraries
2023-07-03 15:44:58,114:INFO:Copying training dataset
2023-07-03 15:44:58,117:INFO:Defining folds
2023-07-03 15:44:58,117:INFO:Declaring metric variables
2023-07-03 15:44:58,120:INFO:Importing untrained model
2023-07-03 15:44:58,124:INFO:Random Forest Classifier Imported successfully
2023-07-03 15:44:58,130:INFO:Starting cross validation
2023-07-03 15:44:58,131:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 15:44:58,842:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:44:58,858:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:44:58,860:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:44:58,863:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:44:58,869:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:44:58,876:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:44:58,884:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:45:02,299:INFO:Calculating mean and std
2023-07-03 15:45:02,300:INFO:Creating metrics dataframe
2023-07-03 15:45:03,080:INFO:Uploading results into container
2023-07-03 15:45:03,081:INFO:Uploading model into container now
2023-07-03 15:45:03,082:INFO:_master_model_container: 7
2023-07-03 15:45:03,082:INFO:_display_container: 2
2023-07-03 15:45:03,082:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-07-03 15:45:03,082:INFO:create_model() successfully completed......................................
2023-07-03 15:45:03,244:INFO:SubProcess create_model() end ==================================
2023-07-03 15:45:03,244:INFO:Creating metrics dataframe
2023-07-03 15:45:03,255:INFO:Initializing Quadratic Discriminant Analysis
2023-07-03 15:45:03,255:INFO:Total runtime is 0.6163953145345052 minutes
2023-07-03 15:45:03,258:INFO:SubProcess create_model() called ==================================
2023-07-03 15:45:03,258:INFO:Initializing create_model()
2023-07-03 15:45:03,258:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE28DC6290>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE2E5AFC10>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 15:45:03,258:INFO:Checking exceptions
2023-07-03 15:45:03,258:INFO:Importing libraries
2023-07-03 15:45:03,258:INFO:Copying training dataset
2023-07-03 15:45:03,262:INFO:Defining folds
2023-07-03 15:45:03,262:INFO:Declaring metric variables
2023-07-03 15:45:03,265:INFO:Importing untrained model
2023-07-03 15:45:03,269:INFO:Quadratic Discriminant Analysis Imported successfully
2023-07-03 15:45:03,275:INFO:Starting cross validation
2023-07-03 15:45:03,276:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 15:45:03,377:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-03 15:45:03,389:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-03 15:45:03,395:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-03 15:45:03,399:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-03 15:45:03,402:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-03 15:45:03,408:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-03 15:45:03,408:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-03 15:45:03,419:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-03 15:45:03,427:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-03 15:45:03,435:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-03 15:45:03,435:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-03 15:45:03,435:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-03 15:45:03,440:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-03 15:45:03,448:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-03 15:45:03,448:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-03 15:45:03,448:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-03 15:45:03,454:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-03 15:45:03,454:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-03 15:45:03,454:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-03 15:45:03,473:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:45:03,484:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-03 15:45:03,484:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-03 15:45:03,485:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-03 15:45:03,489:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

ns that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-03 15:45:03,490:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:45:03,493:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:45:03,494:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-03 15:45:03,494:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-03 15:45:03,494:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-03 15:45:03,497:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-03 15:45:03,501:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-03 15:45:03,501:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-03 15:45:03,501:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-03 15:45:03,505:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-03 15:45:06,917:INFO:Calculating mean and std
2023-07-03 15:45:06,919:INFO:Creating metrics dataframe
2023-07-03 15:45:07,705:INFO:Uploading results into container
2023-07-03 15:45:07,707:INFO:Uploading model into container now
2023-07-03 15:45:07,708:INFO:_master_model_container: 8
2023-07-03 15:45:07,708:INFO:_display_container: 2
2023-07-03 15:45:07,708:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-07-03 15:45:07,708:INFO:create_model() successfully completed......................................
2023-07-03 15:45:07,870:INFO:SubProcess create_model() end ==================================
2023-07-03 15:45:07,870:INFO:Creating metrics dataframe
2023-07-03 15:45:07,882:INFO:Initializing Ada Boost Classifier
2023-07-03 15:45:07,882:INFO:Total runtime is 0.6935181260108948 minutes
2023-07-03 15:45:07,885:INFO:SubProcess create_model() called ==================================
2023-07-03 15:45:07,886:INFO:Initializing create_model()
2023-07-03 15:45:07,886:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE28DC6290>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE2E5AFC10>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 15:45:07,886:INFO:Checking exceptions
2023-07-03 15:45:07,886:INFO:Importing libraries
2023-07-03 15:45:07,886:INFO:Copying training dataset
2023-07-03 15:45:07,890:INFO:Defining folds
2023-07-03 15:45:07,891:INFO:Declaring metric variables
2023-07-03 15:45:07,894:INFO:Importing untrained model
2023-07-03 15:45:07,897:INFO:Ada Boost Classifier Imported successfully
2023-07-03 15:45:07,902:INFO:Starting cross validation
2023-07-03 15:45:07,904:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 15:45:08,094:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:45:08,101:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:45:08,106:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:45:08,112:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:45:08,122:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:45:08,129:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:45:08,146:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:45:11,562:INFO:Calculating mean and std
2023-07-03 15:45:11,563:INFO:Creating metrics dataframe
2023-07-03 15:45:12,349:INFO:Uploading results into container
2023-07-03 15:45:12,350:INFO:Uploading model into container now
2023-07-03 15:45:12,350:INFO:_master_model_container: 9
2023-07-03 15:45:12,350:INFO:_display_container: 2
2023-07-03 15:45:12,350:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-07-03 15:45:12,351:INFO:create_model() successfully completed......................................
2023-07-03 15:45:12,512:INFO:SubProcess create_model() end ==================================
2023-07-03 15:45:12,513:INFO:Creating metrics dataframe
2023-07-03 15:45:12,524:INFO:Initializing Gradient Boosting Classifier
2023-07-03 15:45:12,524:INFO:Total runtime is 0.7708732048670451 minutes
2023-07-03 15:45:12,527:INFO:SubProcess create_model() called ==================================
2023-07-03 15:45:12,528:INFO:Initializing create_model()
2023-07-03 15:45:12,528:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE28DC6290>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE2E5AFC10>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 15:45:12,528:INFO:Checking exceptions
2023-07-03 15:45:12,528:INFO:Importing libraries
2023-07-03 15:45:12,528:INFO:Copying training dataset
2023-07-03 15:45:12,533:INFO:Defining folds
2023-07-03 15:45:12,533:INFO:Declaring metric variables
2023-07-03 15:45:12,537:INFO:Importing untrained model
2023-07-03 15:45:12,541:INFO:Gradient Boosting Classifier Imported successfully
2023-07-03 15:45:12,549:INFO:Starting cross validation
2023-07-03 15:45:12,550:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 15:45:12,901:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:45:12,914:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:45:12,915:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:45:12,920:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:45:12,929:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:45:12,931:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:45:12,955:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:45:16,359:INFO:Calculating mean and std
2023-07-03 15:45:16,360:INFO:Creating metrics dataframe
2023-07-03 15:45:17,119:INFO:Uploading results into container
2023-07-03 15:45:17,120:INFO:Uploading model into container now
2023-07-03 15:45:17,120:INFO:_master_model_container: 10
2023-07-03 15:45:17,120:INFO:_display_container: 2
2023-07-03 15:45:17,121:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-03 15:45:17,121:INFO:create_model() successfully completed......................................
2023-07-03 15:45:17,285:INFO:SubProcess create_model() end ==================================
2023-07-03 15:45:17,285:INFO:Creating metrics dataframe
2023-07-03 15:45:17,295:INFO:Initializing Linear Discriminant Analysis
2023-07-03 15:45:17,295:INFO:Total runtime is 0.8503925879796347 minutes
2023-07-03 15:45:17,298:INFO:SubProcess create_model() called ==================================
2023-07-03 15:45:17,299:INFO:Initializing create_model()
2023-07-03 15:45:17,299:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE28DC6290>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE2E5AFC10>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 15:45:17,299:INFO:Checking exceptions
2023-07-03 15:45:17,299:INFO:Importing libraries
2023-07-03 15:45:17,299:INFO:Copying training dataset
2023-07-03 15:45:17,303:INFO:Defining folds
2023-07-03 15:45:17,303:INFO:Declaring metric variables
2023-07-03 15:45:17,306:INFO:Importing untrained model
2023-07-03 15:45:17,310:INFO:Linear Discriminant Analysis Imported successfully
2023-07-03 15:45:17,315:INFO:Starting cross validation
2023-07-03 15:45:17,317:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 15:45:17,520:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:45:17,529:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:45:17,529:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:45:17,535:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:45:17,538:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:45:17,549:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:45:17,564:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:45:21,019:INFO:Calculating mean and std
2023-07-03 15:45:21,020:INFO:Creating metrics dataframe
2023-07-03 15:45:21,795:INFO:Uploading results into container
2023-07-03 15:45:21,796:INFO:Uploading model into container now
2023-07-03 15:45:21,796:INFO:_master_model_container: 11
2023-07-03 15:45:21,797:INFO:_display_container: 2
2023-07-03 15:45:21,797:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-07-03 15:45:21,797:INFO:create_model() successfully completed......................................
2023-07-03 15:45:21,965:INFO:SubProcess create_model() end ==================================
2023-07-03 15:45:21,965:INFO:Creating metrics dataframe
2023-07-03 15:45:21,976:INFO:Initializing Extra Trees Classifier
2023-07-03 15:45:21,976:INFO:Total runtime is 0.9284075339635214 minutes
2023-07-03 15:45:21,980:INFO:SubProcess create_model() called ==================================
2023-07-03 15:45:21,980:INFO:Initializing create_model()
2023-07-03 15:45:21,980:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE28DC6290>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE2E5AFC10>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 15:45:21,980:INFO:Checking exceptions
2023-07-03 15:45:21,981:INFO:Importing libraries
2023-07-03 15:45:21,981:INFO:Copying training dataset
2023-07-03 15:45:21,984:INFO:Defining folds
2023-07-03 15:45:21,984:INFO:Declaring metric variables
2023-07-03 15:45:21,987:INFO:Importing untrained model
2023-07-03 15:45:21,992:INFO:Extra Trees Classifier Imported successfully
2023-07-03 15:45:21,999:INFO:Starting cross validation
2023-07-03 15:45:22,000:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 15:45:26,131:INFO:Calculating mean and std
2023-07-03 15:45:26,132:INFO:Creating metrics dataframe
2023-07-03 15:45:26,902:INFO:Uploading results into container
2023-07-03 15:45:26,903:INFO:Uploading model into container now
2023-07-03 15:45:26,904:INFO:_master_model_container: 12
2023-07-03 15:45:26,904:INFO:_display_container: 2
2023-07-03 15:45:26,905:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-07-03 15:45:26,905:INFO:create_model() successfully completed......................................
2023-07-03 15:45:27,074:INFO:SubProcess create_model() end ==================================
2023-07-03 15:45:27,074:INFO:Creating metrics dataframe
2023-07-03 15:45:27,084:INFO:Initializing Light Gradient Boosting Machine
2023-07-03 15:45:27,085:INFO:Total runtime is 1.013553277651469 minutes
2023-07-03 15:45:27,088:INFO:SubProcess create_model() called ==================================
2023-07-03 15:45:27,089:INFO:Initializing create_model()
2023-07-03 15:45:27,089:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE28DC6290>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE2E5AFC10>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 15:45:27,089:INFO:Checking exceptions
2023-07-03 15:45:27,089:INFO:Importing libraries
2023-07-03 15:45:27,089:INFO:Copying training dataset
2023-07-03 15:45:27,093:INFO:Defining folds
2023-07-03 15:45:27,093:INFO:Declaring metric variables
2023-07-03 15:45:27,098:INFO:Importing untrained model
2023-07-03 15:45:27,103:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-03 15:45:27,110:INFO:Starting cross validation
2023-07-03 15:45:27,112:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 15:45:28,518:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:45:28,526:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:45:28,537:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:45:28,546:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:45:28,552:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:45:28,554:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:45:28,559:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:45:31,977:INFO:Calculating mean and std
2023-07-03 15:45:31,978:INFO:Creating metrics dataframe
2023-07-03 15:45:32,762:INFO:Uploading results into container
2023-07-03 15:45:32,763:INFO:Uploading model into container now
2023-07-03 15:45:32,763:INFO:_master_model_container: 13
2023-07-03 15:45:32,763:INFO:_display_container: 2
2023-07-03 15:45:32,764:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-07-03 15:45:32,764:INFO:create_model() successfully completed......................................
2023-07-03 15:45:32,925:INFO:SubProcess create_model() end ==================================
2023-07-03 15:45:32,925:INFO:Creating metrics dataframe
2023-07-03 15:45:32,936:INFO:Initializing Dummy Classifier
2023-07-03 15:45:32,936:INFO:Total runtime is 1.1110857685407005 minutes
2023-07-03 15:45:32,939:INFO:SubProcess create_model() called ==================================
2023-07-03 15:45:32,940:INFO:Initializing create_model()
2023-07-03 15:45:32,940:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE28DC6290>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE2E5AFC10>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 15:45:32,940:INFO:Checking exceptions
2023-07-03 15:45:32,940:INFO:Importing libraries
2023-07-03 15:45:32,940:INFO:Copying training dataset
2023-07-03 15:45:32,943:INFO:Defining folds
2023-07-03 15:45:32,943:INFO:Declaring metric variables
2023-07-03 15:45:32,947:INFO:Importing untrained model
2023-07-03 15:45:32,951:INFO:Dummy Classifier Imported successfully
2023-07-03 15:45:32,957:INFO:Starting cross validation
2023-07-03 15:45:32,958:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 15:45:33,145:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:45:33,159:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:45:33,167:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:45:33,167:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:45:33,171:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:45:33,173:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:45:33,194:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:45:36,562:INFO:Calculating mean and std
2023-07-03 15:45:36,563:INFO:Creating metrics dataframe
2023-07-03 15:45:37,323:INFO:Uploading results into container
2023-07-03 15:45:37,325:INFO:Uploading model into container now
2023-07-03 15:45:37,325:INFO:_master_model_container: 14
2023-07-03 15:45:37,325:INFO:_display_container: 2
2023-07-03 15:45:37,326:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-07-03 15:45:37,326:INFO:create_model() successfully completed......................................
2023-07-03 15:45:37,484:INFO:SubProcess create_model() end ==================================
2023-07-03 15:45:37,484:INFO:Creating metrics dataframe
2023-07-03 15:45:37,507:INFO:Initializing create_model()
2023-07-03 15:45:37,507:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE28DC6290>, estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-03 15:45:37,507:INFO:Checking exceptions
2023-07-03 15:45:37,509:INFO:Importing libraries
2023-07-03 15:45:37,510:INFO:Copying training dataset
2023-07-03 15:45:37,512:INFO:Defining folds
2023-07-03 15:45:37,512:INFO:Declaring metric variables
2023-07-03 15:45:37,512:INFO:Importing untrained model
2023-07-03 15:45:37,512:INFO:Declaring custom model
2023-07-03 15:45:37,513:INFO:SVM - Linear Kernel Imported successfully
2023-07-03 15:45:37,514:INFO:Cross validation set to False
2023-07-03 15:45:37,514:INFO:Fitting Model
2023-07-03 15:45:37,918:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-07-03 15:45:37,918:INFO:create_model() successfully completed......................................
2023-07-03 15:45:38,106:INFO:_master_model_container: 14
2023-07-03 15:45:38,106:INFO:_display_container: 2
2023-07-03 15:45:38,107:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-07-03 15:45:38,107:INFO:compare_models() successfully completed......................................
2023-07-03 15:45:48,174:INFO:Initializing create_model()
2023-07-03 15:45:48,175:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE28DC6290>, estimator=svm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-03 15:45:48,175:INFO:Checking exceptions
2023-07-03 15:45:48,187:INFO:Importing libraries
2023-07-03 15:45:48,187:INFO:Copying training dataset
2023-07-03 15:45:48,190:INFO:Defining folds
2023-07-03 15:45:48,190:INFO:Declaring metric variables
2023-07-03 15:45:48,193:INFO:Importing untrained model
2023-07-03 15:45:48,196:INFO:SVM - Linear Kernel Imported successfully
2023-07-03 15:45:48,201:INFO:Starting cross validation
2023-07-03 15:45:48,204:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 15:45:48,353:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 15:45:48,355:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:45:48,360:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 15:45:48,363:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:45:48,367:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 15:45:48,369:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 15:45:48,370:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:45:48,372:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:45:48,376:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 15:45:48,380:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:45:48,382:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 15:45:48,385:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:45:48,386:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 15:45:48,391:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:45:48,401:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 15:45:48,406:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:45:48,408:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 15:45:48,412:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:45:48,419:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 15:45:48,423:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:45:51,749:INFO:Calculating mean and std
2023-07-03 15:45:51,750:INFO:Creating metrics dataframe
2023-07-03 15:45:51,756:INFO:Finalizing model
2023-07-03 15:45:52,355:INFO:Uploading results into container
2023-07-03 15:45:52,356:INFO:Uploading model into container now
2023-07-03 15:45:52,364:INFO:_master_model_container: 15
2023-07-03 15:45:52,364:INFO:_display_container: 3
2023-07-03 15:45:52,365:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-07-03 15:45:52,365:INFO:create_model() successfully completed......................................
2023-07-03 15:46:48,333:INFO:Initializing create_model()
2023-07-03 15:46:48,333:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE28DC6290>, estimator=svm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-03 15:46:48,333:INFO:Checking exceptions
2023-07-03 15:46:48,347:INFO:Importing libraries
2023-07-03 15:46:48,347:INFO:Copying training dataset
2023-07-03 15:46:48,350:INFO:Defining folds
2023-07-03 15:46:48,350:INFO:Declaring metric variables
2023-07-03 15:46:48,353:INFO:Importing untrained model
2023-07-03 15:46:48,356:INFO:SVM - Linear Kernel Imported successfully
2023-07-03 15:46:48,362:INFO:Starting cross validation
2023-07-03 15:46:48,363:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 15:46:48,500:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 15:46:48,502:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:46:48,503:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 15:46:48,505:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 15:46:48,506:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:46:48,506:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 15:46:48,508:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:46:48,510:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:46:48,511:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 15:46:48,514:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:46:48,546:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 15:46:48,550:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 15:46:48,550:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:46:48,554:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:46:48,558:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 15:46:48,562:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:46:48,563:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 15:46:48,566:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 15:46:48,567:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:46:48,570:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:46:51,837:INFO:Calculating mean and std
2023-07-03 15:46:51,839:INFO:Creating metrics dataframe
2023-07-03 15:46:51,843:INFO:Finalizing model
2023-07-03 15:46:52,450:INFO:Uploading results into container
2023-07-03 15:46:52,451:INFO:Uploading model into container now
2023-07-03 15:46:52,458:INFO:_master_model_container: 16
2023-07-03 15:46:52,459:INFO:_display_container: 4
2023-07-03 15:46:52,459:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-07-03 15:46:52,459:INFO:create_model() successfully completed......................................
2023-07-03 15:47:07,133:INFO:Initializing tune_model()
2023-07-03 15:47:07,133:INFO:tune_model(estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE28DC6290>)
2023-07-03 15:47:07,133:INFO:Checking exceptions
2023-07-03 15:47:07,147:INFO:Copying training dataset
2023-07-03 15:47:07,149:INFO:Checking base model
2023-07-03 15:47:07,150:INFO:Base model : SVM - Linear Kernel
2023-07-03 15:47:07,153:INFO:Declaring metric variables
2023-07-03 15:47:07,155:INFO:Defining Hyperparameters
2023-07-03 15:47:07,316:INFO:Tuning with n_jobs=-1
2023-07-03 15:47:07,316:INFO:Initializing RandomizedSearchCV
2023-07-03 15:47:43,682:INFO:best_params: {'actual_estimator__penalty': 'elasticnet', 'actual_estimator__learning_rate': 'adaptive', 'actual_estimator__l1_ratio': 0.7800000001, 'actual_estimator__fit_intercept': False, 'actual_estimator__eta0': 0.5, 'actual_estimator__alpha': 0.15}
2023-07-03 15:47:43,683:INFO:Hyperparameter search completed
2023-07-03 15:47:43,683:INFO:SubProcess create_model() called ==================================
2023-07-03 15:47:43,683:INFO:Initializing create_model()
2023-07-03 15:47:43,684:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE28DC6290>, estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE28DAB7C0>, model_only=True, return_train_score=False, kwargs={'penalty': 'elasticnet', 'learning_rate': 'adaptive', 'l1_ratio': 0.7800000001, 'fit_intercept': False, 'eta0': 0.5, 'alpha': 0.15})
2023-07-03 15:47:43,684:INFO:Checking exceptions
2023-07-03 15:47:43,684:INFO:Importing libraries
2023-07-03 15:47:43,684:INFO:Copying training dataset
2023-07-03 15:47:43,687:INFO:Defining folds
2023-07-03 15:47:43,687:INFO:Declaring metric variables
2023-07-03 15:47:43,690:INFO:Importing untrained model
2023-07-03 15:47:43,690:INFO:Declaring custom model
2023-07-03 15:47:43,694:INFO:SVM - Linear Kernel Imported successfully
2023-07-03 15:47:43,700:INFO:Starting cross validation
2023-07-03 15:47:43,702:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 15:47:43,838:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 15:47:43,842:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:47:43,843:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 15:47:43,846:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 15:47:43,846:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:47:43,848:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 15:47:43,849:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 15:47:43,849:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:47:43,851:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:47:43,852:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:47:43,867:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 15:47:43,868:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 15:47:43,871:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:47:43,872:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:47:43,886:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 15:47:43,887:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 15:47:43,890:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:47:43,891:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:47:43,893:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 15:47:43,897:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:47:47,145:INFO:Calculating mean and std
2023-07-03 15:47:47,146:INFO:Creating metrics dataframe
2023-07-03 15:47:47,151:INFO:Finalizing model
2023-07-03 15:47:47,737:INFO:Uploading results into container
2023-07-03 15:47:47,738:INFO:Uploading model into container now
2023-07-03 15:47:47,738:INFO:_master_model_container: 17
2023-07-03 15:47:47,739:INFO:_display_container: 5
2023-07-03 15:47:47,739:INFO:SGDClassifier(alpha=0.15, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.5, fit_intercept=False,
              l1_ratio=0.7800000001, learning_rate='adaptive', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1,
              penalty='elasticnet', power_t=0.5, random_state=123, shuffle=True,
              tol=0.001, validation_fraction=0.1, verbose=0, warm_start=False)
2023-07-03 15:47:47,739:INFO:create_model() successfully completed......................................
2023-07-03 15:47:47,904:INFO:SubProcess create_model() end ==================================
2023-07-03 15:47:47,904:INFO:choose_better activated
2023-07-03 15:47:47,907:INFO:SubProcess create_model() called ==================================
2023-07-03 15:47:47,908:INFO:Initializing create_model()
2023-07-03 15:47:47,908:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE28DC6290>, estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-03 15:47:47,908:INFO:Checking exceptions
2023-07-03 15:47:47,910:INFO:Importing libraries
2023-07-03 15:47:47,910:INFO:Copying training dataset
2023-07-03 15:47:47,912:INFO:Defining folds
2023-07-03 15:47:47,912:INFO:Declaring metric variables
2023-07-03 15:47:47,912:INFO:Importing untrained model
2023-07-03 15:47:47,912:INFO:Declaring custom model
2023-07-03 15:47:47,913:INFO:SVM - Linear Kernel Imported successfully
2023-07-03 15:47:47,913:INFO:Starting cross validation
2023-07-03 15:47:47,914:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 15:47:48,040:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 15:47:48,044:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:47:48,049:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 15:47:48,053:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:47:48,058:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 15:47:48,062:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:47:48,064:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 15:47:48,067:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:47:48,069:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 15:47:48,072:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:47:48,078:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 15:47:48,082:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:47:48,088:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 15:47:48,092:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 15:47:48,095:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:47:48,098:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 15:47:48,098:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 15:47:48,102:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:47:48,102:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 15:47:51,372:INFO:Calculating mean and std
2023-07-03 15:47:51,372:INFO:Creating metrics dataframe
2023-07-03 15:47:51,374:INFO:Finalizing model
2023-07-03 15:47:51,965:INFO:Uploading results into container
2023-07-03 15:47:51,966:INFO:Uploading model into container now
2023-07-03 15:47:51,966:INFO:_master_model_container: 18
2023-07-03 15:47:51,966:INFO:_display_container: 6
2023-07-03 15:47:51,967:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-07-03 15:47:51,967:INFO:create_model() successfully completed......................................
2023-07-03 15:47:52,126:INFO:SubProcess create_model() end ==================================
2023-07-03 15:47:52,127:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False) result for Accuracy is 0.5
2023-07-03 15:47:52,127:INFO:SGDClassifier(alpha=0.15, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.5, fit_intercept=False,
              l1_ratio=0.7800000001, learning_rate='adaptive', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1,
              penalty='elasticnet', power_t=0.5, random_state=123, shuffle=True,
              tol=0.001, validation_fraction=0.1, verbose=0, warm_start=False) result for Accuracy is 0.5
2023-07-03 15:47:52,127:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False) is best model
2023-07-03 15:47:52,128:INFO:choose_better completed
2023-07-03 15:47:52,128:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-07-03 15:47:52,136:INFO:_master_model_container: 18
2023-07-03 15:47:52,136:INFO:_display_container: 5
2023-07-03 15:47:52,136:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-07-03 15:47:52,137:INFO:tune_model() successfully completed......................................
2023-07-03 16:17:53,084:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-03 16:17:53,084:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-03 16:17:53,084:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-03 16:17:53,084:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-03 16:17:53,673:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-07-03 16:17:54,166:INFO:PyCaret ClassificationExperiment
2023-07-03 16:17:54,166:INFO:Logging name: clf-default-name
2023-07-03 16:17:54,166:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-07-03 16:17:54,166:INFO:version 3.0.2
2023-07-03 16:17:54,166:INFO:Initializing setup()
2023-07-03 16:17:54,166:INFO:self.USI: 1871
2023-07-03 16:17:54,167:INFO:self._variable_keys: {'logging_param', 'pipeline', 'gpu_param', 'X_train', 'X', 'y', 'X_test', 'y_train', 'data', 'is_multiclass', 'exp_id', 'idx', 'fold_shuffle_param', '_ml_usecase', 'log_plots_param', 'fix_imbalance', 'gpu_n_jobs_param', 'memory', 'n_jobs_param', 'fold_generator', 'target_param', 'USI', '_available_plots', 'seed', 'html_param', 'y_test', 'exp_name_log', 'fold_groups_param'}
2023-07-03 16:17:54,167:INFO:Checking environment
2023-07-03 16:17:54,167:INFO:python_version: 3.10.9
2023-07-03 16:17:54,167:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2023-07-03 16:17:54,167:INFO:machine: AMD64
2023-07-03 16:17:54,167:INFO:platform: Windows-10-10.0.22621-SP0
2023-07-03 16:17:54,171:INFO:Memory: svmem(total=33664483328, available=20859588608, percent=38.0, used=12804894720, free=20859588608)
2023-07-03 16:17:54,171:INFO:Physical Core: 6
2023-07-03 16:17:54,171:INFO:Logical Core: 12
2023-07-03 16:17:54,171:INFO:Checking libraries
2023-07-03 16:17:54,171:INFO:System:
2023-07-03 16:17:54,171:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2023-07-03 16:17:54,171:INFO:executable: C:\Users\JHossain\anaconda3\python.exe
2023-07-03 16:17:54,171:INFO:   machine: Windows-10-10.0.22621-SP0
2023-07-03 16:17:54,171:INFO:PyCaret required dependencies:
2023-07-03 16:17:54,171:INFO:                 pip: 22.3.1
2023-07-03 16:17:54,172:INFO:          setuptools: 65.6.3
2023-07-03 16:17:54,172:INFO:             pycaret: 3.0.2
2023-07-03 16:17:54,172:INFO:             IPython: 8.10.0
2023-07-03 16:17:54,172:INFO:          ipywidgets: 7.6.5
2023-07-03 16:17:54,172:INFO:                tqdm: 4.64.1
2023-07-03 16:17:54,172:INFO:               numpy: 1.23.5
2023-07-03 16:17:54,172:INFO:              pandas: 1.5.3
2023-07-03 16:17:54,172:INFO:              jinja2: 3.1.2
2023-07-03 16:17:54,172:INFO:               scipy: 1.10.0
2023-07-03 16:17:54,172:INFO:              joblib: 1.2.0
2023-07-03 16:17:54,172:INFO:             sklearn: 1.2.1
2023-07-03 16:17:54,172:INFO:                pyod: 1.0.9
2023-07-03 16:17:54,172:INFO:            imblearn: 0.10.1
2023-07-03 16:17:54,172:INFO:   category_encoders: 2.6.1
2023-07-03 16:17:54,172:INFO:            lightgbm: 3.3.5
2023-07-03 16:17:54,172:INFO:               numba: 0.56.4
2023-07-03 16:17:54,172:INFO:            requests: 2.28.1
2023-07-03 16:17:54,172:INFO:          matplotlib: 3.7.0
2023-07-03 16:17:54,172:INFO:          scikitplot: 0.3.7
2023-07-03 16:17:54,172:INFO:         yellowbrick: 1.5
2023-07-03 16:17:54,172:INFO:              plotly: 5.9.0
2023-07-03 16:17:54,172:INFO:             kaleido: 0.2.1
2023-07-03 16:17:54,172:INFO:         statsmodels: 0.13.5
2023-07-03 16:17:54,172:INFO:              sktime: 0.17.0
2023-07-03 16:17:54,172:INFO:               tbats: 1.1.3
2023-07-03 16:17:54,172:INFO:            pmdarima: 2.0.3
2023-07-03 16:17:54,172:INFO:              psutil: 5.9.0
2023-07-03 16:17:54,172:INFO:PyCaret optional dependencies:
2023-07-03 16:17:55,163:INFO:                shap: 0.41.0
2023-07-03 16:17:55,164:INFO:           interpret: 0.4.2
2023-07-03 16:17:55,164:INFO:                umap: Not installed
2023-07-03 16:17:55,164:INFO:    pandas_profiling: Not installed
2023-07-03 16:17:55,164:INFO:  explainerdashboard: Not installed
2023-07-03 16:17:55,164:INFO:             autoviz: Not installed
2023-07-03 16:17:55,164:INFO:           fairlearn: Not installed
2023-07-03 16:17:55,164:INFO:             xgboost: Not installed
2023-07-03 16:17:55,164:INFO:            catboost: Not installed
2023-07-03 16:17:55,164:INFO:              kmodes: Not installed
2023-07-03 16:17:55,164:INFO:             mlxtend: Not installed
2023-07-03 16:17:55,164:INFO:       statsforecast: Not installed
2023-07-03 16:17:55,164:INFO:        tune_sklearn: Not installed
2023-07-03 16:17:55,164:INFO:                 ray: Not installed
2023-07-03 16:17:55,164:INFO:            hyperopt: Not installed
2023-07-03 16:17:55,164:INFO:              optuna: Not installed
2023-07-03 16:17:55,164:INFO:               skopt: Not installed
2023-07-03 16:17:55,164:INFO:              mlflow: Not installed
2023-07-03 16:17:55,164:INFO:              gradio: 3.35.2
2023-07-03 16:17:55,164:INFO:             fastapi: 0.99.0
2023-07-03 16:17:55,164:INFO:             uvicorn: 0.22.0
2023-07-03 16:17:55,164:INFO:              m2cgen: Not installed
2023-07-03 16:17:55,164:INFO:           evidently: Not installed
2023-07-03 16:17:55,164:INFO:               fugue: Not installed
2023-07-03 16:17:55,164:INFO:           streamlit: Not installed
2023-07-03 16:17:55,164:INFO:             prophet: Not installed
2023-07-03 16:17:55,164:INFO:None
2023-07-03 16:17:55,165:INFO:Set up data.
2023-07-03 16:17:55,172:INFO:Set up train/test split.
2023-07-03 16:17:55,175:INFO:Set up index.
2023-07-03 16:17:55,175:INFO:Set up folding strategy.
2023-07-03 16:17:55,175:INFO:Assigning column types.
2023-07-03 16:17:55,178:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-07-03 16:17:55,215:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-03 16:17:55,217:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-03 16:17:55,247:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 16:17:55,405:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 16:17:55,449:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-03 16:17:55,450:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-03 16:17:55,473:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 16:17:55,473:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 16:17:55,473:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-07-03 16:17:55,510:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-03 16:17:55,533:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 16:17:55,534:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 16:17:55,570:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-03 16:17:55,597:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 16:17:55,597:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 16:17:55,597:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-07-03 16:17:55,658:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 16:17:55,658:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 16:17:55,718:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 16:17:55,718:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 16:17:55,721:INFO:Preparing preprocessing pipeline...
2023-07-03 16:17:55,721:INFO:Set up label encoding.
2023-07-03 16:17:55,721:INFO:Set up simple imputation.
2023-07-03 16:17:55,724:INFO:Set up encoding of ordinal features.
2023-07-03 16:17:55,725:INFO:Set up encoding of categorical features.
2023-07-03 16:17:55,726:INFO:Set up column name cleaning.
2023-07-03 16:17:55,774:INFO:Finished creating preprocessing pipeline.
2023-07-03 16:17:55,793:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\JHossain\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['AGE', 'STEROID', 'ANTIVIRALS',
                                             'FATIGUE', 'MALAISE', 'ANOREXIA',
                                             'LIVER BIG', 'LIVER FIRM',
                                             'SPLEEN PALPABL...
                                    transformer=OrdinalEncoder(cols=['SEX'],
                                                               drop_invariant=False,
                                                               handle_missing='return_nan',
                                                               handle_unknown='value',
                                                               mapping=[{'col': 'SEX',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 1.0    0
2.0    1
NaN   -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-07-03 16:17:55,793:INFO:Creating final display dataframe.
2023-07-03 16:17:55,938:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             Class
2                   Target type            Binary
3                Target mapping        1: 0, 2: 1
4           Original data shape         (155, 20)
5        Transformed data shape         (155, 20)
6   Transformed train set shape         (108, 20)
7    Transformed test set shape          (47, 20)
8              Ordinal features                 1
9              Numeric features                18
10         Categorical features                 1
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              1871
2023-07-03 16:17:56,004:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 16:17:56,005:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 16:17:56,064:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 16:17:56,065:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 16:17:56,065:INFO:setup() successfully completed in 2.27s...............
2023-07-03 16:18:12,883:INFO:Initializing compare_models()
2023-07-03 16:18:12,883:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BBAE0B95A0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001BBAE0B95A0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-07-03 16:18:12,883:INFO:Checking exceptions
2023-07-03 16:18:12,887:INFO:Preparing display monitor
2023-07-03 16:18:12,905:INFO:Initializing Logistic Regression
2023-07-03 16:18:12,906:INFO:Total runtime is 1.6661485036214194e-05 minutes
2023-07-03 16:18:12,909:INFO:SubProcess create_model() called ==================================
2023-07-03 16:18:12,909:INFO:Initializing create_model()
2023-07-03 16:18:12,909:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BBAE0B95A0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BBAF9FBF40>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 16:18:12,910:INFO:Checking exceptions
2023-07-03 16:18:12,910:INFO:Importing libraries
2023-07-03 16:18:12,910:INFO:Copying training dataset
2023-07-03 16:18:12,913:INFO:Defining folds
2023-07-03 16:18:12,913:INFO:Declaring metric variables
2023-07-03 16:18:12,917:INFO:Importing untrained model
2023-07-03 16:18:12,920:INFO:Logistic Regression Imported successfully
2023-07-03 16:18:12,925:INFO:Starting cross validation
2023-07-03 16:18:12,926:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 16:18:21,600:INFO:Calculating mean and std
2023-07-03 16:18:21,602:INFO:Creating metrics dataframe
2023-07-03 16:18:22,146:INFO:Uploading results into container
2023-07-03 16:18:22,147:INFO:Uploading model into container now
2023-07-03 16:18:22,147:INFO:_master_model_container: 1
2023-07-03 16:18:22,148:INFO:_display_container: 2
2023-07-03 16:18:22,148:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-03 16:18:22,148:INFO:create_model() successfully completed......................................
2023-07-03 16:18:22,455:INFO:SubProcess create_model() end ==================================
2023-07-03 16:18:22,455:INFO:Creating metrics dataframe
2023-07-03 16:18:22,464:INFO:Initializing K Neighbors Classifier
2023-07-03 16:18:22,464:INFO:Total runtime is 0.15931422313054402 minutes
2023-07-03 16:18:22,467:INFO:SubProcess create_model() called ==================================
2023-07-03 16:18:22,467:INFO:Initializing create_model()
2023-07-03 16:18:22,467:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BBAE0B95A0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BBAF9FBF40>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 16:18:22,467:INFO:Checking exceptions
2023-07-03 16:18:22,467:INFO:Importing libraries
2023-07-03 16:18:22,467:INFO:Copying training dataset
2023-07-03 16:18:22,471:INFO:Defining folds
2023-07-03 16:18:22,472:INFO:Declaring metric variables
2023-07-03 16:18:22,475:INFO:Importing untrained model
2023-07-03 16:18:22,477:INFO:K Neighbors Classifier Imported successfully
2023-07-03 16:18:22,482:INFO:Starting cross validation
2023-07-03 16:18:22,483:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 16:18:26,269:INFO:Calculating mean and std
2023-07-03 16:18:26,270:INFO:Creating metrics dataframe
2023-07-03 16:18:26,823:INFO:Uploading results into container
2023-07-03 16:18:26,824:INFO:Uploading model into container now
2023-07-03 16:18:26,824:INFO:_master_model_container: 2
2023-07-03 16:18:26,824:INFO:_display_container: 2
2023-07-03 16:18:26,825:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-07-03 16:18:26,825:INFO:create_model() successfully completed......................................
2023-07-03 16:18:27,132:INFO:SubProcess create_model() end ==================================
2023-07-03 16:18:27,132:INFO:Creating metrics dataframe
2023-07-03 16:18:27,140:INFO:Initializing Naive Bayes
2023-07-03 16:18:27,140:INFO:Total runtime is 0.23725622097651164 minutes
2023-07-03 16:18:27,143:INFO:SubProcess create_model() called ==================================
2023-07-03 16:18:27,143:INFO:Initializing create_model()
2023-07-03 16:18:27,143:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BBAE0B95A0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BBAF9FBF40>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 16:18:27,143:INFO:Checking exceptions
2023-07-03 16:18:27,144:INFO:Importing libraries
2023-07-03 16:18:27,144:INFO:Copying training dataset
2023-07-03 16:18:27,148:INFO:Defining folds
2023-07-03 16:18:27,148:INFO:Declaring metric variables
2023-07-03 16:18:27,151:INFO:Importing untrained model
2023-07-03 16:18:27,154:INFO:Naive Bayes Imported successfully
2023-07-03 16:18:27,159:INFO:Starting cross validation
2023-07-03 16:18:27,160:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 16:18:30,670:INFO:Calculating mean and std
2023-07-03 16:18:30,672:INFO:Creating metrics dataframe
2023-07-03 16:18:31,229:INFO:Uploading results into container
2023-07-03 16:18:31,230:INFO:Uploading model into container now
2023-07-03 16:18:31,230:INFO:_master_model_container: 3
2023-07-03 16:18:31,230:INFO:_display_container: 2
2023-07-03 16:18:31,230:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-07-03 16:18:31,230:INFO:create_model() successfully completed......................................
2023-07-03 16:18:31,539:INFO:SubProcess create_model() end ==================================
2023-07-03 16:18:31,555:INFO:Creating metrics dataframe
2023-07-03 16:18:31,562:INFO:Initializing Decision Tree Classifier
2023-07-03 16:18:31,563:INFO:Total runtime is 0.3109654744466146 minutes
2023-07-03 16:18:31,565:INFO:SubProcess create_model() called ==================================
2023-07-03 16:18:31,566:INFO:Initializing create_model()
2023-07-03 16:18:31,566:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BBAE0B95A0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BBAF9FBF40>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 16:18:31,566:INFO:Checking exceptions
2023-07-03 16:18:31,566:INFO:Importing libraries
2023-07-03 16:18:31,566:INFO:Copying training dataset
2023-07-03 16:18:31,570:INFO:Defining folds
2023-07-03 16:18:31,570:INFO:Declaring metric variables
2023-07-03 16:18:31,573:INFO:Importing untrained model
2023-07-03 16:18:31,576:INFO:Decision Tree Classifier Imported successfully
2023-07-03 16:18:31,581:INFO:Starting cross validation
2023-07-03 16:18:31,583:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 16:18:35,132:INFO:Calculating mean and std
2023-07-03 16:18:35,133:INFO:Creating metrics dataframe
2023-07-03 16:18:35,693:INFO:Uploading results into container
2023-07-03 16:18:35,694:INFO:Uploading model into container now
2023-07-03 16:18:35,695:INFO:_master_model_container: 4
2023-07-03 16:18:35,695:INFO:_display_container: 2
2023-07-03 16:18:35,695:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-07-03 16:18:35,695:INFO:create_model() successfully completed......................................
2023-07-03 16:18:36,023:INFO:SubProcess create_model() end ==================================
2023-07-03 16:18:36,023:INFO:Creating metrics dataframe
2023-07-03 16:18:36,034:INFO:Initializing SVM - Linear Kernel
2023-07-03 16:18:36,034:INFO:Total runtime is 0.38548089265823365 minutes
2023-07-03 16:18:36,037:INFO:SubProcess create_model() called ==================================
2023-07-03 16:18:36,037:INFO:Initializing create_model()
2023-07-03 16:18:36,037:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BBAE0B95A0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BBAF9FBF40>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 16:18:36,037:INFO:Checking exceptions
2023-07-03 16:18:36,037:INFO:Importing libraries
2023-07-03 16:18:36,038:INFO:Copying training dataset
2023-07-03 16:18:36,042:INFO:Defining folds
2023-07-03 16:18:36,042:INFO:Declaring metric variables
2023-07-03 16:18:36,046:INFO:Importing untrained model
2023-07-03 16:18:36,049:INFO:SVM - Linear Kernel Imported successfully
2023-07-03 16:18:36,055:INFO:Starting cross validation
2023-07-03 16:18:36,056:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 16:18:36,220:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 16:18:36,241:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 16:18:36,242:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 16:18:36,244:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 16:18:36,254:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 16:18:36,269:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 16:18:36,277:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 16:18:36,292:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 16:18:36,297:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 16:18:36,307:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 16:18:39,602:INFO:Calculating mean and std
2023-07-03 16:18:39,604:INFO:Creating metrics dataframe
2023-07-03 16:18:40,169:INFO:Uploading results into container
2023-07-03 16:18:40,170:INFO:Uploading model into container now
2023-07-03 16:18:40,170:INFO:_master_model_container: 5
2023-07-03 16:18:40,170:INFO:_display_container: 2
2023-07-03 16:18:40,170:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-07-03 16:18:40,170:INFO:create_model() successfully completed......................................
2023-07-03 16:18:40,489:INFO:SubProcess create_model() end ==================================
2023-07-03 16:18:40,490:INFO:Creating metrics dataframe
2023-07-03 16:18:40,498:INFO:Initializing Ridge Classifier
2023-07-03 16:18:40,498:INFO:Total runtime is 0.45987977981567385 minutes
2023-07-03 16:18:40,500:INFO:SubProcess create_model() called ==================================
2023-07-03 16:18:40,501:INFO:Initializing create_model()
2023-07-03 16:18:40,501:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BBAE0B95A0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BBAF9FBF40>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 16:18:40,501:INFO:Checking exceptions
2023-07-03 16:18:40,501:INFO:Importing libraries
2023-07-03 16:18:40,501:INFO:Copying training dataset
2023-07-03 16:18:40,504:INFO:Defining folds
2023-07-03 16:18:40,505:INFO:Declaring metric variables
2023-07-03 16:18:40,507:INFO:Importing untrained model
2023-07-03 16:18:40,510:INFO:Ridge Classifier Imported successfully
2023-07-03 16:18:40,515:INFO:Starting cross validation
2023-07-03 16:18:40,517:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 16:18:40,661:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 16:18:40,663:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 16:18:40,663:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 16:18:40,663:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 16:18:40,677:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 16:18:40,696:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 16:18:40,706:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 16:18:40,715:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 16:18:40,723:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 16:18:44,028:INFO:Calculating mean and std
2023-07-03 16:18:44,029:INFO:Creating metrics dataframe
2023-07-03 16:18:44,591:INFO:Uploading results into container
2023-07-03 16:18:44,592:INFO:Uploading model into container now
2023-07-03 16:18:44,592:INFO:_master_model_container: 6
2023-07-03 16:18:44,592:INFO:_display_container: 2
2023-07-03 16:18:44,592:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-07-03 16:18:44,592:INFO:create_model() successfully completed......................................
2023-07-03 16:18:44,903:INFO:SubProcess create_model() end ==================================
2023-07-03 16:18:44,903:INFO:Creating metrics dataframe
2023-07-03 16:18:44,912:INFO:Initializing Random Forest Classifier
2023-07-03 16:18:44,912:INFO:Total runtime is 0.5334520061810811 minutes
2023-07-03 16:18:44,914:INFO:SubProcess create_model() called ==================================
2023-07-03 16:18:44,915:INFO:Initializing create_model()
2023-07-03 16:18:44,915:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BBAE0B95A0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BBAF9FBF40>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 16:18:44,915:INFO:Checking exceptions
2023-07-03 16:18:44,915:INFO:Importing libraries
2023-07-03 16:18:44,915:INFO:Copying training dataset
2023-07-03 16:18:44,919:INFO:Defining folds
2023-07-03 16:18:44,919:INFO:Declaring metric variables
2023-07-03 16:18:44,922:INFO:Importing untrained model
2023-07-03 16:18:44,925:INFO:Random Forest Classifier Imported successfully
2023-07-03 16:18:44,930:INFO:Starting cross validation
2023-07-03 16:18:44,931:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 16:18:49,112:INFO:Calculating mean and std
2023-07-03 16:18:49,113:INFO:Creating metrics dataframe
2023-07-03 16:18:49,681:INFO:Uploading results into container
2023-07-03 16:18:49,681:INFO:Uploading model into container now
2023-07-03 16:18:49,682:INFO:_master_model_container: 7
2023-07-03 16:18:49,683:INFO:_display_container: 2
2023-07-03 16:18:49,683:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-07-03 16:18:49,683:INFO:create_model() successfully completed......................................
2023-07-03 16:18:49,998:INFO:SubProcess create_model() end ==================================
2023-07-03 16:18:49,998:INFO:Creating metrics dataframe
2023-07-03 16:18:50,010:INFO:Initializing Quadratic Discriminant Analysis
2023-07-03 16:18:50,010:INFO:Total runtime is 0.6184067527453104 minutes
2023-07-03 16:18:50,013:INFO:SubProcess create_model() called ==================================
2023-07-03 16:18:50,013:INFO:Initializing create_model()
2023-07-03 16:18:50,013:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BBAE0B95A0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BBAF9FBF40>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 16:18:50,013:INFO:Checking exceptions
2023-07-03 16:18:50,013:INFO:Importing libraries
2023-07-03 16:18:50,014:INFO:Copying training dataset
2023-07-03 16:18:50,017:INFO:Defining folds
2023-07-03 16:18:50,017:INFO:Declaring metric variables
2023-07-03 16:18:50,020:INFO:Importing untrained model
2023-07-03 16:18:50,023:INFO:Quadratic Discriminant Analysis Imported successfully
2023-07-03 16:18:50,028:INFO:Starting cross validation
2023-07-03 16:18:50,029:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 16:18:50,121:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-03 16:18:50,131:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-03 16:18:50,131:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-03 16:18:50,134:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-03 16:18:50,140:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-03 16:18:50,156:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-03 16:18:50,156:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-03 16:18:50,166:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-03 16:18:50,174:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-03 16:18:50,179:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-03 16:18:53,593:INFO:Calculating mean and std
2023-07-03 16:18:53,594:INFO:Creating metrics dataframe
2023-07-03 16:18:54,156:INFO:Uploading results into container
2023-07-03 16:18:54,156:INFO:Uploading model into container now
2023-07-03 16:18:54,157:INFO:_master_model_container: 8
2023-07-03 16:18:54,157:INFO:_display_container: 2
2023-07-03 16:18:54,157:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-07-03 16:18:54,157:INFO:create_model() successfully completed......................................
2023-07-03 16:18:54,466:INFO:SubProcess create_model() end ==================================
2023-07-03 16:18:54,467:INFO:Creating metrics dataframe
2023-07-03 16:18:54,477:INFO:Initializing Ada Boost Classifier
2023-07-03 16:18:54,477:INFO:Total runtime is 0.6928704102834066 minutes
2023-07-03 16:18:54,480:INFO:SubProcess create_model() called ==================================
2023-07-03 16:18:54,480:INFO:Initializing create_model()
2023-07-03 16:18:54,480:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BBAE0B95A0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BBAF9FBF40>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 16:18:54,480:INFO:Checking exceptions
2023-07-03 16:18:54,480:INFO:Importing libraries
2023-07-03 16:18:54,481:INFO:Copying training dataset
2023-07-03 16:18:54,485:INFO:Defining folds
2023-07-03 16:18:54,485:INFO:Declaring metric variables
2023-07-03 16:18:54,488:INFO:Importing untrained model
2023-07-03 16:18:54,490:INFO:Ada Boost Classifier Imported successfully
2023-07-03 16:18:54,495:INFO:Starting cross validation
2023-07-03 16:18:54,496:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 16:18:58,188:INFO:Calculating mean and std
2023-07-03 16:18:58,189:INFO:Creating metrics dataframe
2023-07-03 16:18:58,756:INFO:Uploading results into container
2023-07-03 16:18:58,756:INFO:Uploading model into container now
2023-07-03 16:18:58,757:INFO:_master_model_container: 9
2023-07-03 16:18:58,757:INFO:_display_container: 2
2023-07-03 16:18:58,757:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-07-03 16:18:58,757:INFO:create_model() successfully completed......................................
2023-07-03 16:18:59,068:INFO:SubProcess create_model() end ==================================
2023-07-03 16:18:59,068:INFO:Creating metrics dataframe
2023-07-03 16:18:59,078:INFO:Initializing Gradient Boosting Classifier
2023-07-03 16:18:59,078:INFO:Total runtime is 0.769548761844635 minutes
2023-07-03 16:18:59,081:INFO:SubProcess create_model() called ==================================
2023-07-03 16:18:59,081:INFO:Initializing create_model()
2023-07-03 16:18:59,081:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BBAE0B95A0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BBAF9FBF40>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 16:18:59,081:INFO:Checking exceptions
2023-07-03 16:18:59,081:INFO:Importing libraries
2023-07-03 16:18:59,081:INFO:Copying training dataset
2023-07-03 16:18:59,085:INFO:Defining folds
2023-07-03 16:18:59,085:INFO:Declaring metric variables
2023-07-03 16:18:59,088:INFO:Importing untrained model
2023-07-03 16:18:59,091:INFO:Gradient Boosting Classifier Imported successfully
2023-07-03 16:18:59,096:INFO:Starting cross validation
2023-07-03 16:18:59,097:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 16:19:02,969:INFO:Calculating mean and std
2023-07-03 16:19:02,971:INFO:Creating metrics dataframe
2023-07-03 16:19:03,533:INFO:Uploading results into container
2023-07-03 16:19:03,534:INFO:Uploading model into container now
2023-07-03 16:19:03,534:INFO:_master_model_container: 10
2023-07-03 16:19:03,534:INFO:_display_container: 2
2023-07-03 16:19:03,535:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-03 16:19:03,535:INFO:create_model() successfully completed......................................
2023-07-03 16:19:03,849:INFO:SubProcess create_model() end ==================================
2023-07-03 16:19:03,849:INFO:Creating metrics dataframe
2023-07-03 16:19:03,860:INFO:Initializing Linear Discriminant Analysis
2023-07-03 16:19:03,860:INFO:Total runtime is 0.849242913722992 minutes
2023-07-03 16:19:03,862:INFO:SubProcess create_model() called ==================================
2023-07-03 16:19:03,862:INFO:Initializing create_model()
2023-07-03 16:19:03,862:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BBAE0B95A0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BBAF9FBF40>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 16:19:03,863:INFO:Checking exceptions
2023-07-03 16:19:03,863:INFO:Importing libraries
2023-07-03 16:19:03,863:INFO:Copying training dataset
2023-07-03 16:19:03,866:INFO:Defining folds
2023-07-03 16:19:03,867:INFO:Declaring metric variables
2023-07-03 16:19:03,869:INFO:Importing untrained model
2023-07-03 16:19:03,872:INFO:Linear Discriminant Analysis Imported successfully
2023-07-03 16:19:03,877:INFO:Starting cross validation
2023-07-03 16:19:03,878:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 16:19:07,437:INFO:Calculating mean and std
2023-07-03 16:19:07,438:INFO:Creating metrics dataframe
2023-07-03 16:19:08,006:INFO:Uploading results into container
2023-07-03 16:19:08,006:INFO:Uploading model into container now
2023-07-03 16:19:08,007:INFO:_master_model_container: 11
2023-07-03 16:19:08,007:INFO:_display_container: 2
2023-07-03 16:19:08,007:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-07-03 16:19:08,007:INFO:create_model() successfully completed......................................
2023-07-03 16:19:08,313:INFO:SubProcess create_model() end ==================================
2023-07-03 16:19:08,313:INFO:Creating metrics dataframe
2023-07-03 16:19:08,323:INFO:Initializing Extra Trees Classifier
2023-07-03 16:19:08,324:INFO:Total runtime is 0.9236404299736023 minutes
2023-07-03 16:19:08,326:INFO:SubProcess create_model() called ==================================
2023-07-03 16:19:08,326:INFO:Initializing create_model()
2023-07-03 16:19:08,327:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BBAE0B95A0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BBAF9FBF40>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 16:19:08,327:INFO:Checking exceptions
2023-07-03 16:19:08,327:INFO:Importing libraries
2023-07-03 16:19:08,327:INFO:Copying training dataset
2023-07-03 16:19:08,330:INFO:Defining folds
2023-07-03 16:19:08,330:INFO:Declaring metric variables
2023-07-03 16:19:08,333:INFO:Importing untrained model
2023-07-03 16:19:08,335:INFO:Extra Trees Classifier Imported successfully
2023-07-03 16:19:08,341:INFO:Starting cross validation
2023-07-03 16:19:08,342:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 16:19:12,521:INFO:Calculating mean and std
2023-07-03 16:19:12,522:INFO:Creating metrics dataframe
2023-07-03 16:19:13,101:INFO:Uploading results into container
2023-07-03 16:19:13,102:INFO:Uploading model into container now
2023-07-03 16:19:13,102:INFO:_master_model_container: 12
2023-07-03 16:19:13,103:INFO:_display_container: 2
2023-07-03 16:19:13,103:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-07-03 16:19:13,103:INFO:create_model() successfully completed......................................
2023-07-03 16:19:13,413:INFO:SubProcess create_model() end ==================================
2023-07-03 16:19:13,413:INFO:Creating metrics dataframe
2023-07-03 16:19:13,424:INFO:Initializing Light Gradient Boosting Machine
2023-07-03 16:19:13,424:INFO:Total runtime is 1.0086421449979146 minutes
2023-07-03 16:19:13,426:INFO:SubProcess create_model() called ==================================
2023-07-03 16:19:13,427:INFO:Initializing create_model()
2023-07-03 16:19:13,427:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BBAE0B95A0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BBAF9FBF40>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 16:19:13,427:INFO:Checking exceptions
2023-07-03 16:19:13,427:INFO:Importing libraries
2023-07-03 16:19:13,427:INFO:Copying training dataset
2023-07-03 16:19:13,430:INFO:Defining folds
2023-07-03 16:19:13,430:INFO:Declaring metric variables
2023-07-03 16:19:13,433:INFO:Importing untrained model
2023-07-03 16:19:13,436:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-03 16:19:13,441:INFO:Starting cross validation
2023-07-03 16:19:13,442:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 16:19:18,209:INFO:Calculating mean and std
2023-07-03 16:19:18,210:INFO:Creating metrics dataframe
2023-07-03 16:19:18,780:INFO:Uploading results into container
2023-07-03 16:19:18,781:INFO:Uploading model into container now
2023-07-03 16:19:18,781:INFO:_master_model_container: 13
2023-07-03 16:19:18,781:INFO:_display_container: 2
2023-07-03 16:19:18,782:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-07-03 16:19:18,782:INFO:create_model() successfully completed......................................
2023-07-03 16:19:19,091:INFO:SubProcess create_model() end ==================================
2023-07-03 16:19:19,091:INFO:Creating metrics dataframe
2023-07-03 16:19:19,102:INFO:Initializing Dummy Classifier
2023-07-03 16:19:19,103:INFO:Total runtime is 1.1033037781715394 minutes
2023-07-03 16:19:19,106:INFO:SubProcess create_model() called ==================================
2023-07-03 16:19:19,106:INFO:Initializing create_model()
2023-07-03 16:19:19,106:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BBAE0B95A0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BBAF9FBF40>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 16:19:19,106:INFO:Checking exceptions
2023-07-03 16:19:19,106:INFO:Importing libraries
2023-07-03 16:19:19,106:INFO:Copying training dataset
2023-07-03 16:19:19,109:INFO:Defining folds
2023-07-03 16:19:19,111:INFO:Declaring metric variables
2023-07-03 16:19:19,113:INFO:Importing untrained model
2023-07-03 16:19:19,116:INFO:Dummy Classifier Imported successfully
2023-07-03 16:19:19,121:INFO:Starting cross validation
2023-07-03 16:19:19,121:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 16:19:22,684:INFO:Calculating mean and std
2023-07-03 16:19:22,685:INFO:Creating metrics dataframe
2023-07-03 16:19:23,247:INFO:Uploading results into container
2023-07-03 16:19:23,248:INFO:Uploading model into container now
2023-07-03 16:19:23,249:INFO:_master_model_container: 14
2023-07-03 16:19:23,249:INFO:_display_container: 2
2023-07-03 16:19:23,249:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-07-03 16:19:23,249:INFO:create_model() successfully completed......................................
2023-07-03 16:19:23,559:INFO:SubProcess create_model() end ==================================
2023-07-03 16:19:23,559:INFO:Creating metrics dataframe
2023-07-03 16:19:23,577:INFO:Initializing create_model()
2023-07-03 16:19:23,578:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BBAE0B95A0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-03 16:19:23,578:INFO:Checking exceptions
2023-07-03 16:19:23,579:INFO:Importing libraries
2023-07-03 16:19:23,579:INFO:Copying training dataset
2023-07-03 16:19:23,581:INFO:Defining folds
2023-07-03 16:19:23,581:INFO:Declaring metric variables
2023-07-03 16:19:23,582:INFO:Importing untrained model
2023-07-03 16:19:23,582:INFO:Declaring custom model
2023-07-03 16:19:23,582:INFO:Decision Tree Classifier Imported successfully
2023-07-03 16:19:23,583:INFO:Cross validation set to False
2023-07-03 16:19:23,583:INFO:Fitting Model
2023-07-03 16:19:23,985:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-07-03 16:19:23,985:INFO:create_model() successfully completed......................................
2023-07-03 16:19:24,310:INFO:_master_model_container: 14
2023-07-03 16:19:24,311:INFO:_display_container: 2
2023-07-03 16:19:24,311:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-07-03 16:19:24,311:INFO:compare_models() successfully completed......................................
2023-07-03 16:19:54,057:INFO:Initializing create_model()
2023-07-03 16:19:54,057:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BBAE0B95A0>, estimator=dt, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-03 16:19:54,057:INFO:Checking exceptions
2023-07-03 16:19:54,070:INFO:Importing libraries
2023-07-03 16:19:54,070:INFO:Copying training dataset
2023-07-03 16:19:54,074:INFO:Defining folds
2023-07-03 16:19:54,074:INFO:Declaring metric variables
2023-07-03 16:19:54,077:INFO:Importing untrained model
2023-07-03 16:19:54,079:INFO:Decision Tree Classifier Imported successfully
2023-07-03 16:19:54,085:INFO:Starting cross validation
2023-07-03 16:19:54,086:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 16:19:57,756:INFO:Calculating mean and std
2023-07-03 16:19:57,757:INFO:Creating metrics dataframe
2023-07-03 16:19:57,762:INFO:Finalizing model
2023-07-03 16:19:58,392:INFO:Uploading results into container
2023-07-03 16:19:58,393:INFO:Uploading model into container now
2023-07-03 16:19:58,400:INFO:_master_model_container: 15
2023-07-03 16:19:58,402:INFO:_display_container: 3
2023-07-03 16:19:58,402:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-07-03 16:19:58,402:INFO:create_model() successfully completed......................................
2023-07-03 16:20:07,329:INFO:Initializing tune_model()
2023-07-03 16:20:07,329:INFO:tune_model(estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BBAE0B95A0>)
2023-07-03 16:20:07,329:INFO:Checking exceptions
2023-07-03 16:20:07,342:INFO:Copying training dataset
2023-07-03 16:20:07,345:INFO:Checking base model
2023-07-03 16:20:07,345:INFO:Base model : Decision Tree Classifier
2023-07-03 16:20:07,348:INFO:Declaring metric variables
2023-07-03 16:20:07,351:INFO:Defining Hyperparameters
2023-07-03 16:20:07,664:INFO:Tuning with n_jobs=-1
2023-07-03 16:20:07,664:INFO:Initializing RandomizedSearchCV
2023-07-03 16:20:45,482:INFO:best_params: {'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.002, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 6, 'actual_estimator__criterion': 'entropy'}
2023-07-03 16:20:45,483:INFO:Hyperparameter search completed
2023-07-03 16:20:45,483:INFO:SubProcess create_model() called ==================================
2023-07-03 16:20:45,483:INFO:Initializing create_model()
2023-07-03 16:20:45,483:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BBAE0B95A0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BBB34F84C0>, model_only=True, return_train_score=False, kwargs={'min_samples_split': 5, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.002, 'max_features': 1.0, 'max_depth': 6, 'criterion': 'entropy'})
2023-07-03 16:20:45,484:INFO:Checking exceptions
2023-07-03 16:20:45,484:INFO:Importing libraries
2023-07-03 16:20:45,484:INFO:Copying training dataset
2023-07-03 16:20:45,487:INFO:Defining folds
2023-07-03 16:20:45,488:INFO:Declaring metric variables
2023-07-03 16:20:45,491:INFO:Importing untrained model
2023-07-03 16:20:45,491:INFO:Declaring custom model
2023-07-03 16:20:45,493:INFO:Decision Tree Classifier Imported successfully
2023-07-03 16:20:45,499:INFO:Starting cross validation
2023-07-03 16:20:45,500:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 16:20:49,136:INFO:Calculating mean and std
2023-07-03 16:20:49,137:INFO:Creating metrics dataframe
2023-07-03 16:20:49,144:INFO:Finalizing model
2023-07-03 16:20:49,763:INFO:Uploading results into container
2023-07-03 16:20:49,763:INFO:Uploading model into container now
2023-07-03 16:20:49,764:INFO:_master_model_container: 16
2023-07-03 16:20:49,764:INFO:_display_container: 4
2023-07-03 16:20:49,764:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',
                       max_depth=6, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.002, min_samples_leaf=5,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-07-03 16:20:49,765:INFO:create_model() successfully completed......................................
2023-07-03 16:20:50,081:INFO:SubProcess create_model() end ==================================
2023-07-03 16:20:50,081:INFO:choose_better activated
2023-07-03 16:20:50,085:INFO:SubProcess create_model() called ==================================
2023-07-03 16:20:50,085:INFO:Initializing create_model()
2023-07-03 16:20:50,085:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BBAE0B95A0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-03 16:20:50,085:INFO:Checking exceptions
2023-07-03 16:20:50,087:INFO:Importing libraries
2023-07-03 16:20:50,087:INFO:Copying training dataset
2023-07-03 16:20:50,089:INFO:Defining folds
2023-07-03 16:20:50,089:INFO:Declaring metric variables
2023-07-03 16:20:50,089:INFO:Importing untrained model
2023-07-03 16:20:50,089:INFO:Declaring custom model
2023-07-03 16:20:50,090:INFO:Decision Tree Classifier Imported successfully
2023-07-03 16:20:50,090:INFO:Starting cross validation
2023-07-03 16:20:50,091:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 16:20:53,751:INFO:Calculating mean and std
2023-07-03 16:20:53,751:INFO:Creating metrics dataframe
2023-07-03 16:20:53,753:INFO:Finalizing model
2023-07-03 16:20:54,377:INFO:Uploading results into container
2023-07-03 16:20:54,378:INFO:Uploading model into container now
2023-07-03 16:20:54,378:INFO:_master_model_container: 17
2023-07-03 16:20:54,378:INFO:_display_container: 5
2023-07-03 16:20:54,379:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-07-03 16:20:54,379:INFO:create_model() successfully completed......................................
2023-07-03 16:20:54,701:INFO:SubProcess create_model() end ==================================
2023-07-03 16:20:54,701:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best') result for Accuracy is 0.8527
2023-07-03 16:20:54,702:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',
                       max_depth=6, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.002, min_samples_leaf=5,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best') result for Accuracy is 0.8327
2023-07-03 16:20:54,702:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best') is best model
2023-07-03 16:20:54,702:INFO:choose_better completed
2023-07-03 16:20:54,702:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-07-03 16:20:54,711:INFO:_master_model_container: 17
2023-07-03 16:20:54,711:INFO:_display_container: 4
2023-07-03 16:20:54,712:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-07-03 16:20:54,712:INFO:tune_model() successfully completed......................................
2023-07-03 16:21:25,544:INFO:Initializing tune_model()
2023-07-03 16:21:25,544:INFO:tune_model(estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=True, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BBAE0B95A0>)
2023-07-03 16:21:25,544:INFO:Checking exceptions
2023-07-03 16:21:25,558:INFO:Copying training dataset
2023-07-03 16:21:25,561:INFO:Checking base model
2023-07-03 16:21:25,561:INFO:Base model : Decision Tree Classifier
2023-07-03 16:21:25,564:INFO:Declaring metric variables
2023-07-03 16:21:25,567:INFO:Defining Hyperparameters
2023-07-03 16:21:25,888:INFO:Tuning with n_jobs=-1
2023-07-03 16:21:25,888:INFO:Initializing RandomizedSearchCV
2023-07-03 16:22:03,361:INFO:best_params: {'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.002, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 6, 'actual_estimator__criterion': 'entropy'}
2023-07-03 16:22:03,362:INFO:Hyperparameter search completed
2023-07-03 16:22:03,362:INFO:SubProcess create_model() called ==================================
2023-07-03 16:22:03,362:INFO:Initializing create_model()
2023-07-03 16:22:03,363:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BBAE0B95A0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BBACE4FE50>, model_only=True, return_train_score=False, kwargs={'min_samples_split': 5, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.002, 'max_features': 1.0, 'max_depth': 6, 'criterion': 'entropy'})
2023-07-03 16:22:03,363:INFO:Checking exceptions
2023-07-03 16:22:03,363:INFO:Importing libraries
2023-07-03 16:22:03,363:INFO:Copying training dataset
2023-07-03 16:22:03,367:INFO:Defining folds
2023-07-03 16:22:03,367:INFO:Declaring metric variables
2023-07-03 16:22:03,370:INFO:Importing untrained model
2023-07-03 16:22:03,370:INFO:Declaring custom model
2023-07-03 16:22:03,373:INFO:Decision Tree Classifier Imported successfully
2023-07-03 16:22:03,378:INFO:Starting cross validation
2023-07-03 16:22:03,379:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 16:22:06,987:INFO:Calculating mean and std
2023-07-03 16:22:06,987:INFO:Creating metrics dataframe
2023-07-03 16:22:06,992:INFO:Finalizing model
2023-07-03 16:22:07,603:INFO:Uploading results into container
2023-07-03 16:22:07,604:INFO:Uploading model into container now
2023-07-03 16:22:07,604:INFO:_master_model_container: 18
2023-07-03 16:22:07,604:INFO:_display_container: 5
2023-07-03 16:22:07,604:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',
                       max_depth=6, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.002, min_samples_leaf=5,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-07-03 16:22:07,605:INFO:create_model() successfully completed......................................
2023-07-03 16:22:07,927:INFO:SubProcess create_model() end ==================================
2023-07-03 16:22:07,927:INFO:choose_better activated
2023-07-03 16:22:07,930:INFO:SubProcess create_model() called ==================================
2023-07-03 16:22:07,930:INFO:Initializing create_model()
2023-07-03 16:22:07,930:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BBAE0B95A0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-03 16:22:07,930:INFO:Checking exceptions
2023-07-03 16:22:07,932:INFO:Importing libraries
2023-07-03 16:22:07,932:INFO:Copying training dataset
2023-07-03 16:22:07,935:INFO:Defining folds
2023-07-03 16:22:07,935:INFO:Declaring metric variables
2023-07-03 16:22:07,936:INFO:Importing untrained model
2023-07-03 16:22:07,936:INFO:Declaring custom model
2023-07-03 16:22:07,936:INFO:Decision Tree Classifier Imported successfully
2023-07-03 16:22:07,936:INFO:Starting cross validation
2023-07-03 16:22:07,937:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 16:22:11,566:INFO:Calculating mean and std
2023-07-03 16:22:11,567:INFO:Creating metrics dataframe
2023-07-03 16:22:11,568:INFO:Finalizing model
2023-07-03 16:22:12,176:INFO:Uploading results into container
2023-07-03 16:22:12,176:INFO:Uploading model into container now
2023-07-03 16:22:12,177:INFO:_master_model_container: 19
2023-07-03 16:22:12,177:INFO:_display_container: 6
2023-07-03 16:22:12,177:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-07-03 16:22:12,177:INFO:create_model() successfully completed......................................
2023-07-03 16:22:12,483:INFO:SubProcess create_model() end ==================================
2023-07-03 16:22:12,483:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best') result for Accuracy is 0.8527
2023-07-03 16:22:12,484:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',
                       max_depth=6, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.002, min_samples_leaf=5,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best') result for Accuracy is 0.8327
2023-07-03 16:22:12,484:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best') is best model
2023-07-03 16:22:12,484:INFO:choose_better completed
2023-07-03 16:22:12,484:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-07-03 16:22:12,492:INFO:_master_model_container: 19
2023-07-03 16:22:12,493:INFO:_display_container: 5
2023-07-03 16:22:12,493:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-07-03 16:22:12,493:INFO:tune_model() successfully completed......................................
2023-07-03 16:22:33,562:INFO:Initializing plot_model()
2023-07-03 16:22:33,563:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BBAE0B95A0>, system=True)
2023-07-03 16:22:33,563:INFO:Checking exceptions
2023-07-03 16:22:33,566:INFO:Preloading libraries
2023-07-03 16:22:33,566:INFO:Copying training dataset
2023-07-03 16:22:33,566:INFO:Plot type: confusion_matrix
2023-07-03 16:22:33,700:INFO:Fitting Model
2023-07-03 16:22:33,701:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names
  warnings.warn(

2023-07-03 16:22:33,702:INFO:Scoring test/hold-out set
2023-07-03 16:22:33,794:INFO:Visual Rendered Successfully
2023-07-03 16:22:34,099:INFO:plot_model() successfully completed......................................
2023-07-03 16:22:44,266:INFO:Initializing plot_model()
2023-07-03 16:22:44,266:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BBAE0B95A0>, system=True)
2023-07-03 16:22:44,266:INFO:Checking exceptions
2023-07-03 16:22:44,270:INFO:Preloading libraries
2023-07-03 16:22:44,270:INFO:Copying training dataset
2023-07-03 16:22:44,270:INFO:Plot type: auc
2023-07-03 16:22:44,417:INFO:Fitting Model
2023-07-03 16:22:44,417:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names
  warnings.warn(

2023-07-03 16:22:44,418:INFO:Scoring test/hold-out set
2023-07-03 16:22:44,575:INFO:Visual Rendered Successfully
2023-07-03 16:22:44,877:INFO:plot_model() successfully completed......................................
2023-07-03 16:22:46,921:INFO:Initializing plot_model()
2023-07-03 16:22:46,922:INFO:plot_model(plot=class_report, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BBAE0B95A0>, system=True)
2023-07-03 16:22:46,922:INFO:Checking exceptions
2023-07-03 16:22:46,925:INFO:Preloading libraries
2023-07-03 16:22:46,926:INFO:Copying training dataset
2023-07-03 16:22:46,926:INFO:Plot type: class_report
2023-07-03 16:22:47,062:INFO:Fitting Model
2023-07-03 16:22:47,062:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names
  warnings.warn(

2023-07-03 16:22:47,063:INFO:Scoring test/hold-out set
2023-07-03 16:22:47,231:INFO:Visual Rendered Successfully
2023-07-03 16:22:47,536:INFO:plot_model() successfully completed......................................
2023-07-03 16:22:49,185:INFO:Initializing plot_model()
2023-07-03 16:22:49,185:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BBAE0B95A0>, system=True)
2023-07-03 16:22:49,185:INFO:Checking exceptions
2023-07-03 16:22:49,188:INFO:Preloading libraries
2023-07-03 16:22:49,188:INFO:Copying training dataset
2023-07-03 16:22:49,188:INFO:Plot type: feature
2023-07-03 16:22:49,189:WARNING:No coef_ found. Trying feature_importances_
2023-07-03 16:22:49,344:INFO:Visual Rendered Successfully
2023-07-03 16:22:49,653:INFO:plot_model() successfully completed......................................
2023-07-03 16:22:58,307:INFO:Initializing evaluate_model()
2023-07-03 16:22:58,307:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BBAE0B95A0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-07-03 16:22:58,318:INFO:Initializing plot_model()
2023-07-03 16:22:58,318:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BBAE0B95A0>, system=True)
2023-07-03 16:22:58,318:INFO:Checking exceptions
2023-07-03 16:22:58,320:INFO:Preloading libraries
2023-07-03 16:22:58,320:INFO:Copying training dataset
2023-07-03 16:22:58,320:INFO:Plot type: pipeline
2023-07-03 16:22:58,460:INFO:Visual Rendered Successfully
2023-07-03 16:22:58,764:INFO:plot_model() successfully completed......................................
2023-07-03 16:23:01,096:INFO:Initializing finalize_model()
2023-07-03 16:23:01,096:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BBAE0B95A0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-07-03 16:23:01,096:INFO:Finalizing DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-07-03 16:23:01,098:INFO:Initializing create_model()
2023-07-03 16:23:01,098:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BBAE0B95A0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-07-03 16:23:01,098:INFO:Checking exceptions
2023-07-03 16:23:01,100:INFO:Importing libraries
2023-07-03 16:23:01,101:INFO:Copying training dataset
2023-07-03 16:23:01,101:INFO:Defining folds
2023-07-03 16:23:01,101:INFO:Declaring metric variables
2023-07-03 16:23:01,101:INFO:Importing untrained model
2023-07-03 16:23:01,101:INFO:Declaring custom model
2023-07-03 16:23:01,102:INFO:Decision Tree Classifier Imported successfully
2023-07-03 16:23:01,102:INFO:Cross validation set to False
2023-07-03 16:23:01,102:INFO:Fitting Model
2023-07-03 16:23:01,172:INFO:Pipeline(memory=FastMemory(location=C:\Users\JHossain\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['AGE', 'STEROID', 'ANTIVIRALS',
                                             'FATIGUE', 'MALAISE', 'ANOREXIA',
                                             'LIVER BIG', 'LIVER FIRM',
                                             'SPLEEN PALPABL...
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+'))),
                ('actual_estimator',
                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,
                                        criterion='gini', max_depth=None,
                                        max_features=None, max_leaf_nodes=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        random_state=123, splitter='best'))],
         verbose=False)
2023-07-03 16:23:01,172:INFO:create_model() successfully completed......................................
2023-07-03 16:23:01,474:INFO:_master_model_container: 19
2023-07-03 16:23:01,474:INFO:_display_container: 5
2023-07-03 16:23:01,493:INFO:Pipeline(memory=FastMemory(location=C:\Users\JHossain\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['AGE', 'STEROID', 'ANTIVIRALS',
                                             'FATIGUE', 'MALAISE', 'ANOREXIA',
                                             'LIVER BIG', 'LIVER FIRM',
                                             'SPLEEN PALPABL...
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+'))),
                ('actual_estimator',
                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,
                                        criterion='gini', max_depth=None,
                                        max_features=None, max_leaf_nodes=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        random_state=123, splitter='best'))],
         verbose=False)
2023-07-03 16:23:01,493:INFO:finalize_model() successfully completed......................................
2023-07-03 16:23:04,941:INFO:Initializing predict_model()
2023-07-03 16:23:04,941:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BBAE0B95A0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001BBB740F6D0>)
2023-07-03 16:23:04,942:INFO:Checking exceptions
2023-07-03 16:23:04,942:INFO:Preloading libraries
2023-07-03 16:23:26,982:INFO:Initializing predict_model()
2023-07-03 16:23:26,982:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BBAE0B95A0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001BBB740EB00>)
2023-07-03 16:23:26,982:INFO:Checking exceptions
2023-07-03 16:23:26,982:INFO:Preloading libraries
2023-07-03 16:23:26,983:INFO:Set up data.
2023-07-03 16:23:26,989:INFO:Set up index.
2023-07-03 16:23:29,445:INFO:Initializing save_model()
2023-07-03 16:23:29,445:INFO:save_model(model=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), model_name=../models/hepatitis, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JHossain\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['AGE', 'STEROID', 'ANTIVIRALS',
                                             'FATIGUE', 'MALAISE', 'ANOREXIA',
                                             'LIVER BIG', 'LIVER FIRM',
                                             'SPLEEN PALPABL...
                                    transformer=OrdinalEncoder(cols=['SEX'],
                                                               drop_invariant=False,
                                                               handle_missing='return_nan',
                                                               handle_unknown='value',
                                                               mapping=[{'col': 'SEX',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 1.0    0
2.0    1
NaN   -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-07-03 16:23:29,445:INFO:Adding model into prep_pipe
2023-07-03 16:23:29,450:INFO:../models/hepatitis.pkl saved in current working directory
2023-07-03 16:23:29,470:INFO:Pipeline(memory=FastMemory(location=C:\Users\JHossain\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['AGE', 'STEROID', 'ANTIVIRALS',
                                             'FATIGUE', 'MALAISE', 'ANOREXIA',
                                             'LIVER BIG', 'LIVER FIRM',
                                             'SPLEEN PALPABL...
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+'))),
                ('trained_model',
                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,
                                        criterion='gini', max_depth=None,
                                        max_features=None, max_leaf_nodes=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        random_state=123, splitter='best'))],
         verbose=False)
2023-07-03 16:23:29,470:INFO:save_model() successfully completed......................................
2023-07-03 16:23:31,718:INFO:Initializing load_model()
2023-07-03 16:23:31,718:INFO:load_model(model_name=../models/hepatitis, platform=None, authentication=None, verbose=True)
2023-07-03 16:29:07,564:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-03 16:29:07,564:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-03 16:29:07,564:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-03 16:29:07,564:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-03 16:29:08,201:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-07-03 16:29:08,671:INFO:PyCaret ClassificationExperiment
2023-07-03 16:29:08,671:INFO:Logging name: clf-default-name
2023-07-03 16:29:08,672:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-07-03 16:29:08,672:INFO:version 3.0.2
2023-07-03 16:29:08,672:INFO:Initializing setup()
2023-07-03 16:29:08,672:INFO:self.USI: a519
2023-07-03 16:29:08,672:INFO:self._variable_keys: {'idx', 'y_test', 'target_param', 'fold_generator', '_ml_usecase', 'pipeline', 'html_param', 'exp_name_log', 'gpu_n_jobs_param', 'fold_groups_param', 'X_train', 'exp_id', '_available_plots', 'data', 'USI', 'n_jobs_param', 'logging_param', 'is_multiclass', 'fold_shuffle_param', 'X_test', 'log_plots_param', 'memory', 'y', 'seed', 'gpu_param', 'y_train', 'X', 'fix_imbalance'}
2023-07-03 16:29:08,672:INFO:Checking environment
2023-07-03 16:29:08,672:INFO:python_version: 3.10.9
2023-07-03 16:29:08,672:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2023-07-03 16:29:08,672:INFO:machine: AMD64
2023-07-03 16:29:08,672:INFO:platform: Windows-10-10.0.22621-SP0
2023-07-03 16:29:08,676:INFO:Memory: svmem(total=33664483328, available=20165677056, percent=40.1, used=13498806272, free=20165677056)
2023-07-03 16:29:08,676:INFO:Physical Core: 6
2023-07-03 16:29:08,676:INFO:Logical Core: 12
2023-07-03 16:29:08,676:INFO:Checking libraries
2023-07-03 16:29:08,677:INFO:System:
2023-07-03 16:29:08,677:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2023-07-03 16:29:08,677:INFO:executable: C:\Users\JHossain\anaconda3\python.exe
2023-07-03 16:29:08,677:INFO:   machine: Windows-10-10.0.22621-SP0
2023-07-03 16:29:08,677:INFO:PyCaret required dependencies:
2023-07-03 16:29:08,677:INFO:                 pip: 22.3.1
2023-07-03 16:29:08,677:INFO:          setuptools: 65.6.3
2023-07-03 16:29:08,677:INFO:             pycaret: 3.0.2
2023-07-03 16:29:08,677:INFO:             IPython: 8.10.0
2023-07-03 16:29:08,677:INFO:          ipywidgets: 7.6.5
2023-07-03 16:29:08,677:INFO:                tqdm: 4.64.1
2023-07-03 16:29:08,677:INFO:               numpy: 1.23.5
2023-07-03 16:29:08,678:INFO:              pandas: 1.5.3
2023-07-03 16:29:08,678:INFO:              jinja2: 3.1.2
2023-07-03 16:29:08,678:INFO:               scipy: 1.10.0
2023-07-03 16:29:08,678:INFO:              joblib: 1.2.0
2023-07-03 16:29:08,678:INFO:             sklearn: 1.2.1
2023-07-03 16:29:08,678:INFO:                pyod: 1.0.9
2023-07-03 16:29:08,678:INFO:            imblearn: 0.10.1
2023-07-03 16:29:08,678:INFO:   category_encoders: 2.6.1
2023-07-03 16:29:08,678:INFO:            lightgbm: 3.3.5
2023-07-03 16:29:08,678:INFO:               numba: 0.56.4
2023-07-03 16:29:08,678:INFO:            requests: 2.28.1
2023-07-03 16:29:08,678:INFO:          matplotlib: 3.7.0
2023-07-03 16:29:08,678:INFO:          scikitplot: 0.3.7
2023-07-03 16:29:08,678:INFO:         yellowbrick: 1.5
2023-07-03 16:29:08,678:INFO:              plotly: 5.9.0
2023-07-03 16:29:08,678:INFO:             kaleido: 0.2.1
2023-07-03 16:29:08,678:INFO:         statsmodels: 0.13.5
2023-07-03 16:29:08,678:INFO:              sktime: 0.17.0
2023-07-03 16:29:08,678:INFO:               tbats: 1.1.3
2023-07-03 16:29:08,678:INFO:            pmdarima: 2.0.3
2023-07-03 16:29:08,678:INFO:              psutil: 5.9.0
2023-07-03 16:29:08,678:INFO:PyCaret optional dependencies:
2023-07-03 16:29:09,741:INFO:                shap: 0.41.0
2023-07-03 16:29:09,741:INFO:           interpret: 0.4.2
2023-07-03 16:29:09,741:INFO:                umap: Not installed
2023-07-03 16:29:09,741:INFO:    pandas_profiling: Not installed
2023-07-03 16:29:09,741:INFO:  explainerdashboard: Not installed
2023-07-03 16:29:09,741:INFO:             autoviz: Not installed
2023-07-03 16:29:09,742:INFO:           fairlearn: Not installed
2023-07-03 16:29:09,742:INFO:             xgboost: Not installed
2023-07-03 16:29:09,742:INFO:            catboost: Not installed
2023-07-03 16:29:09,742:INFO:              kmodes: Not installed
2023-07-03 16:29:09,742:INFO:             mlxtend: Not installed
2023-07-03 16:29:09,742:INFO:       statsforecast: Not installed
2023-07-03 16:29:09,742:INFO:        tune_sklearn: Not installed
2023-07-03 16:29:09,742:INFO:                 ray: Not installed
2023-07-03 16:29:09,742:INFO:            hyperopt: Not installed
2023-07-03 16:29:09,742:INFO:              optuna: Not installed
2023-07-03 16:29:09,742:INFO:               skopt: Not installed
2023-07-03 16:29:09,742:INFO:              mlflow: Not installed
2023-07-03 16:29:09,742:INFO:              gradio: 3.35.2
2023-07-03 16:29:09,742:INFO:             fastapi: 0.99.0
2023-07-03 16:29:09,742:INFO:             uvicorn: 0.22.0
2023-07-03 16:29:09,742:INFO:              m2cgen: Not installed
2023-07-03 16:29:09,742:INFO:           evidently: Not installed
2023-07-03 16:29:09,742:INFO:               fugue: Not installed
2023-07-03 16:29:09,742:INFO:           streamlit: Not installed
2023-07-03 16:29:09,742:INFO:             prophet: Not installed
2023-07-03 16:29:09,742:INFO:None
2023-07-03 16:29:09,742:INFO:Set up data.
2023-07-03 16:29:09,751:INFO:Set up train/test split.
2023-07-03 16:29:09,754:INFO:Set up index.
2023-07-03 16:29:09,754:INFO:Set up folding strategy.
2023-07-03 16:29:09,754:INFO:Assigning column types.
2023-07-03 16:29:09,756:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-07-03 16:29:09,796:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-03 16:29:09,797:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-03 16:29:09,826:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 16:29:09,975:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 16:29:10,012:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-03 16:29:10,013:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-03 16:29:10,034:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 16:29:10,035:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 16:29:10,035:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-07-03 16:29:10,071:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-03 16:29:10,094:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 16:29:10,094:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 16:29:10,131:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-03 16:29:10,153:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 16:29:10,154:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 16:29:10,154:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-07-03 16:29:10,212:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 16:29:10,212:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 16:29:10,272:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 16:29:10,273:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 16:29:10,275:INFO:Preparing preprocessing pipeline...
2023-07-03 16:29:10,276:INFO:Set up label encoding.
2023-07-03 16:29:10,276:INFO:Set up simple imputation.
2023-07-03 16:29:10,276:INFO:Set up column name cleaning.
2023-07-03 16:29:10,299:INFO:Finished creating preprocessing pipeline.
2023-07-03 16:29:10,305:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\JHossain\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['radius_mean', 'texture_mean',
                                             'perimeter_mean', 'area_mean',
                                             'smoothness_mean',
                                             'compactness_mean',
                                             'c...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-07-03 16:29:10,305:INFO:Creating final display dataframe.
2023-07-03 16:29:10,375:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target         diagnosis
2                   Target type            Binary
3                Target mapping        B: 0, M: 1
4           Original data shape         (569, 31)
5        Transformed data shape         (569, 31)
6   Transformed train set shape         (398, 31)
7    Transformed test set shape         (171, 31)
8              Numeric features                30
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator   StratifiedKFold
14                  Fold Number                10
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  clf-default-name
19                          USI              a519
2023-07-03 16:29:10,440:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 16:29:10,440:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 16:29:10,498:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 16:29:10,499:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 16:29:10,499:INFO:setup() successfully completed in 2.18s...............
2023-07-03 16:29:10,509:INFO:Initializing compare_models()
2023-07-03 16:29:10,509:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002028A5D44F0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002028A5D44F0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-07-03 16:29:10,510:INFO:Checking exceptions
2023-07-03 16:29:10,512:INFO:Preparing display monitor
2023-07-03 16:29:10,533:INFO:Initializing Logistic Regression
2023-07-03 16:29:10,533:INFO:Total runtime is 0.0 minutes
2023-07-03 16:29:10,536:INFO:SubProcess create_model() called ==================================
2023-07-03 16:29:10,537:INFO:Initializing create_model()
2023-07-03 16:29:10,537:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002028A5D44F0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000202897296C0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 16:29:10,537:INFO:Checking exceptions
2023-07-03 16:29:10,537:INFO:Importing libraries
2023-07-03 16:29:10,537:INFO:Copying training dataset
2023-07-03 16:29:10,540:INFO:Defining folds
2023-07-03 16:29:10,540:INFO:Declaring metric variables
2023-07-03 16:29:10,543:INFO:Importing untrained model
2023-07-03 16:29:10,546:INFO:Logistic Regression Imported successfully
2023-07-03 16:29:10,551:INFO:Starting cross validation
2023-07-03 16:29:10,552:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 16:29:18,931:INFO:Calculating mean and std
2023-07-03 16:29:18,932:INFO:Creating metrics dataframe
2023-07-03 16:29:19,495:INFO:Uploading results into container
2023-07-03 16:29:19,495:INFO:Uploading model into container now
2023-07-03 16:29:19,496:INFO:_master_model_container: 1
2023-07-03 16:29:19,496:INFO:_display_container: 2
2023-07-03 16:29:19,496:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-03 16:29:19,497:INFO:create_model() successfully completed......................................
2023-07-03 16:29:19,645:INFO:SubProcess create_model() end ==================================
2023-07-03 16:29:19,645:INFO:Creating metrics dataframe
2023-07-03 16:29:19,653:INFO:Initializing K Neighbors Classifier
2023-07-03 16:29:19,653:INFO:Total runtime is 0.15200809240341187 minutes
2023-07-03 16:29:19,655:INFO:SubProcess create_model() called ==================================
2023-07-03 16:29:19,657:INFO:Initializing create_model()
2023-07-03 16:29:19,657:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002028A5D44F0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000202897296C0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 16:29:19,657:INFO:Checking exceptions
2023-07-03 16:29:19,657:INFO:Importing libraries
2023-07-03 16:29:19,657:INFO:Copying training dataset
2023-07-03 16:29:19,660:INFO:Defining folds
2023-07-03 16:29:19,661:INFO:Declaring metric variables
2023-07-03 16:29:19,664:INFO:Importing untrained model
2023-07-03 16:29:19,667:INFO:K Neighbors Classifier Imported successfully
2023-07-03 16:29:19,673:INFO:Starting cross validation
2023-07-03 16:29:19,674:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 16:29:23,601:INFO:Calculating mean and std
2023-07-03 16:29:23,602:INFO:Creating metrics dataframe
2023-07-03 16:29:24,173:INFO:Uploading results into container
2023-07-03 16:29:24,173:INFO:Uploading model into container now
2023-07-03 16:29:24,174:INFO:_master_model_container: 2
2023-07-03 16:29:24,174:INFO:_display_container: 2
2023-07-03 16:29:24,175:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-07-03 16:29:24,175:INFO:create_model() successfully completed......................................
2023-07-03 16:29:24,325:INFO:SubProcess create_model() end ==================================
2023-07-03 16:29:24,325:INFO:Creating metrics dataframe
2023-07-03 16:29:24,334:INFO:Initializing Naive Bayes
2023-07-03 16:29:24,334:INFO:Total runtime is 0.2300141533215841 minutes
2023-07-03 16:29:24,337:INFO:SubProcess create_model() called ==================================
2023-07-03 16:29:24,337:INFO:Initializing create_model()
2023-07-03 16:29:24,337:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002028A5D44F0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000202897296C0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 16:29:24,337:INFO:Checking exceptions
2023-07-03 16:29:24,337:INFO:Importing libraries
2023-07-03 16:29:24,337:INFO:Copying training dataset
2023-07-03 16:29:24,340:INFO:Defining folds
2023-07-03 16:29:24,341:INFO:Declaring metric variables
2023-07-03 16:29:24,343:INFO:Importing untrained model
2023-07-03 16:29:24,347:INFO:Naive Bayes Imported successfully
2023-07-03 16:29:24,353:INFO:Starting cross validation
2023-07-03 16:29:24,354:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 16:29:27,895:INFO:Calculating mean and std
2023-07-03 16:29:27,897:INFO:Creating metrics dataframe
2023-07-03 16:29:28,463:INFO:Uploading results into container
2023-07-03 16:29:28,464:INFO:Uploading model into container now
2023-07-03 16:29:28,464:INFO:_master_model_container: 3
2023-07-03 16:29:28,464:INFO:_display_container: 2
2023-07-03 16:29:28,464:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-07-03 16:29:28,465:INFO:create_model() successfully completed......................................
2023-07-03 16:29:28,610:INFO:SubProcess create_model() end ==================================
2023-07-03 16:29:28,610:INFO:Creating metrics dataframe
2023-07-03 16:29:28,619:INFO:Initializing Decision Tree Classifier
2023-07-03 16:29:28,619:INFO:Total runtime is 0.3014326612154643 minutes
2023-07-03 16:29:28,622:INFO:SubProcess create_model() called ==================================
2023-07-03 16:29:28,622:INFO:Initializing create_model()
2023-07-03 16:29:28,622:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002028A5D44F0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000202897296C0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 16:29:28,622:INFO:Checking exceptions
2023-07-03 16:29:28,622:INFO:Importing libraries
2023-07-03 16:29:28,622:INFO:Copying training dataset
2023-07-03 16:29:28,625:INFO:Defining folds
2023-07-03 16:29:28,626:INFO:Declaring metric variables
2023-07-03 16:29:28,628:INFO:Importing untrained model
2023-07-03 16:29:28,631:INFO:Decision Tree Classifier Imported successfully
2023-07-03 16:29:28,637:INFO:Starting cross validation
2023-07-03 16:29:28,638:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 16:29:32,192:INFO:Calculating mean and std
2023-07-03 16:29:32,194:INFO:Creating metrics dataframe
2023-07-03 16:29:32,765:INFO:Uploading results into container
2023-07-03 16:29:32,766:INFO:Uploading model into container now
2023-07-03 16:29:32,766:INFO:_master_model_container: 4
2023-07-03 16:29:32,766:INFO:_display_container: 2
2023-07-03 16:29:32,767:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-07-03 16:29:32,767:INFO:create_model() successfully completed......................................
2023-07-03 16:29:32,913:INFO:SubProcess create_model() end ==================================
2023-07-03 16:29:32,914:INFO:Creating metrics dataframe
2023-07-03 16:29:32,922:INFO:Initializing SVM - Linear Kernel
2023-07-03 16:29:32,922:INFO:Total runtime is 0.37315269708633425 minutes
2023-07-03 16:29:32,924:INFO:SubProcess create_model() called ==================================
2023-07-03 16:29:32,925:INFO:Initializing create_model()
2023-07-03 16:29:32,925:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002028A5D44F0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000202897296C0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 16:29:32,925:INFO:Checking exceptions
2023-07-03 16:29:32,925:INFO:Importing libraries
2023-07-03 16:29:32,925:INFO:Copying training dataset
2023-07-03 16:29:32,929:INFO:Defining folds
2023-07-03 16:29:32,929:INFO:Declaring metric variables
2023-07-03 16:29:32,932:INFO:Importing untrained model
2023-07-03 16:29:32,936:INFO:SVM - Linear Kernel Imported successfully
2023-07-03 16:29:32,940:INFO:Starting cross validation
2023-07-03 16:29:32,941:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 16:29:33,024:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 16:29:33,027:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 16:29:33,032:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 16:29:33,035:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 16:29:33,037:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 16:29:33,054:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 16:29:33,064:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 16:29:33,066:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 16:29:33,073:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 16:29:33,078:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 16:29:36,478:INFO:Calculating mean and std
2023-07-03 16:29:36,479:INFO:Creating metrics dataframe
2023-07-03 16:29:37,040:INFO:Uploading results into container
2023-07-03 16:29:37,041:INFO:Uploading model into container now
2023-07-03 16:29:37,042:INFO:_master_model_container: 5
2023-07-03 16:29:37,042:INFO:_display_container: 2
2023-07-03 16:29:37,042:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-07-03 16:29:37,042:INFO:create_model() successfully completed......................................
2023-07-03 16:29:37,197:INFO:SubProcess create_model() end ==================================
2023-07-03 16:29:37,197:INFO:Creating metrics dataframe
2023-07-03 16:29:37,206:INFO:Initializing Ridge Classifier
2023-07-03 16:29:37,206:INFO:Total runtime is 0.44455626408259075 minutes
2023-07-03 16:29:37,209:INFO:SubProcess create_model() called ==================================
2023-07-03 16:29:37,209:INFO:Initializing create_model()
2023-07-03 16:29:37,209:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002028A5D44F0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000202897296C0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 16:29:37,210:INFO:Checking exceptions
2023-07-03 16:29:37,210:INFO:Importing libraries
2023-07-03 16:29:37,210:INFO:Copying training dataset
2023-07-03 16:29:37,214:INFO:Defining folds
2023-07-03 16:29:37,214:INFO:Declaring metric variables
2023-07-03 16:29:37,218:INFO:Importing untrained model
2023-07-03 16:29:37,221:INFO:Ridge Classifier Imported successfully
2023-07-03 16:29:37,225:INFO:Starting cross validation
2023-07-03 16:29:37,227:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 16:29:37,281:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.48848e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-07-03 16:29:37,288:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.07925e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-07-03 16:29:37,289:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.49328e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-07-03 16:29:37,297:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.60935e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-07-03 16:29:37,297:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.32091e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-07-03 16:29:37,309:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 16:29:37,311:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.69502e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-07-03 16:29:37,312:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.93944e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-07-03 16:29:37,315:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 16:29:37,316:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 16:29:37,323:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.99677e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-07-03 16:29:37,323:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 16:29:37,325:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 16:29:37,327:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.68069e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-07-03 16:29:37,327:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.15972e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-07-03 16:29:37,337:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 16:29:37,341:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 16:29:37,349:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 16:29:37,354:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 16:29:37,354:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 16:29:40,761:INFO:Calculating mean and std
2023-07-03 16:29:40,763:INFO:Creating metrics dataframe
2023-07-03 16:29:41,333:INFO:Uploading results into container
2023-07-03 16:29:41,334:INFO:Uploading model into container now
2023-07-03 16:29:41,334:INFO:_master_model_container: 6
2023-07-03 16:29:41,334:INFO:_display_container: 2
2023-07-03 16:29:41,334:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-07-03 16:29:41,335:INFO:create_model() successfully completed......................................
2023-07-03 16:29:41,482:INFO:SubProcess create_model() end ==================================
2023-07-03 16:29:41,482:INFO:Creating metrics dataframe
2023-07-03 16:29:41,491:INFO:Initializing Random Forest Classifier
2023-07-03 16:29:41,491:INFO:Total runtime is 0.5159725944201151 minutes
2023-07-03 16:29:41,494:INFO:SubProcess create_model() called ==================================
2023-07-03 16:29:41,494:INFO:Initializing create_model()
2023-07-03 16:29:41,494:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002028A5D44F0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000202897296C0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 16:29:41,494:INFO:Checking exceptions
2023-07-03 16:29:41,494:INFO:Importing libraries
2023-07-03 16:29:41,494:INFO:Copying training dataset
2023-07-03 16:29:41,498:INFO:Defining folds
2023-07-03 16:29:41,498:INFO:Declaring metric variables
2023-07-03 16:29:41,501:INFO:Importing untrained model
2023-07-03 16:29:41,504:INFO:Random Forest Classifier Imported successfully
2023-07-03 16:29:41,509:INFO:Starting cross validation
2023-07-03 16:29:41,510:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 16:29:45,342:INFO:Calculating mean and std
2023-07-03 16:29:45,344:INFO:Creating metrics dataframe
2023-07-03 16:29:45,915:INFO:Uploading results into container
2023-07-03 16:29:45,917:INFO:Uploading model into container now
2023-07-03 16:29:45,917:INFO:_master_model_container: 7
2023-07-03 16:29:45,917:INFO:_display_container: 2
2023-07-03 16:29:45,918:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-07-03 16:29:45,918:INFO:create_model() successfully completed......................................
2023-07-03 16:29:46,064:INFO:SubProcess create_model() end ==================================
2023-07-03 16:29:46,064:INFO:Creating metrics dataframe
2023-07-03 16:29:46,074:INFO:Initializing Quadratic Discriminant Analysis
2023-07-03 16:29:46,074:INFO:Total runtime is 0.5923502087593078 minutes
2023-07-03 16:29:46,076:INFO:SubProcess create_model() called ==================================
2023-07-03 16:29:46,077:INFO:Initializing create_model()
2023-07-03 16:29:46,077:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002028A5D44F0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000202897296C0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 16:29:46,077:INFO:Checking exceptions
2023-07-03 16:29:46,077:INFO:Importing libraries
2023-07-03 16:29:46,077:INFO:Copying training dataset
2023-07-03 16:29:46,080:INFO:Defining folds
2023-07-03 16:29:46,080:INFO:Declaring metric variables
2023-07-03 16:29:46,083:INFO:Importing untrained model
2023-07-03 16:29:46,087:INFO:Quadratic Discriminant Analysis Imported successfully
2023-07-03 16:29:46,093:INFO:Starting cross validation
2023-07-03 16:29:46,093:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 16:29:49,633:INFO:Calculating mean and std
2023-07-03 16:29:49,635:INFO:Creating metrics dataframe
2023-07-03 16:29:50,197:INFO:Uploading results into container
2023-07-03 16:29:50,198:INFO:Uploading model into container now
2023-07-03 16:29:50,198:INFO:_master_model_container: 8
2023-07-03 16:29:50,198:INFO:_display_container: 2
2023-07-03 16:29:50,199:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-07-03 16:29:50,199:INFO:create_model() successfully completed......................................
2023-07-03 16:29:50,345:INFO:SubProcess create_model() end ==================================
2023-07-03 16:29:50,345:INFO:Creating metrics dataframe
2023-07-03 16:29:50,355:INFO:Initializing Ada Boost Classifier
2023-07-03 16:29:50,355:INFO:Total runtime is 0.6637075940767923 minutes
2023-07-03 16:29:50,358:INFO:SubProcess create_model() called ==================================
2023-07-03 16:29:50,358:INFO:Initializing create_model()
2023-07-03 16:29:50,358:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002028A5D44F0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000202897296C0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 16:29:50,359:INFO:Checking exceptions
2023-07-03 16:29:50,359:INFO:Importing libraries
2023-07-03 16:29:50,359:INFO:Copying training dataset
2023-07-03 16:29:50,362:INFO:Defining folds
2023-07-03 16:29:50,362:INFO:Declaring metric variables
2023-07-03 16:29:50,365:INFO:Importing untrained model
2023-07-03 16:29:50,367:INFO:Ada Boost Classifier Imported successfully
2023-07-03 16:29:50,372:INFO:Starting cross validation
2023-07-03 16:29:50,373:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 16:29:53,986:INFO:Calculating mean and std
2023-07-03 16:29:53,986:INFO:Creating metrics dataframe
2023-07-03 16:29:54,560:INFO:Uploading results into container
2023-07-03 16:29:54,561:INFO:Uploading model into container now
2023-07-03 16:29:54,562:INFO:_master_model_container: 9
2023-07-03 16:29:54,562:INFO:_display_container: 2
2023-07-03 16:29:54,562:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-07-03 16:29:54,562:INFO:create_model() successfully completed......................................
2023-07-03 16:29:54,711:INFO:SubProcess create_model() end ==================================
2023-07-03 16:29:54,711:INFO:Creating metrics dataframe
2023-07-03 16:29:54,721:INFO:Initializing Gradient Boosting Classifier
2023-07-03 16:29:54,721:INFO:Total runtime is 0.7364598433176675 minutes
2023-07-03 16:29:54,724:INFO:SubProcess create_model() called ==================================
2023-07-03 16:29:54,724:INFO:Initializing create_model()
2023-07-03 16:29:54,724:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002028A5D44F0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000202897296C0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 16:29:54,725:INFO:Checking exceptions
2023-07-03 16:29:54,725:INFO:Importing libraries
2023-07-03 16:29:54,725:INFO:Copying training dataset
2023-07-03 16:29:54,728:INFO:Defining folds
2023-07-03 16:29:54,728:INFO:Declaring metric variables
2023-07-03 16:29:54,730:INFO:Importing untrained model
2023-07-03 16:29:54,733:INFO:Gradient Boosting Classifier Imported successfully
2023-07-03 16:29:54,740:INFO:Starting cross validation
2023-07-03 16:29:54,741:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 16:29:58,345:INFO:Calculating mean and std
2023-07-03 16:29:58,346:INFO:Creating metrics dataframe
2023-07-03 16:29:58,921:INFO:Uploading results into container
2023-07-03 16:29:58,922:INFO:Uploading model into container now
2023-07-03 16:29:58,923:INFO:_master_model_container: 10
2023-07-03 16:29:58,923:INFO:_display_container: 2
2023-07-03 16:29:58,923:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-03 16:29:58,923:INFO:create_model() successfully completed......................................
2023-07-03 16:29:59,070:INFO:SubProcess create_model() end ==================================
2023-07-03 16:29:59,071:INFO:Creating metrics dataframe
2023-07-03 16:29:59,081:INFO:Initializing Linear Discriminant Analysis
2023-07-03 16:29:59,081:INFO:Total runtime is 0.8091276049613951 minutes
2023-07-03 16:29:59,084:INFO:SubProcess create_model() called ==================================
2023-07-03 16:29:59,084:INFO:Initializing create_model()
2023-07-03 16:29:59,084:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002028A5D44F0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000202897296C0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 16:29:59,084:INFO:Checking exceptions
2023-07-03 16:29:59,084:INFO:Importing libraries
2023-07-03 16:29:59,084:INFO:Copying training dataset
2023-07-03 16:29:59,087:INFO:Defining folds
2023-07-03 16:29:59,087:INFO:Declaring metric variables
2023-07-03 16:29:59,090:INFO:Importing untrained model
2023-07-03 16:29:59,092:INFO:Linear Discriminant Analysis Imported successfully
2023-07-03 16:29:59,098:INFO:Starting cross validation
2023-07-03 16:29:59,099:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 16:30:02,759:INFO:Calculating mean and std
2023-07-03 16:30:02,760:INFO:Creating metrics dataframe
2023-07-03 16:30:03,325:INFO:Uploading results into container
2023-07-03 16:30:03,326:INFO:Uploading model into container now
2023-07-03 16:30:03,326:INFO:_master_model_container: 11
2023-07-03 16:30:03,327:INFO:_display_container: 2
2023-07-03 16:30:03,327:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-07-03 16:30:03,327:INFO:create_model() successfully completed......................................
2023-07-03 16:30:03,471:INFO:SubProcess create_model() end ==================================
2023-07-03 16:30:03,472:INFO:Creating metrics dataframe
2023-07-03 16:30:03,484:INFO:Initializing Extra Trees Classifier
2023-07-03 16:30:03,484:INFO:Total runtime is 0.8825156927108764 minutes
2023-07-03 16:30:03,486:INFO:SubProcess create_model() called ==================================
2023-07-03 16:30:03,487:INFO:Initializing create_model()
2023-07-03 16:30:03,487:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002028A5D44F0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000202897296C0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 16:30:03,487:INFO:Checking exceptions
2023-07-03 16:30:03,487:INFO:Importing libraries
2023-07-03 16:30:03,487:INFO:Copying training dataset
2023-07-03 16:30:03,490:INFO:Defining folds
2023-07-03 16:30:03,490:INFO:Declaring metric variables
2023-07-03 16:30:03,493:INFO:Importing untrained model
2023-07-03 16:30:03,497:INFO:Extra Trees Classifier Imported successfully
2023-07-03 16:30:03,502:INFO:Starting cross validation
2023-07-03 16:30:03,503:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 16:30:07,313:INFO:Calculating mean and std
2023-07-03 16:30:07,314:INFO:Creating metrics dataframe
2023-07-03 16:30:07,893:INFO:Uploading results into container
2023-07-03 16:30:07,894:INFO:Uploading model into container now
2023-07-03 16:30:07,895:INFO:_master_model_container: 12
2023-07-03 16:30:07,895:INFO:_display_container: 2
2023-07-03 16:30:07,895:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-07-03 16:30:07,895:INFO:create_model() successfully completed......................................
2023-07-03 16:30:08,043:INFO:SubProcess create_model() end ==================================
2023-07-03 16:30:08,043:INFO:Creating metrics dataframe
2023-07-03 16:30:08,054:INFO:Initializing Light Gradient Boosting Machine
2023-07-03 16:30:08,054:INFO:Total runtime is 0.9586892207463582 minutes
2023-07-03 16:30:08,057:INFO:SubProcess create_model() called ==================================
2023-07-03 16:30:08,057:INFO:Initializing create_model()
2023-07-03 16:30:08,058:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002028A5D44F0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000202897296C0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 16:30:08,058:INFO:Checking exceptions
2023-07-03 16:30:08,058:INFO:Importing libraries
2023-07-03 16:30:08,058:INFO:Copying training dataset
2023-07-03 16:30:08,061:INFO:Defining folds
2023-07-03 16:30:08,061:INFO:Declaring metric variables
2023-07-03 16:30:08,064:INFO:Importing untrained model
2023-07-03 16:30:08,066:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-03 16:30:08,072:INFO:Starting cross validation
2023-07-03 16:30:08,073:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 16:30:13,012:INFO:Calculating mean and std
2023-07-03 16:30:13,013:INFO:Creating metrics dataframe
2023-07-03 16:30:13,590:INFO:Uploading results into container
2023-07-03 16:30:13,590:INFO:Uploading model into container now
2023-07-03 16:30:13,591:INFO:_master_model_container: 13
2023-07-03 16:30:13,591:INFO:_display_container: 2
2023-07-03 16:30:13,591:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-07-03 16:30:13,592:INFO:create_model() successfully completed......................................
2023-07-03 16:30:13,739:INFO:SubProcess create_model() end ==================================
2023-07-03 16:30:13,739:INFO:Creating metrics dataframe
2023-07-03 16:30:13,752:INFO:Initializing Dummy Classifier
2023-07-03 16:30:13,752:INFO:Total runtime is 1.0536482095718382 minutes
2023-07-03 16:30:13,755:INFO:SubProcess create_model() called ==================================
2023-07-03 16:30:13,755:INFO:Initializing create_model()
2023-07-03 16:30:13,755:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002028A5D44F0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000202897296C0>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 16:30:13,755:INFO:Checking exceptions
2023-07-03 16:30:13,755:INFO:Importing libraries
2023-07-03 16:30:13,756:INFO:Copying training dataset
2023-07-03 16:30:13,758:INFO:Defining folds
2023-07-03 16:30:13,759:INFO:Declaring metric variables
2023-07-03 16:30:13,761:INFO:Importing untrained model
2023-07-03 16:30:13,764:INFO:Dummy Classifier Imported successfully
2023-07-03 16:30:13,770:INFO:Starting cross validation
2023-07-03 16:30:13,771:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 16:30:13,871:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 16:30:13,879:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 16:30:13,883:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 16:30:13,884:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 16:30:13,891:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 16:30:13,896:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 16:30:13,898:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 16:30:13,908:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 16:30:13,922:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 16:30:13,924:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 16:30:17,299:INFO:Calculating mean and std
2023-07-03 16:30:17,300:INFO:Creating metrics dataframe
2023-07-03 16:30:17,897:INFO:Uploading results into container
2023-07-03 16:30:17,899:INFO:Uploading model into container now
2023-07-03 16:30:17,899:INFO:_master_model_container: 14
2023-07-03 16:30:17,899:INFO:_display_container: 2
2023-07-03 16:30:17,899:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-07-03 16:30:17,900:INFO:create_model() successfully completed......................................
2023-07-03 16:30:18,071:INFO:SubProcess create_model() end ==================================
2023-07-03 16:30:18,071:INFO:Creating metrics dataframe
2023-07-03 16:30:18,095:INFO:Initializing create_model()
2023-07-03 16:30:18,096:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002028A5D44F0>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-03 16:30:18,096:INFO:Checking exceptions
2023-07-03 16:30:18,097:INFO:Importing libraries
2023-07-03 16:30:18,098:INFO:Copying training dataset
2023-07-03 16:30:18,101:INFO:Defining folds
2023-07-03 16:30:18,101:INFO:Declaring metric variables
2023-07-03 16:30:18,102:INFO:Importing untrained model
2023-07-03 16:30:18,102:INFO:Declaring custom model
2023-07-03 16:30:18,103:INFO:Extra Trees Classifier Imported successfully
2023-07-03 16:30:18,104:INFO:Cross validation set to False
2023-07-03 16:30:18,104:INFO:Fitting Model
2023-07-03 16:30:18,552:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-07-03 16:30:18,552:INFO:create_model() successfully completed......................................
2023-07-03 16:30:18,726:INFO:_master_model_container: 14
2023-07-03 16:30:18,726:INFO:_display_container: 2
2023-07-03 16:30:18,726:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-07-03 16:30:18,726:INFO:compare_models() successfully completed......................................
2023-07-03 16:30:18,738:INFO:Initializing create_model()
2023-07-03 16:30:18,738:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002028A5D44F0>, estimator=et, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-03 16:30:18,738:INFO:Checking exceptions
2023-07-03 16:30:18,751:INFO:Importing libraries
2023-07-03 16:30:18,751:INFO:Copying training dataset
2023-07-03 16:30:18,754:INFO:Defining folds
2023-07-03 16:30:18,754:INFO:Declaring metric variables
2023-07-03 16:30:18,757:INFO:Importing untrained model
2023-07-03 16:30:18,760:INFO:Extra Trees Classifier Imported successfully
2023-07-03 16:30:18,766:INFO:Starting cross validation
2023-07-03 16:30:18,767:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 16:30:22,512:INFO:Calculating mean and std
2023-07-03 16:30:22,513:INFO:Creating metrics dataframe
2023-07-03 16:30:22,518:INFO:Finalizing model
2023-07-03 16:30:23,126:INFO:Uploading results into container
2023-07-03 16:30:23,127:INFO:Uploading model into container now
2023-07-03 16:30:23,134:INFO:_master_model_container: 15
2023-07-03 16:30:23,136:INFO:_display_container: 3
2023-07-03 16:30:23,136:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-07-03 16:30:23,136:INFO:create_model() successfully completed......................................
2023-07-03 16:31:23,846:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_18944_d0ef603161244b279073170f5f17209c_26b0853b1dfb479b8c661f92088eee66
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 16:31:23,847:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_18944_5c4bf9a1145045859ef7de55ef5076ed_276fbdf6783c4192944a28d6b9534753
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 16:31:23,847:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_18944_d0ef603161244b279073170f5f17209c_d259fa9eaa51489e960f4a78d777ffca
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 16:31:23,847:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_18944_e1749425358c45738b97e36231d8915a_d88df715d94948dc827d3712293ccf67
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 16:31:23,847:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_18944_d0ef603161244b279073170f5f17209c_c5e7f5c1bab7464eac08ff82be811e98
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 16:31:23,847:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_18944_89d09df0354f4ce7ad92ee8a805dadc3_48d66d29354946e8aa8af59e6c0589ee
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 16:31:23,847:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_18944_d0ef603161244b279073170f5f17209c_3e08ec244d744805a35722e312d46dac
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 16:31:23,848:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_18944_8e588c977ac74546b3bd9b9f8576a5c6_7b99f1c1ee614ff08a0ca64d091013a0
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 16:31:23,848:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_18944_d0ef603161244b279073170f5f17209c_5d0dfd42e84e4c62a991c7a85d67f6e5
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 16:31:23,848:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_18944_cdc70ecff81647b286246720d4b45c4b_8c06e01efb184e4282d5b8fc269e7fee
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 16:31:23,848:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_18944_d0ef603161244b279073170f5f17209c_7f8123813ed54a21acf2d0572158b511
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 16:31:23,848:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_18944_080751b879e9437fb31c7e3c042c22c6_5d0e93c07cda4b898c25dd7b0267bdee
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 16:31:23,848:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_18944_d0ef603161244b279073170f5f17209c_e7f8fa2102a04c60a2060e62827b0abf
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 16:31:23,848:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_18944_860da381640b4513b4266b72815d3f71_5f5725cf2c70477c88d8042c5f64bc23
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 16:31:23,848:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_18944_d0ef603161244b279073170f5f17209c_5f3a25328dc541bcb93fc044d817a5fa
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 16:31:23,848:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_18944_c4e468c52b7c4b7c96717b9e29ba9e6b_4c700ffbc2f6499c8ef90cf5bf1c6d85
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 16:31:23,848:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_18944_d0ef603161244b279073170f5f17209c_238136ca8b2f4798acd2ec348fbcb922
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 16:31:23,849:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_18944_38ffc66b9cf2422a9f59f294c6740659_c0f4591da3cf495ab9a8a90c4fdd1131
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 16:31:23,849:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_18944_d0ef603161244b279073170f5f17209c_045150e0fd2b4c32b968139240c61ab8
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 16:31:23,849:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_18944_65fd2e4559e04bb1b0a00ec49ba62994_62fe102928224fc9965d31257361421f
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 16:31:23,849:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_18944_d0ef603161244b279073170f5f17209c_620a1019998d4d6ba42c64483d5e05cf
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 16:31:23,849:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_18944_44fa9e72be2547b2a6d1c1b79e3f186c_0342f9cec56747ad9452b73d1fe7f018
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 16:31:23,849:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_18944_d0ef603161244b279073170f5f17209c_6ab27658903b4b408a9cb039a4fb0933
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 16:31:23,849:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_18944_d090854a545248d1905acff87920c220_91c7ba8fe98d4f8a9cb813ea84ecbe4c
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 16:31:23,849:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_18944_d0ef603161244b279073170f5f17209c_2e5cd4e6a1af43faadcb0c03726f271f
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 16:31:23,849:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_18944_3ec47058b2684d8c810321fc8480e9d3_a1d617dbb41c4c9faed1ad162f207bb7
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 16:31:23,849:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_18944_d0ef603161244b279073170f5f17209c_a61dc3aa00fe4dbcbd544a410717022e
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 16:31:23,849:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_18944_4f3358aa43784d2dbcaf9a66da4c8a3f_25eafae69083451aa12c540742e91652
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 16:31:23,850:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_18944_d0ef603161244b279073170f5f17209c_9a7a19b6978e41df92dfed795817710f
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 16:31:23,850:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_18944_d0ef603161244b279073170f5f17209c_0fb3cfd17d2a40f4a4452493f2b0b367
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-03 16:31:39,964:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-03 16:31:39,964:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-03 16:31:39,964:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-03 16:31:39,964:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-03 16:31:40,611:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-07-03 16:31:41,088:INFO:PyCaret ClassificationExperiment
2023-07-03 16:31:41,088:INFO:Logging name: clf-default-name
2023-07-03 16:31:41,088:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-07-03 16:31:41,088:INFO:version 3.0.2
2023-07-03 16:31:41,089:INFO:Initializing setup()
2023-07-03 16:31:41,089:INFO:self.USI: 7d04
2023-07-03 16:31:41,089:INFO:self._variable_keys: {'memory', 'target_param', 'html_param', 'log_plots_param', 'data', 'logging_param', 'gpu_n_jobs_param', 'y_test', 'y', '_available_plots', 'is_multiclass', 'fix_imbalance', 'X_test', 'X_train', 'USI', 'pipeline', 'fold_groups_param', 'idx', 'seed', 'y_train', 'X', 'n_jobs_param', 'fold_generator', 'exp_id', 'gpu_param', 'fold_shuffle_param', '_ml_usecase', 'exp_name_log'}
2023-07-03 16:31:41,089:INFO:Checking environment
2023-07-03 16:31:41,089:INFO:python_version: 3.10.9
2023-07-03 16:31:41,089:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2023-07-03 16:31:41,089:INFO:machine: AMD64
2023-07-03 16:31:41,089:INFO:platform: Windows-10-10.0.22621-SP0
2023-07-03 16:31:41,092:INFO:Memory: svmem(total=33664483328, available=20164878336, percent=40.1, used=13499604992, free=20164878336)
2023-07-03 16:31:41,092:INFO:Physical Core: 6
2023-07-03 16:31:41,092:INFO:Logical Core: 12
2023-07-03 16:31:41,092:INFO:Checking libraries
2023-07-03 16:31:41,092:INFO:System:
2023-07-03 16:31:41,092:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2023-07-03 16:31:41,092:INFO:executable: C:\Users\JHossain\anaconda3\python.exe
2023-07-03 16:31:41,092:INFO:   machine: Windows-10-10.0.22621-SP0
2023-07-03 16:31:41,092:INFO:PyCaret required dependencies:
2023-07-03 16:31:41,092:INFO:                 pip: 22.3.1
2023-07-03 16:31:41,092:INFO:          setuptools: 65.6.3
2023-07-03 16:31:41,092:INFO:             pycaret: 3.0.2
2023-07-03 16:31:41,092:INFO:             IPython: 8.10.0
2023-07-03 16:31:41,092:INFO:          ipywidgets: 7.6.5
2023-07-03 16:31:41,092:INFO:                tqdm: 4.64.1
2023-07-03 16:31:41,092:INFO:               numpy: 1.23.5
2023-07-03 16:31:41,093:INFO:              pandas: 1.5.3
2023-07-03 16:31:41,093:INFO:              jinja2: 3.1.2
2023-07-03 16:31:41,093:INFO:               scipy: 1.10.0
2023-07-03 16:31:41,093:INFO:              joblib: 1.2.0
2023-07-03 16:31:41,093:INFO:             sklearn: 1.2.1
2023-07-03 16:31:41,093:INFO:                pyod: 1.0.9
2023-07-03 16:31:41,093:INFO:            imblearn: 0.10.1
2023-07-03 16:31:41,093:INFO:   category_encoders: 2.6.1
2023-07-03 16:31:41,093:INFO:            lightgbm: 3.3.5
2023-07-03 16:31:41,093:INFO:               numba: 0.56.4
2023-07-03 16:31:41,093:INFO:            requests: 2.28.1
2023-07-03 16:31:41,093:INFO:          matplotlib: 3.7.0
2023-07-03 16:31:41,093:INFO:          scikitplot: 0.3.7
2023-07-03 16:31:41,093:INFO:         yellowbrick: 1.5
2023-07-03 16:31:41,093:INFO:              plotly: 5.9.0
2023-07-03 16:31:41,093:INFO:             kaleido: 0.2.1
2023-07-03 16:31:41,093:INFO:         statsmodels: 0.13.5
2023-07-03 16:31:41,093:INFO:              sktime: 0.17.0
2023-07-03 16:31:41,093:INFO:               tbats: 1.1.3
2023-07-03 16:31:41,093:INFO:            pmdarima: 2.0.3
2023-07-03 16:31:41,093:INFO:              psutil: 5.9.0
2023-07-03 16:31:41,093:INFO:PyCaret optional dependencies:
2023-07-03 16:31:42,222:INFO:                shap: 0.41.0
2023-07-03 16:31:42,222:INFO:           interpret: 0.4.2
2023-07-03 16:31:42,222:INFO:                umap: Not installed
2023-07-03 16:31:42,222:INFO:    pandas_profiling: Not installed
2023-07-03 16:31:42,222:INFO:  explainerdashboard: Not installed
2023-07-03 16:31:42,222:INFO:             autoviz: Not installed
2023-07-03 16:31:42,222:INFO:           fairlearn: Not installed
2023-07-03 16:31:42,222:INFO:             xgboost: Not installed
2023-07-03 16:31:42,222:INFO:            catboost: Not installed
2023-07-03 16:31:42,222:INFO:              kmodes: Not installed
2023-07-03 16:31:42,222:INFO:             mlxtend: Not installed
2023-07-03 16:31:42,222:INFO:       statsforecast: Not installed
2023-07-03 16:31:42,222:INFO:        tune_sklearn: Not installed
2023-07-03 16:31:42,222:INFO:                 ray: Not installed
2023-07-03 16:31:42,222:INFO:            hyperopt: Not installed
2023-07-03 16:31:42,222:INFO:              optuna: Not installed
2023-07-03 16:31:42,223:INFO:               skopt: Not installed
2023-07-03 16:31:42,223:INFO:              mlflow: Not installed
2023-07-03 16:31:42,223:INFO:              gradio: 3.35.2
2023-07-03 16:31:42,223:INFO:             fastapi: 0.99.0
2023-07-03 16:31:42,223:INFO:             uvicorn: 0.22.0
2023-07-03 16:31:42,223:INFO:              m2cgen: Not installed
2023-07-03 16:31:42,223:INFO:           evidently: Not installed
2023-07-03 16:31:42,223:INFO:               fugue: Not installed
2023-07-03 16:31:42,223:INFO:           streamlit: Not installed
2023-07-03 16:31:42,223:INFO:             prophet: Not installed
2023-07-03 16:31:42,223:INFO:None
2023-07-03 16:31:42,223:INFO:Set up data.
2023-07-03 16:31:42,231:INFO:Set up train/test split.
2023-07-03 16:31:42,234:INFO:Set up index.
2023-07-03 16:31:42,234:INFO:Set up folding strategy.
2023-07-03 16:31:42,235:INFO:Assigning column types.
2023-07-03 16:31:42,237:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-07-03 16:31:42,276:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-03 16:31:42,278:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-03 16:31:42,310:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 16:31:42,468:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 16:31:42,505:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-03 16:31:42,506:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-03 16:31:42,528:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 16:31:42,528:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 16:31:42,529:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-07-03 16:31:42,565:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-03 16:31:42,588:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 16:31:42,588:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 16:31:42,625:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-03 16:31:42,648:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 16:31:42,648:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 16:31:42,649:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-07-03 16:31:42,708:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 16:31:42,709:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 16:31:42,768:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 16:31:42,768:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 16:31:42,770:INFO:Preparing preprocessing pipeline...
2023-07-03 16:31:42,771:INFO:Set up label encoding.
2023-07-03 16:31:42,771:INFO:Set up simple imputation.
2023-07-03 16:31:42,772:INFO:Set up column name cleaning.
2023-07-03 16:31:42,793:INFO:Finished creating preprocessing pipeline.
2023-07-03 16:31:42,799:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\JHossain\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['radius_mean', 'texture_mean',
                                             'perimeter_mean', 'area_mean',
                                             'smoothness_mean',
                                             'compactness_mean',
                                             'c...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-07-03 16:31:42,799:INFO:Creating final display dataframe.
2023-07-03 16:31:42,872:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target         diagnosis
2                   Target type            Binary
3                Target mapping        B: 0, M: 1
4           Original data shape         (569, 31)
5        Transformed data shape         (569, 31)
6   Transformed train set shape         (398, 31)
7    Transformed test set shape         (171, 31)
8              Numeric features                30
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator   StratifiedKFold
14                  Fold Number                10
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  clf-default-name
19                          USI              7d04
2023-07-03 16:31:42,938:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 16:31:42,939:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 16:31:43,000:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 16:31:43,001:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 16:31:43,001:INFO:setup() successfully completed in 2.27s...............
2023-07-03 16:31:43,021:INFO:Initializing compare_models()
2023-07-03 16:31:43,021:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002821CC82200>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002821CC82200>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-07-03 16:31:43,022:INFO:Checking exceptions
2023-07-03 16:31:43,025:INFO:Preparing display monitor
2023-07-03 16:31:43,046:INFO:Initializing Logistic Regression
2023-07-03 16:31:43,046:INFO:Total runtime is 0.0 minutes
2023-07-03 16:31:43,049:INFO:SubProcess create_model() called ==================================
2023-07-03 16:31:43,050:INFO:Initializing create_model()
2023-07-03 16:31:43,050:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002821CC82200>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002821D70F010>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 16:31:43,050:INFO:Checking exceptions
2023-07-03 16:31:43,050:INFO:Importing libraries
2023-07-03 16:31:43,050:INFO:Copying training dataset
2023-07-03 16:31:43,053:INFO:Defining folds
2023-07-03 16:31:43,053:INFO:Declaring metric variables
2023-07-03 16:31:43,056:INFO:Importing untrained model
2023-07-03 16:31:43,059:INFO:Logistic Regression Imported successfully
2023-07-03 16:31:43,065:INFO:Starting cross validation
2023-07-03 16:31:43,066:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 16:31:51,675:INFO:Calculating mean and std
2023-07-03 16:31:51,676:INFO:Creating metrics dataframe
2023-07-03 16:31:52,496:INFO:Uploading results into container
2023-07-03 16:31:52,497:INFO:Uploading model into container now
2023-07-03 16:31:52,498:INFO:_master_model_container: 1
2023-07-03 16:31:52,498:INFO:_display_container: 2
2023-07-03 16:31:52,499:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-03 16:31:52,499:INFO:create_model() successfully completed......................................
2023-07-03 16:31:52,651:INFO:SubProcess create_model() end ==================================
2023-07-03 16:31:52,651:INFO:Creating metrics dataframe
2023-07-03 16:31:52,661:INFO:Initializing K Neighbors Classifier
2023-07-03 16:31:52,661:INFO:Total runtime is 0.16024556557337444 minutes
2023-07-03 16:31:52,664:INFO:SubProcess create_model() called ==================================
2023-07-03 16:31:52,664:INFO:Initializing create_model()
2023-07-03 16:31:52,664:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002821CC82200>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002821D70F010>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 16:31:52,664:INFO:Checking exceptions
2023-07-03 16:31:52,664:INFO:Importing libraries
2023-07-03 16:31:52,664:INFO:Copying training dataset
2023-07-03 16:31:52,668:INFO:Defining folds
2023-07-03 16:31:52,668:INFO:Declaring metric variables
2023-07-03 16:31:52,672:INFO:Importing untrained model
2023-07-03 16:31:52,676:INFO:K Neighbors Classifier Imported successfully
2023-07-03 16:31:52,684:INFO:Starting cross validation
2023-07-03 16:31:52,685:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 16:31:57,015:INFO:Calculating mean and std
2023-07-03 16:31:57,016:INFO:Creating metrics dataframe
2023-07-03 16:31:57,831:INFO:Uploading results into container
2023-07-03 16:31:57,832:INFO:Uploading model into container now
2023-07-03 16:31:57,832:INFO:_master_model_container: 2
2023-07-03 16:31:57,832:INFO:_display_container: 2
2023-07-03 16:31:57,833:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-07-03 16:31:57,833:INFO:create_model() successfully completed......................................
2023-07-03 16:31:57,981:INFO:SubProcess create_model() end ==================================
2023-07-03 16:31:57,981:INFO:Creating metrics dataframe
2023-07-03 16:31:57,991:INFO:Initializing Naive Bayes
2023-07-03 16:31:57,992:INFO:Total runtime is 0.2490967353185018 minutes
2023-07-03 16:31:57,995:INFO:SubProcess create_model() called ==================================
2023-07-03 16:31:57,995:INFO:Initializing create_model()
2023-07-03 16:31:57,995:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002821CC82200>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002821D70F010>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 16:31:57,995:INFO:Checking exceptions
2023-07-03 16:31:57,995:INFO:Importing libraries
2023-07-03 16:31:57,995:INFO:Copying training dataset
2023-07-03 16:31:57,999:INFO:Defining folds
2023-07-03 16:31:57,999:INFO:Declaring metric variables
2023-07-03 16:31:58,002:INFO:Importing untrained model
2023-07-03 16:31:58,006:INFO:Naive Bayes Imported successfully
2023-07-03 16:31:58,014:INFO:Starting cross validation
2023-07-03 16:31:58,015:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 16:32:01,882:INFO:Calculating mean and std
2023-07-03 16:32:01,882:INFO:Creating metrics dataframe
2023-07-03 16:32:02,678:INFO:Uploading results into container
2023-07-03 16:32:02,679:INFO:Uploading model into container now
2023-07-03 16:32:02,679:INFO:_master_model_container: 3
2023-07-03 16:32:02,679:INFO:_display_container: 2
2023-07-03 16:32:02,679:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-07-03 16:32:02,679:INFO:create_model() successfully completed......................................
2023-07-03 16:32:02,829:INFO:SubProcess create_model() end ==================================
2023-07-03 16:32:02,829:INFO:Creating metrics dataframe
2023-07-03 16:32:02,841:INFO:Initializing Decision Tree Classifier
2023-07-03 16:32:02,841:INFO:Total runtime is 0.32991180022557576 minutes
2023-07-03 16:32:02,844:INFO:SubProcess create_model() called ==================================
2023-07-03 16:32:02,844:INFO:Initializing create_model()
2023-07-03 16:32:02,844:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002821CC82200>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002821D70F010>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 16:32:02,844:INFO:Checking exceptions
2023-07-03 16:32:02,845:INFO:Importing libraries
2023-07-03 16:32:02,845:INFO:Copying training dataset
2023-07-03 16:32:02,849:INFO:Defining folds
2023-07-03 16:32:02,849:INFO:Declaring metric variables
2023-07-03 16:32:02,853:INFO:Importing untrained model
2023-07-03 16:32:02,857:INFO:Decision Tree Classifier Imported successfully
2023-07-03 16:32:02,863:INFO:Starting cross validation
2023-07-03 16:32:02,864:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 16:32:06,677:INFO:Calculating mean and std
2023-07-03 16:32:06,678:INFO:Creating metrics dataframe
2023-07-03 16:32:07,499:INFO:Uploading results into container
2023-07-03 16:32:07,500:INFO:Uploading model into container now
2023-07-03 16:32:07,501:INFO:_master_model_container: 4
2023-07-03 16:32:07,501:INFO:_display_container: 2
2023-07-03 16:32:07,501:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-07-03 16:32:07,501:INFO:create_model() successfully completed......................................
2023-07-03 16:32:07,665:INFO:SubProcess create_model() end ==================================
2023-07-03 16:32:07,665:INFO:Creating metrics dataframe
2023-07-03 16:32:07,677:INFO:Initializing SVM - Linear Kernel
2023-07-03 16:32:07,678:INFO:Total runtime is 0.4105294863382975 minutes
2023-07-03 16:32:07,682:INFO:SubProcess create_model() called ==================================
2023-07-03 16:32:07,683:INFO:Initializing create_model()
2023-07-03 16:32:07,683:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002821CC82200>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002821D70F010>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 16:32:07,683:INFO:Checking exceptions
2023-07-03 16:32:07,683:INFO:Importing libraries
2023-07-03 16:32:07,683:INFO:Copying training dataset
2023-07-03 16:32:07,689:INFO:Defining folds
2023-07-03 16:32:07,689:INFO:Declaring metric variables
2023-07-03 16:32:07,693:INFO:Importing untrained model
2023-07-03 16:32:07,698:INFO:SVM - Linear Kernel Imported successfully
2023-07-03 16:32:07,706:INFO:Starting cross validation
2023-07-03 16:32:07,707:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 16:32:07,813:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 16:32:07,813:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 16:32:07,820:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 16:32:07,827:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 16:32:07,839:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 16:32:07,848:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 16:32:07,848:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 16:32:07,858:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 16:32:07,869:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 16:32:07,885:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 16:32:11,765:INFO:Calculating mean and std
2023-07-03 16:32:11,766:INFO:Creating metrics dataframe
2023-07-03 16:32:12,568:INFO:Uploading results into container
2023-07-03 16:32:12,570:INFO:Uploading model into container now
2023-07-03 16:32:12,570:INFO:_master_model_container: 5
2023-07-03 16:32:12,570:INFO:_display_container: 2
2023-07-03 16:32:12,571:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-07-03 16:32:12,571:INFO:create_model() successfully completed......................................
2023-07-03 16:32:12,718:INFO:SubProcess create_model() end ==================================
2023-07-03 16:32:12,718:INFO:Creating metrics dataframe
2023-07-03 16:32:12,729:INFO:Initializing Ridge Classifier
2023-07-03 16:32:12,729:INFO:Total runtime is 0.4947269002596537 minutes
2023-07-03 16:32:12,731:INFO:SubProcess create_model() called ==================================
2023-07-03 16:32:12,733:INFO:Initializing create_model()
2023-07-03 16:32:12,733:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002821CC82200>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002821D70F010>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 16:32:12,733:INFO:Checking exceptions
2023-07-03 16:32:12,733:INFO:Importing libraries
2023-07-03 16:32:12,733:INFO:Copying training dataset
2023-07-03 16:32:12,736:INFO:Defining folds
2023-07-03 16:32:12,737:INFO:Declaring metric variables
2023-07-03 16:32:12,740:INFO:Importing untrained model
2023-07-03 16:32:12,743:INFO:Ridge Classifier Imported successfully
2023-07-03 16:32:12,748:INFO:Starting cross validation
2023-07-03 16:32:12,749:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 16:32:12,815:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.48848e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-07-03 16:32:12,825:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.07925e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-07-03 16:32:12,826:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.32091e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-07-03 16:32:12,827:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.49328e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-07-03 16:32:12,830:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.60935e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-07-03 16:32:12,837:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.93944e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-07-03 16:32:12,844:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 16:32:12,844:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.69502e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-07-03 16:32:12,846:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 16:32:12,849:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.99677e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-07-03 16:32:12,853:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 16:32:12,855:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 16:32:12,857:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 16:32:12,858:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.15972e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-07-03 16:32:12,863:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 16:32:12,867:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 16:32:12,869:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.68069e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-07-03 16:32:12,876:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 16:32:12,883:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 16:32:12,899:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 16:32:16,503:INFO:Calculating mean and std
2023-07-03 16:32:16,504:INFO:Creating metrics dataframe
2023-07-03 16:32:17,292:INFO:Uploading results into container
2023-07-03 16:32:17,293:INFO:Uploading model into container now
2023-07-03 16:32:17,293:INFO:_master_model_container: 6
2023-07-03 16:32:17,293:INFO:_display_container: 2
2023-07-03 16:32:17,294:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-07-03 16:32:17,294:INFO:create_model() successfully completed......................................
2023-07-03 16:32:17,456:INFO:SubProcess create_model() end ==================================
2023-07-03 16:32:17,457:INFO:Creating metrics dataframe
2023-07-03 16:32:17,469:INFO:Initializing Random Forest Classifier
2023-07-03 16:32:17,469:INFO:Total runtime is 0.5737246473630269 minutes
2023-07-03 16:32:17,473:INFO:SubProcess create_model() called ==================================
2023-07-03 16:32:17,474:INFO:Initializing create_model()
2023-07-03 16:32:17,474:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002821CC82200>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002821D70F010>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 16:32:17,474:INFO:Checking exceptions
2023-07-03 16:32:17,474:INFO:Importing libraries
2023-07-03 16:32:17,474:INFO:Copying training dataset
2023-07-03 16:32:17,478:INFO:Defining folds
2023-07-03 16:32:17,478:INFO:Declaring metric variables
2023-07-03 16:32:17,482:INFO:Importing untrained model
2023-07-03 16:32:17,486:INFO:Random Forest Classifier Imported successfully
2023-07-03 16:32:17,493:INFO:Starting cross validation
2023-07-03 16:32:17,494:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 16:32:21,907:INFO:Calculating mean and std
2023-07-03 16:32:21,908:INFO:Creating metrics dataframe
2023-07-03 16:32:22,726:INFO:Uploading results into container
2023-07-03 16:32:22,727:INFO:Uploading model into container now
2023-07-03 16:32:22,728:INFO:_master_model_container: 7
2023-07-03 16:32:22,728:INFO:_display_container: 2
2023-07-03 16:32:22,729:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-07-03 16:32:22,729:INFO:create_model() successfully completed......................................
2023-07-03 16:32:22,884:INFO:SubProcess create_model() end ==================================
2023-07-03 16:32:22,885:INFO:Creating metrics dataframe
2023-07-03 16:32:22,895:INFO:Initializing Quadratic Discriminant Analysis
2023-07-03 16:32:22,895:INFO:Total runtime is 0.6641448259353637 minutes
2023-07-03 16:32:22,898:INFO:SubProcess create_model() called ==================================
2023-07-03 16:32:22,899:INFO:Initializing create_model()
2023-07-03 16:32:22,899:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002821CC82200>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002821D70F010>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 16:32:22,899:INFO:Checking exceptions
2023-07-03 16:32:22,899:INFO:Importing libraries
2023-07-03 16:32:22,899:INFO:Copying training dataset
2023-07-03 16:32:22,903:INFO:Defining folds
2023-07-03 16:32:22,904:INFO:Declaring metric variables
2023-07-03 16:32:22,907:INFO:Importing untrained model
2023-07-03 16:32:22,913:INFO:Quadratic Discriminant Analysis Imported successfully
2023-07-03 16:32:22,920:INFO:Starting cross validation
2023-07-03 16:32:22,922:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 16:32:26,655:INFO:Calculating mean and std
2023-07-03 16:32:26,656:INFO:Creating metrics dataframe
2023-07-03 16:32:27,467:INFO:Uploading results into container
2023-07-03 16:32:27,468:INFO:Uploading model into container now
2023-07-03 16:32:27,468:INFO:_master_model_container: 8
2023-07-03 16:32:27,468:INFO:_display_container: 2
2023-07-03 16:32:27,469:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-07-03 16:32:27,469:INFO:create_model() successfully completed......................................
2023-07-03 16:32:27,621:INFO:SubProcess create_model() end ==================================
2023-07-03 16:32:27,621:INFO:Creating metrics dataframe
2023-07-03 16:32:27,632:INFO:Initializing Ada Boost Classifier
2023-07-03 16:32:27,632:INFO:Total runtime is 0.7431084195772806 minutes
2023-07-03 16:32:27,636:INFO:SubProcess create_model() called ==================================
2023-07-03 16:32:27,636:INFO:Initializing create_model()
2023-07-03 16:32:27,636:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002821CC82200>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002821D70F010>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 16:32:27,636:INFO:Checking exceptions
2023-07-03 16:32:27,636:INFO:Importing libraries
2023-07-03 16:32:27,637:INFO:Copying training dataset
2023-07-03 16:32:27,641:INFO:Defining folds
2023-07-03 16:32:27,641:INFO:Declaring metric variables
2023-07-03 16:32:27,645:INFO:Importing untrained model
2023-07-03 16:32:27,648:INFO:Ada Boost Classifier Imported successfully
2023-07-03 16:32:27,653:INFO:Starting cross validation
2023-07-03 16:32:27,654:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 16:32:31,630:INFO:Calculating mean and std
2023-07-03 16:32:31,631:INFO:Creating metrics dataframe
2023-07-03 16:32:32,451:INFO:Uploading results into container
2023-07-03 16:32:32,452:INFO:Uploading model into container now
2023-07-03 16:32:32,453:INFO:_master_model_container: 9
2023-07-03 16:32:32,453:INFO:_display_container: 2
2023-07-03 16:32:32,453:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-07-03 16:32:32,453:INFO:create_model() successfully completed......................................
2023-07-03 16:32:32,606:INFO:SubProcess create_model() end ==================================
2023-07-03 16:32:32,606:INFO:Creating metrics dataframe
2023-07-03 16:32:32,617:INFO:Initializing Gradient Boosting Classifier
2023-07-03 16:32:32,617:INFO:Total runtime is 0.8261824886004129 minutes
2023-07-03 16:32:32,621:INFO:SubProcess create_model() called ==================================
2023-07-03 16:32:32,621:INFO:Initializing create_model()
2023-07-03 16:32:32,621:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002821CC82200>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002821D70F010>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 16:32:32,621:INFO:Checking exceptions
2023-07-03 16:32:32,621:INFO:Importing libraries
2023-07-03 16:32:32,621:INFO:Copying training dataset
2023-07-03 16:32:32,625:INFO:Defining folds
2023-07-03 16:32:32,625:INFO:Declaring metric variables
2023-07-03 16:32:32,629:INFO:Importing untrained model
2023-07-03 16:32:32,633:INFO:Gradient Boosting Classifier Imported successfully
2023-07-03 16:32:32,639:INFO:Starting cross validation
2023-07-03 16:32:32,641:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 16:32:36,893:INFO:Calculating mean and std
2023-07-03 16:32:36,894:INFO:Creating metrics dataframe
2023-07-03 16:32:37,709:INFO:Uploading results into container
2023-07-03 16:32:37,710:INFO:Uploading model into container now
2023-07-03 16:32:37,711:INFO:_master_model_container: 10
2023-07-03 16:32:37,711:INFO:_display_container: 2
2023-07-03 16:32:37,711:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-03 16:32:37,711:INFO:create_model() successfully completed......................................
2023-07-03 16:32:37,878:INFO:SubProcess create_model() end ==================================
2023-07-03 16:32:37,878:INFO:Creating metrics dataframe
2023-07-03 16:32:37,889:INFO:Initializing Linear Discriminant Analysis
2023-07-03 16:32:37,889:INFO:Total runtime is 0.9140574733416238 minutes
2023-07-03 16:32:37,893:INFO:SubProcess create_model() called ==================================
2023-07-03 16:32:37,893:INFO:Initializing create_model()
2023-07-03 16:32:37,893:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002821CC82200>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002821D70F010>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 16:32:37,894:INFO:Checking exceptions
2023-07-03 16:32:37,894:INFO:Importing libraries
2023-07-03 16:32:37,894:INFO:Copying training dataset
2023-07-03 16:32:37,897:INFO:Defining folds
2023-07-03 16:32:37,898:INFO:Declaring metric variables
2023-07-03 16:32:37,901:INFO:Importing untrained model
2023-07-03 16:32:37,906:INFO:Linear Discriminant Analysis Imported successfully
2023-07-03 16:32:37,912:INFO:Starting cross validation
2023-07-03 16:32:37,913:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 16:32:41,830:INFO:Calculating mean and std
2023-07-03 16:32:41,831:INFO:Creating metrics dataframe
2023-07-03 16:32:42,624:INFO:Uploading results into container
2023-07-03 16:32:42,625:INFO:Uploading model into container now
2023-07-03 16:32:42,625:INFO:_master_model_container: 11
2023-07-03 16:32:42,625:INFO:_display_container: 2
2023-07-03 16:32:42,625:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-07-03 16:32:42,626:INFO:create_model() successfully completed......................................
2023-07-03 16:32:42,773:INFO:SubProcess create_model() end ==================================
2023-07-03 16:32:42,774:INFO:Creating metrics dataframe
2023-07-03 16:32:42,785:INFO:Initializing Extra Trees Classifier
2023-07-03 16:32:42,785:INFO:Total runtime is 0.9956497708956399 minutes
2023-07-03 16:32:42,789:INFO:SubProcess create_model() called ==================================
2023-07-03 16:32:42,789:INFO:Initializing create_model()
2023-07-03 16:32:42,790:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002821CC82200>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002821D70F010>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 16:32:42,790:INFO:Checking exceptions
2023-07-03 16:32:42,790:INFO:Importing libraries
2023-07-03 16:32:42,790:INFO:Copying training dataset
2023-07-03 16:32:42,793:INFO:Defining folds
2023-07-03 16:32:42,793:INFO:Declaring metric variables
2023-07-03 16:32:42,797:INFO:Importing untrained model
2023-07-03 16:32:42,801:INFO:Extra Trees Classifier Imported successfully
2023-07-03 16:32:42,808:INFO:Starting cross validation
2023-07-03 16:32:42,810:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 16:32:46,831:INFO:Calculating mean and std
2023-07-03 16:32:46,831:INFO:Creating metrics dataframe
2023-07-03 16:32:47,488:INFO:Uploading results into container
2023-07-03 16:32:47,489:INFO:Uploading model into container now
2023-07-03 16:32:47,489:INFO:_master_model_container: 12
2023-07-03 16:32:47,489:INFO:_display_container: 2
2023-07-03 16:32:47,490:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-07-03 16:32:47,490:INFO:create_model() successfully completed......................................
2023-07-03 16:32:47,654:INFO:SubProcess create_model() end ==================================
2023-07-03 16:32:47,654:INFO:Creating metrics dataframe
2023-07-03 16:32:47,664:INFO:Initializing Light Gradient Boosting Machine
2023-07-03 16:32:47,664:INFO:Total runtime is 1.076975925763448 minutes
2023-07-03 16:32:47,667:INFO:SubProcess create_model() called ==================================
2023-07-03 16:32:47,668:INFO:Initializing create_model()
2023-07-03 16:32:47,668:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002821CC82200>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002821D70F010>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 16:32:47,668:INFO:Checking exceptions
2023-07-03 16:32:47,668:INFO:Importing libraries
2023-07-03 16:32:47,668:INFO:Copying training dataset
2023-07-03 16:32:47,672:INFO:Defining folds
2023-07-03 16:32:47,672:INFO:Declaring metric variables
2023-07-03 16:32:47,675:INFO:Importing untrained model
2023-07-03 16:32:47,678:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-03 16:32:47,684:INFO:Starting cross validation
2023-07-03 16:32:47,685:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 16:32:52,588:INFO:Calculating mean and std
2023-07-03 16:32:52,589:INFO:Creating metrics dataframe
2023-07-03 16:32:53,403:INFO:Uploading results into container
2023-07-03 16:32:53,404:INFO:Uploading model into container now
2023-07-03 16:32:53,404:INFO:_master_model_container: 13
2023-07-03 16:32:53,404:INFO:_display_container: 2
2023-07-03 16:32:53,405:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-07-03 16:32:53,405:INFO:create_model() successfully completed......................................
2023-07-03 16:32:53,596:INFO:SubProcess create_model() end ==================================
2023-07-03 16:32:53,596:INFO:Creating metrics dataframe
2023-07-03 16:32:53,610:INFO:Initializing Dummy Classifier
2023-07-03 16:32:53,610:INFO:Total runtime is 1.176063787937164 minutes
2023-07-03 16:32:53,614:INFO:SubProcess create_model() called ==================================
2023-07-03 16:32:53,614:INFO:Initializing create_model()
2023-07-03 16:32:53,614:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002821CC82200>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002821D70F010>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 16:32:53,614:INFO:Checking exceptions
2023-07-03 16:32:53,614:INFO:Importing libraries
2023-07-03 16:32:53,615:INFO:Copying training dataset
2023-07-03 16:32:53,619:INFO:Defining folds
2023-07-03 16:32:53,619:INFO:Declaring metric variables
2023-07-03 16:32:53,623:INFO:Importing untrained model
2023-07-03 16:32:53,626:INFO:Dummy Classifier Imported successfully
2023-07-03 16:32:53,632:INFO:Starting cross validation
2023-07-03 16:32:53,633:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 16:32:53,737:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 16:32:53,755:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 16:32:53,765:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 16:32:53,769:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 16:32:53,778:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 16:32:53,783:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 16:32:53,789:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 16:32:53,797:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 16:32:53,806:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 16:32:53,816:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 16:32:57,354:INFO:Calculating mean and std
2023-07-03 16:32:57,355:INFO:Creating metrics dataframe
2023-07-03 16:32:58,186:INFO:Uploading results into container
2023-07-03 16:32:58,187:INFO:Uploading model into container now
2023-07-03 16:32:58,188:INFO:_master_model_container: 14
2023-07-03 16:32:58,188:INFO:_display_container: 2
2023-07-03 16:32:58,188:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-07-03 16:32:58,188:INFO:create_model() successfully completed......................................
2023-07-03 16:32:58,355:INFO:SubProcess create_model() end ==================================
2023-07-03 16:32:58,355:INFO:Creating metrics dataframe
2023-07-03 16:32:58,375:INFO:Initializing create_model()
2023-07-03 16:32:58,376:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002821CC82200>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-03 16:32:58,376:INFO:Checking exceptions
2023-07-03 16:32:58,378:INFO:Importing libraries
2023-07-03 16:32:58,378:INFO:Copying training dataset
2023-07-03 16:32:58,381:INFO:Defining folds
2023-07-03 16:32:58,381:INFO:Declaring metric variables
2023-07-03 16:32:58,381:INFO:Importing untrained model
2023-07-03 16:32:58,381:INFO:Declaring custom model
2023-07-03 16:32:58,381:INFO:Extra Trees Classifier Imported successfully
2023-07-03 16:32:58,383:INFO:Cross validation set to False
2023-07-03 16:32:58,383:INFO:Fitting Model
2023-07-03 16:32:58,851:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-07-03 16:32:58,851:INFO:create_model() successfully completed......................................
2023-07-03 16:32:59,047:INFO:_master_model_container: 14
2023-07-03 16:32:59,047:INFO:_display_container: 2
2023-07-03 16:32:59,048:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-07-03 16:32:59,048:INFO:compare_models() successfully completed......................................
2023-07-03 16:32:59,066:INFO:Initializing create_model()
2023-07-03 16:32:59,066:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002821CC82200>, estimator=et, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-03 16:32:59,066:INFO:Checking exceptions
2023-07-03 16:32:59,080:INFO:Importing libraries
2023-07-03 16:32:59,080:INFO:Copying training dataset
2023-07-03 16:32:59,085:INFO:Defining folds
2023-07-03 16:32:59,085:INFO:Declaring metric variables
2023-07-03 16:32:59,089:INFO:Importing untrained model
2023-07-03 16:32:59,093:INFO:Extra Trees Classifier Imported successfully
2023-07-03 16:32:59,100:INFO:Starting cross validation
2023-07-03 16:32:59,102:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 16:33:03,212:INFO:Calculating mean and std
2023-07-03 16:33:03,214:INFO:Creating metrics dataframe
2023-07-03 16:33:03,220:INFO:Finalizing model
2023-07-03 16:33:04,084:INFO:Uploading results into container
2023-07-03 16:33:04,086:INFO:Uploading model into container now
2023-07-03 16:33:04,100:INFO:_master_model_container: 15
2023-07-03 16:33:04,100:INFO:_display_container: 3
2023-07-03 16:33:04,102:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-07-03 16:33:04,102:INFO:create_model() successfully completed......................................
2023-07-03 16:33:04,297:INFO:Initializing tune_model()
2023-07-03 16:33:04,297:INFO:tune_model(estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002821CC82200>)
2023-07-03 16:33:04,297:INFO:Checking exceptions
2023-07-03 16:33:04,315:INFO:Copying training dataset
2023-07-03 16:33:04,318:INFO:Checking base model
2023-07-03 16:33:04,318:INFO:Base model : Extra Trees Classifier
2023-07-03 16:33:04,322:INFO:Declaring metric variables
2023-07-03 16:33:04,327:INFO:Defining Hyperparameters
2023-07-03 16:33:04,483:INFO:Tuning with n_jobs=-1
2023-07-03 16:33:04,483:INFO:Initializing RandomizedSearchCV
2023-07-03 16:33:55,194:INFO:best_params: {'actual_estimator__n_estimators': 200, 'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 6, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': 'balanced_subsample', 'actual_estimator__bootstrap': False}
2023-07-03 16:33:55,196:INFO:Hyperparameter search completed
2023-07-03 16:33:55,196:INFO:SubProcess create_model() called ==================================
2023-07-03 16:33:55,197:INFO:Initializing create_model()
2023-07-03 16:33:55,197:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002821CC82200>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002821D70EC20>, model_only=True, return_train_score=False, kwargs={'n_estimators': 200, 'min_samples_split': 7, 'min_samples_leaf': 4, 'min_impurity_decrease': 0, 'max_features': 1.0, 'max_depth': 6, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'bootstrap': False})
2023-07-03 16:33:55,197:INFO:Checking exceptions
2023-07-03 16:33:55,197:INFO:Importing libraries
2023-07-03 16:33:55,197:INFO:Copying training dataset
2023-07-03 16:33:55,200:INFO:Defining folds
2023-07-03 16:33:55,201:INFO:Declaring metric variables
2023-07-03 16:33:55,203:INFO:Importing untrained model
2023-07-03 16:33:55,203:INFO:Declaring custom model
2023-07-03 16:33:55,207:INFO:Extra Trees Classifier Imported successfully
2023-07-03 16:33:55,212:INFO:Starting cross validation
2023-07-03 16:33:55,213:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 16:34:00,247:INFO:Calculating mean and std
2023-07-03 16:34:00,248:INFO:Creating metrics dataframe
2023-07-03 16:34:00,255:INFO:Finalizing model
2023-07-03 16:34:01,625:INFO:Uploading results into container
2023-07-03 16:34:01,626:INFO:Uploading model into container now
2023-07-03 16:34:01,627:INFO:_master_model_container: 16
2023-07-03 16:34:01,627:INFO:_display_container: 4
2023-07-03 16:34:01,627:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,
                     class_weight='balanced_subsample', criterion='gini',
                     max_depth=6, max_features=1.0, max_leaf_nodes=None,
                     max_samples=None, min_impurity_decrease=0,
                     min_samples_leaf=4, min_samples_split=7,
                     min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2023-07-03 16:34:01,627:INFO:create_model() successfully completed......................................
2023-07-03 16:34:01,780:INFO:SubProcess create_model() end ==================================
2023-07-03 16:34:01,780:INFO:choose_better activated
2023-07-03 16:34:01,782:INFO:SubProcess create_model() called ==================================
2023-07-03 16:34:01,783:INFO:Initializing create_model()
2023-07-03 16:34:01,783:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002821CC82200>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-03 16:34:01,783:INFO:Checking exceptions
2023-07-03 16:34:01,785:INFO:Importing libraries
2023-07-03 16:34:01,785:INFO:Copying training dataset
2023-07-03 16:34:01,788:INFO:Defining folds
2023-07-03 16:34:01,789:INFO:Declaring metric variables
2023-07-03 16:34:01,789:INFO:Importing untrained model
2023-07-03 16:34:01,789:INFO:Declaring custom model
2023-07-03 16:34:01,789:INFO:Extra Trees Classifier Imported successfully
2023-07-03 16:34:01,791:INFO:Starting cross validation
2023-07-03 16:34:01,792:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 16:34:06,027:INFO:Calculating mean and std
2023-07-03 16:34:06,027:INFO:Creating metrics dataframe
2023-07-03 16:34:06,029:INFO:Finalizing model
2023-07-03 16:34:06,937:INFO:Uploading results into container
2023-07-03 16:34:06,938:INFO:Uploading model into container now
2023-07-03 16:34:06,939:INFO:_master_model_container: 17
2023-07-03 16:34:06,939:INFO:_display_container: 5
2023-07-03 16:34:06,939:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-07-03 16:34:06,940:INFO:create_model() successfully completed......................................
2023-07-03 16:34:07,089:INFO:SubProcess create_model() end ==================================
2023-07-03 16:34:07,089:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False) result for Accuracy is 0.9673
2023-07-03 16:34:07,090:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,
                     class_weight='balanced_subsample', criterion='gini',
                     max_depth=6, max_features=1.0, max_leaf_nodes=None,
                     max_samples=None, min_impurity_decrease=0,
                     min_samples_leaf=4, min_samples_split=7,
                     min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False) result for Accuracy is 0.9647
2023-07-03 16:34:07,090:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False) is best model
2023-07-03 16:34:07,090:INFO:choose_better completed
2023-07-03 16:34:07,090:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-07-03 16:34:07,102:INFO:_master_model_container: 17
2023-07-03 16:34:07,102:INFO:_display_container: 4
2023-07-03 16:34:07,103:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-07-03 16:34:07,103:INFO:tune_model() successfully completed......................................
2023-07-03 16:34:07,665:INFO:Initializing tune_model()
2023-07-03 16:34:07,665:INFO:tune_model(estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=True, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002821CC82200>)
2023-07-03 16:34:07,665:INFO:Checking exceptions
2023-07-03 16:34:07,682:INFO:Copying training dataset
2023-07-03 16:34:07,685:INFO:Checking base model
2023-07-03 16:34:07,686:INFO:Base model : Extra Trees Classifier
2023-07-03 16:34:07,690:INFO:Declaring metric variables
2023-07-03 16:34:07,694:INFO:Defining Hyperparameters
2023-07-03 16:34:07,855:INFO:Tuning with n_jobs=-1
2023-07-03 16:34:07,855:INFO:Initializing RandomizedSearchCV
2023-07-03 16:34:54,184:INFO:best_params: {'actual_estimator__n_estimators': 200, 'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 6, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': 'balanced_subsample', 'actual_estimator__bootstrap': False}
2023-07-03 16:34:54,185:INFO:Hyperparameter search completed
2023-07-03 16:34:54,185:INFO:SubProcess create_model() called ==================================
2023-07-03 16:34:54,186:INFO:Initializing create_model()
2023-07-03 16:34:54,186:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002821CC82200>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002821C3F41C0>, model_only=True, return_train_score=False, kwargs={'n_estimators': 200, 'min_samples_split': 7, 'min_samples_leaf': 4, 'min_impurity_decrease': 0, 'max_features': 1.0, 'max_depth': 6, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'bootstrap': False})
2023-07-03 16:34:54,186:INFO:Checking exceptions
2023-07-03 16:34:54,187:INFO:Importing libraries
2023-07-03 16:34:54,187:INFO:Copying training dataset
2023-07-03 16:34:54,191:INFO:Defining folds
2023-07-03 16:34:54,191:INFO:Declaring metric variables
2023-07-03 16:34:54,194:INFO:Importing untrained model
2023-07-03 16:34:54,195:INFO:Declaring custom model
2023-07-03 16:34:54,198:INFO:Extra Trees Classifier Imported successfully
2023-07-03 16:34:54,205:INFO:Starting cross validation
2023-07-03 16:34:54,206:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 16:34:58,554:INFO:Calculating mean and std
2023-07-03 16:34:58,555:INFO:Creating metrics dataframe
2023-07-03 16:34:58,561:INFO:Finalizing model
2023-07-03 16:34:59,481:INFO:Uploading results into container
2023-07-03 16:34:59,482:INFO:Uploading model into container now
2023-07-03 16:34:59,482:INFO:_master_model_container: 18
2023-07-03 16:34:59,482:INFO:_display_container: 5
2023-07-03 16:34:59,483:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,
                     class_weight='balanced_subsample', criterion='gini',
                     max_depth=6, max_features=1.0, max_leaf_nodes=None,
                     max_samples=None, min_impurity_decrease=0,
                     min_samples_leaf=4, min_samples_split=7,
                     min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2023-07-03 16:34:59,483:INFO:create_model() successfully completed......................................
2023-07-03 16:34:59,634:INFO:SubProcess create_model() end ==================================
2023-07-03 16:34:59,634:INFO:choose_better activated
2023-07-03 16:34:59,637:INFO:SubProcess create_model() called ==================================
2023-07-03 16:34:59,637:INFO:Initializing create_model()
2023-07-03 16:34:59,637:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002821CC82200>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-03 16:34:59,637:INFO:Checking exceptions
2023-07-03 16:34:59,640:INFO:Importing libraries
2023-07-03 16:34:59,640:INFO:Copying training dataset
2023-07-03 16:34:59,643:INFO:Defining folds
2023-07-03 16:34:59,643:INFO:Declaring metric variables
2023-07-03 16:34:59,643:INFO:Importing untrained model
2023-07-03 16:34:59,643:INFO:Declaring custom model
2023-07-03 16:34:59,644:INFO:Extra Trees Classifier Imported successfully
2023-07-03 16:34:59,644:INFO:Starting cross validation
2023-07-03 16:34:59,646:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 16:35:03,785:INFO:Calculating mean and std
2023-07-03 16:35:03,786:INFO:Creating metrics dataframe
2023-07-03 16:35:03,788:INFO:Finalizing model
2023-07-03 16:35:04,687:INFO:Uploading results into container
2023-07-03 16:35:04,688:INFO:Uploading model into container now
2023-07-03 16:35:04,689:INFO:_master_model_container: 19
2023-07-03 16:35:04,689:INFO:_display_container: 6
2023-07-03 16:35:04,689:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-07-03 16:35:04,689:INFO:create_model() successfully completed......................................
2023-07-03 16:35:04,836:INFO:SubProcess create_model() end ==================================
2023-07-03 16:35:04,836:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False) result for Accuracy is 0.9673
2023-07-03 16:35:04,837:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,
                     class_weight='balanced_subsample', criterion='gini',
                     max_depth=6, max_features=1.0, max_leaf_nodes=None,
                     max_samples=None, min_impurity_decrease=0,
                     min_samples_leaf=4, min_samples_split=7,
                     min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False) result for Accuracy is 0.9647
2023-07-03 16:35:04,837:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False) is best model
2023-07-03 16:35:04,837:INFO:choose_better completed
2023-07-03 16:35:04,837:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-07-03 16:35:04,846:INFO:_master_model_container: 19
2023-07-03 16:35:04,846:INFO:_display_container: 5
2023-07-03 16:35:04,847:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-07-03 16:35:04,847:INFO:tune_model() successfully completed......................................
2023-07-03 16:35:05,069:INFO:Initializing plot_model()
2023-07-03 16:35:05,069:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002821CC82200>, system=True)
2023-07-03 16:35:05,070:INFO:Checking exceptions
2023-07-03 16:35:05,087:INFO:Preloading libraries
2023-07-03 16:35:05,096:INFO:Copying training dataset
2023-07-03 16:35:05,096:INFO:Plot type: confusion_matrix
2023-07-03 16:35:05,173:INFO:Fitting Model
2023-07-03 16:35:05,174:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\base.py:420: UserWarning: X does not have valid feature names, but ExtraTreesClassifier was fitted with feature names
  warnings.warn(

2023-07-03 16:35:05,174:INFO:Scoring test/hold-out set
2023-07-03 16:35:05,309:INFO:Visual Rendered Successfully
2023-07-03 16:35:05,459:INFO:plot_model() successfully completed......................................
2023-07-03 16:35:05,465:INFO:Initializing plot_model()
2023-07-03 16:35:05,465:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002821CC82200>, system=True)
2023-07-03 16:35:05,465:INFO:Checking exceptions
2023-07-03 16:35:05,482:INFO:Preloading libraries
2023-07-03 16:35:05,492:INFO:Copying training dataset
2023-07-03 16:35:05,493:INFO:Plot type: auc
2023-07-03 16:35:05,566:INFO:Fitting Model
2023-07-03 16:35:05,566:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\base.py:420: UserWarning: X does not have valid feature names, but ExtraTreesClassifier was fitted with feature names
  warnings.warn(

2023-07-03 16:35:05,566:INFO:Scoring test/hold-out set
2023-07-03 16:35:05,769:INFO:Visual Rendered Successfully
2023-07-03 16:35:05,917:INFO:plot_model() successfully completed......................................
2023-07-03 16:35:05,938:INFO:Initializing plot_model()
2023-07-03 16:35:05,938:INFO:plot_model(plot=class_report, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002821CC82200>, system=True)
2023-07-03 16:35:05,938:INFO:Checking exceptions
2023-07-03 16:35:05,956:INFO:Preloading libraries
2023-07-03 16:35:05,963:INFO:Copying training dataset
2023-07-03 16:35:05,964:INFO:Plot type: class_report
2023-07-03 16:35:06,040:INFO:Fitting Model
2023-07-03 16:35:06,040:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\base.py:420: UserWarning: X does not have valid feature names, but ExtraTreesClassifier was fitted with feature names
  warnings.warn(

2023-07-03 16:35:06,041:INFO:Scoring test/hold-out set
2023-07-03 16:35:06,248:INFO:Visual Rendered Successfully
2023-07-03 16:35:06,400:INFO:plot_model() successfully completed......................................
2023-07-03 16:35:06,407:INFO:Initializing plot_model()
2023-07-03 16:35:06,407:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002821CC82200>, system=True)
2023-07-03 16:35:06,409:INFO:Checking exceptions
2023-07-03 16:35:06,426:INFO:Preloading libraries
2023-07-03 16:35:06,435:INFO:Copying training dataset
2023-07-03 16:35:06,435:INFO:Plot type: feature
2023-07-03 16:35:06,436:WARNING:No coef_ found. Trying feature_importances_
2023-07-03 16:35:06,589:INFO:Visual Rendered Successfully
2023-07-03 16:35:06,739:INFO:plot_model() successfully completed......................................
2023-07-03 16:35:06,755:INFO:Initializing evaluate_model()
2023-07-03 16:35:06,755:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002821CC82200>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-07-03 16:35:06,768:INFO:Initializing plot_model()
2023-07-03 16:35:06,768:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002821CC82200>, system=True)
2023-07-03 16:35:06,768:INFO:Checking exceptions
2023-07-03 16:35:06,783:INFO:Preloading libraries
2023-07-03 16:35:06,790:INFO:Copying training dataset
2023-07-03 16:35:06,790:INFO:Plot type: pipeline
2023-07-03 16:35:06,908:INFO:Visual Rendered Successfully
2023-07-03 16:35:07,059:INFO:plot_model() successfully completed......................................
2023-07-03 16:35:07,069:INFO:Initializing finalize_model()
2023-07-03 16:35:07,069:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002821CC82200>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-07-03 16:35:07,069:INFO:Finalizing ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-07-03 16:35:07,074:INFO:Initializing create_model()
2023-07-03 16:35:07,074:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002821CC82200>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-07-03 16:35:07,074:INFO:Checking exceptions
2023-07-03 16:35:07,075:INFO:Importing libraries
2023-07-03 16:35:07,075:INFO:Copying training dataset
2023-07-03 16:35:07,076:INFO:Defining folds
2023-07-03 16:35:07,076:INFO:Declaring metric variables
2023-07-03 16:35:07,076:INFO:Importing untrained model
2023-07-03 16:35:07,076:INFO:Declaring custom model
2023-07-03 16:35:07,077:INFO:Extra Trees Classifier Imported successfully
2023-07-03 16:35:07,077:INFO:Cross validation set to False
2023-07-03 16:35:07,077:INFO:Fitting Model
2023-07-03 16:35:07,316:INFO:Pipeline(memory=FastMemory(location=C:\Users\JHossain\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['radius_mean', 'texture_mean',
                                             'perimeter_mean', 'area_mean',
                                             'smoothness_mean',
                                             'compactness_mean',
                                             'c...
                 ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,
                                      class_weight=None, criterion='gini',
                                      max_depth=None, max_features='sqrt',
                                      max_leaf_nodes=None, max_samples=None,
                                      min_impurity_decrease=0.0,
                                      min_samples_leaf=1, min_samples_split=2,
                                      min_weight_fraction_leaf=0.0,
                                      n_estimators=100, n_jobs=-1,
                                      oob_score=False, random_state=123,
                                      verbose=0, warm_start=False))],
         verbose=False)
2023-07-03 16:35:07,316:INFO:create_model() successfully completed......................................
2023-07-03 16:35:07,462:INFO:_master_model_container: 19
2023-07-03 16:35:07,462:INFO:_display_container: 5
2023-07-03 16:35:07,468:INFO:Pipeline(memory=FastMemory(location=C:\Users\JHossain\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['radius_mean', 'texture_mean',
                                             'perimeter_mean', 'area_mean',
                                             'smoothness_mean',
                                             'compactness_mean',
                                             'c...
                 ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,
                                      class_weight=None, criterion='gini',
                                      max_depth=None, max_features='sqrt',
                                      max_leaf_nodes=None, max_samples=None,
                                      min_impurity_decrease=0.0,
                                      min_samples_leaf=1, min_samples_split=2,
                                      min_weight_fraction_leaf=0.0,
                                      n_estimators=100, n_jobs=-1,
                                      oob_score=False, random_state=123,
                                      verbose=0, warm_start=False))],
         verbose=False)
2023-07-03 16:35:07,468:INFO:finalize_model() successfully completed......................................
2023-07-03 16:35:07,650:INFO:Initializing predict_model()
2023-07-03 16:35:07,650:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002821CC82200>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000028224F57760>)
2023-07-03 16:35:07,650:INFO:Checking exceptions
2023-07-03 16:35:07,650:INFO:Preloading libraries
2023-07-03 21:46:11,291:INFO:Initializing predict_model()
2023-07-03 21:46:11,291:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002821CC82200>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000028224F57880>)
2023-07-03 21:46:11,291:INFO:Checking exceptions
2023-07-03 21:46:11,291:INFO:Preloading libraries
2023-07-03 21:46:11,294:INFO:Set up data.
2023-07-03 21:46:11,301:INFO:Set up index.
2023-07-03 21:46:15,040:INFO:Initializing save_model()
2023-07-03 21:46:15,040:INFO:save_model(model=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), model_name=../models/breast_cancer, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JHossain\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['radius_mean', 'texture_mean',
                                             'perimeter_mean', 'area_mean',
                                             'smoothness_mean',
                                             'compactness_mean',
                                             'c...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-07-03 21:46:15,040:INFO:Adding model into prep_pipe
2023-07-03 21:46:15,079:INFO:../models/breast_cancer.pkl saved in current working directory
2023-07-03 21:46:15,084:INFO:Pipeline(memory=FastMemory(location=C:\Users\JHossain\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['radius_mean', 'texture_mean',
                                             'perimeter_mean', 'area_mean',
                                             'smoothness_mean',
                                             'compactness_mean',
                                             'c...
                 ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,
                                      class_weight=None, criterion='gini',
                                      max_depth=None, max_features='sqrt',
                                      max_leaf_nodes=None, max_samples=None,
                                      min_impurity_decrease=0.0,
                                      min_samples_leaf=1, min_samples_split=2,
                                      min_weight_fraction_leaf=0.0,
                                      n_estimators=100, n_jobs=-1,
                                      oob_score=False, random_state=123,
                                      verbose=0, warm_start=False))],
         verbose=False)
2023-07-03 21:46:15,085:INFO:save_model() successfully completed......................................
2023-07-03 21:46:17,786:INFO:Initializing load_model()
2023-07-03 21:46:17,786:INFO:load_model(model_name=../models/breast_cancer, platform=None, authentication=None, verbose=True)
2023-07-03 22:02:48,269:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-03 22:02:48,269:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-03 22:02:48,269:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-03 22:02:48,269:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-03 22:02:48,875:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-07-03 22:02:49,518:INFO:PyCaret ClassificationExperiment
2023-07-03 22:02:49,518:INFO:Logging name: clf-default-name
2023-07-03 22:02:49,518:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-07-03 22:02:49,518:INFO:version 3.0.2
2023-07-03 22:02:49,518:INFO:Initializing setup()
2023-07-03 22:02:49,518:INFO:self.USI: 6a11
2023-07-03 22:02:49,518:INFO:self._variable_keys: {'gpu_param', 'X_train', 'X_test', '_ml_usecase', 'data', 'y_test', 'fold_groups_param', 'y', 'exp_id', 'n_jobs_param', 'memory', 'is_multiclass', 'fix_imbalance', 'seed', 'X', 'gpu_n_jobs_param', 'logging_param', 'exp_name_log', 'fold_generator', 'y_train', 'fold_shuffle_param', '_available_plots', 'log_plots_param', 'html_param', 'USI', 'target_param', 'pipeline', 'idx'}
2023-07-03 22:02:49,518:INFO:Checking environment
2023-07-03 22:02:49,518:INFO:python_version: 3.10.9
2023-07-03 22:02:49,518:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2023-07-03 22:02:49,518:INFO:machine: AMD64
2023-07-03 22:02:49,518:INFO:platform: Windows-10-10.0.22621-SP0
2023-07-03 22:02:49,523:INFO:Memory: svmem(total=33664483328, available=20232138752, percent=39.9, used=13432344576, free=20232138752)
2023-07-03 22:02:49,523:INFO:Physical Core: 6
2023-07-03 22:02:49,523:INFO:Logical Core: 12
2023-07-03 22:02:49,523:INFO:Checking libraries
2023-07-03 22:02:49,523:INFO:System:
2023-07-03 22:02:49,523:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2023-07-03 22:02:49,523:INFO:executable: C:\Users\JHossain\anaconda3\python.exe
2023-07-03 22:02:49,523:INFO:   machine: Windows-10-10.0.22621-SP0
2023-07-03 22:02:49,523:INFO:PyCaret required dependencies:
2023-07-03 22:02:49,523:INFO:                 pip: 22.3.1
2023-07-03 22:02:49,523:INFO:          setuptools: 65.6.3
2023-07-03 22:02:49,523:INFO:             pycaret: 3.0.2
2023-07-03 22:02:49,523:INFO:             IPython: 8.10.0
2023-07-03 22:02:49,523:INFO:          ipywidgets: 7.6.5
2023-07-03 22:02:49,523:INFO:                tqdm: 4.64.1
2023-07-03 22:02:49,523:INFO:               numpy: 1.23.5
2023-07-03 22:02:49,523:INFO:              pandas: 1.5.3
2023-07-03 22:02:49,523:INFO:              jinja2: 3.1.2
2023-07-03 22:02:49,523:INFO:               scipy: 1.10.0
2023-07-03 22:02:49,523:INFO:              joblib: 1.2.0
2023-07-03 22:02:49,524:INFO:             sklearn: 1.2.1
2023-07-03 22:02:49,524:INFO:                pyod: 1.0.9
2023-07-03 22:02:49,524:INFO:            imblearn: 0.10.1
2023-07-03 22:02:49,524:INFO:   category_encoders: 2.6.1
2023-07-03 22:02:49,524:INFO:            lightgbm: 3.3.5
2023-07-03 22:02:49,524:INFO:               numba: 0.56.4
2023-07-03 22:02:49,524:INFO:            requests: 2.28.1
2023-07-03 22:02:49,524:INFO:          matplotlib: 3.7.0
2023-07-03 22:02:49,524:INFO:          scikitplot: 0.3.7
2023-07-03 22:02:49,524:INFO:         yellowbrick: 1.5
2023-07-03 22:02:49,524:INFO:              plotly: 5.9.0
2023-07-03 22:02:49,524:INFO:             kaleido: 0.2.1
2023-07-03 22:02:49,524:INFO:         statsmodels: 0.13.5
2023-07-03 22:02:49,524:INFO:              sktime: 0.17.0
2023-07-03 22:02:49,524:INFO:               tbats: 1.1.3
2023-07-03 22:02:49,524:INFO:            pmdarima: 2.0.3
2023-07-03 22:02:49,524:INFO:              psutil: 5.9.0
2023-07-03 22:02:49,524:INFO:PyCaret optional dependencies:
2023-07-03 22:02:50,682:INFO:                shap: 0.41.0
2023-07-03 22:02:50,683:INFO:           interpret: 0.4.2
2023-07-03 22:02:50,683:INFO:                umap: Not installed
2023-07-03 22:02:50,683:INFO:    pandas_profiling: Not installed
2023-07-03 22:02:50,683:INFO:  explainerdashboard: Not installed
2023-07-03 22:02:50,683:INFO:             autoviz: Not installed
2023-07-03 22:02:50,683:INFO:           fairlearn: Not installed
2023-07-03 22:02:50,683:INFO:             xgboost: Not installed
2023-07-03 22:02:50,683:INFO:            catboost: Not installed
2023-07-03 22:02:50,683:INFO:              kmodes: Not installed
2023-07-03 22:02:50,683:INFO:             mlxtend: Not installed
2023-07-03 22:02:50,683:INFO:       statsforecast: Not installed
2023-07-03 22:02:50,683:INFO:        tune_sklearn: Not installed
2023-07-03 22:02:50,683:INFO:                 ray: Not installed
2023-07-03 22:02:50,683:INFO:            hyperopt: Not installed
2023-07-03 22:02:50,683:INFO:              optuna: Not installed
2023-07-03 22:02:50,683:INFO:               skopt: Not installed
2023-07-03 22:02:50,683:INFO:              mlflow: Not installed
2023-07-03 22:02:50,683:INFO:              gradio: 3.35.2
2023-07-03 22:02:50,683:INFO:             fastapi: 0.99.0
2023-07-03 22:02:50,683:INFO:             uvicorn: 0.22.0
2023-07-03 22:02:50,683:INFO:              m2cgen: Not installed
2023-07-03 22:02:50,683:INFO:           evidently: Not installed
2023-07-03 22:02:50,683:INFO:               fugue: Not installed
2023-07-03 22:02:50,683:INFO:           streamlit: Not installed
2023-07-03 22:02:50,683:INFO:             prophet: Not installed
2023-07-03 22:02:50,684:INFO:None
2023-07-03 22:02:50,684:INFO:Set up data.
2023-07-03 22:02:50,690:INFO:Set up train/test split.
2023-07-03 22:02:50,693:INFO:Set up index.
2023-07-03 22:02:50,693:INFO:Set up folding strategy.
2023-07-03 22:02:50,693:INFO:Assigning column types.
2023-07-03 22:02:50,696:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-07-03 22:02:50,733:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-03 22:02:50,736:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-03 22:02:50,763:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 22:02:50,921:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 22:02:50,958:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-03 22:02:50,958:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-03 22:02:50,980:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 22:02:50,981:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 22:02:50,981:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-07-03 22:02:51,017:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-03 22:02:51,040:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 22:02:51,040:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 22:02:51,078:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-03 22:02:51,100:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 22:02:51,101:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 22:02:51,101:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-07-03 22:02:51,160:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 22:02:51,160:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 22:02:51,219:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 22:02:51,219:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 22:02:51,221:INFO:Preparing preprocessing pipeline...
2023-07-03 22:02:51,222:INFO:Set up label encoding.
2023-07-03 22:02:51,222:INFO:Set up simple imputation.
2023-07-03 22:02:51,224:INFO:Set up encoding of ordinal features.
2023-07-03 22:02:51,225:INFO:Set up encoding of categorical features.
2023-07-03 22:02:51,267:INFO:Finished creating preprocessing pipeline.
2023-07-03 22:02:51,281:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\JHossain\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Total_Bilirubin',
                                             'Direct_Bilirubin',
                                             'Alkaline_Phosphotase',
                                             'Alamine_Aminotransferase',
                                             'Asp...
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('ordinal_encoding',
                 TransformerWrapper(exclude=None, include=['Gender'],
                                    transformer=OrdinalEncoder(cols=['Gender'],
                                                               drop_invariant=False,
                                                               handle_missing='return_nan',
                                                               handle_unknown='value',
                                                               mapping=[{'col': 'Gender',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': Female    0
Male      1
NaN      -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0)))],
         verbose=False)
2023-07-03 22:02:51,281:INFO:Creating final display dataframe.
2023-07-03 22:02:51,402:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target           Outcome
2                   Target type            Binary
3                Target mapping        1: 0, 2: 1
4           Original data shape         (583, 11)
5        Transformed data shape         (583, 11)
6   Transformed train set shape         (408, 11)
7    Transformed test set shape         (175, 11)
8              Ordinal features                 1
9              Numeric features                 9
10         Categorical features                 1
11     Rows with missing values              0.7%
12                   Preprocess              True
13              Imputation type            simple
14           Numeric imputation              mean
15       Categorical imputation              mode
16     Maximum one-hot encoding                25
17              Encoding method              None
18               Fold Generator   StratifiedKFold
19                  Fold Number                10
20                     CPU Jobs                -1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  clf-default-name
24                          USI              6a11
2023-07-03 22:02:51,467:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 22:02:51,468:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 22:02:51,528:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 22:02:51,529:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-03 22:02:51,529:INFO:setup() successfully completed in 2.52s...............
2023-07-03 22:03:50,087:INFO:Initializing compare_models()
2023-07-03 22:03:50,087:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028B2B8DB0D0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000028B2B8DB0D0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-07-03 22:03:50,087:INFO:Checking exceptions
2023-07-03 22:03:50,091:INFO:Preparing display monitor
2023-07-03 22:03:50,113:INFO:Initializing Logistic Regression
2023-07-03 22:03:50,113:INFO:Total runtime is 0.0 minutes
2023-07-03 22:03:50,117:INFO:SubProcess create_model() called ==================================
2023-07-03 22:03:50,117:INFO:Initializing create_model()
2023-07-03 22:03:50,117:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028B2B8DB0D0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028B2A843F10>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 22:03:50,117:INFO:Checking exceptions
2023-07-03 22:03:50,117:INFO:Importing libraries
2023-07-03 22:03:50,117:INFO:Copying training dataset
2023-07-03 22:03:50,121:INFO:Defining folds
2023-07-03 22:03:50,121:INFO:Declaring metric variables
2023-07-03 22:03:50,124:INFO:Importing untrained model
2023-07-03 22:03:50,126:INFO:Logistic Regression Imported successfully
2023-07-03 22:03:50,132:INFO:Starting cross validation
2023-07-03 22:03:50,133:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 22:03:59,992:INFO:Calculating mean and std
2023-07-03 22:03:59,993:INFO:Creating metrics dataframe
2023-07-03 22:04:00,616:INFO:Uploading results into container
2023-07-03 22:04:00,617:INFO:Uploading model into container now
2023-07-03 22:04:00,617:INFO:_master_model_container: 1
2023-07-03 22:04:00,617:INFO:_display_container: 2
2023-07-03 22:04:00,618:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-03 22:04:00,618:INFO:create_model() successfully completed......................................
2023-07-03 22:04:00,807:INFO:SubProcess create_model() end ==================================
2023-07-03 22:04:00,808:INFO:Creating metrics dataframe
2023-07-03 22:04:00,817:INFO:Initializing K Neighbors Classifier
2023-07-03 22:04:00,817:INFO:Total runtime is 0.17840043306350709 minutes
2023-07-03 22:04:00,819:INFO:SubProcess create_model() called ==================================
2023-07-03 22:04:00,820:INFO:Initializing create_model()
2023-07-03 22:04:00,820:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028B2B8DB0D0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028B2A843F10>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 22:04:00,820:INFO:Checking exceptions
2023-07-03 22:04:00,820:INFO:Importing libraries
2023-07-03 22:04:00,820:INFO:Copying training dataset
2023-07-03 22:04:00,823:INFO:Defining folds
2023-07-03 22:04:00,824:INFO:Declaring metric variables
2023-07-03 22:04:00,826:INFO:Importing untrained model
2023-07-03 22:04:00,829:INFO:K Neighbors Classifier Imported successfully
2023-07-03 22:04:00,834:INFO:Starting cross validation
2023-07-03 22:04:00,835:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 22:04:04,869:INFO:Calculating mean and std
2023-07-03 22:04:04,870:INFO:Creating metrics dataframe
2023-07-03 22:04:05,493:INFO:Uploading results into container
2023-07-03 22:04:05,493:INFO:Uploading model into container now
2023-07-03 22:04:05,494:INFO:_master_model_container: 2
2023-07-03 22:04:05,494:INFO:_display_container: 2
2023-07-03 22:04:05,494:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-07-03 22:04:05,494:INFO:create_model() successfully completed......................................
2023-07-03 22:04:05,680:INFO:SubProcess create_model() end ==================================
2023-07-03 22:04:05,681:INFO:Creating metrics dataframe
2023-07-03 22:04:05,689:INFO:Initializing Naive Bayes
2023-07-03 22:04:05,689:INFO:Total runtime is 0.25958433945973713 minutes
2023-07-03 22:04:05,691:INFO:SubProcess create_model() called ==================================
2023-07-03 22:04:05,692:INFO:Initializing create_model()
2023-07-03 22:04:05,692:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028B2B8DB0D0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028B2A843F10>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 22:04:05,692:INFO:Checking exceptions
2023-07-03 22:04:05,692:INFO:Importing libraries
2023-07-03 22:04:05,692:INFO:Copying training dataset
2023-07-03 22:04:05,696:INFO:Defining folds
2023-07-03 22:04:05,696:INFO:Declaring metric variables
2023-07-03 22:04:05,699:INFO:Importing untrained model
2023-07-03 22:04:05,701:INFO:Naive Bayes Imported successfully
2023-07-03 22:04:05,707:INFO:Starting cross validation
2023-07-03 22:04:05,708:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 22:04:09,553:INFO:Calculating mean and std
2023-07-03 22:04:09,554:INFO:Creating metrics dataframe
2023-07-03 22:04:10,166:INFO:Uploading results into container
2023-07-03 22:04:10,167:INFO:Uploading model into container now
2023-07-03 22:04:10,167:INFO:_master_model_container: 3
2023-07-03 22:04:10,167:INFO:_display_container: 2
2023-07-03 22:04:10,168:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-07-03 22:04:10,168:INFO:create_model() successfully completed......................................
2023-07-03 22:04:10,353:INFO:SubProcess create_model() end ==================================
2023-07-03 22:04:10,354:INFO:Creating metrics dataframe
2023-07-03 22:04:10,362:INFO:Initializing Decision Tree Classifier
2023-07-03 22:04:10,362:INFO:Total runtime is 0.33748348156611124 minutes
2023-07-03 22:04:10,365:INFO:SubProcess create_model() called ==================================
2023-07-03 22:04:10,365:INFO:Initializing create_model()
2023-07-03 22:04:10,365:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028B2B8DB0D0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028B2A843F10>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 22:04:10,365:INFO:Checking exceptions
2023-07-03 22:04:10,365:INFO:Importing libraries
2023-07-03 22:04:10,366:INFO:Copying training dataset
2023-07-03 22:04:10,369:INFO:Defining folds
2023-07-03 22:04:10,369:INFO:Declaring metric variables
2023-07-03 22:04:10,372:INFO:Importing untrained model
2023-07-03 22:04:10,375:INFO:Decision Tree Classifier Imported successfully
2023-07-03 22:04:10,380:INFO:Starting cross validation
2023-07-03 22:04:10,381:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 22:04:14,249:INFO:Calculating mean and std
2023-07-03 22:04:14,250:INFO:Creating metrics dataframe
2023-07-03 22:04:14,863:INFO:Uploading results into container
2023-07-03 22:04:14,864:INFO:Uploading model into container now
2023-07-03 22:04:14,865:INFO:_master_model_container: 4
2023-07-03 22:04:14,865:INFO:_display_container: 2
2023-07-03 22:04:14,865:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-07-03 22:04:14,865:INFO:create_model() successfully completed......................................
2023-07-03 22:04:15,051:INFO:SubProcess create_model() end ==================================
2023-07-03 22:04:15,051:INFO:Creating metrics dataframe
2023-07-03 22:04:15,059:INFO:Initializing SVM - Linear Kernel
2023-07-03 22:04:15,059:INFO:Total runtime is 0.41575812498728437 minutes
2023-07-03 22:04:15,062:INFO:SubProcess create_model() called ==================================
2023-07-03 22:04:15,062:INFO:Initializing create_model()
2023-07-03 22:04:15,062:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028B2B8DB0D0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028B2A843F10>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 22:04:15,063:INFO:Checking exceptions
2023-07-03 22:04:15,063:INFO:Importing libraries
2023-07-03 22:04:15,063:INFO:Copying training dataset
2023-07-03 22:04:15,066:INFO:Defining folds
2023-07-03 22:04:15,067:INFO:Declaring metric variables
2023-07-03 22:04:15,069:INFO:Importing untrained model
2023-07-03 22:04:15,072:INFO:SVM - Linear Kernel Imported successfully
2023-07-03 22:04:15,077:INFO:Starting cross validation
2023-07-03 22:04:15,079:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 22:04:15,218:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 22:04:15,221:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 22:04:15,231:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 22:04:15,237:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 22:04:15,243:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 22:04:15,248:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 22:04:15,258:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 22:04:15,259:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 22:04:15,263:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 22:04:15,269:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 22:04:15,275:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 22:04:15,277:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-03 22:04:15,280:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 22:04:15,282:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 22:04:18,912:INFO:Calculating mean and std
2023-07-03 22:04:18,913:INFO:Creating metrics dataframe
2023-07-03 22:04:19,538:INFO:Uploading results into container
2023-07-03 22:04:19,539:INFO:Uploading model into container now
2023-07-03 22:04:19,539:INFO:_master_model_container: 5
2023-07-03 22:04:19,539:INFO:_display_container: 2
2023-07-03 22:04:19,539:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-07-03 22:04:19,540:INFO:create_model() successfully completed......................................
2023-07-03 22:04:19,727:INFO:SubProcess create_model() end ==================================
2023-07-03 22:04:19,727:INFO:Creating metrics dataframe
2023-07-03 22:04:19,737:INFO:Initializing Ridge Classifier
2023-07-03 22:04:19,737:INFO:Total runtime is 0.49372443358103435 minutes
2023-07-03 22:04:19,739:INFO:SubProcess create_model() called ==================================
2023-07-03 22:04:19,740:INFO:Initializing create_model()
2023-07-03 22:04:19,740:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028B2B8DB0D0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028B2A843F10>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 22:04:19,740:INFO:Checking exceptions
2023-07-03 22:04:19,740:INFO:Importing libraries
2023-07-03 22:04:19,740:INFO:Copying training dataset
2023-07-03 22:04:19,744:INFO:Defining folds
2023-07-03 22:04:19,744:INFO:Declaring metric variables
2023-07-03 22:04:19,747:INFO:Importing untrained model
2023-07-03 22:04:19,749:INFO:Ridge Classifier Imported successfully
2023-07-03 22:04:19,754:INFO:Starting cross validation
2023-07-03 22:04:19,755:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 22:04:19,909:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 22:04:19,920:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 22:04:19,924:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 22:04:19,925:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 22:04:19,926:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 22:04:19,937:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 22:04:19,941:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

ns that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 22:04:19,950:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 22:04:19,956:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 22:04:19,971:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 22:04:19,974:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-03 22:04:19,976:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 22:04:19,980:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 22:04:23,643:INFO:Calculating mean and std
2023-07-03 22:04:23,644:INFO:Creating metrics dataframe
2023-07-03 22:04:24,257:INFO:Uploading results into container
2023-07-03 22:04:24,258:INFO:Uploading model into container now
2023-07-03 22:04:24,258:INFO:_master_model_container: 6
2023-07-03 22:04:24,258:INFO:_display_container: 2
2023-07-03 22:04:24,259:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-07-03 22:04:24,259:INFO:create_model() successfully completed......................................
2023-07-03 22:04:24,443:INFO:SubProcess create_model() end ==================================
2023-07-03 22:04:24,443:INFO:Creating metrics dataframe
2023-07-03 22:04:24,452:INFO:Initializing Random Forest Classifier
2023-07-03 22:04:24,452:INFO:Total runtime is 0.5723142266273499 minutes
2023-07-03 22:04:24,454:INFO:SubProcess create_model() called ==================================
2023-07-03 22:04:24,455:INFO:Initializing create_model()
2023-07-03 22:04:24,455:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028B2B8DB0D0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028B2A843F10>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 22:04:24,455:INFO:Checking exceptions
2023-07-03 22:04:24,455:INFO:Importing libraries
2023-07-03 22:04:24,455:INFO:Copying training dataset
2023-07-03 22:04:24,459:INFO:Defining folds
2023-07-03 22:04:24,459:INFO:Declaring metric variables
2023-07-03 22:04:24,462:INFO:Importing untrained model
2023-07-03 22:04:24,465:INFO:Random Forest Classifier Imported successfully
2023-07-03 22:04:24,470:INFO:Starting cross validation
2023-07-03 22:04:24,472:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 22:04:28,964:INFO:Calculating mean and std
2023-07-03 22:04:28,965:INFO:Creating metrics dataframe
2023-07-03 22:04:29,589:INFO:Uploading results into container
2023-07-03 22:04:29,590:INFO:Uploading model into container now
2023-07-03 22:04:29,590:INFO:_master_model_container: 7
2023-07-03 22:04:29,590:INFO:_display_container: 2
2023-07-03 22:04:29,591:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-07-03 22:04:29,591:INFO:create_model() successfully completed......................................
2023-07-03 22:04:29,778:INFO:SubProcess create_model() end ==================================
2023-07-03 22:04:29,778:INFO:Creating metrics dataframe
2023-07-03 22:04:29,788:INFO:Initializing Quadratic Discriminant Analysis
2023-07-03 22:04:29,788:INFO:Total runtime is 0.6612421194712321 minutes
2023-07-03 22:04:29,791:INFO:SubProcess create_model() called ==================================
2023-07-03 22:04:29,792:INFO:Initializing create_model()
2023-07-03 22:04:29,792:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028B2B8DB0D0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028B2A843F10>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 22:04:29,792:INFO:Checking exceptions
2023-07-03 22:04:29,792:INFO:Importing libraries
2023-07-03 22:04:29,792:INFO:Copying training dataset
2023-07-03 22:04:29,796:INFO:Defining folds
2023-07-03 22:04:29,796:INFO:Declaring metric variables
2023-07-03 22:04:29,799:INFO:Importing untrained model
2023-07-03 22:04:29,803:INFO:Quadratic Discriminant Analysis Imported successfully
2023-07-03 22:04:29,810:INFO:Starting cross validation
2023-07-03 22:04:29,811:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 22:04:33,728:INFO:Calculating mean and std
2023-07-03 22:04:33,729:INFO:Creating metrics dataframe
2023-07-03 22:04:34,347:INFO:Uploading results into container
2023-07-03 22:04:34,348:INFO:Uploading model into container now
2023-07-03 22:04:34,348:INFO:_master_model_container: 8
2023-07-03 22:04:34,348:INFO:_display_container: 2
2023-07-03 22:04:34,349:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-07-03 22:04:34,349:INFO:create_model() successfully completed......................................
2023-07-03 22:04:34,538:INFO:SubProcess create_model() end ==================================
2023-07-03 22:04:34,539:INFO:Creating metrics dataframe
2023-07-03 22:04:34,548:INFO:Initializing Ada Boost Classifier
2023-07-03 22:04:34,548:INFO:Total runtime is 0.7405747135480245 minutes
2023-07-03 22:04:34,551:INFO:SubProcess create_model() called ==================================
2023-07-03 22:04:34,551:INFO:Initializing create_model()
2023-07-03 22:04:34,551:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028B2B8DB0D0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028B2A843F10>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 22:04:34,552:INFO:Checking exceptions
2023-07-03 22:04:34,552:INFO:Importing libraries
2023-07-03 22:04:34,552:INFO:Copying training dataset
2023-07-03 22:04:34,555:INFO:Defining folds
2023-07-03 22:04:34,555:INFO:Declaring metric variables
2023-07-03 22:04:34,559:INFO:Importing untrained model
2023-07-03 22:04:34,562:INFO:Ada Boost Classifier Imported successfully
2023-07-03 22:04:34,567:INFO:Starting cross validation
2023-07-03 22:04:34,568:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 22:04:38,690:INFO:Calculating mean and std
2023-07-03 22:04:38,691:INFO:Creating metrics dataframe
2023-07-03 22:04:39,324:INFO:Uploading results into container
2023-07-03 22:04:39,325:INFO:Uploading model into container now
2023-07-03 22:04:39,326:INFO:_master_model_container: 9
2023-07-03 22:04:39,327:INFO:_display_container: 2
2023-07-03 22:04:39,327:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-07-03 22:04:39,327:INFO:create_model() successfully completed......................................
2023-07-03 22:04:39,511:INFO:SubProcess create_model() end ==================================
2023-07-03 22:04:39,511:INFO:Creating metrics dataframe
2023-07-03 22:04:39,522:INFO:Initializing Gradient Boosting Classifier
2023-07-03 22:04:39,522:INFO:Total runtime is 0.8234805782636007 minutes
2023-07-03 22:04:39,525:INFO:SubProcess create_model() called ==================================
2023-07-03 22:04:39,525:INFO:Initializing create_model()
2023-07-03 22:04:39,525:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028B2B8DB0D0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028B2A843F10>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 22:04:39,525:INFO:Checking exceptions
2023-07-03 22:04:39,525:INFO:Importing libraries
2023-07-03 22:04:39,525:INFO:Copying training dataset
2023-07-03 22:04:39,529:INFO:Defining folds
2023-07-03 22:04:39,529:INFO:Declaring metric variables
2023-07-03 22:04:39,532:INFO:Importing untrained model
2023-07-03 22:04:39,535:INFO:Gradient Boosting Classifier Imported successfully
2023-07-03 22:04:39,540:INFO:Starting cross validation
2023-07-03 22:04:39,541:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 22:04:43,845:INFO:Calculating mean and std
2023-07-03 22:04:43,846:INFO:Creating metrics dataframe
2023-07-03 22:04:44,467:INFO:Uploading results into container
2023-07-03 22:04:44,468:INFO:Uploading model into container now
2023-07-03 22:04:44,468:INFO:_master_model_container: 10
2023-07-03 22:04:44,468:INFO:_display_container: 2
2023-07-03 22:04:44,469:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-03 22:04:44,469:INFO:create_model() successfully completed......................................
2023-07-03 22:04:44,656:INFO:SubProcess create_model() end ==================================
2023-07-03 22:04:44,656:INFO:Creating metrics dataframe
2023-07-03 22:04:44,666:INFO:Initializing Linear Discriminant Analysis
2023-07-03 22:04:44,666:INFO:Total runtime is 0.90921364625295 minutes
2023-07-03 22:04:44,669:INFO:SubProcess create_model() called ==================================
2023-07-03 22:04:44,669:INFO:Initializing create_model()
2023-07-03 22:04:44,669:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028B2B8DB0D0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028B2A843F10>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 22:04:44,669:INFO:Checking exceptions
2023-07-03 22:04:44,669:INFO:Importing libraries
2023-07-03 22:04:44,669:INFO:Copying training dataset
2023-07-03 22:04:44,673:INFO:Defining folds
2023-07-03 22:04:44,673:INFO:Declaring metric variables
2023-07-03 22:04:44,676:INFO:Importing untrained model
2023-07-03 22:04:44,678:INFO:Linear Discriminant Analysis Imported successfully
2023-07-03 22:04:44,684:INFO:Starting cross validation
2023-07-03 22:04:44,685:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 22:04:44,921:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 22:04:44,925:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 22:04:48,633:INFO:Calculating mean and std
2023-07-03 22:04:48,635:INFO:Creating metrics dataframe
2023-07-03 22:04:49,264:INFO:Uploading results into container
2023-07-03 22:04:49,265:INFO:Uploading model into container now
2023-07-03 22:04:49,266:INFO:_master_model_container: 11
2023-07-03 22:04:49,266:INFO:_display_container: 2
2023-07-03 22:04:49,266:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-07-03 22:04:49,266:INFO:create_model() successfully completed......................................
2023-07-03 22:04:49,453:INFO:SubProcess create_model() end ==================================
2023-07-03 22:04:49,454:INFO:Creating metrics dataframe
2023-07-03 22:04:49,464:INFO:Initializing Extra Trees Classifier
2023-07-03 22:04:49,465:INFO:Total runtime is 0.9891919573148091 minutes
2023-07-03 22:04:49,467:INFO:SubProcess create_model() called ==================================
2023-07-03 22:04:49,468:INFO:Initializing create_model()
2023-07-03 22:04:49,468:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028B2B8DB0D0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028B2A843F10>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 22:04:49,468:INFO:Checking exceptions
2023-07-03 22:04:49,468:INFO:Importing libraries
2023-07-03 22:04:49,468:INFO:Copying training dataset
2023-07-03 22:04:49,471:INFO:Defining folds
2023-07-03 22:04:49,472:INFO:Declaring metric variables
2023-07-03 22:04:49,474:INFO:Importing untrained model
2023-07-03 22:04:49,477:INFO:Extra Trees Classifier Imported successfully
2023-07-03 22:04:49,483:INFO:Starting cross validation
2023-07-03 22:04:49,484:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 22:04:54,022:INFO:Calculating mean and std
2023-07-03 22:04:54,023:INFO:Creating metrics dataframe
2023-07-03 22:04:54,655:INFO:Uploading results into container
2023-07-03 22:04:54,656:INFO:Uploading model into container now
2023-07-03 22:04:54,657:INFO:_master_model_container: 12
2023-07-03 22:04:54,657:INFO:_display_container: 2
2023-07-03 22:04:54,657:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-07-03 22:04:54,657:INFO:create_model() successfully completed......................................
2023-07-03 22:04:54,846:INFO:SubProcess create_model() end ==================================
2023-07-03 22:04:54,846:INFO:Creating metrics dataframe
2023-07-03 22:04:54,856:INFO:Initializing Light Gradient Boosting Machine
2023-07-03 22:04:54,856:INFO:Total runtime is 1.0790357947349547 minutes
2023-07-03 22:04:54,859:INFO:SubProcess create_model() called ==================================
2023-07-03 22:04:54,859:INFO:Initializing create_model()
2023-07-03 22:04:54,860:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028B2B8DB0D0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028B2A843F10>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 22:04:54,860:INFO:Checking exceptions
2023-07-03 22:04:54,860:INFO:Importing libraries
2023-07-03 22:04:54,860:INFO:Copying training dataset
2023-07-03 22:04:54,863:INFO:Defining folds
2023-07-03 22:04:54,863:INFO:Declaring metric variables
2023-07-03 22:04:54,866:INFO:Importing untrained model
2023-07-03 22:04:54,869:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-03 22:04:54,874:INFO:Starting cross validation
2023-07-03 22:04:54,875:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 22:04:59,906:INFO:Calculating mean and std
2023-07-03 22:04:59,907:INFO:Creating metrics dataframe
2023-07-03 22:05:00,543:INFO:Uploading results into container
2023-07-03 22:05:00,544:INFO:Uploading model into container now
2023-07-03 22:05:00,544:INFO:_master_model_container: 13
2023-07-03 22:05:00,544:INFO:_display_container: 2
2023-07-03 22:05:00,545:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-07-03 22:05:00,545:INFO:create_model() successfully completed......................................
2023-07-03 22:05:00,736:INFO:SubProcess create_model() end ==================================
2023-07-03 22:05:00,736:INFO:Creating metrics dataframe
2023-07-03 22:05:00,748:INFO:Initializing Dummy Classifier
2023-07-03 22:05:00,748:INFO:Total runtime is 1.1772470792134602 minutes
2023-07-03 22:05:00,751:INFO:SubProcess create_model() called ==================================
2023-07-03 22:05:00,751:INFO:Initializing create_model()
2023-07-03 22:05:00,751:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028B2B8DB0D0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028B2A843F10>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 22:05:00,751:INFO:Checking exceptions
2023-07-03 22:05:00,752:INFO:Importing libraries
2023-07-03 22:05:00,752:INFO:Copying training dataset
2023-07-03 22:05:00,755:INFO:Defining folds
2023-07-03 22:05:00,755:INFO:Declaring metric variables
2023-07-03 22:05:00,758:INFO:Importing untrained model
2023-07-03 22:05:00,761:INFO:Dummy Classifier Imported successfully
2023-07-03 22:05:00,766:INFO:Starting cross validation
2023-07-03 22:05:00,767:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 22:05:00,935:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 22:05:00,940:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 22:05:00,962:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 22:05:00,963:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 22:05:00,966:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 22:05:00,980:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 22:05:00,986:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 22:05:00,988:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 22:05:00,993:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 22:05:01,012:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-03 22:05:04,765:INFO:Calculating mean and std
2023-07-03 22:05:04,767:INFO:Creating metrics dataframe
2023-07-03 22:05:05,411:INFO:Uploading results into container
2023-07-03 22:05:05,412:INFO:Uploading model into container now
2023-07-03 22:05:05,412:INFO:_master_model_container: 14
2023-07-03 22:05:05,412:INFO:_display_container: 2
2023-07-03 22:05:05,412:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-07-03 22:05:05,413:INFO:create_model() successfully completed......................................
2023-07-03 22:05:05,601:INFO:SubProcess create_model() end ==================================
2023-07-03 22:05:05,601:INFO:Creating metrics dataframe
2023-07-03 22:05:05,620:INFO:Initializing create_model()
2023-07-03 22:05:05,620:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028B2B8DB0D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-03 22:05:05,620:INFO:Checking exceptions
2023-07-03 22:05:05,622:INFO:Importing libraries
2023-07-03 22:05:05,622:INFO:Copying training dataset
2023-07-03 22:05:05,625:INFO:Defining folds
2023-07-03 22:05:05,625:INFO:Declaring metric variables
2023-07-03 22:05:05,625:INFO:Importing untrained model
2023-07-03 22:05:05,625:INFO:Declaring custom model
2023-07-03 22:05:05,625:INFO:Logistic Regression Imported successfully
2023-07-03 22:05:05,626:INFO:Cross validation set to False
2023-07-03 22:05:05,626:INFO:Fitting Model
2023-07-03 22:05:06,131:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-03 22:05:06,131:INFO:create_model() successfully completed......................................
2023-07-03 22:05:06,346:INFO:_master_model_container: 14
2023-07-03 22:05:06,346:INFO:_display_container: 2
2023-07-03 22:05:06,346:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-03 22:05:06,346:INFO:compare_models() successfully completed......................................
2023-07-03 22:06:41,497:INFO:Initializing create_model()
2023-07-03 22:06:41,497:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028B2B8DB0D0>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-03 22:06:41,497:INFO:Checking exceptions
2023-07-03 22:06:41,510:INFO:Importing libraries
2023-07-03 22:06:41,510:INFO:Copying training dataset
2023-07-03 22:06:41,514:INFO:Defining folds
2023-07-03 22:06:41,514:INFO:Declaring metric variables
2023-07-03 22:06:41,516:INFO:Importing untrained model
2023-07-03 22:06:41,519:INFO:Logistic Regression Imported successfully
2023-07-03 22:06:41,525:INFO:Starting cross validation
2023-07-03 22:06:41,526:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 22:06:45,508:INFO:Calculating mean and std
2023-07-03 22:06:45,510:INFO:Creating metrics dataframe
2023-07-03 22:06:45,514:INFO:Finalizing model
2023-07-03 22:06:46,254:INFO:Uploading results into container
2023-07-03 22:06:46,255:INFO:Uploading model into container now
2023-07-03 22:06:46,264:INFO:_master_model_container: 15
2023-07-03 22:06:46,264:INFO:_display_container: 3
2023-07-03 22:06:46,264:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-03 22:06:46,264:INFO:create_model() successfully completed......................................
2023-07-03 22:07:52,121:INFO:Initializing tune_model()
2023-07-03 22:07:52,121:INFO:tune_model(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028B2B8DB0D0>)
2023-07-03 22:07:52,121:INFO:Checking exceptions
2023-07-03 22:07:52,135:INFO:Copying training dataset
2023-07-03 22:07:52,138:INFO:Checking base model
2023-07-03 22:07:52,138:INFO:Base model : Logistic Regression
2023-07-03 22:07:52,141:INFO:Declaring metric variables
2023-07-03 22:07:52,144:INFO:Defining Hyperparameters
2023-07-03 22:07:52,329:INFO:Tuning with n_jobs=-1
2023-07-03 22:07:52,329:INFO:Initializing RandomizedSearchCV
2023-07-03 22:08:03,144:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-07-03 22:08:11,009:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-07-03 22:08:21,334:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-07-03 22:08:33,952:INFO:best_params: {'actual_estimator__class_weight': {}, 'actual_estimator__C': 0.056}
2023-07-03 22:08:33,953:INFO:Hyperparameter search completed
2023-07-03 22:08:33,954:INFO:SubProcess create_model() called ==================================
2023-07-03 22:08:33,954:INFO:Initializing create_model()
2023-07-03 22:08:33,954:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028B2B8DB0D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028B315000D0>, model_only=True, return_train_score=False, kwargs={'class_weight': {}, 'C': 0.056})
2023-07-03 22:08:33,954:INFO:Checking exceptions
2023-07-03 22:08:33,954:INFO:Importing libraries
2023-07-03 22:08:33,954:INFO:Copying training dataset
2023-07-03 22:08:33,958:INFO:Defining folds
2023-07-03 22:08:33,958:INFO:Declaring metric variables
2023-07-03 22:08:33,961:INFO:Importing untrained model
2023-07-03 22:08:33,961:INFO:Declaring custom model
2023-07-03 22:08:33,965:INFO:Logistic Regression Imported successfully
2023-07-03 22:08:33,971:INFO:Starting cross validation
2023-07-03 22:08:33,972:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 22:08:38,041:INFO:Calculating mean and std
2023-07-03 22:08:38,043:INFO:Creating metrics dataframe
2023-07-03 22:08:38,048:INFO:Finalizing model
2023-07-03 22:08:38,748:INFO:Uploading results into container
2023-07-03 22:08:38,749:INFO:Uploading model into container now
2023-07-03 22:08:38,750:INFO:_master_model_container: 16
2023-07-03 22:08:38,750:INFO:_display_container: 4
2023-07-03 22:08:38,750:INFO:LogisticRegression(C=0.056, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-03 22:08:38,750:INFO:create_model() successfully completed......................................
2023-07-03 22:08:38,937:INFO:SubProcess create_model() end ==================================
2023-07-03 22:08:38,938:INFO:choose_better activated
2023-07-03 22:08:38,941:INFO:SubProcess create_model() called ==================================
2023-07-03 22:08:38,941:INFO:Initializing create_model()
2023-07-03 22:08:38,942:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028B2B8DB0D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-03 22:08:38,942:INFO:Checking exceptions
2023-07-03 22:08:38,943:INFO:Importing libraries
2023-07-03 22:08:38,943:INFO:Copying training dataset
2023-07-03 22:08:38,946:INFO:Defining folds
2023-07-03 22:08:38,946:INFO:Declaring metric variables
2023-07-03 22:08:38,946:INFO:Importing untrained model
2023-07-03 22:08:38,946:INFO:Declaring custom model
2023-07-03 22:08:38,947:INFO:Logistic Regression Imported successfully
2023-07-03 22:08:38,947:INFO:Starting cross validation
2023-07-03 22:08:38,948:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 22:08:42,893:INFO:Calculating mean and std
2023-07-03 22:08:42,893:INFO:Creating metrics dataframe
2023-07-03 22:08:42,895:INFO:Finalizing model
2023-07-03 22:08:43,634:INFO:Uploading results into container
2023-07-03 22:08:43,635:INFO:Uploading model into container now
2023-07-03 22:08:43,635:INFO:_master_model_container: 17
2023-07-03 22:08:43,635:INFO:_display_container: 5
2023-07-03 22:08:43,635:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-03 22:08:43,635:INFO:create_model() successfully completed......................................
2023-07-03 22:08:43,821:INFO:SubProcess create_model() end ==================================
2023-07-03 22:08:43,821:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Accuracy is 0.7133
2023-07-03 22:08:43,822:INFO:LogisticRegression(C=0.056, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Accuracy is 0.7206
2023-07-03 22:08:43,822:INFO:LogisticRegression(C=0.056, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2023-07-03 22:08:43,822:INFO:choose_better completed
2023-07-03 22:08:43,829:INFO:_master_model_container: 17
2023-07-03 22:08:43,830:INFO:_display_container: 4
2023-07-03 22:08:43,830:INFO:LogisticRegression(C=0.056, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-03 22:08:43,830:INFO:tune_model() successfully completed......................................
2023-07-03 22:09:02,259:INFO:Initializing tune_model()
2023-07-03 22:09:02,259:INFO:tune_model(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=True, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028B2B8DB0D0>)
2023-07-03 22:09:02,259:INFO:Checking exceptions
2023-07-03 22:09:02,274:INFO:Copying training dataset
2023-07-03 22:09:02,277:INFO:Checking base model
2023-07-03 22:09:02,277:INFO:Base model : Logistic Regression
2023-07-03 22:09:02,281:INFO:Declaring metric variables
2023-07-03 22:09:02,284:INFO:Defining Hyperparameters
2023-07-03 22:09:02,469:INFO:Tuning with n_jobs=-1
2023-07-03 22:09:02,470:INFO:Initializing RandomizedSearchCV
2023-07-03 22:09:22,546:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-07-03 22:09:27,907:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-07-03 22:09:33,201:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-07-03 22:09:45,153:INFO:best_params: {'actual_estimator__class_weight': {}, 'actual_estimator__C': 0.056}
2023-07-03 22:09:45,154:INFO:Hyperparameter search completed
2023-07-03 22:09:45,154:INFO:SubProcess create_model() called ==================================
2023-07-03 22:09:45,155:INFO:Initializing create_model()
2023-07-03 22:09:45,155:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028B2B8DB0D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028B27C57AF0>, model_only=True, return_train_score=False, kwargs={'class_weight': {}, 'C': 0.056})
2023-07-03 22:09:45,155:INFO:Checking exceptions
2023-07-03 22:09:45,155:INFO:Importing libraries
2023-07-03 22:09:45,155:INFO:Copying training dataset
2023-07-03 22:09:45,159:INFO:Defining folds
2023-07-03 22:09:45,159:INFO:Declaring metric variables
2023-07-03 22:09:45,161:INFO:Importing untrained model
2023-07-03 22:09:45,161:INFO:Declaring custom model
2023-07-03 22:09:45,164:INFO:Logistic Regression Imported successfully
2023-07-03 22:09:45,169:INFO:Starting cross validation
2023-07-03 22:09:45,170:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 22:09:49,220:INFO:Calculating mean and std
2023-07-03 22:09:49,221:INFO:Creating metrics dataframe
2023-07-03 22:09:49,226:INFO:Finalizing model
2023-07-03 22:09:49,926:INFO:Uploading results into container
2023-07-03 22:09:49,927:INFO:Uploading model into container now
2023-07-03 22:09:49,927:INFO:_master_model_container: 18
2023-07-03 22:09:49,927:INFO:_display_container: 5
2023-07-03 22:09:49,927:INFO:LogisticRegression(C=0.056, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-03 22:09:49,928:INFO:create_model() successfully completed......................................
2023-07-03 22:09:50,115:INFO:SubProcess create_model() end ==================================
2023-07-03 22:09:50,115:INFO:choose_better activated
2023-07-03 22:09:50,118:INFO:SubProcess create_model() called ==================================
2023-07-03 22:09:50,119:INFO:Initializing create_model()
2023-07-03 22:09:50,119:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028B2B8DB0D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-03 22:09:50,119:INFO:Checking exceptions
2023-07-03 22:09:50,120:INFO:Importing libraries
2023-07-03 22:09:50,121:INFO:Copying training dataset
2023-07-03 22:09:50,123:INFO:Defining folds
2023-07-03 22:09:50,124:INFO:Declaring metric variables
2023-07-03 22:09:50,124:INFO:Importing untrained model
2023-07-03 22:09:50,124:INFO:Declaring custom model
2023-07-03 22:09:50,124:INFO:Logistic Regression Imported successfully
2023-07-03 22:09:50,124:INFO:Starting cross validation
2023-07-03 22:09:50,125:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 22:09:54,246:INFO:Calculating mean and std
2023-07-03 22:09:54,246:INFO:Creating metrics dataframe
2023-07-03 22:09:54,249:INFO:Finalizing model
2023-07-03 22:09:55,000:INFO:Uploading results into container
2023-07-03 22:09:55,001:INFO:Uploading model into container now
2023-07-03 22:09:55,001:INFO:_master_model_container: 19
2023-07-03 22:09:55,001:INFO:_display_container: 6
2023-07-03 22:09:55,002:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-03 22:09:55,002:INFO:create_model() successfully completed......................................
2023-07-03 22:09:55,186:INFO:SubProcess create_model() end ==================================
2023-07-03 22:09:55,186:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Accuracy is 0.7133
2023-07-03 22:09:55,187:INFO:LogisticRegression(C=0.056, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Accuracy is 0.7206
2023-07-03 22:09:55,187:INFO:LogisticRegression(C=0.056, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2023-07-03 22:09:55,187:INFO:choose_better completed
2023-07-03 22:09:55,195:INFO:_master_model_container: 19
2023-07-03 22:09:55,195:INFO:_display_container: 5
2023-07-03 22:09:55,195:INFO:LogisticRegression(C=0.056, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-03 22:09:55,195:INFO:tune_model() successfully completed......................................
2023-07-03 22:13:46,287:INFO:Initializing plot_model()
2023-07-03 22:13:46,287:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028B2B8DB0D0>, system=True)
2023-07-03 22:13:46,287:INFO:Checking exceptions
2023-07-03 22:13:46,290:INFO:Preloading libraries
2023-07-03 22:13:46,291:INFO:Copying training dataset
2023-07-03 22:13:46,291:INFO:Plot type: confusion_matrix
2023-07-03 22:13:46,416:INFO:Fitting Model
2023-07-03 22:13:46,417:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\base.py:420: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2023-07-03 22:13:46,417:INFO:Scoring test/hold-out set
2023-07-03 22:13:46,512:INFO:Visual Rendered Successfully
2023-07-03 22:13:46,699:INFO:plot_model() successfully completed......................................
2023-07-03 22:13:57,518:INFO:Initializing plot_model()
2023-07-03 22:13:57,518:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028B2B8DB0D0>, system=True)
2023-07-03 22:13:57,519:INFO:Checking exceptions
2023-07-03 22:13:57,522:INFO:Preloading libraries
2023-07-03 22:13:57,522:INFO:Copying training dataset
2023-07-03 22:13:57,522:INFO:Plot type: auc
2023-07-03 22:13:57,645:INFO:Fitting Model
2023-07-03 22:13:57,646:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\base.py:420: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2023-07-03 22:13:57,646:INFO:Scoring test/hold-out set
2023-07-03 22:13:57,805:INFO:Visual Rendered Successfully
2023-07-03 22:13:57,992:INFO:plot_model() successfully completed......................................
2023-07-03 22:14:01,981:INFO:Initializing plot_model()
2023-07-03 22:14:01,981:INFO:plot_model(plot=class_report, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028B2B8DB0D0>, system=True)
2023-07-03 22:14:01,981:INFO:Checking exceptions
2023-07-03 22:14:01,984:INFO:Preloading libraries
2023-07-03 22:14:01,984:INFO:Copying training dataset
2023-07-03 22:14:01,984:INFO:Plot type: class_report
2023-07-03 22:14:02,108:INFO:Fitting Model
2023-07-03 22:14:02,109:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\base.py:420: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2023-07-03 22:14:02,109:INFO:Scoring test/hold-out set
2023-07-03 22:14:02,272:INFO:Visual Rendered Successfully
2023-07-03 22:14:02,455:INFO:plot_model() successfully completed......................................
2023-07-03 22:14:09,343:INFO:Initializing plot_model()
2023-07-03 22:14:09,343:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028B2B8DB0D0>, system=True)
2023-07-03 22:14:09,343:INFO:Checking exceptions
2023-07-03 22:14:09,347:INFO:Preloading libraries
2023-07-03 22:14:09,347:INFO:Copying training dataset
2023-07-03 22:14:09,348:INFO:Plot type: feature
2023-07-03 22:14:09,541:INFO:Visual Rendered Successfully
2023-07-03 22:14:09,724:INFO:plot_model() successfully completed......................................
2023-07-03 22:14:15,222:INFO:Initializing evaluate_model()
2023-07-03 22:14:15,222:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028B2B8DB0D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-07-03 22:14:15,233:INFO:Initializing plot_model()
2023-07-03 22:14:15,233:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028B2B8DB0D0>, system=True)
2023-07-03 22:14:15,233:INFO:Checking exceptions
2023-07-03 22:14:15,235:INFO:Preloading libraries
2023-07-03 22:14:15,235:INFO:Copying training dataset
2023-07-03 22:14:15,235:INFO:Plot type: pipeline
2023-07-03 22:14:15,363:INFO:Visual Rendered Successfully
2023-07-03 22:14:15,554:INFO:plot_model() successfully completed......................................
2023-07-03 22:14:18,249:INFO:Initializing finalize_model()
2023-07-03 22:14:18,249:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028B2B8DB0D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-07-03 22:14:18,249:INFO:Finalizing LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-03 22:14:18,252:INFO:Initializing create_model()
2023-07-03 22:14:18,252:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028B2B8DB0D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-07-03 22:14:18,252:INFO:Checking exceptions
2023-07-03 22:14:18,254:INFO:Importing libraries
2023-07-03 22:14:18,254:INFO:Copying training dataset
2023-07-03 22:14:18,255:INFO:Defining folds
2023-07-03 22:14:18,255:INFO:Declaring metric variables
2023-07-03 22:14:18,255:INFO:Importing untrained model
2023-07-03 22:14:18,255:INFO:Declaring custom model
2023-07-03 22:14:18,255:INFO:Logistic Regression Imported successfully
2023-07-03 22:14:18,256:INFO:Cross validation set to False
2023-07-03 22:14:18,256:INFO:Fitting Model
2023-07-03 22:14:18,356:INFO:Pipeline(memory=FastMemory(location=C:\Users\JHossain\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Total_Bilirubin',
                                             'Direct_Bilirubin',
                                             'Alkaline_Phosphotase',
                                             'Alamine_Aminotransferase',
                                             'Asp...
                                                                         'data_type': dtype('O'),
                                                                         'mapping': Female    0
Male      1
NaN      -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=123,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2023-07-03 22:14:18,357:INFO:create_model() successfully completed......................................
2023-07-03 22:14:18,546:INFO:_master_model_container: 19
2023-07-03 22:14:18,546:INFO:_display_container: 5
2023-07-03 22:14:18,559:INFO:Pipeline(memory=FastMemory(location=C:\Users\JHossain\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Total_Bilirubin',
                                             'Direct_Bilirubin',
                                             'Alkaline_Phosphotase',
                                             'Alamine_Aminotransferase',
                                             'Asp...
                                                                         'data_type': dtype('O'),
                                                                         'mapping': Female    0
Male      1
NaN      -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=123,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2023-07-03 22:14:18,560:INFO:finalize_model() successfully completed......................................
2023-07-03 22:14:21,227:INFO:Initializing predict_model()
2023-07-03 22:14:21,227:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028B2B8DB0D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000028B319CE5F0>)
2023-07-03 22:14:21,227:INFO:Checking exceptions
2023-07-03 22:14:21,228:INFO:Preloading libraries
2023-07-03 22:14:39,297:INFO:Initializing predict_model()
2023-07-03 22:14:39,298:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028B2B8DB0D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000028B319CE3B0>)
2023-07-03 22:14:39,298:INFO:Checking exceptions
2023-07-03 22:14:39,298:INFO:Preloading libraries
2023-07-03 22:14:39,300:INFO:Set up data.
2023-07-03 22:14:39,304:INFO:Set up index.
2023-07-03 22:15:02,211:INFO:Initializing save_model()
2023-07-03 22:15:02,212:INFO:save_model(model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), model_name=../models/liver_disorder, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JHossain\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Total_Bilirubin',
                                             'Direct_Bilirubin',
                                             'Alkaline_Phosphotase',
                                             'Alamine_Aminotransferase',
                                             'Asp...
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('ordinal_encoding',
                 TransformerWrapper(exclude=None, include=['Gender'],
                                    transformer=OrdinalEncoder(cols=['Gender'],
                                                               drop_invariant=False,
                                                               handle_missing='return_nan',
                                                               handle_unknown='value',
                                                               mapping=[{'col': 'Gender',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': Female    0
Male      1
NaN      -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-07-03 22:15:02,212:INFO:Adding model into prep_pipe
2023-07-03 22:15:02,216:INFO:../models/liver_disorder.pkl saved in current working directory
2023-07-03 22:15:02,230:INFO:Pipeline(memory=FastMemory(location=C:\Users\JHossain\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Total_Bilirubin',
                                             'Direct_Bilirubin',
                                             'Alkaline_Phosphotase',
                                             'Alamine_Aminotransferase',
                                             'Asp...
                                                                         'data_type': dtype('O'),
                                                                         'mapping': Female    0
Male      1
NaN      -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('trained_model',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=123,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2023-07-03 22:15:02,230:INFO:save_model() successfully completed......................................
2023-07-03 22:15:04,593:INFO:Initializing load_model()
2023-07-03 22:15:04,593:INFO:load_model(model_name=../models/liver_disorder, platform=None, authentication=None, verbose=True)
2023-07-04 05:35:30,784:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-04 05:35:30,799:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-04 05:35:30,799:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-04 05:35:30,799:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-04 05:35:32,011:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-07-04 05:35:33,207:INFO:PyCaret ClassificationExperiment
2023-07-04 05:35:33,207:INFO:Logging name: clf-default-name
2023-07-04 05:35:33,207:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-07-04 05:35:33,207:INFO:version 3.0.2
2023-07-04 05:35:33,207:INFO:Initializing setup()
2023-07-04 05:35:33,207:INFO:self.USI: 7dba
2023-07-04 05:35:33,207:INFO:self._variable_keys: {'USI', 'n_jobs_param', 'X_test', 'fix_imbalance', 'log_plots_param', '_available_plots', 'gpu_n_jobs_param', 'fold_shuffle_param', 'idx', 'fold_generator', 'exp_id', 'X', 'y', 'fold_groups_param', 'seed', 'target_param', 'y_train', '_ml_usecase', 'memory', 'logging_param', 'gpu_param', 'is_multiclass', 'y_test', 'pipeline', 'X_train', 'data', 'exp_name_log', 'html_param'}
2023-07-04 05:35:33,207:INFO:Checking environment
2023-07-04 05:35:33,207:INFO:python_version: 3.10.9
2023-07-04 05:35:33,207:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2023-07-04 05:35:33,207:INFO:machine: AMD64
2023-07-04 05:35:33,207:INFO:platform: Windows-10-10.0.22621-SP0
2023-07-04 05:35:33,211:INFO:Memory: svmem(total=33664483328, available=24531324928, percent=27.1, used=9133158400, free=24531324928)
2023-07-04 05:35:33,211:INFO:Physical Core: 6
2023-07-04 05:35:33,211:INFO:Logical Core: 12
2023-07-04 05:35:33,211:INFO:Checking libraries
2023-07-04 05:35:33,211:INFO:System:
2023-07-04 05:35:33,211:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2023-07-04 05:35:33,211:INFO:executable: C:\Users\JHossain\anaconda3\python.exe
2023-07-04 05:35:33,211:INFO:   machine: Windows-10-10.0.22621-SP0
2023-07-04 05:35:33,211:INFO:PyCaret required dependencies:
2023-07-04 05:35:33,211:INFO:                 pip: 22.3.1
2023-07-04 05:35:33,211:INFO:          setuptools: 65.6.3
2023-07-04 05:35:33,211:INFO:             pycaret: 3.0.2
2023-07-04 05:35:33,211:INFO:             IPython: 8.10.0
2023-07-04 05:35:33,211:INFO:          ipywidgets: 7.6.5
2023-07-04 05:35:33,211:INFO:                tqdm: 4.64.1
2023-07-04 05:35:33,211:INFO:               numpy: 1.23.5
2023-07-04 05:35:33,211:INFO:              pandas: 1.5.3
2023-07-04 05:35:33,211:INFO:              jinja2: 3.1.2
2023-07-04 05:35:33,211:INFO:               scipy: 1.10.0
2023-07-04 05:35:33,212:INFO:              joblib: 1.2.0
2023-07-04 05:35:33,212:INFO:             sklearn: 1.2.1
2023-07-04 05:35:33,212:INFO:                pyod: 1.0.9
2023-07-04 05:35:33,212:INFO:            imblearn: 0.10.1
2023-07-04 05:35:33,212:INFO:   category_encoders: 2.6.1
2023-07-04 05:35:33,212:INFO:            lightgbm: 3.3.5
2023-07-04 05:35:33,212:INFO:               numba: 0.56.4
2023-07-04 05:35:33,212:INFO:            requests: 2.28.1
2023-07-04 05:35:33,212:INFO:          matplotlib: 3.7.0
2023-07-04 05:35:33,212:INFO:          scikitplot: 0.3.7
2023-07-04 05:35:33,212:INFO:         yellowbrick: 1.5
2023-07-04 05:35:33,212:INFO:              plotly: 5.9.0
2023-07-04 05:35:33,212:INFO:             kaleido: 0.2.1
2023-07-04 05:35:33,212:INFO:         statsmodels: 0.13.5
2023-07-04 05:35:33,212:INFO:              sktime: 0.17.0
2023-07-04 05:35:33,212:INFO:               tbats: 1.1.3
2023-07-04 05:35:33,212:INFO:            pmdarima: 2.0.3
2023-07-04 05:35:33,212:INFO:              psutil: 5.9.0
2023-07-04 05:35:33,212:INFO:PyCaret optional dependencies:
2023-07-04 05:35:34,395:INFO:                shap: 0.41.0
2023-07-04 05:35:34,395:INFO:           interpret: 0.4.2
2023-07-04 05:35:34,395:INFO:                umap: Not installed
2023-07-04 05:35:34,395:INFO:    pandas_profiling: Not installed
2023-07-04 05:35:34,395:INFO:  explainerdashboard: Not installed
2023-07-04 05:35:34,395:INFO:             autoviz: Not installed
2023-07-04 05:35:34,395:INFO:           fairlearn: Not installed
2023-07-04 05:35:34,395:INFO:             xgboost: Not installed
2023-07-04 05:35:34,395:INFO:            catboost: Not installed
2023-07-04 05:35:34,396:INFO:              kmodes: Not installed
2023-07-04 05:35:34,396:INFO:             mlxtend: Not installed
2023-07-04 05:35:34,396:INFO:       statsforecast: Not installed
2023-07-04 05:35:34,396:INFO:        tune_sklearn: Not installed
2023-07-04 05:35:34,396:INFO:                 ray: Not installed
2023-07-04 05:35:34,396:INFO:            hyperopt: Not installed
2023-07-04 05:35:34,396:INFO:              optuna: Not installed
2023-07-04 05:35:34,396:INFO:               skopt: Not installed
2023-07-04 05:35:34,396:INFO:              mlflow: Not installed
2023-07-04 05:35:34,396:INFO:              gradio: 3.35.2
2023-07-04 05:35:34,396:INFO:             fastapi: 0.99.0
2023-07-04 05:35:34,396:INFO:             uvicorn: 0.22.0
2023-07-04 05:35:34,396:INFO:              m2cgen: Not installed
2023-07-04 05:35:34,396:INFO:           evidently: Not installed
2023-07-04 05:35:34,396:INFO:               fugue: Not installed
2023-07-04 05:35:34,396:INFO:           streamlit: Not installed
2023-07-04 05:35:34,396:INFO:             prophet: Not installed
2023-07-04 05:35:34,396:INFO:None
2023-07-04 05:35:34,396:INFO:Set up data.
2023-07-04 05:35:34,402:INFO:Set up train/test split.
2023-07-04 05:35:34,407:INFO:Set up index.
2023-07-04 05:35:34,407:INFO:Set up folding strategy.
2023-07-04 05:35:34,407:INFO:Assigning column types.
2023-07-04 05:35:34,410:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-07-04 05:35:34,446:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-04 05:35:34,449:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-04 05:35:34,479:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-04 05:35:34,684:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-04 05:35:34,720:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-04 05:35:34,721:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-04 05:35:34,743:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-04 05:35:34,743:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-04 05:35:34,743:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-07-04 05:35:34,781:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-04 05:35:34,805:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-04 05:35:34,805:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-04 05:35:34,841:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-04 05:35:34,863:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-04 05:35:34,863:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-04 05:35:34,864:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-07-04 05:35:34,922:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-04 05:35:34,923:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-04 05:35:34,982:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-04 05:35:34,982:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-04 05:35:34,985:INFO:Preparing preprocessing pipeline...
2023-07-04 05:35:34,986:INFO:Set up simple imputation.
2023-07-04 05:35:34,988:INFO:Set up encoding of ordinal features.
2023-07-04 05:35:34,989:INFO:Set up encoding of categorical features.
2023-07-04 05:35:35,029:INFO:Finished creating preprocessing pipeline.
2023-07-04 05:35:35,047:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\JHossain\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'cp', 'trestbps', 'chol',
                                             'fbs', 'restecg', 'thalach',
                                             'exang', 'oldpeak', 'slope', 'ca',
                                             'thal'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_...
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('ordinal_encoding',
                 TransformerWrapper(exclude=None, include=['sex'],
                                    transformer=OrdinalEncoder(cols=['sex'],
                                                               drop_invariant=False,
                                                               handle_missing='return_nan',
                                                               handle_unknown='value',
                                                               mapping=[{'col': 'sex',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0)))],
         verbose=False)
2023-07-04 05:35:35,047:INFO:Creating final display dataframe.
2023-07-04 05:35:35,155:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            target
2                   Target type            Binary
3           Original data shape         (303, 14)
4        Transformed data shape         (303, 14)
5   Transformed train set shape         (212, 14)
6    Transformed test set shape          (91, 14)
7              Ordinal features                 1
8              Numeric features                12
9          Categorical features                 1
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              7dba
2023-07-04 05:35:35,220:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-04 05:35:35,220:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-04 05:35:35,281:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-04 05:35:35,281:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-04 05:35:35,282:INFO:setup() successfully completed in 3.08s...............
2023-07-04 05:35:41,705:INFO:Initializing compare_models()
2023-07-04 05:35:41,705:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019867DEA140>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000019867DEA140>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-07-04 05:35:41,705:INFO:Checking exceptions
2023-07-04 05:35:41,709:INFO:Preparing display monitor
2023-07-04 05:35:41,727:INFO:Initializing Logistic Regression
2023-07-04 05:35:41,727:INFO:Total runtime is 0.0 minutes
2023-07-04 05:35:41,731:INFO:SubProcess create_model() called ==================================
2023-07-04 05:35:41,731:INFO:Initializing create_model()
2023-07-04 05:35:41,731:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019867DEA140>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000198663991B0>, model_only=True, return_train_score=False, kwargs={})
2023-07-04 05:35:41,731:INFO:Checking exceptions
2023-07-04 05:35:41,732:INFO:Importing libraries
2023-07-04 05:35:41,732:INFO:Copying training dataset
2023-07-04 05:35:41,737:INFO:Defining folds
2023-07-04 05:35:41,737:INFO:Declaring metric variables
2023-07-04 05:35:41,741:INFO:Importing untrained model
2023-07-04 05:35:41,744:INFO:Logistic Regression Imported successfully
2023-07-04 05:35:41,750:INFO:Starting cross validation
2023-07-04 05:35:41,751:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-04 05:35:46,926:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-07-04 05:35:50,622:INFO:Calculating mean and std
2023-07-04 05:35:50,623:INFO:Creating metrics dataframe
2023-07-04 05:35:51,226:INFO:Uploading results into container
2023-07-04 05:35:51,226:INFO:Uploading model into container now
2023-07-04 05:35:51,227:INFO:_master_model_container: 1
2023-07-04 05:35:51,227:INFO:_display_container: 2
2023-07-04 05:35:51,227:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-04 05:35:51,228:INFO:create_model() successfully completed......................................
2023-07-04 05:35:51,545:INFO:SubProcess create_model() end ==================================
2023-07-04 05:35:51,545:INFO:Creating metrics dataframe
2023-07-04 05:35:51,553:INFO:Initializing K Neighbors Classifier
2023-07-04 05:35:51,553:INFO:Total runtime is 0.16375795205434163 minutes
2023-07-04 05:35:51,555:INFO:SubProcess create_model() called ==================================
2023-07-04 05:35:51,555:INFO:Initializing create_model()
2023-07-04 05:35:51,555:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019867DEA140>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000198663991B0>, model_only=True, return_train_score=False, kwargs={})
2023-07-04 05:35:51,556:INFO:Checking exceptions
2023-07-04 05:35:51,556:INFO:Importing libraries
2023-07-04 05:35:51,556:INFO:Copying training dataset
2023-07-04 05:35:51,560:INFO:Defining folds
2023-07-04 05:35:51,560:INFO:Declaring metric variables
2023-07-04 05:35:51,563:INFO:Importing untrained model
2023-07-04 05:35:51,565:INFO:K Neighbors Classifier Imported successfully
2023-07-04 05:35:51,570:INFO:Starting cross validation
2023-07-04 05:35:51,571:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-04 05:35:55,550:INFO:Calculating mean and std
2023-07-04 05:35:55,551:INFO:Creating metrics dataframe
2023-07-04 05:35:56,150:INFO:Uploading results into container
2023-07-04 05:35:56,151:INFO:Uploading model into container now
2023-07-04 05:35:56,151:INFO:_master_model_container: 2
2023-07-04 05:35:56,152:INFO:_display_container: 2
2023-07-04 05:35:56,152:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-07-04 05:35:56,152:INFO:create_model() successfully completed......................................
2023-07-04 05:35:56,479:INFO:SubProcess create_model() end ==================================
2023-07-04 05:35:56,479:INFO:Creating metrics dataframe
2023-07-04 05:35:56,487:INFO:Initializing Naive Bayes
2023-07-04 05:35:56,488:INFO:Total runtime is 0.24600094556808472 minutes
2023-07-04 05:35:56,490:INFO:SubProcess create_model() called ==================================
2023-07-04 05:35:56,490:INFO:Initializing create_model()
2023-07-04 05:35:56,490:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019867DEA140>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000198663991B0>, model_only=True, return_train_score=False, kwargs={})
2023-07-04 05:35:56,491:INFO:Checking exceptions
2023-07-04 05:35:56,491:INFO:Importing libraries
2023-07-04 05:35:56,491:INFO:Copying training dataset
2023-07-04 05:35:56,494:INFO:Defining folds
2023-07-04 05:35:56,494:INFO:Declaring metric variables
2023-07-04 05:35:56,497:INFO:Importing untrained model
2023-07-04 05:35:56,500:INFO:Naive Bayes Imported successfully
2023-07-04 05:35:56,505:INFO:Starting cross validation
2023-07-04 05:35:56,506:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-04 05:36:00,286:INFO:Calculating mean and std
2023-07-04 05:36:00,288:INFO:Creating metrics dataframe
2023-07-04 05:36:00,885:INFO:Uploading results into container
2023-07-04 05:36:00,886:INFO:Uploading model into container now
2023-07-04 05:36:00,887:INFO:_master_model_container: 3
2023-07-04 05:36:00,887:INFO:_display_container: 2
2023-07-04 05:36:00,887:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-07-04 05:36:00,887:INFO:create_model() successfully completed......................................
2023-07-04 05:36:01,210:INFO:SubProcess create_model() end ==================================
2023-07-04 05:36:01,210:INFO:Creating metrics dataframe
2023-07-04 05:36:01,219:INFO:Initializing Decision Tree Classifier
2023-07-04 05:36:01,219:INFO:Total runtime is 0.3248594363530477 minutes
2023-07-04 05:36:01,222:INFO:SubProcess create_model() called ==================================
2023-07-04 05:36:01,223:INFO:Initializing create_model()
2023-07-04 05:36:01,223:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019867DEA140>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000198663991B0>, model_only=True, return_train_score=False, kwargs={})
2023-07-04 05:36:01,223:INFO:Checking exceptions
2023-07-04 05:36:01,223:INFO:Importing libraries
2023-07-04 05:36:01,223:INFO:Copying training dataset
2023-07-04 05:36:01,227:INFO:Defining folds
2023-07-04 05:36:01,227:INFO:Declaring metric variables
2023-07-04 05:36:01,230:INFO:Importing untrained model
2023-07-04 05:36:01,233:INFO:Decision Tree Classifier Imported successfully
2023-07-04 05:36:01,239:INFO:Starting cross validation
2023-07-04 05:36:01,240:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-04 05:36:05,002:INFO:Calculating mean and std
2023-07-04 05:36:05,004:INFO:Creating metrics dataframe
2023-07-04 05:36:05,604:INFO:Uploading results into container
2023-07-04 05:36:05,605:INFO:Uploading model into container now
2023-07-04 05:36:05,606:INFO:_master_model_container: 4
2023-07-04 05:36:05,606:INFO:_display_container: 2
2023-07-04 05:36:05,606:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-07-04 05:36:05,606:INFO:create_model() successfully completed......................................
2023-07-04 05:36:05,932:INFO:SubProcess create_model() end ==================================
2023-07-04 05:36:05,932:INFO:Creating metrics dataframe
2023-07-04 05:36:05,940:INFO:Initializing SVM - Linear Kernel
2023-07-04 05:36:05,940:INFO:Total runtime is 0.4035402774810791 minutes
2023-07-04 05:36:05,943:INFO:SubProcess create_model() called ==================================
2023-07-04 05:36:05,943:INFO:Initializing create_model()
2023-07-04 05:36:05,943:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019867DEA140>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000198663991B0>, model_only=True, return_train_score=False, kwargs={})
2023-07-04 05:36:05,943:INFO:Checking exceptions
2023-07-04 05:36:05,943:INFO:Importing libraries
2023-07-04 05:36:05,944:INFO:Copying training dataset
2023-07-04 05:36:05,948:INFO:Defining folds
2023-07-04 05:36:05,948:INFO:Declaring metric variables
2023-07-04 05:36:05,951:INFO:Importing untrained model
2023-07-04 05:36:05,954:INFO:SVM - Linear Kernel Imported successfully
2023-07-04 05:36:05,960:INFO:Starting cross validation
2023-07-04 05:36:05,961:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-04 05:36:06,095:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-04 05:36:06,095:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-04 05:36:06,096:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-04 05:36:06,096:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-04 05:36:06,098:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-04 05:36:06,101:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-04 05:36:06,101:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-04 05:36:06,101:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-04 05:36:06,116:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-04 05:36:06,117:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-04 05:36:06,130:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-04 05:36:06,145:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-04 05:36:09,652:INFO:Calculating mean and std
2023-07-04 05:36:09,653:INFO:Creating metrics dataframe
2023-07-04 05:36:10,258:INFO:Uploading results into container
2023-07-04 05:36:10,259:INFO:Uploading model into container now
2023-07-04 05:36:10,259:INFO:_master_model_container: 5
2023-07-04 05:36:10,259:INFO:_display_container: 2
2023-07-04 05:36:10,259:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-07-04 05:36:10,260:INFO:create_model() successfully completed......................................
2023-07-04 05:36:10,584:INFO:SubProcess create_model() end ==================================
2023-07-04 05:36:10,584:INFO:Creating metrics dataframe
2023-07-04 05:36:10,592:INFO:Initializing Ridge Classifier
2023-07-04 05:36:10,592:INFO:Total runtime is 0.48108005126317344 minutes
2023-07-04 05:36:10,595:INFO:SubProcess create_model() called ==================================
2023-07-04 05:36:10,595:INFO:Initializing create_model()
2023-07-04 05:36:10,596:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019867DEA140>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000198663991B0>, model_only=True, return_train_score=False, kwargs={})
2023-07-04 05:36:10,596:INFO:Checking exceptions
2023-07-04 05:36:10,596:INFO:Importing libraries
2023-07-04 05:36:10,596:INFO:Copying training dataset
2023-07-04 05:36:10,599:INFO:Defining folds
2023-07-04 05:36:10,599:INFO:Declaring metric variables
2023-07-04 05:36:10,602:INFO:Importing untrained model
2023-07-04 05:36:10,605:INFO:Ridge Classifier Imported successfully
2023-07-04 05:36:10,611:INFO:Starting cross validation
2023-07-04 05:36:10,612:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-04 05:36:10,748:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-04 05:36:10,755:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-04 05:36:10,755:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-04 05:36:10,757:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-04 05:36:10,757:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-04 05:36:10,767:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-04 05:36:10,776:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-04 05:36:10,786:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-04 05:36:10,786:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-04 05:36:10,796:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-04 05:36:14,346:INFO:Calculating mean and std
2023-07-04 05:36:14,347:INFO:Creating metrics dataframe
2023-07-04 05:36:14,954:INFO:Uploading results into container
2023-07-04 05:36:14,955:INFO:Uploading model into container now
2023-07-04 05:36:14,955:INFO:_master_model_container: 6
2023-07-04 05:36:14,955:INFO:_display_container: 2
2023-07-04 05:36:14,956:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-07-04 05:36:14,956:INFO:create_model() successfully completed......................................
2023-07-04 05:36:15,278:INFO:SubProcess create_model() end ==================================
2023-07-04 05:36:15,279:INFO:Creating metrics dataframe
2023-07-04 05:36:15,287:INFO:Initializing Random Forest Classifier
2023-07-04 05:36:15,287:INFO:Total runtime is 0.5593368808428447 minutes
2023-07-04 05:36:15,291:INFO:SubProcess create_model() called ==================================
2023-07-04 05:36:15,291:INFO:Initializing create_model()
2023-07-04 05:36:15,291:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019867DEA140>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000198663991B0>, model_only=True, return_train_score=False, kwargs={})
2023-07-04 05:36:15,291:INFO:Checking exceptions
2023-07-04 05:36:15,291:INFO:Importing libraries
2023-07-04 05:36:15,291:INFO:Copying training dataset
2023-07-04 05:36:15,295:INFO:Defining folds
2023-07-04 05:36:15,295:INFO:Declaring metric variables
2023-07-04 05:36:15,298:INFO:Importing untrained model
2023-07-04 05:36:15,301:INFO:Random Forest Classifier Imported successfully
2023-07-04 05:36:15,305:INFO:Starting cross validation
2023-07-04 05:36:15,306:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-04 05:36:19,650:INFO:Calculating mean and std
2023-07-04 05:36:19,651:INFO:Creating metrics dataframe
2023-07-04 05:36:20,247:INFO:Uploading results into container
2023-07-04 05:36:20,248:INFO:Uploading model into container now
2023-07-04 05:36:20,248:INFO:_master_model_container: 7
2023-07-04 05:36:20,248:INFO:_display_container: 2
2023-07-04 05:36:20,249:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-07-04 05:36:20,249:INFO:create_model() successfully completed......................................
2023-07-04 05:36:20,575:INFO:SubProcess create_model() end ==================================
2023-07-04 05:36:20,575:INFO:Creating metrics dataframe
2023-07-04 05:36:20,584:INFO:Initializing Quadratic Discriminant Analysis
2023-07-04 05:36:20,584:INFO:Total runtime is 0.6476197719573975 minutes
2023-07-04 05:36:20,587:INFO:SubProcess create_model() called ==================================
2023-07-04 05:36:20,587:INFO:Initializing create_model()
2023-07-04 05:36:20,587:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019867DEA140>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000198663991B0>, model_only=True, return_train_score=False, kwargs={})
2023-07-04 05:36:20,587:INFO:Checking exceptions
2023-07-04 05:36:20,588:INFO:Importing libraries
2023-07-04 05:36:20,588:INFO:Copying training dataset
2023-07-04 05:36:20,591:INFO:Defining folds
2023-07-04 05:36:20,591:INFO:Declaring metric variables
2023-07-04 05:36:20,594:INFO:Importing untrained model
2023-07-04 05:36:20,597:INFO:Quadratic Discriminant Analysis Imported successfully
2023-07-04 05:36:20,602:INFO:Starting cross validation
2023-07-04 05:36:20,604:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-04 05:36:24,449:INFO:Calculating mean and std
2023-07-04 05:36:24,450:INFO:Creating metrics dataframe
2023-07-04 05:36:25,080:INFO:Uploading results into container
2023-07-04 05:36:25,081:INFO:Uploading model into container now
2023-07-04 05:36:25,081:INFO:_master_model_container: 8
2023-07-04 05:36:25,081:INFO:_display_container: 2
2023-07-04 05:36:25,082:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-07-04 05:36:25,082:INFO:create_model() successfully completed......................................
2023-07-04 05:36:25,405:INFO:SubProcess create_model() end ==================================
2023-07-04 05:36:25,405:INFO:Creating metrics dataframe
2023-07-04 05:36:25,414:INFO:Initializing Ada Boost Classifier
2023-07-04 05:36:25,415:INFO:Total runtime is 0.7281213442484538 minutes
2023-07-04 05:36:25,417:INFO:SubProcess create_model() called ==================================
2023-07-04 05:36:25,418:INFO:Initializing create_model()
2023-07-04 05:36:25,418:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019867DEA140>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000198663991B0>, model_only=True, return_train_score=False, kwargs={})
2023-07-04 05:36:25,418:INFO:Checking exceptions
2023-07-04 05:36:25,418:INFO:Importing libraries
2023-07-04 05:36:25,418:INFO:Copying training dataset
2023-07-04 05:36:25,421:INFO:Defining folds
2023-07-04 05:36:25,422:INFO:Declaring metric variables
2023-07-04 05:36:25,424:INFO:Importing untrained model
2023-07-04 05:36:25,427:INFO:Ada Boost Classifier Imported successfully
2023-07-04 05:36:25,433:INFO:Starting cross validation
2023-07-04 05:36:25,434:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-04 05:36:29,475:INFO:Calculating mean and std
2023-07-04 05:36:29,476:INFO:Creating metrics dataframe
2023-07-04 05:36:30,333:INFO:Uploading results into container
2023-07-04 05:36:30,334:INFO:Uploading model into container now
2023-07-04 05:36:30,335:INFO:_master_model_container: 9
2023-07-04 05:36:30,335:INFO:_display_container: 2
2023-07-04 05:36:30,335:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-07-04 05:36:30,335:INFO:create_model() successfully completed......................................
2023-07-04 05:36:30,655:INFO:SubProcess create_model() end ==================================
2023-07-04 05:36:30,655:INFO:Creating metrics dataframe
2023-07-04 05:36:30,668:INFO:Initializing Gradient Boosting Classifier
2023-07-04 05:36:30,669:INFO:Total runtime is 0.8156967361768086 minutes
2023-07-04 05:36:30,671:INFO:SubProcess create_model() called ==================================
2023-07-04 05:36:30,672:INFO:Initializing create_model()
2023-07-04 05:36:30,672:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019867DEA140>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000198663991B0>, model_only=True, return_train_score=False, kwargs={})
2023-07-04 05:36:30,672:INFO:Checking exceptions
2023-07-04 05:36:30,672:INFO:Importing libraries
2023-07-04 05:36:30,672:INFO:Copying training dataset
2023-07-04 05:36:30,676:INFO:Defining folds
2023-07-04 05:36:30,676:INFO:Declaring metric variables
2023-07-04 05:36:30,679:INFO:Importing untrained model
2023-07-04 05:36:30,683:INFO:Gradient Boosting Classifier Imported successfully
2023-07-04 05:36:30,689:INFO:Starting cross validation
2023-07-04 05:36:30,690:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-04 05:36:34,812:INFO:Calculating mean and std
2023-07-04 05:36:34,813:INFO:Creating metrics dataframe
2023-07-04 05:36:35,680:INFO:Uploading results into container
2023-07-04 05:36:35,680:INFO:Uploading model into container now
2023-07-04 05:36:35,681:INFO:_master_model_container: 10
2023-07-04 05:36:35,681:INFO:_display_container: 2
2023-07-04 05:36:35,682:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-04 05:36:35,682:INFO:create_model() successfully completed......................................
2023-07-04 05:36:36,000:INFO:SubProcess create_model() end ==================================
2023-07-04 05:36:36,000:INFO:Creating metrics dataframe
2023-07-04 05:36:36,013:INFO:Initializing Linear Discriminant Analysis
2023-07-04 05:36:36,013:INFO:Total runtime is 0.9047710299491881 minutes
2023-07-04 05:36:36,016:INFO:SubProcess create_model() called ==================================
2023-07-04 05:36:36,017:INFO:Initializing create_model()
2023-07-04 05:36:36,017:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019867DEA140>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000198663991B0>, model_only=True, return_train_score=False, kwargs={})
2023-07-04 05:36:36,017:INFO:Checking exceptions
2023-07-04 05:36:36,017:INFO:Importing libraries
2023-07-04 05:36:36,017:INFO:Copying training dataset
2023-07-04 05:36:36,021:INFO:Defining folds
2023-07-04 05:36:36,022:INFO:Declaring metric variables
2023-07-04 05:36:36,025:INFO:Importing untrained model
2023-07-04 05:36:36,029:INFO:Linear Discriminant Analysis Imported successfully
2023-07-04 05:36:36,037:INFO:Starting cross validation
2023-07-04 05:36:36,038:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-04 05:36:39,925:INFO:Calculating mean and std
2023-07-04 05:36:39,926:INFO:Creating metrics dataframe
2023-07-04 05:36:40,794:INFO:Uploading results into container
2023-07-04 05:36:40,795:INFO:Uploading model into container now
2023-07-04 05:36:40,795:INFO:_master_model_container: 11
2023-07-04 05:36:40,795:INFO:_display_container: 2
2023-07-04 05:36:40,796:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-07-04 05:36:40,797:INFO:create_model() successfully completed......................................
2023-07-04 05:36:41,114:INFO:SubProcess create_model() end ==================================
2023-07-04 05:36:41,114:INFO:Creating metrics dataframe
2023-07-04 05:36:41,124:INFO:Initializing Extra Trees Classifier
2023-07-04 05:36:41,124:INFO:Total runtime is 0.9899543285369872 minutes
2023-07-04 05:36:41,127:INFO:SubProcess create_model() called ==================================
2023-07-04 05:36:41,127:INFO:Initializing create_model()
2023-07-04 05:36:41,128:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019867DEA140>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000198663991B0>, model_only=True, return_train_score=False, kwargs={})
2023-07-04 05:36:41,128:INFO:Checking exceptions
2023-07-04 05:36:41,128:INFO:Importing libraries
2023-07-04 05:36:41,128:INFO:Copying training dataset
2023-07-04 05:36:41,133:INFO:Defining folds
2023-07-04 05:36:41,133:INFO:Declaring metric variables
2023-07-04 05:36:41,136:INFO:Importing untrained model
2023-07-04 05:36:41,139:INFO:Extra Trees Classifier Imported successfully
2023-07-04 05:36:41,145:INFO:Starting cross validation
2023-07-04 05:36:41,146:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-04 05:36:45,532:INFO:Calculating mean and std
2023-07-04 05:36:45,533:INFO:Creating metrics dataframe
2023-07-04 05:36:46,161:INFO:Uploading results into container
2023-07-04 05:36:46,162:INFO:Uploading model into container now
2023-07-04 05:36:46,162:INFO:_master_model_container: 12
2023-07-04 05:36:46,162:INFO:_display_container: 2
2023-07-04 05:36:46,163:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-07-04 05:36:46,163:INFO:create_model() successfully completed......................................
2023-07-04 05:36:46,494:INFO:SubProcess create_model() end ==================================
2023-07-04 05:36:46,494:INFO:Creating metrics dataframe
2023-07-04 05:36:46,504:INFO:Initializing Light Gradient Boosting Machine
2023-07-04 05:36:46,504:INFO:Total runtime is 1.0796091636021932 minutes
2023-07-04 05:36:46,507:INFO:SubProcess create_model() called ==================================
2023-07-04 05:36:46,507:INFO:Initializing create_model()
2023-07-04 05:36:46,507:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019867DEA140>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000198663991B0>, model_only=True, return_train_score=False, kwargs={})
2023-07-04 05:36:46,507:INFO:Checking exceptions
2023-07-04 05:36:46,508:INFO:Importing libraries
2023-07-04 05:36:46,508:INFO:Copying training dataset
2023-07-04 05:36:46,511:INFO:Defining folds
2023-07-04 05:36:46,511:INFO:Declaring metric variables
2023-07-04 05:36:46,514:INFO:Importing untrained model
2023-07-04 05:36:46,516:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-04 05:36:46,521:INFO:Starting cross validation
2023-07-04 05:36:46,522:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-04 05:36:51,399:INFO:Calculating mean and std
2023-07-04 05:36:51,400:INFO:Creating metrics dataframe
2023-07-04 05:36:52,026:INFO:Uploading results into container
2023-07-04 05:36:52,027:INFO:Uploading model into container now
2023-07-04 05:36:52,027:INFO:_master_model_container: 13
2023-07-04 05:36:52,027:INFO:_display_container: 2
2023-07-04 05:36:52,028:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-07-04 05:36:52,028:INFO:create_model() successfully completed......................................
2023-07-04 05:36:52,353:INFO:SubProcess create_model() end ==================================
2023-07-04 05:36:52,353:INFO:Creating metrics dataframe
2023-07-04 05:36:52,364:INFO:Initializing Dummy Classifier
2023-07-04 05:36:52,364:INFO:Total runtime is 1.1772873441378275 minutes
2023-07-04 05:36:52,367:INFO:SubProcess create_model() called ==================================
2023-07-04 05:36:52,367:INFO:Initializing create_model()
2023-07-04 05:36:52,367:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019867DEA140>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000198663991B0>, model_only=True, return_train_score=False, kwargs={})
2023-07-04 05:36:52,367:INFO:Checking exceptions
2023-07-04 05:36:52,367:INFO:Importing libraries
2023-07-04 05:36:52,367:INFO:Copying training dataset
2023-07-04 05:36:52,371:INFO:Defining folds
2023-07-04 05:36:52,372:INFO:Declaring metric variables
2023-07-04 05:36:52,375:INFO:Importing untrained model
2023-07-04 05:36:52,377:INFO:Dummy Classifier Imported successfully
2023-07-04 05:36:52,382:INFO:Starting cross validation
2023-07-04 05:36:52,383:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-04 05:36:56,213:INFO:Calculating mean and std
2023-07-04 05:36:56,215:INFO:Creating metrics dataframe
2023-07-04 05:36:56,829:INFO:Uploading results into container
2023-07-04 05:36:56,830:INFO:Uploading model into container now
2023-07-04 05:36:56,830:INFO:_master_model_container: 14
2023-07-04 05:36:56,830:INFO:_display_container: 2
2023-07-04 05:36:56,831:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-07-04 05:36:56,831:INFO:create_model() successfully completed......................................
2023-07-04 05:36:57,153:INFO:SubProcess create_model() end ==================================
2023-07-04 05:36:57,154:INFO:Creating metrics dataframe
2023-07-04 05:36:57,172:INFO:Initializing create_model()
2023-07-04 05:36:57,172:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019867DEA140>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-04 05:36:57,172:INFO:Checking exceptions
2023-07-04 05:36:57,173:INFO:Importing libraries
2023-07-04 05:36:57,174:INFO:Copying training dataset
2023-07-04 05:36:57,176:INFO:Defining folds
2023-07-04 05:36:57,176:INFO:Declaring metric variables
2023-07-04 05:36:57,177:INFO:Importing untrained model
2023-07-04 05:36:57,177:INFO:Declaring custom model
2023-07-04 05:36:57,177:INFO:Naive Bayes Imported successfully
2023-07-04 05:36:57,178:INFO:Cross validation set to False
2023-07-04 05:36:57,178:INFO:Fitting Model
2023-07-04 05:36:57,589:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-07-04 05:36:57,590:INFO:create_model() successfully completed......................................
2023-07-04 05:36:57,944:INFO:_master_model_container: 14
2023-07-04 05:36:57,944:INFO:_display_container: 2
2023-07-04 05:36:57,945:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-07-04 05:36:57,945:INFO:compare_models() successfully completed......................................
2023-07-04 05:38:22,572:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7336_ba12580254ec4692917988bc67100baa_42626ddf5b5849718ce434c0be850945
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-04 05:38:22,572:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7336_bfe3fbcca7bd44d398a0b0e97106d716_cd8db2d7f0fd48f398c6f701f45f2847
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-04 05:38:22,573:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7336_ba12580254ec4692917988bc67100baa_5efcfe9619f5470c942f2027cbd3e3ff
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-04 05:38:22,573:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7336_09917b9a38d942b4a56f554a1e084d42_8725b7aa27af4fb796c31ba62db7d236
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-04 05:38:22,573:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7336_ba12580254ec4692917988bc67100baa_6317137131294fbf99132bb606d11415
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-04 05:38:22,573:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7336_f961b95a63494abeb58152143a1fae71_a4e91c6c1f3b4e99a983f77f1b16ab27
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-04 05:38:22,573:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7336_ba12580254ec4692917988bc67100baa_fd8bb47fc6874c68812c679d85362b0d
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-04 05:38:22,573:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7336_4daf1a4f005a4774afe01d6593c841d9_f5908c684f304b92a0c295af7d6cb144
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-04 05:38:22,573:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7336_ba12580254ec4692917988bc67100baa_ffec9f2c7c0c4c8eabc913a733df5068
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-04 05:38:22,573:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7336_2e9ede86786b454ab34987415b3a8fd4_824f977642d2423aaf0e6562ee3e3ea6
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-04 05:38:22,573:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7336_ba12580254ec4692917988bc67100baa_7ca1b32bca6c48b499f98c38ee480f08
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-04 05:38:22,573:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7336_3f413c1c24ae4349a7170243139ab78e_b5defe700e9d487ba071c780aed7e3e3
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-04 05:38:22,573:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7336_ba12580254ec4692917988bc67100baa_96c195e517ac43c190b63d4deb16904e
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-04 05:38:22,574:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7336_44a61da38dd5422d8471feae5c4e65cb_7a27fdcb5c2d45218100d4da0dff2c50
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-04 05:38:22,574:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7336_ba12580254ec4692917988bc67100baa_1be3970c615a491eb0b3d0840565bd1a
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-04 05:38:22,574:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7336_08a954b36f3a4dfe99987d5d241eef91_9581623ec7b04c5eb0940088c318908a
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-04 05:38:22,574:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7336_ba12580254ec4692917988bc67100baa_28bb0073136e4c0ea53870c43d309983
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-04 05:38:22,574:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7336_c669f9f982794e3da769f3270486f1b3_a322af5e39d44b108a1f5c111965edd0
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-04 05:38:22,574:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7336_ba12580254ec4692917988bc67100baa_63474a1a96e8430992f4b384f17fefaf
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-04 05:38:22,574:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7336_fa4880b3e534469383cb0f20d25f5190_d6e62bc653224ad6a0ba414ac4af773b
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-04 05:38:22,574:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7336_ba12580254ec4692917988bc67100baa_c6a8f3db92cd4901b74596f055763f31
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-04 05:38:22,574:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7336_28fa2e1a299443c590cb9186081a6ed7_502d67a1edbc476e82fd27fa0099668b
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-04 05:38:22,574:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7336_ba12580254ec4692917988bc67100baa_7dfae92af03e4eadaf49f3e2c2f9947e
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-04 05:38:22,574:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7336_678fa5157ae34604bb09e7f93a76d912_c66ec4e27c83433d8f1bc3bfee572a17
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-04 05:38:22,574:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7336_ba12580254ec4692917988bc67100baa_2f8b8cf85a174488b54bf14792788043
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-04 05:38:22,575:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7336_a75b7d6e8c1141bfb43f0f10a3e5d3d0_d36124e374624e5daaa9c13dcdb2bb77
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-04 05:38:22,575:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7336_ba12580254ec4692917988bc67100baa_ef3a996f1b144bab973563ba2f0cd973
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-04 05:38:22,575:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\JHossain\AppData\Local\Temp\joblib_memmapping_folder_7336_ba12580254ec4692917988bc67100baa_36515786058647a0ad4498b0d72c36d4
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-04 05:38:34,593:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-04 05:38:34,593:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-04 05:38:34,593:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-04 05:38:34,593:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-04 05:38:35,116:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-07-04 05:38:35,725:INFO:PyCaret ClassificationExperiment
2023-07-04 05:38:35,725:INFO:Logging name: clf-default-name
2023-07-04 05:38:35,725:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-07-04 05:38:35,725:INFO:version 3.0.2
2023-07-04 05:38:35,725:INFO:Initializing setup()
2023-07-04 05:38:35,725:INFO:self.USI: b6bb
2023-07-04 05:38:35,725:INFO:self._variable_keys: {'USI', 'y_test', 'data', 'gpu_param', 'gpu_n_jobs_param', 'fold_generator', 'X_test', 'pipeline', 'y', 'exp_name_log', 'memory', 'X', 'fold_groups_param', 'idx', 'X_train', '_available_plots', 'target_param', 'html_param', 'fix_imbalance', '_ml_usecase', 'exp_id', 'fold_shuffle_param', 'log_plots_param', 'seed', 'logging_param', 'y_train', 'n_jobs_param', 'is_multiclass'}
2023-07-04 05:38:35,725:INFO:Checking environment
2023-07-04 05:38:35,726:INFO:python_version: 3.10.9
2023-07-04 05:38:35,726:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2023-07-04 05:38:35,726:INFO:machine: AMD64
2023-07-04 05:38:35,726:INFO:platform: Windows-10-10.0.22621-SP0
2023-07-04 05:38:35,729:INFO:Memory: svmem(total=33664483328, available=24561778688, percent=27.0, used=9102704640, free=24561778688)
2023-07-04 05:38:35,729:INFO:Physical Core: 6
2023-07-04 05:38:35,729:INFO:Logical Core: 12
2023-07-04 05:38:35,729:INFO:Checking libraries
2023-07-04 05:38:35,729:INFO:System:
2023-07-04 05:38:35,729:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2023-07-04 05:38:35,729:INFO:executable: C:\Users\JHossain\anaconda3\python.exe
2023-07-04 05:38:35,729:INFO:   machine: Windows-10-10.0.22621-SP0
2023-07-04 05:38:35,729:INFO:PyCaret required dependencies:
2023-07-04 05:38:35,730:INFO:                 pip: 22.3.1
2023-07-04 05:38:35,730:INFO:          setuptools: 65.6.3
2023-07-04 05:38:35,730:INFO:             pycaret: 3.0.2
2023-07-04 05:38:35,730:INFO:             IPython: 8.10.0
2023-07-04 05:38:35,730:INFO:          ipywidgets: 7.6.5
2023-07-04 05:38:35,730:INFO:                tqdm: 4.64.1
2023-07-04 05:38:35,730:INFO:               numpy: 1.23.5
2023-07-04 05:38:35,730:INFO:              pandas: 1.5.3
2023-07-04 05:38:35,730:INFO:              jinja2: 3.1.2
2023-07-04 05:38:35,730:INFO:               scipy: 1.10.0
2023-07-04 05:38:35,730:INFO:              joblib: 1.2.0
2023-07-04 05:38:35,730:INFO:             sklearn: 1.2.1
2023-07-04 05:38:35,730:INFO:                pyod: 1.0.9
2023-07-04 05:38:35,730:INFO:            imblearn: 0.10.1
2023-07-04 05:38:35,730:INFO:   category_encoders: 2.6.1
2023-07-04 05:38:35,730:INFO:            lightgbm: 3.3.5
2023-07-04 05:38:35,730:INFO:               numba: 0.56.4
2023-07-04 05:38:35,730:INFO:            requests: 2.28.1
2023-07-04 05:38:35,730:INFO:          matplotlib: 3.7.0
2023-07-04 05:38:35,730:INFO:          scikitplot: 0.3.7
2023-07-04 05:38:35,730:INFO:         yellowbrick: 1.5
2023-07-04 05:38:35,730:INFO:              plotly: 5.9.0
2023-07-04 05:38:35,730:INFO:             kaleido: 0.2.1
2023-07-04 05:38:35,730:INFO:         statsmodels: 0.13.5
2023-07-04 05:38:35,730:INFO:              sktime: 0.17.0
2023-07-04 05:38:35,730:INFO:               tbats: 1.1.3
2023-07-04 05:38:35,730:INFO:            pmdarima: 2.0.3
2023-07-04 05:38:35,730:INFO:              psutil: 5.9.0
2023-07-04 05:38:35,731:INFO:PyCaret optional dependencies:
2023-07-04 05:38:36,624:INFO:                shap: 0.41.0
2023-07-04 05:38:36,624:INFO:           interpret: 0.4.2
2023-07-04 05:38:36,624:INFO:                umap: Not installed
2023-07-04 05:38:36,624:INFO:    pandas_profiling: Not installed
2023-07-04 05:38:36,624:INFO:  explainerdashboard: Not installed
2023-07-04 05:38:36,625:INFO:             autoviz: Not installed
2023-07-04 05:38:36,625:INFO:           fairlearn: Not installed
2023-07-04 05:38:36,625:INFO:             xgboost: Not installed
2023-07-04 05:38:36,625:INFO:            catboost: Not installed
2023-07-04 05:38:36,625:INFO:              kmodes: Not installed
2023-07-04 05:38:36,625:INFO:             mlxtend: Not installed
2023-07-04 05:38:36,625:INFO:       statsforecast: Not installed
2023-07-04 05:38:36,625:INFO:        tune_sklearn: Not installed
2023-07-04 05:38:36,625:INFO:                 ray: Not installed
2023-07-04 05:38:36,625:INFO:            hyperopt: Not installed
2023-07-04 05:38:36,625:INFO:              optuna: Not installed
2023-07-04 05:38:36,625:INFO:               skopt: Not installed
2023-07-04 05:38:36,625:INFO:              mlflow: Not installed
2023-07-04 05:38:36,625:INFO:              gradio: 3.35.2
2023-07-04 05:38:36,625:INFO:             fastapi: 0.99.0
2023-07-04 05:38:36,625:INFO:             uvicorn: 0.22.0
2023-07-04 05:38:36,625:INFO:              m2cgen: Not installed
2023-07-04 05:38:36,625:INFO:           evidently: Not installed
2023-07-04 05:38:36,625:INFO:               fugue: Not installed
2023-07-04 05:38:36,625:INFO:           streamlit: Not installed
2023-07-04 05:38:36,625:INFO:             prophet: Not installed
2023-07-04 05:38:36,625:INFO:None
2023-07-04 05:38:36,625:INFO:Set up data.
2023-07-04 05:38:36,632:INFO:Set up train/test split.
2023-07-04 05:38:36,635:INFO:Set up index.
2023-07-04 05:38:36,636:INFO:Set up folding strategy.
2023-07-04 05:38:36,636:INFO:Assigning column types.
2023-07-04 05:38:36,638:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-07-04 05:38:36,674:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-04 05:38:36,676:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-04 05:38:36,702:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-04 05:38:36,846:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-04 05:38:36,882:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-04 05:38:36,884:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-04 05:38:36,906:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-04 05:38:36,906:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-04 05:38:36,906:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-07-04 05:38:36,945:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-04 05:38:36,967:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-04 05:38:36,967:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-04 05:38:37,003:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-04 05:38:37,025:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-04 05:38:37,026:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-04 05:38:37,026:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-07-04 05:38:37,084:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-04 05:38:37,085:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-04 05:38:37,143:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-04 05:38:37,143:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-04 05:38:37,147:INFO:Preparing preprocessing pipeline...
2023-07-04 05:38:37,148:INFO:Set up simple imputation.
2023-07-04 05:38:37,150:INFO:Set up encoding of ordinal features.
2023-07-04 05:38:37,151:INFO:Set up encoding of categorical features.
2023-07-04 05:38:37,183:INFO:Finished creating preprocessing pipeline.
2023-07-04 05:38:37,201:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\JHossain\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'cp', 'trestbps', 'chol',
                                             'fbs', 'restecg', 'thalach',
                                             'exang', 'oldpeak', 'slope', 'ca',
                                             'thal'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_...
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('ordinal_encoding',
                 TransformerWrapper(exclude=None, include=['sex'],
                                    transformer=OrdinalEncoder(cols=['sex'],
                                                               drop_invariant=False,
                                                               handle_missing='return_nan',
                                                               handle_unknown='value',
                                                               mapping=[{'col': 'sex',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0)))],
         verbose=False)
2023-07-04 05:38:37,201:INFO:Creating final display dataframe.
2023-07-04 05:38:37,305:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            target
2                   Target type            Binary
3           Original data shape         (303, 14)
4        Transformed data shape         (303, 14)
5   Transformed train set shape         (212, 14)
6    Transformed test set shape          (91, 14)
7              Ordinal features                 1
8              Numeric features                12
9          Categorical features                 1
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              b6bb
2023-07-04 05:38:37,370:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-04 05:38:37,371:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-04 05:38:37,429:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-04 05:38:37,430:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-04 05:38:37,430:INFO:setup() successfully completed in 2.2s...............
2023-07-04 05:38:37,450:INFO:Initializing compare_models()
2023-07-04 05:38:37,450:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000203EFA84A00>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000203EFA84A00>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-07-04 05:38:37,450:INFO:Checking exceptions
2023-07-04 05:38:37,454:INFO:Preparing display monitor
2023-07-04 05:38:37,474:INFO:Initializing Logistic Regression
2023-07-04 05:38:37,475:INFO:Total runtime is 1.6689300537109375e-05 minutes
2023-07-04 05:38:37,477:INFO:SubProcess create_model() called ==================================
2023-07-04 05:38:37,477:INFO:Initializing create_model()
2023-07-04 05:38:37,477:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000203EFA84A00>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000203EDF51DB0>, model_only=True, return_train_score=False, kwargs={})
2023-07-04 05:38:37,478:INFO:Checking exceptions
2023-07-04 05:38:37,478:INFO:Importing libraries
2023-07-04 05:38:37,478:INFO:Copying training dataset
2023-07-04 05:38:37,481:INFO:Defining folds
2023-07-04 05:38:37,481:INFO:Declaring metric variables
2023-07-04 05:38:37,483:INFO:Importing untrained model
2023-07-04 05:38:37,486:INFO:Logistic Regression Imported successfully
2023-07-04 05:38:37,491:INFO:Starting cross validation
2023-07-04 05:38:37,492:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-04 05:38:46,163:INFO:Calculating mean and std
2023-07-04 05:38:46,164:INFO:Creating metrics dataframe
2023-07-04 05:38:46,773:INFO:Uploading results into container
2023-07-04 05:38:46,774:INFO:Uploading model into container now
2023-07-04 05:38:46,775:INFO:_master_model_container: 1
2023-07-04 05:38:46,775:INFO:_display_container: 2
2023-07-04 05:38:46,775:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-04 05:38:46,775:INFO:create_model() successfully completed......................................
2023-07-04 05:38:46,918:INFO:SubProcess create_model() end ==================================
2023-07-04 05:38:46,919:INFO:Creating metrics dataframe
2023-07-04 05:38:46,926:INFO:Initializing K Neighbors Classifier
2023-07-04 05:38:46,927:INFO:Total runtime is 0.15754531621932982 minutes
2023-07-04 05:38:46,929:INFO:SubProcess create_model() called ==================================
2023-07-04 05:38:46,930:INFO:Initializing create_model()
2023-07-04 05:38:46,930:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000203EFA84A00>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000203EDF51DB0>, model_only=True, return_train_score=False, kwargs={})
2023-07-04 05:38:46,930:INFO:Checking exceptions
2023-07-04 05:38:46,930:INFO:Importing libraries
2023-07-04 05:38:46,930:INFO:Copying training dataset
2023-07-04 05:38:46,934:INFO:Defining folds
2023-07-04 05:38:46,934:INFO:Declaring metric variables
2023-07-04 05:38:46,937:INFO:Importing untrained model
2023-07-04 05:38:46,940:INFO:K Neighbors Classifier Imported successfully
2023-07-04 05:38:46,945:INFO:Starting cross validation
2023-07-04 05:38:46,946:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-04 05:38:50,955:INFO:Calculating mean and std
2023-07-04 05:38:50,956:INFO:Creating metrics dataframe
2023-07-04 05:38:51,575:INFO:Uploading results into container
2023-07-04 05:38:51,576:INFO:Uploading model into container now
2023-07-04 05:38:51,576:INFO:_master_model_container: 2
2023-07-04 05:38:51,577:INFO:_display_container: 2
2023-07-04 05:38:51,577:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-07-04 05:38:51,578:INFO:create_model() successfully completed......................................
2023-07-04 05:38:51,720:INFO:SubProcess create_model() end ==================================
2023-07-04 05:38:51,720:INFO:Creating metrics dataframe
2023-07-04 05:38:51,728:INFO:Initializing Naive Bayes
2023-07-04 05:38:51,728:INFO:Total runtime is 0.23756213982899982 minutes
2023-07-04 05:38:51,731:INFO:SubProcess create_model() called ==================================
2023-07-04 05:38:51,731:INFO:Initializing create_model()
2023-07-04 05:38:51,732:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000203EFA84A00>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000203EDF51DB0>, model_only=True, return_train_score=False, kwargs={})
2023-07-04 05:38:51,732:INFO:Checking exceptions
2023-07-04 05:38:51,732:INFO:Importing libraries
2023-07-04 05:38:51,732:INFO:Copying training dataset
2023-07-04 05:38:51,735:INFO:Defining folds
2023-07-04 05:38:51,735:INFO:Declaring metric variables
2023-07-04 05:38:51,738:INFO:Importing untrained model
2023-07-04 05:38:51,741:INFO:Naive Bayes Imported successfully
2023-07-04 05:38:51,747:INFO:Starting cross validation
2023-07-04 05:38:51,748:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-04 05:38:55,566:INFO:Calculating mean and std
2023-07-04 05:38:55,568:INFO:Creating metrics dataframe
2023-07-04 05:38:56,181:INFO:Uploading results into container
2023-07-04 05:38:56,182:INFO:Uploading model into container now
2023-07-04 05:38:56,182:INFO:_master_model_container: 3
2023-07-04 05:38:56,182:INFO:_display_container: 2
2023-07-04 05:38:56,183:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-07-04 05:38:56,183:INFO:create_model() successfully completed......................................
2023-07-04 05:38:56,325:INFO:SubProcess create_model() end ==================================
2023-07-04 05:38:56,325:INFO:Creating metrics dataframe
2023-07-04 05:38:56,334:INFO:Initializing Decision Tree Classifier
2023-07-04 05:38:56,334:INFO:Total runtime is 0.31434082984924316 minutes
2023-07-04 05:38:56,337:INFO:SubProcess create_model() called ==================================
2023-07-04 05:38:56,337:INFO:Initializing create_model()
2023-07-04 05:38:56,337:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000203EFA84A00>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000203EDF51DB0>, model_only=True, return_train_score=False, kwargs={})
2023-07-04 05:38:56,337:INFO:Checking exceptions
2023-07-04 05:38:56,338:INFO:Importing libraries
2023-07-04 05:38:56,338:INFO:Copying training dataset
2023-07-04 05:38:56,341:INFO:Defining folds
2023-07-04 05:38:56,341:INFO:Declaring metric variables
2023-07-04 05:38:56,344:INFO:Importing untrained model
2023-07-04 05:38:56,348:INFO:Decision Tree Classifier Imported successfully
2023-07-04 05:38:56,354:INFO:Starting cross validation
2023-07-04 05:38:56,355:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-04 05:39:00,182:INFO:Calculating mean and std
2023-07-04 05:39:00,183:INFO:Creating metrics dataframe
2023-07-04 05:39:00,808:INFO:Uploading results into container
2023-07-04 05:39:00,809:INFO:Uploading model into container now
2023-07-04 05:39:00,809:INFO:_master_model_container: 4
2023-07-04 05:39:00,809:INFO:_display_container: 2
2023-07-04 05:39:00,810:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-07-04 05:39:00,810:INFO:create_model() successfully completed......................................
2023-07-04 05:39:00,954:INFO:SubProcess create_model() end ==================================
2023-07-04 05:39:00,954:INFO:Creating metrics dataframe
2023-07-04 05:39:00,962:INFO:Initializing SVM - Linear Kernel
2023-07-04 05:39:00,962:INFO:Total runtime is 0.3914626757303874 minutes
2023-07-04 05:39:00,965:INFO:SubProcess create_model() called ==================================
2023-07-04 05:39:00,965:INFO:Initializing create_model()
2023-07-04 05:39:00,965:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000203EFA84A00>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000203EDF51DB0>, model_only=True, return_train_score=False, kwargs={})
2023-07-04 05:39:00,965:INFO:Checking exceptions
2023-07-04 05:39:00,965:INFO:Importing libraries
2023-07-04 05:39:00,965:INFO:Copying training dataset
2023-07-04 05:39:00,969:INFO:Defining folds
2023-07-04 05:39:00,969:INFO:Declaring metric variables
2023-07-04 05:39:00,972:INFO:Importing untrained model
2023-07-04 05:39:00,974:INFO:SVM - Linear Kernel Imported successfully
2023-07-04 05:39:00,981:INFO:Starting cross validation
2023-07-04 05:39:00,982:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-04 05:39:01,104:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-04 05:39:01,105:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-04 05:39:01,111:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-04 05:39:01,114:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-04 05:39:01,115:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-04 05:39:01,120:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-04 05:39:01,121:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-04 05:39:01,130:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-04 05:39:01,141:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-04 05:39:01,150:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-04 05:39:01,155:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-04 05:39:01,157:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-04 05:39:04,820:INFO:Calculating mean and std
2023-07-04 05:39:04,821:INFO:Creating metrics dataframe
2023-07-04 05:39:05,428:INFO:Uploading results into container
2023-07-04 05:39:05,429:INFO:Uploading model into container now
2023-07-04 05:39:05,430:INFO:_master_model_container: 5
2023-07-04 05:39:05,430:INFO:_display_container: 2
2023-07-04 05:39:05,430:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-07-04 05:39:05,430:INFO:create_model() successfully completed......................................
2023-07-04 05:39:05,577:INFO:SubProcess create_model() end ==================================
2023-07-04 05:39:05,577:INFO:Creating metrics dataframe
2023-07-04 05:39:05,587:INFO:Initializing Ridge Classifier
2023-07-04 05:39:05,587:INFO:Total runtime is 0.46854706605275476 minutes
2023-07-04 05:39:05,589:INFO:SubProcess create_model() called ==================================
2023-07-04 05:39:05,590:INFO:Initializing create_model()
2023-07-04 05:39:05,590:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000203EFA84A00>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000203EDF51DB0>, model_only=True, return_train_score=False, kwargs={})
2023-07-04 05:39:05,590:INFO:Checking exceptions
2023-07-04 05:39:05,590:INFO:Importing libraries
2023-07-04 05:39:05,590:INFO:Copying training dataset
2023-07-04 05:39:05,594:INFO:Defining folds
2023-07-04 05:39:05,594:INFO:Declaring metric variables
2023-07-04 05:39:05,596:INFO:Importing untrained model
2023-07-04 05:39:05,600:INFO:Ridge Classifier Imported successfully
2023-07-04 05:39:05,608:INFO:Starting cross validation
2023-07-04 05:39:05,608:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-04 05:39:05,735:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-04 05:39:05,737:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-04 05:39:05,740:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-04 05:39:05,741:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-04 05:39:05,747:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-04 05:39:05,771:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-04 05:39:05,771:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-04 05:39:05,785:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-04 05:39:05,785:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-04 05:39:05,797:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\JHossain\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-04 05:39:09,408:INFO:Calculating mean and std
2023-07-04 05:39:09,410:INFO:Creating metrics dataframe
2023-07-04 05:39:10,028:INFO:Uploading results into container
2023-07-04 05:39:10,029:INFO:Uploading model into container now
2023-07-04 05:39:10,030:INFO:_master_model_container: 6
2023-07-04 05:39:10,030:INFO:_display_container: 2
2023-07-04 05:39:10,031:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-07-04 05:39:10,031:INFO:create_model() successfully completed......................................
2023-07-04 05:39:10,172:INFO:SubProcess create_model() end ==================================
2023-07-04 05:39:10,172:INFO:Creating metrics dataframe
2023-07-04 05:39:10,181:INFO:Initializing Random Forest Classifier
2023-07-04 05:39:10,182:INFO:Total runtime is 0.545141355196635 minutes
2023-07-04 05:39:10,184:INFO:SubProcess create_model() called ==================================
2023-07-04 05:39:10,185:INFO:Initializing create_model()
2023-07-04 05:39:10,185:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000203EFA84A00>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000203EDF51DB0>, model_only=True, return_train_score=False, kwargs={})
2023-07-04 05:39:10,185:INFO:Checking exceptions
2023-07-04 05:39:10,185:INFO:Importing libraries
2023-07-04 05:39:10,185:INFO:Copying training dataset
2023-07-04 05:39:10,188:INFO:Defining folds
2023-07-04 05:39:10,188:INFO:Declaring metric variables
2023-07-04 05:39:10,191:INFO:Importing untrained model
2023-07-04 05:39:10,194:INFO:Random Forest Classifier Imported successfully
2023-07-04 05:39:10,199:INFO:Starting cross validation
2023-07-04 05:39:10,200:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-04 05:39:14,244:INFO:Calculating mean and std
2023-07-04 05:39:14,245:INFO:Creating metrics dataframe
2023-07-04 05:39:14,868:INFO:Uploading results into container
2023-07-04 05:39:14,869:INFO:Uploading model into container now
2023-07-04 05:39:14,870:INFO:_master_model_container: 7
2023-07-04 05:39:14,870:INFO:_display_container: 2
2023-07-04 05:39:14,870:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-07-04 05:39:14,871:INFO:create_model() successfully completed......................................
2023-07-04 05:39:15,009:INFO:SubProcess create_model() end ==================================
2023-07-04 05:39:15,010:INFO:Creating metrics dataframe
2023-07-04 05:39:15,019:INFO:Initializing Quadratic Discriminant Analysis
2023-07-04 05:39:15,019:INFO:Total runtime is 0.6257590095202129 minutes
2023-07-04 05:39:15,023:INFO:SubProcess create_model() called ==================================
2023-07-04 05:39:15,023:INFO:Initializing create_model()
2023-07-04 05:39:15,023:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000203EFA84A00>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000203EDF51DB0>, model_only=True, return_train_score=False, kwargs={})
2023-07-04 05:39:15,023:INFO:Checking exceptions
2023-07-04 05:39:15,023:INFO:Importing libraries
2023-07-04 05:39:15,023:INFO:Copying training dataset
2023-07-04 05:39:15,027:INFO:Defining folds
2023-07-04 05:39:15,027:INFO:Declaring metric variables
2023-07-04 05:39:15,030:INFO:Importing untrained model
2023-07-04 05:39:15,033:INFO:Quadratic Discriminant Analysis Imported successfully
2023-07-04 05:39:15,038:INFO:Starting cross validation
2023-07-04 05:39:15,039:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-04 05:39:18,857:INFO:Calculating mean and std
2023-07-04 05:39:18,858:INFO:Creating metrics dataframe
2023-07-04 05:39:19,478:INFO:Uploading results into container
2023-07-04 05:39:19,479:INFO:Uploading model into container now
2023-07-04 05:39:19,479:INFO:_master_model_container: 8
2023-07-04 05:39:19,479:INFO:_display_container: 2
2023-07-04 05:39:19,480:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-07-04 05:39:19,480:INFO:create_model() successfully completed......................................
2023-07-04 05:39:19,621:INFO:SubProcess create_model() end ==================================
2023-07-04 05:39:19,621:INFO:Creating metrics dataframe
2023-07-04 05:39:19,632:INFO:Initializing Ada Boost Classifier
2023-07-04 05:39:19,632:INFO:Total runtime is 0.7026312788327536 minutes
2023-07-04 05:39:19,635:INFO:SubProcess create_model() called ==================================
2023-07-04 05:39:19,635:INFO:Initializing create_model()
2023-07-04 05:39:19,636:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000203EFA84A00>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000203EDF51DB0>, model_only=True, return_train_score=False, kwargs={})
2023-07-04 05:39:19,636:INFO:Checking exceptions
2023-07-04 05:39:19,636:INFO:Importing libraries
2023-07-04 05:39:19,636:INFO:Copying training dataset
2023-07-04 05:39:19,640:INFO:Defining folds
2023-07-04 05:39:19,640:INFO:Declaring metric variables
2023-07-04 05:39:19,643:INFO:Importing untrained model
2023-07-04 05:39:19,646:INFO:Ada Boost Classifier Imported successfully
2023-07-04 05:39:19,652:INFO:Starting cross validation
2023-07-04 05:39:19,653:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-04 05:39:23,613:INFO:Calculating mean and std
2023-07-04 05:39:23,615:INFO:Creating metrics dataframe
2023-07-04 05:39:24,231:INFO:Uploading results into container
2023-07-04 05:39:24,232:INFO:Uploading model into container now
2023-07-04 05:39:24,232:INFO:_master_model_container: 9
2023-07-04 05:39:24,232:INFO:_display_container: 2
2023-07-04 05:39:24,232:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-07-04 05:39:24,233:INFO:create_model() successfully completed......................................
2023-07-04 05:39:24,367:INFO:SubProcess create_model() end ==================================
2023-07-04 05:39:24,367:INFO:Creating metrics dataframe
2023-07-04 05:39:24,377:INFO:Initializing Gradient Boosting Classifier
2023-07-04 05:39:24,378:INFO:Total runtime is 0.7817320624987285 minutes
2023-07-04 05:39:24,380:INFO:SubProcess create_model() called ==================================
2023-07-04 05:39:24,381:INFO:Initializing create_model()
2023-07-04 05:39:24,381:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000203EFA84A00>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000203EDF51DB0>, model_only=True, return_train_score=False, kwargs={})
2023-07-04 05:39:24,381:INFO:Checking exceptions
2023-07-04 05:39:24,381:INFO:Importing libraries
2023-07-04 05:39:24,381:INFO:Copying training dataset
2023-07-04 05:39:24,385:INFO:Defining folds
2023-07-04 05:39:24,385:INFO:Declaring metric variables
2023-07-04 05:39:24,388:INFO:Importing untrained model
2023-07-04 05:39:24,391:INFO:Gradient Boosting Classifier Imported successfully
2023-07-04 05:39:24,396:INFO:Starting cross validation
2023-07-04 05:39:24,397:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-04 05:39:28,337:INFO:Calculating mean and std
2023-07-04 05:39:28,338:INFO:Creating metrics dataframe
2023-07-04 05:39:28,945:INFO:Uploading results into container
2023-07-04 05:39:28,946:INFO:Uploading model into container now
2023-07-04 05:39:28,946:INFO:_master_model_container: 10
2023-07-04 05:39:28,946:INFO:_display_container: 2
2023-07-04 05:39:28,947:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-04 05:39:28,947:INFO:create_model() successfully completed......................................
2023-07-04 05:39:29,085:INFO:SubProcess create_model() end ==================================
2023-07-04 05:39:29,085:INFO:Creating metrics dataframe
2023-07-04 05:39:29,095:INFO:Initializing Linear Discriminant Analysis
2023-07-04 05:39:29,095:INFO:Total runtime is 0.8603602925936382 minutes
2023-07-04 05:39:29,098:INFO:SubProcess create_model() called ==================================
2023-07-04 05:39:29,098:INFO:Initializing create_model()
2023-07-04 05:39:29,098:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000203EFA84A00>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000203EDF51DB0>, model_only=True, return_train_score=False, kwargs={})
2023-07-04 05:39:29,098:INFO:Checking exceptions
2023-07-04 05:39:29,098:INFO:Importing libraries
2023-07-04 05:39:29,098:INFO:Copying training dataset
2023-07-04 05:39:29,102:INFO:Defining folds
2023-07-04 05:39:29,102:INFO:Declaring metric variables
2023-07-04 05:39:29,105:INFO:Importing untrained model
2023-07-04 05:39:29,107:INFO:Linear Discriminant Analysis Imported successfully
2023-07-04 05:39:29,114:INFO:Starting cross validation
2023-07-04 05:39:29,115:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-04 05:39:32,974:INFO:Calculating mean and std
2023-07-04 05:39:32,975:INFO:Creating metrics dataframe
2023-07-04 05:39:33,604:INFO:Uploading results into container
2023-07-04 05:39:33,605:INFO:Uploading model into container now
2023-07-04 05:39:33,605:INFO:_master_model_container: 11
2023-07-04 05:39:33,605:INFO:_display_container: 2
2023-07-04 05:39:33,606:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-07-04 05:39:33,606:INFO:create_model() successfully completed......................................
2023-07-04 05:39:33,748:INFO:SubProcess create_model() end ==================================
2023-07-04 05:39:33,748:INFO:Creating metrics dataframe
2023-07-04 05:39:33,759:INFO:Initializing Extra Trees Classifier
2023-07-04 05:39:33,759:INFO:Total runtime is 0.9380898435910544 minutes
2023-07-04 05:39:33,761:INFO:SubProcess create_model() called ==================================
2023-07-04 05:39:33,762:INFO:Initializing create_model()
2023-07-04 05:39:33,762:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000203EFA84A00>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000203EDF51DB0>, model_only=True, return_train_score=False, kwargs={})
2023-07-04 05:39:33,762:INFO:Checking exceptions
2023-07-04 05:39:33,762:INFO:Importing libraries
2023-07-04 05:39:33,762:INFO:Copying training dataset
2023-07-04 05:39:33,766:INFO:Defining folds
2023-07-04 05:39:33,766:INFO:Declaring metric variables
2023-07-04 05:39:33,769:INFO:Importing untrained model
2023-07-04 05:39:33,771:INFO:Extra Trees Classifier Imported successfully
2023-07-04 05:39:33,777:INFO:Starting cross validation
2023-07-04 05:39:33,778:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-04 05:39:37,867:INFO:Calculating mean and std
2023-07-04 05:39:37,868:INFO:Creating metrics dataframe
2023-07-04 05:39:38,497:INFO:Uploading results into container
2023-07-04 05:39:38,497:INFO:Uploading model into container now
2023-07-04 05:39:38,498:INFO:_master_model_container: 12
2023-07-04 05:39:38,498:INFO:_display_container: 2
2023-07-04 05:39:38,498:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-07-04 05:39:38,498:INFO:create_model() successfully completed......................................
2023-07-04 05:39:38,642:INFO:SubProcess create_model() end ==================================
2023-07-04 05:39:38,642:INFO:Creating metrics dataframe
2023-07-04 05:39:38,652:INFO:Initializing Light Gradient Boosting Machine
2023-07-04 05:39:38,652:INFO:Total runtime is 1.0196323116620383 minutes
2023-07-04 05:39:38,655:INFO:SubProcess create_model() called ==================================
2023-07-04 05:39:38,655:INFO:Initializing create_model()
2023-07-04 05:39:38,655:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000203EFA84A00>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000203EDF51DB0>, model_only=True, return_train_score=False, kwargs={})
2023-07-04 05:39:38,655:INFO:Checking exceptions
2023-07-04 05:39:38,655:INFO:Importing libraries
2023-07-04 05:39:38,655:INFO:Copying training dataset
2023-07-04 05:39:38,659:INFO:Defining folds
2023-07-04 05:39:38,659:INFO:Declaring metric variables
2023-07-04 05:39:38,662:INFO:Importing untrained model
2023-07-04 05:39:38,665:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-04 05:39:38,670:INFO:Starting cross validation
2023-07-04 05:39:38,671:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-04 05:39:43,523:INFO:Calculating mean and std
2023-07-04 05:39:43,524:INFO:Creating metrics dataframe
2023-07-04 05:39:44,145:INFO:Uploading results into container
2023-07-04 05:39:44,146:INFO:Uploading model into container now
2023-07-04 05:39:44,147:INFO:_master_model_container: 13
2023-07-04 05:39:44,147:INFO:_display_container: 2
2023-07-04 05:39:44,147:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-07-04 05:39:44,147:INFO:create_model() successfully completed......................................
2023-07-04 05:39:44,285:INFO:SubProcess create_model() end ==================================
2023-07-04 05:39:44,285:INFO:Creating metrics dataframe
2023-07-04 05:39:44,296:INFO:Initializing Dummy Classifier
2023-07-04 05:39:44,296:INFO:Total runtime is 1.1137030879656475 minutes
2023-07-04 05:39:44,298:INFO:SubProcess create_model() called ==================================
2023-07-04 05:39:44,299:INFO:Initializing create_model()
2023-07-04 05:39:44,299:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000203EFA84A00>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000203EDF51DB0>, model_only=True, return_train_score=False, kwargs={})
2023-07-04 05:39:44,299:INFO:Checking exceptions
2023-07-04 05:39:44,299:INFO:Importing libraries
2023-07-04 05:39:44,299:INFO:Copying training dataset
2023-07-04 05:39:44,303:INFO:Defining folds
2023-07-04 05:39:44,303:INFO:Declaring metric variables
2023-07-04 05:39:44,305:INFO:Importing untrained model
2023-07-04 05:39:44,308:INFO:Dummy Classifier Imported successfully
2023-07-04 05:39:44,314:INFO:Starting cross validation
2023-07-04 05:39:44,315:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-04 05:39:48,140:INFO:Calculating mean and std
2023-07-04 05:39:48,140:INFO:Creating metrics dataframe
2023-07-04 05:39:48,750:INFO:Uploading results into container
2023-07-04 05:39:48,751:INFO:Uploading model into container now
2023-07-04 05:39:48,751:INFO:_master_model_container: 14
2023-07-04 05:39:48,752:INFO:_display_container: 2
2023-07-04 05:39:48,752:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-07-04 05:39:48,752:INFO:create_model() successfully completed......................................
2023-07-04 05:39:48,894:INFO:SubProcess create_model() end ==================================
2023-07-04 05:39:48,894:INFO:Creating metrics dataframe
2023-07-04 05:39:48,913:INFO:Initializing create_model()
2023-07-04 05:39:48,913:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000203EFA84A00>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-04 05:39:48,913:INFO:Checking exceptions
2023-07-04 05:39:48,914:INFO:Importing libraries
2023-07-04 05:39:48,914:INFO:Copying training dataset
2023-07-04 05:39:48,917:INFO:Defining folds
2023-07-04 05:39:48,917:INFO:Declaring metric variables
2023-07-04 05:39:48,917:INFO:Importing untrained model
2023-07-04 05:39:48,917:INFO:Declaring custom model
2023-07-04 05:39:48,918:INFO:Naive Bayes Imported successfully
2023-07-04 05:39:48,919:INFO:Cross validation set to False
2023-07-04 05:39:48,919:INFO:Fitting Model
2023-07-04 05:39:49,329:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-07-04 05:39:49,329:INFO:create_model() successfully completed......................................
2023-07-04 05:39:49,492:INFO:_master_model_container: 14
2023-07-04 05:39:49,493:INFO:_display_container: 2
2023-07-04 05:39:49,493:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-07-04 05:39:49,493:INFO:compare_models() successfully completed......................................
2023-07-04 05:39:49,502:INFO:Initializing create_model()
2023-07-04 05:39:49,502:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000203EFA84A00>, estimator=nb, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-04 05:39:49,502:INFO:Checking exceptions
2023-07-04 05:39:49,514:INFO:Importing libraries
2023-07-04 05:39:49,514:INFO:Copying training dataset
2023-07-04 05:39:49,520:INFO:Defining folds
2023-07-04 05:39:49,520:INFO:Declaring metric variables
2023-07-04 05:39:49,525:INFO:Importing untrained model
2023-07-04 05:39:49,528:INFO:Naive Bayes Imported successfully
2023-07-04 05:39:49,534:INFO:Starting cross validation
2023-07-04 05:39:49,535:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-04 05:39:53,353:INFO:Calculating mean and std
2023-07-04 05:39:53,354:INFO:Creating metrics dataframe
2023-07-04 05:39:53,359:INFO:Finalizing model
2023-07-04 05:39:54,015:INFO:Uploading results into container
2023-07-04 05:39:54,016:INFO:Uploading model into container now
2023-07-04 05:39:54,024:INFO:_master_model_container: 15
2023-07-04 05:39:54,024:INFO:_display_container: 3
2023-07-04 05:39:54,024:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-07-04 05:39:54,024:INFO:create_model() successfully completed......................................
2023-07-04 05:39:54,203:INFO:Initializing tune_model()
2023-07-04 05:39:54,203:INFO:tune_model(estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000203EFA84A00>)
2023-07-04 05:39:54,203:INFO:Checking exceptions
2023-07-04 05:39:54,217:INFO:Copying training dataset
2023-07-04 05:39:54,220:INFO:Checking base model
2023-07-04 05:39:54,220:INFO:Base model : Naive Bayes
2023-07-04 05:39:54,223:INFO:Declaring metric variables
2023-07-04 05:39:54,226:INFO:Defining Hyperparameters
2023-07-04 05:39:54,369:INFO:Tuning with n_jobs=-1
2023-07-04 05:39:54,369:INFO:Initializing RandomizedSearchCV
2023-07-04 05:40:34,540:INFO:best_params: {'actual_estimator__var_smoothing': 2e-09}
2023-07-04 05:40:34,541:INFO:Hyperparameter search completed
2023-07-04 05:40:34,541:INFO:SubProcess create_model() called ==================================
2023-07-04 05:40:34,541:INFO:Initializing create_model()
2023-07-04 05:40:34,541:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000203EFA84A00>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000203F314B9D0>, model_only=True, return_train_score=False, kwargs={'var_smoothing': 2e-09})
2023-07-04 05:40:34,542:INFO:Checking exceptions
2023-07-04 05:40:34,542:INFO:Importing libraries
2023-07-04 05:40:34,542:INFO:Copying training dataset
2023-07-04 05:40:34,545:INFO:Defining folds
2023-07-04 05:40:34,545:INFO:Declaring metric variables
2023-07-04 05:40:34,548:INFO:Importing untrained model
2023-07-04 05:40:34,549:INFO:Declaring custom model
2023-07-04 05:40:34,552:INFO:Naive Bayes Imported successfully
2023-07-04 05:40:34,557:INFO:Starting cross validation
2023-07-04 05:40:34,558:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-04 05:40:38,413:INFO:Calculating mean and std
2023-07-04 05:40:38,414:INFO:Creating metrics dataframe
2023-07-04 05:40:38,419:INFO:Finalizing model
2023-07-04 05:40:39,076:INFO:Uploading results into container
2023-07-04 05:40:39,077:INFO:Uploading model into container now
2023-07-04 05:40:39,078:INFO:_master_model_container: 16
2023-07-04 05:40:39,078:INFO:_display_container: 4
2023-07-04 05:40:39,078:INFO:GaussianNB(priors=None, var_smoothing=2e-09)
2023-07-04 05:40:39,078:INFO:create_model() successfully completed......................................
2023-07-04 05:40:39,223:INFO:SubProcess create_model() end ==================================
2023-07-04 05:40:39,224:INFO:choose_better activated
2023-07-04 05:40:39,227:INFO:SubProcess create_model() called ==================================
2023-07-04 05:40:39,227:INFO:Initializing create_model()
2023-07-04 05:40:39,227:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000203EFA84A00>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-04 05:40:39,227:INFO:Checking exceptions
2023-07-04 05:40:39,229:INFO:Importing libraries
2023-07-04 05:40:39,229:INFO:Copying training dataset
2023-07-04 05:40:39,232:INFO:Defining folds
2023-07-04 05:40:39,232:INFO:Declaring metric variables
2023-07-04 05:40:39,232:INFO:Importing untrained model
2023-07-04 05:40:39,232:INFO:Declaring custom model
2023-07-04 05:40:39,233:INFO:Naive Bayes Imported successfully
2023-07-04 05:40:39,233:INFO:Starting cross validation
2023-07-04 05:40:39,234:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-04 05:40:43,097:INFO:Calculating mean and std
2023-07-04 05:40:43,097:INFO:Creating metrics dataframe
2023-07-04 05:40:43,099:INFO:Finalizing model
2023-07-04 05:40:43,758:INFO:Uploading results into container
2023-07-04 05:40:43,758:INFO:Uploading model into container now
2023-07-04 05:40:43,759:INFO:_master_model_container: 17
2023-07-04 05:40:43,759:INFO:_display_container: 5
2023-07-04 05:40:43,760:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-07-04 05:40:43,760:INFO:create_model() successfully completed......................................
2023-07-04 05:40:43,899:INFO:SubProcess create_model() end ==================================
2023-07-04 05:40:43,899:INFO:GaussianNB(priors=None, var_smoothing=1e-09) result for Accuracy is 0.8201
2023-07-04 05:40:43,899:INFO:GaussianNB(priors=None, var_smoothing=2e-09) result for Accuracy is 0.8201
2023-07-04 05:40:43,900:INFO:GaussianNB(priors=None, var_smoothing=1e-09) is best model
2023-07-04 05:40:43,900:INFO:choose_better completed
2023-07-04 05:40:43,900:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-07-04 05:40:43,908:INFO:_master_model_container: 17
2023-07-04 05:40:43,908:INFO:_display_container: 4
2023-07-04 05:40:43,908:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-07-04 05:40:43,908:INFO:tune_model() successfully completed......................................
2023-07-04 05:40:44,434:INFO:Initializing tune_model()
2023-07-04 05:40:44,434:INFO:tune_model(estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=True, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000203EFA84A00>)
2023-07-04 05:40:44,434:INFO:Checking exceptions
2023-07-04 05:40:44,449:INFO:Copying training dataset
2023-07-04 05:40:44,451:INFO:Checking base model
2023-07-04 05:40:44,451:INFO:Base model : Naive Bayes
2023-07-04 05:40:44,454:INFO:Declaring metric variables
2023-07-04 05:40:44,457:INFO:Defining Hyperparameters
2023-07-04 05:40:44,591:INFO:Tuning with n_jobs=-1
2023-07-04 05:40:44,591:INFO:Initializing RandomizedSearchCV
2023-07-04 05:41:24,770:INFO:best_params: {'actual_estimator__var_smoothing': 2e-09}
2023-07-04 05:41:24,771:INFO:Hyperparameter search completed
2023-07-04 05:41:24,771:INFO:SubProcess create_model() called ==================================
2023-07-04 05:41:24,772:INFO:Initializing create_model()
2023-07-04 05:41:24,772:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000203EFA84A00>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000203F57C00D0>, model_only=True, return_train_score=False, kwargs={'var_smoothing': 2e-09})
2023-07-04 05:41:24,772:INFO:Checking exceptions
2023-07-04 05:41:24,772:INFO:Importing libraries
2023-07-04 05:41:24,773:INFO:Copying training dataset
2023-07-04 05:41:24,776:INFO:Defining folds
2023-07-04 05:41:24,776:INFO:Declaring metric variables
2023-07-04 05:41:24,779:INFO:Importing untrained model
2023-07-04 05:41:24,779:INFO:Declaring custom model
2023-07-04 05:41:24,782:INFO:Naive Bayes Imported successfully
2023-07-04 05:41:24,787:INFO:Starting cross validation
2023-07-04 05:41:24,788:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-04 05:41:28,628:INFO:Calculating mean and std
2023-07-04 05:41:28,629:INFO:Creating metrics dataframe
2023-07-04 05:41:28,634:INFO:Finalizing model
2023-07-04 05:41:29,292:INFO:Uploading results into container
2023-07-04 05:41:29,292:INFO:Uploading model into container now
2023-07-04 05:41:29,293:INFO:_master_model_container: 18
2023-07-04 05:41:29,293:INFO:_display_container: 5
2023-07-04 05:41:29,293:INFO:GaussianNB(priors=None, var_smoothing=2e-09)
2023-07-04 05:41:29,293:INFO:create_model() successfully completed......................................
2023-07-04 05:41:29,435:INFO:SubProcess create_model() end ==================================
2023-07-04 05:41:29,435:INFO:choose_better activated
2023-07-04 05:41:29,439:INFO:SubProcess create_model() called ==================================
2023-07-04 05:41:29,439:INFO:Initializing create_model()
2023-07-04 05:41:29,439:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000203EFA84A00>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-04 05:41:29,439:INFO:Checking exceptions
2023-07-04 05:41:29,441:INFO:Importing libraries
2023-07-04 05:41:29,441:INFO:Copying training dataset
2023-07-04 05:41:29,444:INFO:Defining folds
2023-07-04 05:41:29,444:INFO:Declaring metric variables
2023-07-04 05:41:29,444:INFO:Importing untrained model
2023-07-04 05:41:29,444:INFO:Declaring custom model
2023-07-04 05:41:29,445:INFO:Naive Bayes Imported successfully
2023-07-04 05:41:29,445:INFO:Starting cross validation
2023-07-04 05:41:29,446:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-04 05:41:33,357:INFO:Calculating mean and std
2023-07-04 05:41:33,358:INFO:Creating metrics dataframe
2023-07-04 05:41:33,359:INFO:Finalizing model
2023-07-04 05:41:34,015:INFO:Uploading results into container
2023-07-04 05:41:34,016:INFO:Uploading model into container now
2023-07-04 05:41:34,016:INFO:_master_model_container: 19
2023-07-04 05:41:34,016:INFO:_display_container: 6
2023-07-04 05:41:34,016:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-07-04 05:41:34,016:INFO:create_model() successfully completed......................................
2023-07-04 05:41:34,159:INFO:SubProcess create_model() end ==================================
2023-07-04 05:41:34,159:INFO:GaussianNB(priors=None, var_smoothing=1e-09) result for Accuracy is 0.8201
2023-07-04 05:41:34,159:INFO:GaussianNB(priors=None, var_smoothing=2e-09) result for Accuracy is 0.8201
2023-07-04 05:41:34,159:INFO:GaussianNB(priors=None, var_smoothing=1e-09) is best model
2023-07-04 05:41:34,159:INFO:choose_better completed
2023-07-04 05:41:34,160:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-07-04 05:41:34,167:INFO:_master_model_container: 19
2023-07-04 05:41:34,167:INFO:_display_container: 5
2023-07-04 05:41:34,168:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-07-04 05:41:34,168:INFO:tune_model() successfully completed......................................
2023-07-04 05:41:34,458:INFO:Initializing plot_model()
2023-07-04 05:41:34,458:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=GaussianNB(priors=None, var_smoothing=1e-09), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000203EFA84A00>, system=True)
2023-07-04 05:41:34,458:INFO:Checking exceptions
2023-07-04 05:41:34,461:INFO:Preloading libraries
2023-07-04 05:41:34,462:INFO:Copying training dataset
2023-07-04 05:41:34,462:INFO:Plot type: confusion_matrix
2023-07-04 05:41:34,569:INFO:Fitting Model
2023-07-04 05:41:34,571:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\base.py:420: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names
  warnings.warn(

2023-07-04 05:41:34,571:INFO:Scoring test/hold-out set
2023-07-04 05:41:34,660:INFO:Visual Rendered Successfully
2023-07-04 05:41:34,798:INFO:plot_model() successfully completed......................................
2023-07-04 05:41:34,804:INFO:Initializing plot_model()
2023-07-04 05:41:34,804:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=GaussianNB(priors=None, var_smoothing=1e-09), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000203EFA84A00>, system=True)
2023-07-04 05:41:34,805:INFO:Checking exceptions
2023-07-04 05:41:34,807:INFO:Preloading libraries
2023-07-04 05:41:34,808:INFO:Copying training dataset
2023-07-04 05:41:34,808:INFO:Plot type: auc
2023-07-04 05:41:34,913:INFO:Fitting Model
2023-07-04 05:41:34,914:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\base.py:420: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names
  warnings.warn(

2023-07-04 05:41:34,914:INFO:Scoring test/hold-out set
2023-07-04 05:41:59,552:INFO:Initializing plot_model()
2023-07-04 05:41:59,552:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=GaussianNB(priors=None, var_smoothing=1e-09), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000203EFA84A00>, system=True)
2023-07-04 05:41:59,552:INFO:Checking exceptions
2023-07-04 05:41:59,556:INFO:Preloading libraries
2023-07-04 05:41:59,556:INFO:Copying training dataset
2023-07-04 05:41:59,556:INFO:Plot type: auc
2023-07-04 05:41:59,665:INFO:Fitting Model
2023-07-04 05:41:59,665:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\base.py:420: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names
  warnings.warn(

2023-07-04 05:41:59,666:INFO:Scoring test/hold-out set
2023-07-04 05:42:07,085:INFO:Initializing plot_model()
2023-07-04 05:42:07,085:INFO:plot_model(plot=class_report, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=GaussianNB(priors=None, var_smoothing=1e-09), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000203EFA84A00>, system=True)
2023-07-04 05:42:07,086:INFO:Checking exceptions
2023-07-04 05:42:07,089:INFO:Preloading libraries
2023-07-04 05:42:07,089:INFO:Copying training dataset
2023-07-04 05:42:07,089:INFO:Plot type: class_report
2023-07-04 05:42:07,197:INFO:Fitting Model
2023-07-04 05:42:07,197:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\base.py:420: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names
  warnings.warn(

2023-07-04 05:42:07,197:INFO:Scoring test/hold-out set
2023-07-04 05:42:07,357:INFO:Visual Rendered Successfully
2023-07-04 05:42:07,531:INFO:plot_model() successfully completed......................................
2023-07-04 05:42:16,957:INFO:Initializing plot_model()
2023-07-04 05:42:16,957:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=GaussianNB(priors=None, var_smoothing=1e-09), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000203EFA84A00>, system=True)
2023-07-04 05:42:16,957:INFO:Checking exceptions
2023-07-04 05:42:27,733:INFO:Initializing evaluate_model()
2023-07-04 05:42:27,733:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000203EFA84A00>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-07-04 05:42:27,746:INFO:Initializing plot_model()
2023-07-04 05:42:27,746:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=GaussianNB(priors=None, var_smoothing=1e-09), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000203EFA84A00>, system=True)
2023-07-04 05:42:27,746:INFO:Checking exceptions
2023-07-04 05:42:27,747:INFO:Preloading libraries
2023-07-04 05:42:27,748:INFO:Copying training dataset
2023-07-04 05:42:27,748:INFO:Plot type: pipeline
2023-07-04 05:42:27,860:INFO:Visual Rendered Successfully
2023-07-04 05:42:28,037:INFO:plot_model() successfully completed......................................
2023-07-04 05:42:30,099:INFO:Initializing plot_model()
2023-07-04 05:42:30,100:INFO:plot_model(plot=auc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=GaussianNB(priors=None, var_smoothing=1e-09), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000203EFA84A00>, system=True)
2023-07-04 05:42:30,100:INFO:Checking exceptions
2023-07-04 05:42:30,102:INFO:Preloading libraries
2023-07-04 05:42:30,102:INFO:Copying training dataset
2023-07-04 05:42:30,102:INFO:Plot type: auc
2023-07-04 05:42:30,205:INFO:Fitting Model
2023-07-04 05:42:30,205:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\base.py:420: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names
  warnings.warn(

2023-07-04 05:42:30,205:INFO:Scoring test/hold-out set
2023-07-04 05:42:32,545:INFO:Initializing plot_model()
2023-07-04 05:42:32,546:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=GaussianNB(priors=None, var_smoothing=1e-09), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000203EFA84A00>, system=True)
2023-07-04 05:42:32,546:INFO:Checking exceptions
2023-07-04 05:42:32,547:INFO:Preloading libraries
2023-07-04 05:42:32,547:INFO:Copying training dataset
2023-07-04 05:42:32,547:INFO:Plot type: pipeline
2023-07-04 05:42:32,622:INFO:Visual Rendered Successfully
2023-07-04 05:42:32,795:INFO:plot_model() successfully completed......................................
2023-07-04 05:42:34,434:INFO:Initializing plot_model()
2023-07-04 05:42:34,434:INFO:plot_model(plot=learning, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=GaussianNB(priors=None, var_smoothing=1e-09), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000203EFA84A00>, system=True)
2023-07-04 05:42:34,434:INFO:Checking exceptions
2023-07-04 05:42:34,436:INFO:Preloading libraries
2023-07-04 05:42:34,436:INFO:Copying training dataset
2023-07-04 05:42:34,436:INFO:Plot type: learning
2023-07-04 05:42:34,556:INFO:Fitting Model
2023-07-04 05:42:34,858:INFO:Visual Rendered Successfully
2023-07-04 05:42:35,031:INFO:plot_model() successfully completed......................................
2023-07-04 05:42:40,040:INFO:Initializing plot_model()
2023-07-04 05:42:40,040:INFO:plot_model(plot=boundary, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=GaussianNB(priors=None, var_smoothing=1e-09), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000203EFA84A00>, system=True)
2023-07-04 05:42:40,041:INFO:Checking exceptions
2023-07-04 05:42:40,042:INFO:Preloading libraries
2023-07-04 05:42:40,043:INFO:Copying training dataset
2023-07-04 05:42:40,043:INFO:Plot type: boundary
2023-07-04 05:42:40,109:INFO:Fitting StandardScaler()
2023-07-04 05:42:40,112:INFO:Fitting PCA()
2023-07-04 05:42:40,169:INFO:Fitting Model
2023-07-04 05:42:41,089:INFO:Visual Rendered Successfully
2023-07-04 05:42:41,300:INFO:plot_model() successfully completed......................................
2023-07-04 05:42:44,589:INFO:Initializing plot_model()
2023-07-04 05:42:44,589:INFO:plot_model(plot=confusion_matrix, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=GaussianNB(priors=None, var_smoothing=1e-09), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000203EFA84A00>, system=True)
2023-07-04 05:42:44,589:INFO:Checking exceptions
2023-07-04 05:42:44,591:INFO:Preloading libraries
2023-07-04 05:42:44,591:INFO:Copying training dataset
2023-07-04 05:42:44,591:INFO:Plot type: confusion_matrix
2023-07-04 05:42:44,693:INFO:Fitting Model
2023-07-04 05:42:44,694:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\base.py:420: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names
  warnings.warn(

2023-07-04 05:42:44,694:INFO:Scoring test/hold-out set
2023-07-04 05:42:44,780:INFO:Visual Rendered Successfully
2023-07-04 05:42:44,952:INFO:plot_model() successfully completed......................................
2023-07-04 05:42:48,833:INFO:Initializing plot_model()
2023-07-04 05:42:48,833:INFO:plot_model(plot=threshold, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=GaussianNB(priors=None, var_smoothing=1e-09), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000203EFA84A00>, system=True)
2023-07-04 05:42:48,833:INFO:Checking exceptions
2023-07-04 05:42:48,835:INFO:Preloading libraries
2023-07-04 05:42:48,835:INFO:Copying training dataset
2023-07-04 05:42:48,835:INFO:Plot type: threshold
2023-07-04 05:42:48,938:INFO:Fitting Model
2023-07-04 05:42:49,083:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\base.py:420: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names
  warnings.warn(

2023-07-04 05:42:49,098:INFO:Scoring test/hold-out set
2023-07-04 05:42:49,336:INFO:Visual Rendered Successfully
2023-07-04 05:42:49,508:INFO:plot_model() successfully completed......................................
2023-07-04 05:42:53,271:INFO:Initializing plot_model()
2023-07-04 05:42:53,271:INFO:plot_model(plot=pr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=GaussianNB(priors=None, var_smoothing=1e-09), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000203EFA84A00>, system=True)
2023-07-04 05:42:53,272:INFO:Checking exceptions
2023-07-04 05:42:53,274:INFO:Preloading libraries
2023-07-04 05:42:53,274:INFO:Copying training dataset
2023-07-04 05:42:53,274:INFO:Plot type: pr
2023-07-04 05:42:53,375:INFO:Fitting Model
2023-07-04 05:42:53,375:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\base.py:420: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names
  warnings.warn(

2023-07-04 05:42:53,375:INFO:Scoring test/hold-out set
2023-07-04 05:42:53,507:INFO:Visual Rendered Successfully
2023-07-04 05:42:53,682:INFO:plot_model() successfully completed......................................
2023-07-04 05:42:56,967:INFO:Initializing plot_model()
2023-07-04 05:42:56,967:INFO:plot_model(plot=vc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=GaussianNB(priors=None, var_smoothing=1e-09), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000203EFA84A00>, system=True)
2023-07-04 05:42:56,967:INFO:Checking exceptions
2023-07-04 05:42:56,969:INFO:Preloading libraries
2023-07-04 05:42:56,969:INFO:Copying training dataset
2023-07-04 05:42:56,969:INFO:Plot type: vc
2023-07-04 05:42:56,969:INFO:Determining param_name
2023-07-04 05:42:56,969:INFO:param_name: var_smoothing
2023-07-04 05:42:57,072:INFO:Fitting Model
2023-07-04 05:42:58,553:INFO:Visual Rendered Successfully
2023-07-04 05:42:58,733:INFO:plot_model() successfully completed......................................
2023-07-04 05:43:01,828:INFO:Initializing plot_model()
2023-07-04 05:43:01,828:INFO:plot_model(plot=tree, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=GaussianNB(priors=None, var_smoothing=1e-09), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000203EFA84A00>, system=True)
2023-07-04 05:43:01,828:INFO:Checking exceptions
2023-07-04 05:43:04,360:INFO:Initializing plot_model()
2023-07-04 05:43:04,361:INFO:plot_model(plot=error, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=GaussianNB(priors=None, var_smoothing=1e-09), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000203EFA84A00>, system=True)
2023-07-04 05:43:04,361:INFO:Checking exceptions
2023-07-04 05:43:04,362:INFO:Preloading libraries
2023-07-04 05:43:04,363:INFO:Copying training dataset
2023-07-04 05:43:04,363:INFO:Plot type: error
2023-07-04 05:43:04,465:INFO:Fitting Model
2023-07-04 05:43:04,465:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\base.py:420: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names
  warnings.warn(

2023-07-04 05:43:04,465:INFO:Scoring test/hold-out set
2023-07-04 05:43:04,610:INFO:Visual Rendered Successfully
2023-07-04 05:43:04,783:INFO:plot_model() successfully completed......................................
2023-07-04 05:43:08,402:INFO:Initializing plot_model()
2023-07-04 05:43:08,402:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=GaussianNB(priors=None, var_smoothing=1e-09), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000203EFA84A00>, system=True)
2023-07-04 05:43:08,402:INFO:Checking exceptions
2023-07-04 05:43:08,404:INFO:Preloading libraries
2023-07-04 05:43:08,404:INFO:Copying training dataset
2023-07-04 05:43:08,404:INFO:Plot type: pipeline
2023-07-04 05:43:08,478:INFO:Visual Rendered Successfully
2023-07-04 05:43:08,654:INFO:plot_model() successfully completed......................................
2023-07-04 05:43:09,314:INFO:Initializing plot_model()
2023-07-04 05:43:09,315:INFO:plot_model(plot=class_report, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=GaussianNB(priors=None, var_smoothing=1e-09), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000203EFA84A00>, system=True)
2023-07-04 05:43:09,315:INFO:Checking exceptions
2023-07-04 05:43:09,316:INFO:Preloading libraries
2023-07-04 05:43:09,317:INFO:Copying training dataset
2023-07-04 05:43:09,317:INFO:Plot type: class_report
2023-07-04 05:43:09,419:INFO:Fitting Model
2023-07-04 05:43:09,419:WARNING:C:\Users\JHossain\anaconda3\lib\site-packages\sklearn\base.py:420: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names
  warnings.warn(

2023-07-04 05:43:09,419:INFO:Scoring test/hold-out set
2023-07-04 05:43:09,577:INFO:Visual Rendered Successfully
2023-07-04 05:43:09,751:INFO:plot_model() successfully completed......................................
2023-07-04 05:43:10,650:INFO:Initializing plot_model()
2023-07-04 05:43:10,651:INFO:plot_model(plot=feature, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=GaussianNB(priors=None, var_smoothing=1e-09), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000203EFA84A00>, system=True)
2023-07-04 05:43:10,651:INFO:Checking exceptions
2023-07-04 05:44:31,059:INFO:Initializing finalize_model()
2023-07-04 05:44:31,059:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000203EFA84A00>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-07-04 05:44:31,059:INFO:Finalizing GaussianNB(priors=None, var_smoothing=1e-09)
2023-07-04 05:44:31,062:INFO:Initializing create_model()
2023-07-04 05:44:31,063:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000203EFA84A00>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-07-04 05:44:31,063:INFO:Checking exceptions
2023-07-04 05:44:31,064:INFO:Importing libraries
2023-07-04 05:44:31,064:INFO:Copying training dataset
2023-07-04 05:44:31,064:INFO:Defining folds
2023-07-04 05:44:31,064:INFO:Declaring metric variables
2023-07-04 05:44:31,064:INFO:Importing untrained model
2023-07-04 05:44:31,064:INFO:Declaring custom model
2023-07-04 05:44:31,065:INFO:Naive Bayes Imported successfully
2023-07-04 05:44:31,066:INFO:Cross validation set to False
2023-07-04 05:44:31,066:INFO:Fitting Model
2023-07-04 05:44:31,128:INFO:Pipeline(memory=FastMemory(location=C:\Users\JHossain\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'cp', 'trestbps', 'chol',
                                             'fbs', 'restecg', 'thalach',
                                             'exang', 'oldpeak', 'slope', 'ca',
                                             'thal'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_...
                 TransformerWrapper(exclude=None, include=['sex'],
                                    transformer=OrdinalEncoder(cols=['sex'],
                                                               drop_invariant=False,
                                                               handle_missing='return_nan',
                                                               handle_unknown='value',
                                                               mapping=[{'col': 'sex',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('actual_estimator',
                 GaussianNB(priors=None, var_smoothing=1e-09))],
         verbose=False)
2023-07-04 05:44:31,128:INFO:create_model() successfully completed......................................
2023-07-04 05:44:31,305:INFO:_master_model_container: 19
2023-07-04 05:44:31,305:INFO:_display_container: 5
2023-07-04 05:44:31,322:INFO:Pipeline(memory=FastMemory(location=C:\Users\JHossain\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'cp', 'trestbps', 'chol',
                                             'fbs', 'restecg', 'thalach',
                                             'exang', 'oldpeak', 'slope', 'ca',
                                             'thal'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_...
                 TransformerWrapper(exclude=None, include=['sex'],
                                    transformer=OrdinalEncoder(cols=['sex'],
                                                               drop_invariant=False,
                                                               handle_missing='return_nan',
                                                               handle_unknown='value',
                                                               mapping=[{'col': 'sex',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('actual_estimator',
                 GaussianNB(priors=None, var_smoothing=1e-09))],
         verbose=False)
2023-07-04 05:44:31,322:INFO:finalize_model() successfully completed......................................
2023-07-04 05:44:33,706:INFO:Initializing predict_model()
2023-07-04 05:44:33,706:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000203EFA84A00>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000203ED1ADFC0>)
2023-07-04 05:44:33,706:INFO:Checking exceptions
2023-07-04 05:44:33,706:INFO:Preloading libraries
2023-07-04 05:44:43,018:INFO:Initializing predict_model()
2023-07-04 05:44:43,018:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000203EFA84A00>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000203ECC572E0>)
2023-07-04 05:44:43,018:INFO:Checking exceptions
2023-07-04 05:44:43,018:INFO:Preloading libraries
2023-07-04 05:44:43,019:INFO:Set up data.
2023-07-04 05:44:43,025:INFO:Set up index.
2023-07-04 05:44:51,506:INFO:Initializing save_model()
2023-07-04 05:44:51,506:INFO:save_model(model=GaussianNB(priors=None, var_smoothing=1e-09), model_name=../models/heart_diseases, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JHossain\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'cp', 'trestbps', 'chol',
                                             'fbs', 'restecg', 'thalach',
                                             'exang', 'oldpeak', 'slope', 'ca',
                                             'thal'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_...
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('ordinal_encoding',
                 TransformerWrapper(exclude=None, include=['sex'],
                                    transformer=OrdinalEncoder(cols=['sex'],
                                                               drop_invariant=False,
                                                               handle_missing='return_nan',
                                                               handle_unknown='value',
                                                               mapping=[{'col': 'sex',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-07-04 05:44:51,507:INFO:Adding model into prep_pipe
2023-07-04 05:44:51,534:INFO:../models/heart_diseases.pkl saved in current working directory
2023-07-04 05:44:51,552:INFO:Pipeline(memory=FastMemory(location=C:\Users\JHossain\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'cp', 'trestbps', 'chol',
                                             'fbs', 'restecg', 'thalach',
                                             'exang', 'oldpeak', 'slope', 'ca',
                                             'thal'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_...
                 TransformerWrapper(exclude=None, include=['sex'],
                                    transformer=OrdinalEncoder(cols=['sex'],
                                                               drop_invariant=False,
                                                               handle_missing='return_nan',
                                                               handle_unknown='value',
                                                               mapping=[{'col': 'sex',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('trained_model',
                 GaussianNB(priors=None, var_smoothing=1e-09))],
         verbose=False)
2023-07-04 05:44:51,552:INFO:save_model() successfully completed......................................
2023-07-04 05:44:54,495:INFO:Initializing load_model()
2023-07-04 05:44:54,495:INFO:load_model(model_name=../models/heart_diseases, platform=None, authentication=None, verbose=True)
